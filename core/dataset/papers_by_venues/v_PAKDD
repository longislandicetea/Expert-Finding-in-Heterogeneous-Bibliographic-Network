#index 455098
#* Proceedings of the Second Pacific-Asia Conference on Research and Development in Knowledge Discovery and Data Mining
#@ Xindong Wu;Kotagiri Ramamohanarao;Kevin B. Korb
#t 1998
#c 3

#index 455099
#* Proceedings of the Third Pacific-Asia Conference on Methodologies for Knowledge Discovery and Data Mining
#@ Ning Zhong;Lizhu Zhou
#t 1999
#c 3

#index 455101
#* Proceedings of the 5th Pacific-Asia Conference on Knowledge Discovery and Data Mining
#@ David Wai-Lok Cheung;Graham J. Williams;Qing Li
#t 2001
#c 3

#index 455102
#* Proceedings of the 6th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining
#@ Ming-Shan Cheng;Philip S. Yu;Bing Liu
#t 2002
#c 3
#! From the Publisher:This book constitutes the refereed proceedings of the 6th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2002, held in Taipei, Taiwan, in May 2002. The 32 revised full papers and 20 short papers presented together with 4 invited contributions were carefully reviewed and selected from a total of 128 submissions. The papers are organized in topical sections on association rules; classification; interestingness; sequence mining; clustering; Web mining; semi-structure and concept mining; data warehouse and data cube; bio-data mining; temporal mining; and outliers, missing data, and causation.

#index 501064
#* Feature Mining and Mapping of Collinear Data
#@ Olivier Y. de Vel;Danny Coomans;S. Patrick
#t 1998
#c 3

#index 501065
#* Towards Real Time Discovery from Distributed Information Sources
#@ Vincent Cho;Beat Wüthrich
#t 1998
#c 3

#index 501066
#* Discovering Associations in Spatial Data - An Efficient Medoid Based Approach
#@ Vladimir Estivill-Castro;Alan T. Murray
#t 1998
#c 3

#index 501185
#* Data Mining Based on the Generalization Distribution Table and Rough Sets
#@ Ning Zhong;Juzhen Dong;Setsuo Ohsuga
#t 1998
#c 3

#index 501186
#* Trend Directed Learning: A Case Study
#@ Honghua Dai
#t 1998
#c 3

#index 501187
#* Treatment of Missing Values for Association Rules
#@ Arnaud Ragel;Bruno Crémilleux
#t 1998
#c 3

#index 501188
#* An Efficient Global Discretization Method
#@ K. M. Ho;P. D. Scott
#t 1998
#c 3

#index 501189
#* Contextual Text Representation for Unsupervised Discovery in Texts
#@ Patrick Perrin;Frederick E. Petry
#t 1998
#c 3

#index 501190
#* Constructing Conceptual Scales in Formal Analysis
#@ Richard J. Cole, II;Peter W. Eklund;Don Walker
#t 1998
#c 3

#index 501191
#* Knowledge Acquisition for Goal Prediction in a Multi-user Adventure Game
#@ David W. Albrecht;Ann E. Nicholson;Ingrid Zukerman
#t 1998
#c 3

#index 501192
#* CFMD: A Conflict-Free Multivariate Discretization Algorithm
#@ Ying Lu;Huan Liu;Chew Lim Tan
#t 1998
#c 3

#index 501193
#* Representative Association Rules
#@ Marzena Kryszkiewicz
#t 1998
#c 3

#index 501194
#* Data-Mining Massive Time Series Astronomical Data Sets - A Case Study
#@ Michael K. Ng;Zhexue Huang;Markus Hegland
#t 1998
#c 3

#index 501195
#* Design Recovery with Data Mining Techniques
#@ Carlos Montes de Oca;Doris L. Carver
#t 1998
#c 3

#index 501196
#* Rule Generalization by Condition Combination
#@ Hanhong Xue;Qingsheng Cai
#t 1998
#c 3

#index 501197
#* Using Rough Sets for Knowledge Discovery in the Development of a Decision Support System for Issuing Smog Alerts
#@ Ilona Jagielska
#t 1998
#c 3

#index 501198
#* LRTree: A Hybrid technique for Classifying Myocardial Infarction Data Containing Unknown Attribute Values
#@ Christine L. Tsien;Hamish S. F. Fraser;Isaac S. Kohane
#t 1998
#c 3

#index 501199
#* Automatic Visualization Method for Visual Data Mining
#@ Yuichi Iizuka;Hisako Shiohara;Tetsuya Iizuka;Seiji Isobe
#t 1998
#c 3

#index 501200
#* Single Factor Analysis in MML Mixture Modelling
#@ Russell T. Edwards;David L. Dowe
#t 1998
#c 3

#index 501201
#* Discovery of Association Rules over Ordinal Data: A New and Faster Algorithm and Its Application to Basket Analysis
#@ Oliver Büchter;Rüdiger Wirth
#t 1998
#c 3

#index 501202
#* Rough-Set Inspired Approach to Knowledge Discovery in Business Databases
#@ W. Kowalczyk;Zdzislaw Piasta
#t 1998
#c 3

#index 501203
#* Improved Rule Discovery Performance on Uncertainty
#@ Mehmet R. Tolun;Hayri Sever;Mahmut Uludag
#t 1998
#c 3

#index 501204
#* Interestingness of Discovered Association Rules in Terms of Neighborhood-Based Unexpectedness
#@ Guozhu Dong;Jinyan Li
#t 1998
#c 3

#index 501205
#* Discovering Case Knowledge Using Data Mining
#@ Sarabjot S. Anand;W. R. David Patterson;John G. Hughes;David A. Bell
#t 1998
#c 3

#index 501206
#* Mining Association Rules with Linguistic Cloud Models
#@ Deyi Li;Kaichang Di;Deren Li;Xuemei Shi
#t 1998
#c 3

#index 501207
#* Effect of Data Skewness in Parallel Mining of Association Rules
#@ David Wai-Lok Cheung;Yongqiao Xiao
#t 1998
#c 3

#index 501208
#* Knowledge Discovery in Discretionary Legal Domains
#@ John Zeleznikow;Andrew Stranieri
#t 1998
#c 3

#index 501209
#* Identifying Relevant Databases for Multidatabase Mining
#@ Huan Liu;Hongjun Lu;Jun Yao
#t 1998
#c 3

#index 501210
#* The CLARET Algorithm
#@ Adrian R. Pearce;Terry Caelli
#t 1998
#c 3

#index 501211
#* Hybrid Data Mining Systems: The Next Generation
#@ Sarabjot S. Anand;John G. Hughes
#t 1998
#c 3

#index 501212
#* Point Estimation Using the Kullback-Leibler Loss Function and MML
#@ David L. Dowe;Rohan A. Baxter;Jonathan J. Oliver;Chris S. Wallace
#t 1998
#c 3

#index 501213
#* Mining Regression Rules and Regression Trees
#@ Buh-Yun Sher;Shin-Chung Shao;Wen-Shyong Hsieh
#t 1998
#c 3

#index 501214
#* Empirical Results on Data Dimensionality Reduction Using the Divided Self-Organizing Map
#@ Takamasa Koshizen;Hiroaki Ogawa;John Fulcher
#t 1998
#c 3

#index 501215
#* Mining Association Rules for Estimation and Prediction
#@ Takashi Washio;Hiroshi Motoda
#t 1998
#c 3

#index 501216
#* Mining Algorithms for Sequential Patterns in Parallel: Hash Based Approach
#@ Takahiko Shintani;Masaru Kitsuregawa
#t 1998
#c 3

#index 501217
#* A Data Mining Approach for Query Refinement
#@ Ye Liu;Hanxiong Chen;Jeffrey Xu Yu;Nobuo Ohbo
#t 1998
#c 3

#index 501218
#* Learning User Preferences on the WEB
#@ François Jacquenet;Patrice Brenot
#t 1998
#c 3

#index 501219
#* Characteristic Rule Induction Algorithm for Data Mining
#@ Akira Maeda;Hideyuki Maki;Hiroyuji Akimori
#t 1998
#c 3

#index 501220
#* Bayesian Classification Trees with Overlapping Leaves Applied to Credit-Scoring
#@ Gerhard Paass;Jörg Kindermann
#t 1998
#c 3

#index 501221
#* Modelling Decision Tables from Data
#@ Geert Wets;Jan Vanthienen;H. Timmermans
#t 1998
#c 3

#index 501222
#* The Hunter and the Hunted - Modelling the Relationship Between Web Pages and Search Engines
#@ David L. Dowe;Lloyd Allison;Glen Pringle
#t 1998
#c 3

#index 501223
#* Minimum Message Length Segmentation
#@ Jonathan J. Oliver;Rohan A. Baxter;Chris S. Wallace
#t 1998
#c 3

#index 501224
#* Data Mining Using Dynamically Constructed Recurrent Fuzzy Neural Networks
#@ Yakov Frayman;Lipo Wang
#t 1998
#c 3

#index 501225
#* A Classification and Relationship Extraction Scheme for Raltional Databases Based on Fuzzy Logic
#@ Michalis Vazirgiannis
#t 1998
#c 3

#index 501226
#* Selective Materialization: An Efficient Method for Spatial Data Cube Construction
#@ Jiawei Han;Nebojsa Stefanovic;Krzysztof Koperski
#t 1998
#c 3

#index 501345
#* Wavelet Transform in Similarity Paradigm
#@ Zbigniew R. Struzik;Arno Siebes
#t 1998
#c 3

#index 501346
#* CCAIIA: Clustering Categorial Attributed into Interseting Accociation Rules
#@ Brett Gray;Maria E. Orlowska
#t 1998
#c 3

#index 501347
#* Multiple Databases, Partial Reasoning, and Knowledge Discovery
#@ Chris Nowak
#t 1998
#c 3

#index 501348
#* Constructing Personalized Information Agents
#@ Chia-Hui Chang;Ching-Chi Hsu
#t 1998
#c 3

#index 501349
#* KD-FGS: A Knowledge Discovery System from Graph Data Using Formal Graph System
#@ Tetsuhiro Miyahara;Tomoyuki Uchida;Tetsuji Kuboyama;Tasuya Yamamoto;Kenichi Takayashi;Hiroaki Ueda
#t 1999
#c 3
#% 165660
#% 182566
#% 365671
#! A graph is one of the most common abstract structures and is suitable for representing relations between various objects. The analyzing system directly manipulating graphs is useful for knowledge discovery. Formal Graph System (FGS) is a kind of logic programming system which directly deals with graphs just like first order terms. We have designed and implemented a knowledge discovery system KD-FGS, which receives the graph data and produces a hypothesis by using FGS as a knowledge representation language. The system consists of an FGS interpreter and a refutably inductive inference algorithm for FGSs. We report some experiments of running KD-FGS and confirm that the system is useful for knowledge discovery from graph data.

#index 501350
#* Induction as Pre-processing
#@ Xindong Wu
#t 1999
#c 3
#% 73374
#% 93697
#% 99396
#% 136350
#% 153652
#% 362396
#% 449529
#% 449588
#% 840577
#! In most data mining applications where induction is used as the primary tool for knowledge extraction, it is difficult to precisely identify a complete set of relevant attributes. The real world database from which knowledge is to be extracted usually contains a combination of relevant, noisy and irrelevant attributes. Therefore, pre-processing the database to select relevant attributes becomes a very important task in knowledge discovery and data mining. This paper starts with two existing induction systems, C4.5 and HCV, and uses one of them to select relevant attributes for the other. Experimental results on 12 standard data sets showtha t using HCV induction for C4.5 attribute selection is generally useful.

#index 501351
#* A Fast Algorithm for Density-Based Clustering in Large Database
#@ Bo Zhou;David Wai-Lok Cheung;Ben Kao
#t 1999
#c 3
#% 152902
#% 210173
#% 248790
#% 479658
#% 481281
#! Clustering in large database is an important and useful data mining activity. It expects to find out meaningful patterns among the data set. Some new requirements of clustering have been raised : good efficiency for large database; easy to determine the input parameters; separate noise from the clusters [1]. However, conventional clustering algorithms seldom can fulfill all these requirements. The notion of density-based clustering has been proposed which satisfies all these requirements [1]. In this paper, we present a new and more efficient density-based clustering algorithm called FDC. The clustering in this algorithm is defined by an equivalence relationship on the objects in the database. The complexity of FDC is linear to the size of the database, which is much faster than that of the algorithm DBSCAN proposed in [1]. Extensive performance studies have been carried out on both synthetic and real data which show that FDC is the fastest density-based clustering algorithm proposed as far.

#index 501352
#* Combining Forecasts from Multiple Textual Data Sources
#@ Vincent Cho;Beat Wüthrich
#t 1999
#c 3
#! These days more and more crucial and commercially valuable information becomes available on the World Wide Web. Also financial services companies are making their products increasingly available on the Web. This paper suggests and investigates six methods to combine multiple categorical predictions that are generated from distributed information available on the World Wide Web.

#index 501353
#* Robust Clustering of Large Geo-referenced Data Sets
#@ Vladimir Estivill-Castro;Michael E. Houle
#t 1999
#c 3
#% 121114
#% 210173
#% 227996
#% 462243
#% 481281
#% 501066
#% 527021
#% 527022
#% 527035
#% 527160
#% 566128
#! Clustering geo-referenced data with the medoid method is related to k-Means, with the restriction that cluster representatives are chosen from the data. Although the medoid method in general produces clusters of high quality, it is often criticised for the Ω(n2) time that it requires. Our method incorporates both proximity and density information to achieve high-quality clusters in O(n log n) expected time. This is achieved by fast approximation to the medoid objective function using proximity information from Delaunay triangulations.

#index 501354
#* An Algorithm for Constrained Association Rule Mining in Semi-structured Data
#@ Lisa Singh;Bin Chen;Rebecca Haight;Peter Scheuermann
#t 1999
#c 3
#% 240197
#% 251693
#% 407996
#% 481290
#! The need for sophisticated analysis of textual documents is becoming more apparent as data is being placed on the Web and digital libraries are surfacing. This paper presents an algorithm for generating constrained association rules from textual documents. The user specifies a set of constraints, concepts and/or structured values. Our algorithm creates matrices and lists based on these prespecified constraints and uses them to generate large itemsets. Because these matrices are small and sparse, we are able to quickly generate higher order large itemsets. Further, since we maintain concept relationship information in a concept library, we can also generate rulesets involving concepts related to the initial set of constraints.

#index 501355
#* Mining Association Rules on Related Numeric Attributes
#@ Xiaoyong Du;Zhibin Liu;Naohiro Ishii
#t 1999
#c 3
#% 152934
#% 210160
#% 210162
#% 213977
#% 227953
#% 232102
#% 232171
#% 481290
#! In practical applications, some property is represented by a pair of related attributes. For example, blood pressure, temperature changes etc. The existing data mining approaches for association rules can not tackle those cases, because they treat every attribute independently. In this paper, as a special kind of correlation, we express the pair of attributes as a range-type attribute. We define a set of fuzzified relations between ranges and revise the definition of association rules. We also propose effective algorithms to evaluate the measures for ranking association rules on related numeric attributes.

#index 501356
#* Mining Classification Knowledge Based on Cloud Models
#@ Jianhua Fan;Deyi Li
#t 1999
#c 3
#% 136350
#% 449588
#% 452747
#% 459008
#% 480940
#! Data classification is an important research topic in the field of data mining and knowledge discovery. There have been many data classification methods studied, including decision-tree method, statistical methods, neural networks, rough sets, etc. In this paper, we present a new mathematical representation of qualitative concepts-Cloud Models. With the new models, mapping between quantities and qualities becomes much easier and interchangeable. Based on the cloud models, a novel qualitative strategy for data classification in large relational databases is proposed. Then, the algorithms for classification are developed, such as cloud generation, complexity reduction, identifying interacting attributes, etc. Finally, we perform experiments on a challenging medical diagnosis domain, acute abdominal pain. The results show the advantages of the model in the process of knowledge discovery.

#index 501357
#* Automatic Labeling of Self-Organizing Maps: Making a Treasure-Map Reveal Its Secrets
#@ Andreas Rauber;Dieter Merkl
#t 1999
#c 3
#% 67565
#! Self-organizing maps are an unsupervised neural network model which lends itself to the cluster analysis of high-dimensional input data. However, interpreting a trained map proves to be difficult because the features responsible for a specific cluster assignment are not evident from the resulting map representation. In this paper we present our LabelSOM approach for automatically labeling a trained self-organizing map with the features of the input data that are the most relevant ones for the assignment of a set of input data to a particular cluster. The resulting labeled map allows the user to better understand the structure and the information available in the map and the reason for a specific map organization, especially when only little prior information on the data set and its characteristics is available.

#index 501358
#* DVIZ: A System for Visualizing Data Mining
#@ Jianchao Han;Nick Cercone
#t 1999
#c 3
#% 152934
#% 210162
#% 221382
#% 252362
#% 435315
#% 443086
#% 481758
#% 726032
#! We introduce an interactive system which visualizes the knowledge in data mining processes, including attribute values, evolutionary attributes, associations of attributes, classiffications and hierarchical concepts. The basic framework of knowledge visualization in data mining is discussed and the algorithms for visualizing different forms of knowledge are presented. The application of our initial prototype system, DVIZ, to Canada Education Statistics is described and some preliminary results presented.

#index 501359
#* Discretization of Continuous Attributes for Learning Classification Rules
#@ Aijun An;Nick Cercone
#t 1999
#c 3
#% 136350
#% 533968
#! We present a comparison of three entropy-based discretization methods in a context of learning classification rules. We compare the binary recursive discretization with a stopping criterion based on the Minimum Description Length Principle (MDLP)[3], a nonrecursive method which simply chooses a number of cut-points with the highest entropy gains, and a non-recursive method that selects cut-points according to both information entropy and distribution of potential cut-points over the instance space. Our empirical results show that the third method gives the best predictive performance among the three methods tested.

#index 501360
#* A Minimal Causal Model Learner
#@ Honghua Dai
#t 1999
#c 3
#! The minimal-model semantics of causation is an essential concept for the identification of a best ffitting model in the sense of satisfactory consistent with the given data and be the simpler, less expressive model. Therefore to develop an algorithm being able to derive a minimal model is an interesting topic in the area of causal model discovery. various causal induction algorithms and tools developed so far can not guarantee that the derived model is a minimal model. This paper proves that the MML induction approach introduced by Wallace, et al is a minimal causal model learner. The experimental results obtained from the tests on a number of both artificial and real models provided in this paper conform this theoretical result.

#index 501361
#* Probing Knowledge in Distributed Data Mining
#@ Yike Guo;Janjao Sutiwaraphun
#t 1999
#c 3
#% 209021
#% 218961
#% 225872
#% 240798
#% 424997
#% 443616
#% 520224
#% 637522
#! In this paper, we propose a new approach to apply metalearning concept to distributed data mining. We name this approach Knowledge Probing where a supervised learning process is organised into two learning stages. In the first learning phase, a set of base classifiers are learned in parallel from a distributed data set. In the second learning phase, meta-learning is applied to induce the relationship between an attribute vector and the class predictions from all the base classifiers. By applying this approach to an environment where base classifiers are produced from distributed data sources, the output of Knowledge Probing process can be viewed as the assimilated knowledge of that distributed learning system. Some initial experimental results on the quality of the assimilated knowledge are presented. We believe that an integration of Knowledge Probing technique and the available data mining algorithms can provide a practical framework for distributed data mining applications.

#index 501362
#* Optimising the Distance Metric in the Nearest Neighbour Algorithm on a Real-World Patient Classification Problem
#@ Hongxing He;Simon Hawkins
#t 1999
#c 3
#% 114994
#% 376589
#% 840577
#! The study develops a new method for finding the optimal non-Euclidean distance metric in the nearest neighbour algorithm. The data used to develop this method is a real world doctor shopper classification problem. A statistical measure derived from Shannon's information theory - known as mutual information - is used to weight attributes in the distance metric. This weighted distance metric produced a much better agreement rate on a five-class classification task than the Euclidean distance metric (63% versus 51%). The agreement rate increased to 77% and 73% respectively when a genetic algorithm and simulated annealing were used to further optimise the weights. This excellent performance paves the way for the development of a highly accurate system for detecting high risk doctor-shoppers both automatically and efficiently.

#index 501363
#* KDD as an Enterprise IT Tool: Reality and Agenda (Abstract)
#@ Won Kim
#t 1999
#c 3
#! KDD is a key technology for harnessing the "business intelligence" IT infrastructure. Although KDD has been a longstanding field of research, it is in its infancy in commercial endeavors. Commercial KDD products have many major weaknesses that have slowed KDD's becoming an enterprise IT tool. In this presentation, I will review the technological and business reality of KDD, and discuss what needs to happen before KDD can attain the status that other enterprise IT tools have reached, including database servers, data warehouses, decision support and OLAP tools, etc.

#index 501364
#* A Technique of Dynamic Feature Selection Using the Feature Group Mutual Information
#@ Kee-Cheol Lee
#t 1999
#c 3
#% 92148
#% 136350
#% 443157
#% 840577
#! Knowledge discovery from raw data is very important to non-experts and even experts who feel difficulty in expressing their skills in machine interpretable forms. However, real world data often contain some redundant or unnecessary features, and if they are directly used, the quality of the seeking knowledge may be much degraded. Here, a new technique of dynamically selecting features is suggested. Contrary to the static feature selection, this scheme selects each new feature based on its correlation with the previously selected features. In addition, this scheme does not require setting any threshold, which would be too difficult to decide. Experiments have been conducted for some real world domains in terms of tree sizes and test data error rates. The results show the soundness of this scheme.

#index 501365
#* Incremental Discovering Association Rules: A Concept Lattice Approach
#@ Keyun Hu;Yuchang Lu;Chunyi Shi
#t 1999
#c 3
#% 90513
#% 152934
#% 443082
#% 500518
#% 566924
#! Concept lattice is an efficient tool for data analysis. Mining association rules is a impor tant subfield of data mining. In this paper we investigate the ability of concept lattice on associate ru les and present an efficient algorithm which genera te the large itemsets increm entally on the basis of Godin's work.

#index 501366
#* Data Mining: Granular Computing Approach
#@ T. Y. Lin
#t 1999
#c 3
#% 149878
#% 152934
#% 237867
#% 290106
#% 366687
#% 442902
#! In the relational database theory, it is assumed that the universe U to be represented is a set. The classical data mining took such assumption. In real life applications, the entities are often related. A "new" data mining theory is explored with such additional semantics.

#index 501367
#* Data Mining - a Rough Set Perspective
#@ Zdzislaw Pawlak
#t 1999
#c 3
#% 19852
#% 154305
#% 168563
#% 249840
#% 267537
#% 365894
#% 497476
#% 500524
#% 501202

#index 501368
#* Incremental Mining of Schema for Semistructured Data
#@ Aoying Zhou;Wen Jin;Shuigeng Zhou;Zengping Tian
#t 1999
#c 3
#% 152934
#% 232102
#% 340295
#% 443082
#% 463919
#% 464204
#% 464825
#% 481290
#% 481758
#% 527021
#% 614598
#! Semistructured data is specified by the lack of any fixed and rigid schema, even though typically some implicit structure appears in the data. The huge amounts of on-line applications make it important and imperative to mine schema of semistructured data, both for the users (e.g., to gather useful information and facilitate querying) and for the systems (e.g., to optimize access). The critical problem is to discover the implicit structure in the semistructured data. Current methods in extracting Web data structure are either in a general way independent of application background [8], [9], or bound in some concrete environment such as HTML etc [13], [14], [15]. But both face the burden of expensive cost and difficulty in keeping along with the frequent and complicated variances of Web data. In this paper, we first deal with the problem of incremental mining of schema for semistructured data after the update of the raw data. An algorithm for incrementally mining schema of semistructured data is provided, and some experimental results are also given, which shows that our incremental mining for semistructured data is more efficient than non-incremental mining.

#index 501369
#* A Situated Information Articulation Neural Network: VSF Network
#@ Yoshitsugu Kakemoto;Shinichi Nakasuka
#t 1999
#c 3
#% 92135
#% 132944
#! when a system will recognize the world around one, system requires segmenting or articulating information of the world. In this paper, we introduce a neural network model called VSF network for situated articulation. At first, we discuss situation and its relation to information coding. Next, we introduce the architecture and main procedure of the VSF network. Finally, we examine the validity of VSF-network model through the experiment which applies the VSF-network to a path planning task of a rover.

#index 501370
#* An Improved Definition of Multidimensional Inter-transaction Association Rule
#@ Aoying Zhou;Shuigeng Zhou;Wen Jin;Zengping Tian
#t 1999
#c 3
#% 152934
#% 248865
#% 527021
#! Association rule is an important contribution to the data mining field from the database research community, and its mining has become a promising research topic. Traditional association rule is limited to intra-transaction mining. Recently the concept of multidimensional inter-transaction association rule (MDITAR) is proposed by H.J. Lu. Based on analysis of inadequencies of Lu's definition, this paper introduces a modified and extended definition of MDITAR, which consequently makes MDITAR more general, practical and reasonable.

#index 501371
#* Knowledge Discovery in SportsFinder: An Agent to Extract Sports Results from the Web
#@ Hongen Lu;Leon Sterling;Alex Wyatt
#t 1999
#c 3
#% 240955
#% 266216
#% 496886
#% 589715
#% 747945
#% 1275347
#! There is a wealth of information to be mined from the World Wide Web. Unfortunately, standard natural language processing (NLP) extraction techniques perform poorly on the choppy, semi-structured information fragments, such as sports results, which are popular to be published on the Web pages nowadays. In this paper, we present an information agent: SportsFinder, an agent to extract sports scores from the World Wide Web, as well as the knowledge discovering method to learn new express patterns to improve the agent's performance

#index 501372
#* Association Rules in Incomplete Databases
#@ Marzena Kryszkiewicz
#t 1999
#c 3
#% 152934
#% 232136
#% 366687
#% 481754
#% 481758
#% 481954
#% 501187
#% 501193
#% 501215
#! Discovering association rules among items in large databases is recognized as an important database mining problem. The problem has been introduced originally for sales transaction database and did not relate to missing data. However, missing data often occur in relational databases, especially in business ones. It is not obvious how to compute association rules t~om such incomplete databases. It is provided and proved in the paper how to estimate support and confidence of an association rule induced t~om an incomplete relational database. We also introduce definitions of expected support and confidence of an association rule. The proposed definitions guarantee some required properties of itemsets and association rules. Eventually, we discuss another approach to missing values based on so called valid databases and compare both approaches.

#index 501373
#* Sustainability Knowledge Mining from Human Development Database
#@ Xuefei Wang;Rusong Wang;Jue Wang
#t 1999
#c 3
#% 232106
#% 366687
#! This paper is to expose the concealed sustainability information to users from UNDP annual report of human development database. Different from the "understanding database by computer", the task is to tell user what meaning of the database is, and called "understanding database by human". The decernibility matrix (DM) in rough sets is used to get a qualitative description of the database. Domain knowledge is embedded in DM, and the set of its attribute reduction is employed to develop the sustainable development indicators (SDI) and its applications to the world's sustainability assessment.

#index 501374
#* Basket Analysis for Graph Structured Data
#@ Akihiro Inokuchi;Takashi Washio;Hiroshi Motoda;Kouhei Kumasawa;Naohide Arai
#t 1999
#c 3
#% 184048
#% 443194
#% 481290
#% 501193
#% 501215
#% 501216
#% 1271949
#! The Basket Analysis derives frequent itemsets and association rules having support and confidence levels greater than their thresholds from massive transaction data. Though some recent research tries to discover wider classes of knowledge on the regularities contained in the data, the regularities in form of the graph structure has not been explored in the field of the Basket Analysis. The work reported in this paper proposes a new method to mine frequent graph structure appearing in the massive amount of transactions. A specific procedure to preprocess graph structured transactions is introduced to enable the application of the Basket Analysis to extract frequently appearing graph patterns. The basic performance of our proposing approach has been evaluated by a set of graph structured transactions generated by an artificial simulation. Moreover, its practicality has been confirmed through the appliaction to discover popular browsing patterns of clients in WWW URL network.

#index 501375
#* Extending the Applicability of Association Rules
#@ Karthick Rajamani;Sam Yuan Sung;Alan L. Cox
#t 1999
#c 3
#% 152934
#% 201894
#% 210160
#% 227919
#% 227953
#% 479484
#% 481290
#% 481588
#% 481754
#% 481758
#% 481779
#! An important issue that needs to be addressed when using association rules is the validity of the rules for new situations. Rules are typically derived from the patterns in a particular dataset. When the conditions under which the dataset has been obtained change, a new situation is said to have risen. Since the conditions existing at the time of observation could affect the observed data, a change in those conditions could imply a changed set of rules for a new situation. Using the set of rules derived from the dataset for an earlier situation could lead to wrong decisions. In this paper, we provide a model explaining the difference between the sets of rules for different situations. Our model is based on the concept of rule-generating groups that we call caucuses. Using this model, we provide a simple technique, called Linear Combinations, to get a good estimate of the set of rules for a new situation. Our approach is independent of the core mining process, and so can be easily implemented with any specific technique for association rule mining. In our experiments using controlled datasets, we found that we could get up to 98.3% accuracy with our techniques as opposed to 26.6% when directly using the results of the old situation.

#index 501376
#* An Efficient Space-Partitioning Based Algorithm for the K-Means Clustering
#@ Khaled Alsabti;Sanjay Ranka;Vineet Singh
#t 1999
#c 3
#% 36672
#% 210173
#% 217580
#% 633175
#% 708610
#! k-means clustering is a popular clustering method.Its core task of finding the closest prototype for every input pattern involves expensive distance calculations.W e present a novel algorithm for performing this task.Th is and other optimizations are shown to significantly improve the performance of the k-means algorithm.T he resultant algorithm produces the same (except for round-off errors) results as those of the direct algorithm.

#index 501377
#* Automated Discovery of Plausible Rules Based on Rough Sets and Rough Inclusion
#@ Shusaku Tsumoto
#t 1999
#c 3
#% 92533
#% 136350
#% 152934
#% 154305
#% 191680
#% 237867
#% 449566
#! One of the most important problems on rule induction methods is that they cannot extract rules, which plausibly represent experts' decision processes. On one hand, rule induction methods induce probabilistic rules, the description length of which is too short, compared with the experts' rules. On the other hand, construction of Bayesian networks generates too lengthy rules. In this paper, the characteristics of experts' rules are closely examined and a new approach to extract plausible rules is introduced, which consists of the following three procedures. First, the characterization of decision attributes (given classes) is extracted from databases and the classes are classified into several groups with respect to the characterization. Then, two kinds of sub-rules, characterization rules for each group and discrimination rules for each class in the group are induced. Finally, those two parts are integrated into one rule for each decision attribute. The proposed method was evaluated on medical databases, the experimental results of which show that induced rules correctly represent experts' decision processes.

#index 501378
#* Discovery of Equations and the Shared Operational Semantics in Distributed Autonomous Databases
#@ Zbigniew W. Ras;Jan M. Zytkow
#t 1999
#c 3
#% 22948
#% 215574
#% 244356
#% 385564
#% 451042
#% 497947
#! Empirical equations are an important class of regularities that can be discovered in databases. In this paper we concentrate on the role of equations as definitions of attribute values. Such definitions can be used in many ways that we briefly describe. We present a discovery mechanism that specializes in finding equations that can be used as definitions. We introduce the notion of shared operational semantics. It consists of an equation-based system of partial definitions and it is used as a tool for knowledge exchange between independently built databases. This semantics augments the earlier developed semantics for rules used as attribute definitions. To put the shared operational semantics on a firm theoretical foundation we developed a formal interpretation which justifies empirical equations in their definitional role.

#index 501379
#* A Strong Relevant Logic Model of Epistemic Processes in Scientific Discovery (Extended Abstract)
#@ Jingde Cheng
#t 1999
#c 3
#% 194987
#! This paper presents some significant fundamental observations and/or assumptions on scientific discovery processes and their automation, shows why classical mathematical logic, its various classical conservative extensions, and traditional (weak) relevant logics cannot satisfactorily underlie epistemic processes in scientific discovery, and presents a strong relevant logic model of epistemic processes in scientific discovery.

#index 501380
#* BRRA: A Based Relevant Rectangles Algorithm for Mining Relationships in Databases
#@ Sadok Ben Yahia;Ali Jaoua
#t 1999
#c 3
#% 152934
#% 221879
#% 449588
#! Data mining is the discovery of previously unknown or hidden and potentially useful knowledge in databases. In this paper, we present an algorithm, called BRRA, that mines relationships in a database in order to derive compact rules set. This algorithm is based on a mathematical concept called relevant rectangles representing full association between a set of i arguments and a set of j images in a binary relation.

#index 501381
#* An Analysis of Quantitative Measures Associated with Rules
#@ Y. Y. Yao;Ning Zhong
#t 1999
#c 3
#% 152934
#% 187763
#% 232102
#% 232126
#% 366687
#% 420073
#% 443082
#% 449588
#% 451036
#% 452822
#% 455098
#% 501201
#% 501209
#% 501346
#! In this paper, we analyze quantitative measures associated with if-then type rules. Basic quantities are identified and many existing measures are examined using the basic quantities. The main objective is to provide a synthesis of existing results in a simple and unified framework. The quantitative measure is viewed as a multi-facet concept, representing the confidence, uncertainty, applicability, quality, accuracy, and interestingness of rules. Roughly, they may be classified as representing one-way and two-way supports.

#index 501382
#* Event Mining with Event Processing Networks
#@ Louis Perrochon;Walter Mann;Stephane Kasriel;David C. Luckham
#t 1999
#c 3
#% 14999
#% 102752
#! Event Mining discovers information in a stream of data, or events, and delivers knowledge in real-time. Our event processing engine consists of a network of event processing agents (EPAs) running in parallel that interact using a dedicated event processing infrastructure. EPAs can be configured at run-time using a formal pattern language. The underlying infrastructure provides an abstract communication mechanism and thus allows dynamic reconfiguration of the communication topology between agents at run-time and provides transparent, location-independent access to all data. These features support dynamic allocation of EPAs to machines in a local area network at run time.

#index 501383
#* Rule Discovery in Databases with Missing Values Based on Rough Set Model
#@ Shusaku Tsumoto
#t 1999
#c 3
#% 152934
#! One of the most important problems on rule induction methods is that measures used for rule search will be influenced by missing values. In this paper, a new approach to missing values is introduced, called rough estimation of conditional probabilities. This technique uses three estimation strategies, ground mean, lower and upper methods. Attributes which have missing values will be estimated by these methods and will be checked by constraints for probabilistic rules. The proposed method was evaluated on medical databases, the experimental results of which show that induced rules correctly represented experts'knowledge.

#index 501384
#* Discernibility System in Rough Sets
#@ Liu Zongtian;Xie Zhipeng
#t 1999
#c 3
#% 232106
#% 366687
#! In the classic rough set theory [1], two important concepts (reduct of information system and relative reduct of decision table) are defined. They play important roles in the KDD system based on rough sets, and can be used to remove the irrelevant or redundant attributes from practical database to improve the efficiency of rule extraction and the performance of the rules mined. Many researchers have provided some reduct-computing algorithms. But most of them are designed for static database; hence they don't have the incremental learning capability. The paper first proposes the idea of discernibility system and gives out its formal definition, then presents the concept of reduct in discernibility system, which can be viewed as a generalization of the relative reduct of decision table and the reduct of information system. At last, based on the concept of discernibility system, an incremental algorithm, ASRAI, for computing relative reduct of decision table is presented.

#index 501385
#* Characterization of Default Knowledge in Ripple Down Rules Method
#@ Takuya Wada;Tadashi Horiuchi;Hiroshi Motoda;Takashi Washio
#t 1999
#c 3
#% 85334
#% 136350
#% 373871
#% 449588
#% 703439
#% 1274670
#! "Ripple Down Rules (RDR)" Method is one of the promising approaches to directly acquire and encode knowledge from human experts. It requires data to be supplied incrementally to the knowledgebase being constructed and new piece of knowledge is added as an exception to the existing knowledge. Because of this patching principle, the knowledge acquired strongly depends on what is given as the default knowledge. Further, data are often noisy and we want the RDR noise resistant. This paper reports experimental results about the effect of the selection of default knowledge and the amount of noise in data on the performance of RDR using a simulated expert. The best default knowledge is characterized as the class knowledge that maximizes the minimum description length to encode rules and misclassified cases. This criterion also holds even when the data are noisy.

#index 501502
#* Heuristic for Ranking the Interestigness of Discovered Knowledge
#@ Robert J. Hilderman;Howard J. Hamilton
#t 1999
#c 3
#% 232106
#% 443193
#% 477480
#% 477624
#% 477802
#% 501209
#% 515387
#% 566862
#% 840577
#! We describe heuristics, based upon information theory and statistics, for ranking the interestingness of summaries generated from databases. The tuples in a summary are unique, and therefore, can be considered to be a population described by some probability distribution. The four interestingness measures presented here are based upon common measures of diversity of a population: variance, the Simpson index, and the Shannon index. Using each of the proposed measures, we assign a single real value to a summary that describes its interestingness. Our experimental results show that the ranks assigned by the four interestingness measures are highly correlated.

#index 501503
#* Neural Method for Detection of Complex Patterns in Databases
#@ Chao Deng;Fanlun Xiong
#t 1999
#c 3
#% 225851
#% 232111
#! Databases storing real data contain complex patterns, such as chaotic pattern which generally are characteristics of greatly random fluctuation that often appear between deterministic and stochastic patterns of knowledge discovery in database. Chaotic patterns are always treated as random fluctuation distributions and ignored in literature so far. A novel network approach to discover and predict chaotic pattern in databases is proposed in this paper, which together with Zytkow's Forty-Niner can not only discover the chaotic pattern but also predict it efficiently. In addition, this approach is very suitable to deal with large databases and has extensive applicable prospects in the vivid research fields of KDD.

#index 501504
#* On Information-Theoretic Measures of Attribute Importance
#@ Y. Y. Yao;S. K. Michael Wong;Cory J. Butz
#t 1999
#c 3
#% 5385
#% 30077
#% 46479
#% 73045
#% 115608
#% 152934
#% 232126
#% 443087
#% 449588
#! An attribute is deemed important in data mining if it partitions the database such that previously unknown regularities are observable. Many information-theoretic measures have been applied to quantify the importance of an attribute. In this paper, we summarize and critically analyze these measures.

#index 501505
#* Accuracy Tuning on Combinatorial Neural Model
#@ Hércules A. Prado;Karla F. Machado;Sandra R. Frigeri;Paulo Martins Engel
#t 1999
#c 3
#% 114737
#% 152003
#% 152005
#% 175368
#% 240233
#% 614302
#% 1860368
#! The Combinatorial Neural Model (CNM) ([8] and [9]) is a hybrid architecture for intelligent systems that integrates symbolic and connectionist computational paradigms. This model has shown to be a good alternative to be used on data mining; in this sense some works have been presented in order to deal with scalability of the core algorithm to large databases ([2,1] and [10]). Another important issue is the prunning of the network, after the trainingp hase. In the original proposal this prunningi s done on the basis of accumulators values. However, this criterion does not give a precise notion of the classification accuracy that results after the prunning. In this paper we present an implementation of the CNM with a feature based on the wrapper method ([6] and [12]) to prune the network by usingt he accuracy level, instead of the value of accumulators as in the original approach.

#index 501506
#* Data Mining Techniques for Associations, Clustering and Classification
#@ Charu C. Aggarwal;Philip S. Yu
#t 1999
#c 3
#% 36672
#% 90661
#% 152934
#% 210160
#% 210173
#% 227919
#% 237187
#% 248012
#% 248791
#% 443164
#% 449588
#% 462238
#% 481281
#% 481290
#% 481754
#% 481758
#% 481945
#% 527022
#% 566123
#! This paper provides a survey of various data mining techniques for advanced database applications. These include association rule generation, clustering and classification. With the recent increase in large online repositories of information, such techniques have great importance. The focus is on high dimensional data spaces with large volumes of data. The paper discusses past research on the topic and also studies the corresponding algorithms and applications.

#index 501507
#* Time-Series Prediction with Cloud Models in DMKD
#@ Rong Jiang;Deyi Li;Hui Chen
#t 1999
#c 3
#! A growing attention has been paid to mining time-series knowledge, while time-series prediction becomes one of the important aspects of data mining and knowledge discovery (DMKD). This paper presents a new mechanism of time-series prediction with cloud models. This mechanism not only synthesizes different predictive knowledge with different granularities, but also combines two kinds of predictive strategy: local prediction and overall prediction. We focus this paper on the application of cloud models to transform between quantitative and qualitative knowledge, synthesize different kinds of knowledge and realize the soft inference.

#index 501508
#* Discovering Structure from Document Databases
#@ Mon-Fong Jiang;Shian-Shyong Tseng;Chang-Jiun Tsai
#t 1999
#c 3
#% 36672
#% 237053
#! Querying a database for document retrieval is often a process close to querying an answering expert system. In this work, we apply the knowledge discovery techniques to build an information retrieval system by regarding the structural document database as the expertise of the knowledge discovery. In order to elicit the knowledge embedded in the document structure, a new knowledge representation, named StructuralDocuments(SD), is defined and a transformation process which can transform the documents into a set of SDs is proposed. To evaluate the performance of our idea, we developed an intelligent information retrieval system which can help users to retrieve the required personnel regulations in Taiwan. In our experiments, it can be easily seen that the retrieval results using SD are better than traditional approaches.

#index 501509
#* Discovering Conceptual Differences among Different People via Diverse Structures
#@ Tetsuya Yoshida;Teruyuki Kondo;Shogo Nishida
#t 1999
#c 3
#% 165144
#% 363938
#% 449588
#% 545859
#! We extend a method for discovering conceptual differences among people by introducing diverse structures utilizing Genetic Algorithm (GA). In general different people seem to have different ways of conception and thus can have different concepts even on the same thing. Removing conceptual differences seems especially important when people with different backgrounds and knowledge carry out collaborative works as a group; otherwise they cannot communicate ideas and establish mutual understanding even on the same thing. In our approach knowledge from users is structured into decision trees so that differences in concepts can be discovered as the differences in the structure of trees. In our previous approach ID3algorit hm is utilized to construct a single decision tree based on the information theory. However, it has a problem that conceptual differences which are not represented in the tree due to the low information gain cannot be dealt with. To solve this problem, this paper proposes a new method for discovering conceptual differences which utilizes diverse structures via GA. Experiments were carried out on motor diagnosis cases with artificially encoded conceptual differences and the result shows the superiority of introducing diverse structures with GA to a single decision tree which is constructed with ID3.

#index 501510
#* Efficient Graph-Based Algorithm for Discovering and Maintaining Knowledge in Large Databases
#@ K. L. Lee;Guanling Lee;Arbee L. P. Chen
#t 1999
#c 3
#% 152934
#% 172892
#% 221879
#% 340289
#% 381493
#% 459006
#% 464204
#% 481290
#% 511169
#% 511333
#! In this paper, we study the issues of mining and maintaining association rules in a large database of customer transactions. The problem of mining association rules can be mapped into the problems of finding large itemsets which are sets of items bought together in a sufficient number of transactions. We revise a graph-based algorithm to further speed up the process of itemset generation. In addition, we extend our revised algorithm to maintain discovered association rules when incremental or decremental updates are made to the databases. Experimental results show the efficiency of our algorithms. The revised algorithm significantly improves over the original one on mining association rules. The algorithms for maintaining association rules are more efficient than re-running the mining algorithms for the whole updated database and outperform previously proposed algorithms that need multiple passes over the database.

#index 501511
#* Preserve Discovered Linguistic Patterns Valid in Volatility Data Environment
#@ Xuemei Shi;Man-chung Chan;Deyi Li
#t 1999
#c 3
#% 232106
#% 363391
#% 443082
#! Many data mining techniques have been developed and shown to be successful in financial domains. A further aim is to make sense of numerical data through a human-friendly way, by which general patterns are extracted in terms of linguistic concepts. Problems associated with the linguistic mining approach are the effective representation and the validity preservation of the linguistic patterns. The volatile data may vary linguistic concepts and make previously discovered patterns invalid. This paper aims to solve the problem. Based on the cloud model proposed in our previous works, linguistic patterns can be represented effectively. Outdated linguistic patterns can be valid by a GA-based validity preservation technique in line with current data set. An example of Hong Kong stock market is given to illustrate how the technique works.

#index 501512
#* Evolutionary Hot Spots Data Mining - An Architecture for Exploring for Interesting Discoveries
#@ Graham J. Williams
#t 1999
#c 3
#% 172386
#% 232170
#% 420081
#% 443092
#% 486316
#% 1272369
#! Data Mining delivers novel and useful knowledge from very large collections of data. The task is often characterised as identifying key areas within a very large dataset which have some importance or are otherwise interesting to the data owners. We call this hot spots data mining. Data mining projects usually begin with ill-defined goals expressed vaguely in terms of making interesting discoveries. The actual goals are refined and clarified as the process proceeds. Data mining is an exploratory process where the goals may change and such changes may impact the data space being explored. In this paper we introduce an approach to data mining where the development of the goal itself is part of the problem solving process. We propose an evolutionary approach to hot spots data mining where both the measure of interestingness and the descriptions of groups in the data are evolved under the influence of a user guiding the system towards significant discoveries.

#index 501513
#* Parallel SQL Based Association Rule Mining on Large Scale PC Cluster: Performance Comparison with Directly Coded C Implementation
#@ Iko Pramudiono;Takahiko Shintani;Takayuki Tamura;Masaru Kitsuregawa
#t 1999
#c 3
#% 152934
#% 248786
#% 248813
#% 347040
#% 463883
#% 481290
#% 481758
#! Data mining is becoming increasingly important since the size of databases grows even larger and the need to explore hidden rules from the databases becomes widely recognized. Currently database systems are dominated by relational database and the ability to perform data mining using standard SQL queries will definitely ease implementation of data mining. However the performance of SQL based data mining is known to fall behind specialized implementation. In this paper we present an evaluation of parallel SQL based data mining on large scale PC cluster. The performance achieved by parallelizing SQL query for mining association rule using 4 processing nodes is even with C based program.

#index 501514
#* Prediction Rule Discovery Based on Dynamic Bias Selection
#@ Einoshin Suzuki;Toru Ohno
#t 1999
#c 3
#% 234988
#% 234991
#% 442814
#% 451052
#! This paper presents an algorithm for discovering prediction rules with dynamic bias selection. A prediction rule, which is aimed at predicting the class of an unseen example, deserves special attention due to its usefulness. However, little attention has been paid to the dynamic selection of biases in prediction rule discovery. A dynamic selection of biases is useful since it reduces humans' burden of choosing and adjusting multiple mining algorithms. In this paper, we propose a novel rule discovery algorithm D3BiS, which is based on a data-driven criterion. Our approach has been validated using 17 data sets.

#index 501515
#* Ordered Estimation of Missing Values
#@ Oscar Ortega Lobo;Masayuki Numao
#t 1999
#c 3
#% 90157
#% 136350
#% 449588
#% 551615
#! When attempting to discover by learning concepts embedded in data, it is not uncommon to find that information is missing from the data. Such missing information can diminish the confidence on the concepts learned from the data. This paper describes a new approach to fill missing values in examples provided to a learning algorithm. A decision tree is constructed to determine the missing values of each attribute by using the information contained in other attributes. Also, an ordering for the construction of the decision trees for the attributes is formulated. Experimental results on three datasets show that completing the data by using decision trees leads to final concepts with less error under different rates of random missing values. The approach should be suitable for domains with strong relations among the attributes, and for which improving accuracy is desirable even if computational cost increases.

#index 501516
#* Convex Hulls in Concept Induction
#@ D. A. Newlands;Geoffrey I. Webb
#t 1999
#c 3
#% 2115
#% 92533
#% 136350
#% 182686
#% 194760
#% 212297
#% 449566
#% 676983
#% 1272358
#% 1273368
#! This paper investigates modelling concepts as a few, large convex hulls rather than as many, small, axis-orthogonal divisions as is done by systems which currently dominate classification learning. It is argued that this approach produces classifiers which have less strong hypothesis language bias and which, because of the fewness of the concepts induced, are more understandable. The design of such a system is described and its performance is investigated. Convex hulls are shown to be a useful inductive generalisation technique offering rather different biases than well-known systems such as C4.5 and CN2. The types of domains where convex hulls can be usefully employed are described.

#index 501517
#* Domain Knowledge Extracting in a Chinese Natural Language Interface to Databases: NChiql
#@ Xiaofeng Meng;Yong Zhou;Shan Wang
#t 1999
#c 3
#% 21141
#% 748791
#! This paper presents the method of domain knowledge extracting in NChiql, a Chinese natural language interface to databases. After describing the overall extracting strategy in NChiql, we mainly discuss the basic semantic information extracting method, called DSE. A semantic conceptual graph is employed to specify two types of modification and three types of verbal relationship among the entities, relationships and attributes. Compared with related works. DSE has more strongly extracting ability.

#index 501518
#* A Lazy Model-Based Algorithm for On-Line Classification
#@ Gabor Melli
#t 1999
#c 3
#% 92533
#% 136350
#% 209023
#% 246243
#% 443091
#% 1272280
#% 1476368
#% 1499572
#! This paper presents a lazy model-based algorithm, named DBPredictor, for on-line classification tasks. The algorithm proposes a local discretization process to avoid the need for a lengthy preprocess stage. Another advantage of this approach is the ability to implement the algorithm with tightly-coupled SQL relational database queries. To test the algorithm's performance in the presence of continuous attributes an empirical test is reported against both an eagermodelbased algorithm (C4.5) and a lazy instance-based algorithm (k-NN).

#index 501519
#* Visually Aided Exploration of Interesting Association Rules
#@ Bing Liu;Wynne Hsu;Ke Wang;Shu Chen
#t 1999
#c 3
#% 136350
#% 152934
#% 172386
#% 232106
#% 443092
#% 481758
#! Association rules are a class of important regularities in databases. They are found to be very useful in practical applications. However, the number of association rules discovered in a database can be huge, thus making manual inspection and analysis of the rules difficult. In this paper, we propose a new framework to allow the user to explore the discovered rules to identify those interesting ones. This framework has two components, an interestingness analysis component, and a visualization component. The interestingness analysis component analyzes and organizes the discovered rules according to various interestingness criteria with respect to the user's existing knowledge. The visualization component enables the user to visually explore those potentially interesting rules. The key strength of the visualization component is that from a single screen, the user is able to obtain a global and yet detailed picture of various interesting aspects of the discovered rules. Enhanced with color effects, the user can easily and quickly focus his/her attention on the more interesting/useful rules.

#index 501520
#* Efficient Search of Reliable Exceptions
#@ Huan Liu;Hongjun Lu;Ling Feng;Farhad Hussain
#t 1999
#c 3
#% 90155
#% 136350
#% 152934
#% 172386
#% 412588
#% 443092
#% 481290
#! Finding patterns from data sets is a fundamental task of data mining. If we categorize all patterns into strong, weak, and random, conventional data mining techniques are designed only to find strong patterns, which hold for numerous objects and are usually consistent with the expectations of experts. While such strong patterns are helpful in prediction, the unexpectedness and contradiction exhibited by weak patterns are also very useful although they represent a relatively small number of objects. In this paper, we address the problem of finding weak patterns (i.e., reliable exceptions) from databases. A simple and efficient approach is proposed which uses deviation analysis to identify interesting exceptions and explore reliable ones. Besides, it is flexible in handling both subjective and objective exceptions. We demonstrate the effectiveness of the proposed approach through a set of real-life data sets, and present interesting findings.

#index 501521
#* The Data-Mining and the Technology af Agents to Fight the Illicit Electronic Messages
#@ Djamel A. Zighed;M. Côté;Nader Troudi
#t 1999
#c 3
#% 136350
#! The SPAMS are these undesirable messages that we receive by the slant of the electronic mail and that promise us glory and fortune or stun us of political slogans or violent or pornographic contents. The following article shows how to use techniques of data mining, like methods of supervised learning based on induction graphs, to analyse these Spams in order to be able to eliminate them from our electronic mail.

#index 501522
#* A Fast Clustering Process for Outliers and Remainder Clusters
#@ Chih-Ming Su;Shian-Shyong Tseng;Mon-Fong Jiang;Joe C. S. Chen
#t 1999
#c 3
#% 255141
#! Identifying outliers and remainder clusters which are used to designate few patterns that much different from other clusters is a fundamental step in many application domain. However, current outliers diagnostics are often inadequate when in a large amount of data. In this paper, we propose a two-phase clustering algorithm for outliers. In Phase 1 we modified k-means algorithm by using the heuristic "if one new input pattern is far enough away from all clusters' centers, then assign it as a new cluster center". So that the number of clusters found in this phase is more than that originally set in k-means algorithm. And then we propose a clusters-merging process in the second phase to merge the resulting clusters obtained in Phase 1 into the same number of clusters originally set by the user. The results of three experiments show that the outliers or remainder clusters can be easily identified by our method.

#index 501523
#* LGen - A Lattice-Based Candidate Set Generation Algorithm for I/O Efficient Association Rule Mining
#@ Chi Lap Yip;K. K. Loo;Ben Kao;David Wai-Lok Cheung;C. K. Cheng
#t 1999
#c 3
#% 152934
#% 201894
#% 210160
#% 340291
#% 464204
#% 481290
#% 481588
#% 481779
#! Most algorithms for association rule mining are variants of the basic Apriori algorithm [2]. One characteristic of these Aprioribased algorithms is that candidate itemsets are generated in rounds, with the size of the itemsets incremented by one per round. The number of database scans required by Apriori-based algorithms thus depends on the size of the largest large itemsets. In this paper we devise a more general candidate set generation algorithm, LGen, which generates candidate itemsets of multiple sizes during each database scan. We show that, given a reasonable set of suggested large itemsets, LGen can significantly reduce the number of I/O passes required. In the best cases, only two passes are sufficient to discover all the large itemsets irrespective of the size of the largest ones.

#index 501524
#* Improving the Performance of Boosting for Naive Bayesian Classification
#@ Kai Ming Ting;Zijian Zheng
#t 1999
#c 3
#% 136350
#% 191910
#% 424997
#% 465746
#% 1499573
#! This paper investigates boosting naive Bayesian classification. It first shows that boosting cannot improve the accuracy of the naive Bayesian classifier on average in a set of natural domains. By analyzing the reasons of boosting's failures, we propose to introduce tree structures into naive Bayesian classification to improve the performance of boosting when working with naive Bayesian classification. The experimental results show that although introducing tree structures into naive Bayesian classification increases the average error of naive Bayesian classification for individual models, boosting naive Bayesian classifiers with tree structures can achieve significantly lower average error than the naive Bayesian classifier, providing a method of successfully applying the boosting technique to naive Bayesian classification.

#index 501525
#* Neural Network Based Classifers for a Vast Amount of Data
#@ Ling Zhang;Bo Zhang
#t 1999
#c 3
#% 693
#% 94926
#% 106049
#% 106571
#% 132970
#% 143059
#% 176712
#% 361854
#% 1787923
#% 1788920
#! When using neural networks to train a large number of data for classification, there generally exists a learning complexity problem. In this paper, a new geometrical interpretation of McCulloch-Pitts (M-P) neural model is presented. Based on the interpretation, a new constructive learning approach is discussed. Experimental results show that the new algorithm can greatly reduce the learning complexity and can be applied to real classification problems with a vast amount of data.

#index 501526
#* The Evolution of Causal Models: A Comparison of Bayesian Metrics and Structure Priors
#@ Julian R. Neil;Kevin B. Korb
#t 1999
#c 3
#% 44876
#% 129987
#% 197387
#% 1650658
#% 1650659
#! We report the use genetic algorithms (GAs) as a search mechanism for the discovery of linear causal models when using two Bayesian metrics for linear causal models, a Minimum Message Length (MML) metric [10] and a full posterior analysis (BGe) [3]. We also consider two structure priors over causal models, one giving all variable orderings for models with the same arc density equal prior probability (P1) and one assigning all causal structures with the same arc density equal priors (P2). Evaluated with Kullback-Leibler distance prior P2 tended to produce models closer to the true model than P1 for both metrics, with MML performing slightly better than BGe. By contrast, when using an evaluation metric that better reflects the nature of the causal discovery task, namely a metric that compares the results of predictive performance on the effect nodes in the discovered model P1 outperformed P2 in general, with MML and BGe discovering models of similar predictive performance at various sample sizes. This supports our conjecture that the P1 prior is more appropriate for causal discovery.

#index 501527
#* Classifying Unseen Cases with Many Missing Values
#@ Zijian Zheng;Boon Toh Low
#t 1999
#c 3
#% 73372
#% 90157
#% 136350
#% 209021
#% 465746
#% 486474
#% 501528
#% 1499573
#! Handling missing attribute values is an important issue for classifier learning, since missing attribute values in either training data or test (unseen) data affect the prediction accuracy of learned classifiers. In many real KDD applications, attributes with missing values are very common. This paper studies the robustness of four recently developed committee learning techniques, including Boosting, Bagging, Sasc, and SascMB, relative to C4.5 for tolerating missing values in test data. Boosting is found to have a similar level of robustness to C4.5 for tolerating missing values in test data in terms of average error in a representative collection of natural domains under investigation. Bagging performs slightly better than Boosting, while Sasc and SascMB perform better than them in this regard, with SascMB performing best.

#index 501528
#* Stochastic Attribute Selection Committees with Aultiple Boosting: Learning More Accurate and More Stable Classifer Committees
#@ Zijian Zheng;Geoffrey I. Webb
#t 1999
#c 3
#% 73372
#% 136350
#% 198701
#% 209021
#% 424997
#% 465746
#% 486474
#% 702456
#% 1499573
#! Classifier learning is a key technique for KDD. Approaches to learning classifier committees, including Boosting, Bagging, Sasc, and SascB, have demonstrated great success in increasing the prediction accuracy of decision trees. Boosting and Bagging create different classifiers by modifying the distribution of the training set. Sasc adopts a different method. It generates committees by stochastic manipulation of the set of attributes considered at each node during tree induction, but keeping the distribution of the training set unchanged. SascB, a combination of Boosting and Sasc, has shown the ability to further increase, on average, the prediction accuracy of decision trees. It has been found that the performance of SascB and Boosting is more variable than that of Sasc, although SascB is more accurate than the others on average. In this paper, we present a novel method to reduce variability of SascB and Boosting, and further increase their average accuracy. It generates multiple committees by incorporating Bagging into SascB. As well as improving stability and average accuracy, the resulting method is amenable to parallel or distributed processing, while Boosting and SascB are not. This is an important characteristic for datamining in large datasets.

#index 501529
#* An Induction Algorithm Based on Fuzzy Logic Programming
#@ Daisuke Shibata;Nobuhiro Inuzuka;Shohei Kato;Tohgoroh Matsui;Hidenori Itoh
#t 1999
#c 3
#% 33376
#% 288770
#% 449508
#% 550389
#% 550396
#% 550401
#% 1272280
#! This paper gives a formulation of inductive learning based on fuzzy logic programming (FLP) and a top-down algorithm for it by extending an inductive logic programming (ILP) algorithm FOIL. The algorithm was implemented and evaluated by experiments. Linguistic hedges, which modifies truth, are shown to have effect to adjust classification properties. The algorithm deals with structural domain as other ILP algorithms do and also works well with numeric attributes.

#index 501530
#* Rule Extraction from Prediction Models
#@ Hiroshi Tsukimoto
#t 1999
#c 3
#% 136350
#% 204015
#% 204714
#% 210160
#% 217939
#% 246002
#% 326072
#% 443090
#% 545875
#% 1271874
#% 1275289
#! Knowledge Discovery in Databases(KDD) should provide not only predictions but also knowledge such as rules comprehensible to humans. That is, KDD has two requirements, accurate predictions and comprehensible rules. The major KDD techniques are neural networks, statistics, decision trees, and association rules. Prediction models such as neural networks and multiple regression formulas cannot provide comprehensible rules. Linguistic rules such as decision trees and association rules cannot work well when classes are continuous. Therefore, there is no perfect KDD technique. Rule extraction from prediction models is needed for perfect KDD techniques, which satisfy the two KDD requirements, accurate predictions and comprehensible rules. Several researchers have been developing techniques for rule extraction from neural networks. The author also has been developing techniques for rule extraction from prediction models. This paper briefly explains the techniques of rule extraction from prediction models.

#index 501531
#* A Data Pre-processing Method Using Association Rules of Attributes for Improving Decision Tree
#@ Masahiro Terabe;Osamu Katai;Tetsuo Sawaragi;Takashi Washio;Hiroshi Motoda
#t 1999
#c 3
#% 136350
#% 393792
#% 445217
#% 481290
#! One of the approaches to generate a good decision tree is preprocessing the data to improve its description. There are many researches on data pre-processing such as attributes generation and attributes selection methods. However, most of them are based on logic programming so that it takes much run time. Additionally, some of them need a priori knowledge. These are disadvantage for the data mining. We propose a novel data driven approach that knowledge on the relevance of attributes are generated as association rules from the data, so a priori knowledge is not necessary. In this paper, we present the method and clarify its feature. The effectiveness of our method as data mining one is evaluated through experiments.

#index 501680
#* Data Allocation Algorithm for Parallel Association Rule Discovery
#@ Anna M. Manning;John A. Keane
#t 2001
#c 3
#% 152934
#% 218573
#% 232136
#% 250046
#% 501207
#! Association rule discovery techniques have gradually been adapt-ed to parallel systems in order to take advantage of the higher speed and greater storage capacity that they offer. The transition to a distributed memory system requires the partitioning of the database among the processors, a procedure that is generally carried out indiscriminately. However, for some techniques the nature of the database partitioning can have a pronounced impact on execution time and attention will be focused on one such algorithm, Fast Parallel Mining (FPM). A new algorithm, Data Allocation Algorithm (DAA), is presented that uses Principal Component Analysis to improve the data distribution prior to FPM.

#index 501681
#* Seamless Integration of Data Mining with DBMS and Applications
#@ Hongjun Lu
#t 2001
#c 3
#! Data mining has been widely recognized as a powerful tool for exploring added value from data accumulated in the daily operations of an organization. A large number of data mining algorithms have been developed during the past decade. Those algorithms can be roughly divided into two groups. The fist group of techniques, such as classification, clustering, prediction and deviation analysis, has been studied for a long time in machine learning, statistics, and other fields. The second group of techniques, such as association rule mining, mining in spatial-temporal databases and mining from the Web, addresses problems related to large amounts of data. Most classical algorithms in the first group assume that the data to be mined is somehow available in memory. Although initial effort in data mining has concentrated on making those algorithms scalable with respect to large volume of data, most of those scalable algorithms, even developed by database researchers, are still stand-alone. It is often assumed that data is available in desired forms, without considering the fact that most organizations store their data in databases managed by database management systems (DBMS). As such, most data mining algorithms can only be loosely coupled with data infrastructures in organizations and are difficult to infuse into existing mission-critical applications. Seamlessly integrating data mining techniques with database applications and database management systems remains an open problem. In this paper, we propose to tackle the problem of seamless integration of data mining with DBMS and applications from three directions. First, with the recent development of database technology, most database management systems have extended their functionality in data analysis. Such capability should be fully explored to develop DBMS-awre data mining algorithms. Ideally, data mining algorithms can be fully implemented using DBMS supported functions so that they become database application themselves. Second, major difficulties in integrating data mining with applications are algorithm selection and parameter setting. Reducing or eliminating mining parameters as much as possible and developing automatic or semi-automatic mining algorithm selection techniques will greatly increase the application friendliness of data mining systems. Lastly, standardizing the interface among databases, data mining algorithms and applications can also facilitate the integration to certain extent.

#index 501682
#* Knowledge Acquisition from Both Human Expert and Data
#@ Takuya Wada;Hiroshi Motoda;Takashi Washio
#t 2001
#c 3
#% 61792
#% 90155
#% 136350
#% 143046
#% 196796
#% 363670
#% 395603
#% 703439
#! A Knowledge Acquisition method "Ripple Down Rules" can directly acquire and encode knowledge from human experts. It is an incremental acquisition method and each new piece of knowledge is added as an exception to the existing knowledge base. This knowledge base takes the form of a binary tree. There is another type of knowledge acquisition method that learns directly from data. Induction of decision tree is one such representative example. Noting that more data are stored in the database in this digital era, use of both expertise of humans and these stored data becomes even more important. In this paper, we attempt to integrate inductive learning and knowledge acquisition. We show that using the minimum description length principle, the knowledge base of Ripple Down Rules is automatically and incrementally constructed from data and thus, making it possible to switch between manual acquisition by a human expert and automatic induction from data at any point of knowledge acquisition. Experiments are carefully designed and tested to verify that the proposed method indeed works for many data sets having different natures.

#index 501800
#* Building Behaviour Knowledge Space to Make Classification Decision
#@ Xiuzhen Zhang;Guozhu Dong;Kotagiri Ramamohanarao
#t 2001
#c 3
#% 5182
#% 73372
#% 136350
#% 181242
#% 280409
#% 310550
#% 496966
#! CAEP, namely Classification by Aggregating Emerging Patterns, builds classifiers from Emerging Patterns (EPs). EPs mined from the training data of a class are distinguishing features of the class. To classify a test instance t, the scores by aggregating EPs in t measures the weight we put on each class; direct comparison of scores decides t's class. However the skewed distribution of EPs among classes and intricate relationship between EPs sometimes make the decision by directly comparing scores unreliable. In this paper, we propose to build Score Behaviour Knowledge Space (SBKS) to record the behaviour of training data on scores; classification decision is drawn from SBKS from a statistical point of view. Extensive experiments on real-world datasets show that SBKS frequently improves CAEP classifiers, especially on datasets where they have relatively poor performance. The improved CAEP classifiers outperform the start-of-the-art decision tree classifier C5.0.

#index 501801
#* Hierarchical Classification of Documents with Error Control
#@ Chun Hung Cheng;Jian Tang;Ada Wai-Chee Fu;Irwin King
#t 2001
#c 3
#% 67565
#% 90661
#% 136350
#% 267537
#% 420055
#% 449588
#% 459008
#% 465747
#% 479643
#% 479787
#% 479817
#% 480940
#% 481945
#% 481949
#% 482113
#% 1476310
#% 1499570
#! Classification is a function that matches a new object with one of the predefined classes. Document classification is characterized by the large number of attributes involved in the objects (documents). The traditional method of building a single classifier to do all the classification work would incur a high overhead. Hierarchical classification is a more efficient method -- instead of a single classifier, we use a set of classifiers distributed over a class taxonomy, one for each internal node. However, once a misclassification occurs at a high level class, it may result in a class that is far apart from the correct one. An existing approach to coping with this problem requires terms also to be arranged hierarchically. In this paper, instead of overhauling the classifier itself, we propose mechanisms to detect misclassification and take appropriate actions. We then discuss an alternative that masks the misclassification based on a well known software fault tolerance technique. Our experiments show our algorithms represent a good trade-off between speed and accuracy in most applications.

#index 501802
#* Peculiarity Oriented Mining and Its Application for Knowledge Discovery in Amino-Acid Data
#@ Ning Zhong;Muneaki Ohshima;Setsuo Ohsuga
#t 2001
#c 3
#% 51647
#% 185976
#% 232102
#% 232136
#% 237867
#% 443092
#% 452821
#% 455266
#% 477497
#% 477813
#% 565963
#! The paper proposes a way of peculiarity oriented mining and its application for knowledge discovery in the amino-acid data set. We introduce the peculiarity rules as a new type of association rules, which can be discovered from a relatively small number of peculiar data by searching the relevance among the peculiar data. We argue that the peculiarity rules represent a typically unexpected, interesting regularity hidden in the amino-acid data set.

#index 501803
#* Boosting the Performance of Nearest Neighbour Methods with Feature Selection
#@ Shlomo Geva
#t 2001
#c 3
#% 129212
#% 136350
#% 140588
#% 385564
#% 1272280
#! This paper describes a Nearest Neighbour procedure for variable selection in function approximation, pattern classification, and time series prediction. Given a training set of input/output vector pairs the procedure identifies a subset of input vector components that effectively capture the input-output relationship implicit in the training set. The utility of this procedure is demonstrated with numerous data sets from the UCI repository of machine learning databases and the Mackey-Glass time series prediction. A comprehensive set of benchmark problems is used to demonstrate comparable performance to that of much more complex boosted C4.5 decision trees.

#index 501804
#* Efficient Algorithms for Concept Space Construction
#@ Chi-Yuen Ng;Joseph Lee;Felix Cheung;Ben Kao;David Wai-Lok Cheung
#t 2001
#c 3
#% 27049
#% 115462
#% 204668
#% 229068
#% 387427
#! The vocabulary problem in information retrieval arises because authors and indexers often use different terms for the same concept. A thesaurus defines mappings between different but related terms. It is widely used in modern information retrieval systems to solve the vocabulary problem. Chen et al. proposed the concept space approach to automatic thesaurus construction. A concept space contains the associations between every pair of terms. Previous research studies show that concept space is a useful tool for helping information searchers in revising their queries in order to get better results from information retrieval systems. The construction of a concept space, however, is very computationally intensive. In this paper, we propose and evaluate efficient algorithms for constructing concept spaces that include only strong associations. Since weak associations are not useful in thesauri construction, our algorithms use various prunning techniques to avoid computing weak associations to achieve efficiency.

#index 501805
#* Interactive Construction of Decision Trees
#@ Jianchao Han;Nick Cercone
#t 2001
#c 3
#% 280511
#% 310517
#% 310531
#% 501657
#! We introduce an interactive decision tree construction system, DTViz, which consists of five components and maintains two interaction windows, and attempts to integrate the user's preference and domain knowledge into the construction process.

#index 501806
#* Semi-supervised Learning in Medical Image Database
#@ Chun Hung Li;Pong Chi Yuen
#t 2001
#c 3
#% 211247
#% 311027
#% 313959
#% 457710
#% 466263
#! This paper presents a novel graph-based algorithm for solving the semi-supervised learning problem. The graph-based algorithm makes use of the recent advances in stochastic graph sampling technqiue and a modeling of the labeling consistency in semi-supervised learning. The quality of the algorithm is empirically evaluated on a synthetic clustering problem. The semi-supervised clustering is also applied to the problem of symptoms classification in medical image database and shows promising results.

#index 501807
#* Generating Concept Hierarchies/Networks: Mining Additional Semantics in Relational Data
#@ T. Y. Lin
#t 2001
#c 3
#% 154305
#% 366687
#% 418139
#% 498610
#% 836134
#! In relational theory, attribute domains are classical sets; no interactions among attribute values are modeled. So the concept hierarchies, which are additional semantics, used in data mining have to be input by users. In this paper, "real world" data model - relational model with additional semantics specified by binary relational structures (adopt from first order logic) - are explored; in such model, concept hierarchies/networks can be generated automatically. In fact, there are two families of concepts. One family forms a traditional hierarchy. Another forms a hierarchy syntactically, but semantically the hierarchy is a network; this is due to the fact that distinct concepts may be semantically related. A simple example is illustrated.

#index 501808
#* On Application of Rough Data Mining Methods to Automatic Construction of Student Models
#@ Feng-Hsu Wang;Shiou-Wen Hung
#t 2001
#c 3
#% 69167
#% 73373
#% 247585
#% 247587
#! Student modeling has been an active research area in the field of intelligent tutoring systems. In this paper, we propose a rough data mining approach to the student modeling problems. The problem is modeled as a knowledge discovery process in which a student's domain knowledge (classification rules) was discovered and rebuilt using rough set data mining techniques. We design two knowledge extraction modules based on the lower approximation set and upper approximation set of the rough set theory, respectively. To verify the effectiveness of the knowledge extraction modules, two similarity metrics are presented. A set of experiments is conducted to evaluate the capability of the knowledge extraction modules. At last, based on the experimental results some suggestions about a future knowledge extraction module are outlined.

#index 501809
#* The S2-Tree: An Index Structure for Subsequence Matching of Spatial Objects
#@ Haixun Wang;Chang-Shing Perng
#t 2001
#c 3
#% 86950
#% 131061
#% 172949
#% 239699
#% 252304
#% 257637
#% 273919
#% 289010
#% 315005
#% 427199
#% 468476
#% 481956
#! We present the S2-Tree, an indexing method for subsequence matching of spatial objects. The S2-Tree locates subsequences within a collection of spatial sequences, i.e., sequences made up of spatial objects, such that the subsequences match a given query pattern within a specified tolerance. Our method is based on (i) the string-searching techniques that locate substrings within a string of symbols drawn from a discrete alphabet (e.g., ASCII characters) and (ii) the spatial access methods that index (unsequenced) spatial objects. Particularly, the S2-Tree can be applied to solve problems such as subsequence matching of time-series data, where features of subsequences are often extracted and mapped into spatial objects. Moreover, it supports queries such as "what is the longest common pattern of the two time series?", which previous subsequence matching algorithms find difficult to solve efficiently.

#index 501810
#* Predictive Self-Organizing Networks for Text Categorization
#@ Ah-Hwee Tan
#t 2001
#c 3
#% 23408
#% 46803
#% 111415
#% 165110
#% 165111
#% 169718
#% 185921
#% 232653
#% 260001
#% 280817
#% 458379
#% 465754
#% 1860145
#! This paper introduces a class of predictive self-organizing neural networks known as Adaptive Resonance Associative Map (ARAM) for classification of free-text documents. Whereas most statistical approaches to text categorization derive classification knowledge based on training examples alone, ARAM performs supervised learning and integrates user-defined classification knowledge in the form of IF-THEN rules. Through our experiments on the Reuters-21578 news database, we showed that ARAM performed reasonably well in mining categorization knowledge from sparse and high dimensional document feature space. In addition, ARAM predictive accuracy and learning efficiency can be improved by incorporating a set of rules derived from the Reuters category description. The impact of rule insertion is most significant for categories with a small number of relevant documents.

#index 501811
#* Seabreeze Prediction Using Bayesian Networks
#@ Russell J. Kennett;Kevin B. Korb;Ann E. Nicholson
#t 2001
#c 3
#% 44876
#% 138290
#% 527830
#! In this paper we examine the use of Bayesian networks (BNs) for improving weather prediction, applying them to the problem of predicting sea breezes. We compare a pre-existing Bureau of Meteorology rule-based system with an elicited BN and others learned by two data mining programs, TETRAD II [Spirtes et al., 1993] and Causal MML [Wallace and Korb, 1999]. These Bayesian nets are shown to significantly outperform the rule-based system in predictive accuracy.

#index 501812
#* Incompleteness in Data Mining
#@ H. V. Jagadish
#t 2001
#c 3
#! Database technology, as well as the bulk of data mining technology, is founded upon logic, with absolute notions of truth and falsehood, at least with respect to the data set. Patterns are discovered exhaustively, with carefully engineered algorithms devised to determine all patterns in a data set that belong to a certain class. For large data sets, many such data mining techniques are extremely expensive, leading to considerable research towards solving these problems more cheaply. We argue that the central goal of data mining is to find SOME interesting patterns, and not necessarily ALL of them. As such, techniques that can find most of the answers cheaply are clearly more valuable than computationally much more expensive techniques that can guarantee completeness. In fact, it is probably the case that patterns that can be found cheaply are indeed the most important ones. Furthermore, knowledge discovery can be the most effective with the human analyst heavily involved in the endeavor. To engage a human analyst, it is important that data mining techniques be interactive, hopefully delivering (close to) real time responses and feedback. Clearly then, extreme accuracy and completeness (i.e., finding all patterns satisfying some specified criteria) would almost always be a luxury. Instead, incompleteness (i.e., finding only some patterns) and approximation would be essential. We exemplify this discussion through the notion of fascicles. Often many records in a database share similar values for several attributes. If one is able to identify and group together records that share similar values for some - even if not all - attributes, one can both obtain a more parsimonious representation of the data, and gain useful insight into the data from a mining perspective. Such groupings are called fascicles. We explore the relationship of fascicle-finding to association rule mining, and experimentally demonstrate the benefit of incomplete but inexpensive algorithms. We also present analytical results demonstrating both the limits and the benefits of such incomplete algorithms.

#index 501813
#* Rule Reduction over Numerical Attributes in Decision Tree Using Multilayer Perceptron
#@ DaeEun Kim;Jaeho Lee
#t 2001
#c 3
#% 61477
#% 89881
#% 92542
#% 160857
#% 169767
#% 204434
#% 356892
#% 376683
#% 404505
#% 443288
#% 458187
#% 458339
#% 478116
#% 1272280
#% 1273391
#! Many data sets show significant correlations between input variables, and much useful information is hidden in the data in a non-linear format. It has been shown that a neural network is better than a direct application of induction trees in modeling nonlinear characteristics of sample data. We have extracted a compact set of rules to support data with input variable relations over continuous-valued attributes. Those relations as a set of linear classifiers can be obtained from neural network modeling based on back-propagation. It is shown in this paper that variable thresholds play an important role in constructing linear classifier rules when we use a decision tree over linear classifiers extracted from a multilayer perceptron. We have tested this scheme over several data sets to compare it with the decision tree results.

#index 501814
#* Meta-learning Models for Automatic Textual Document Categorization
#@ Kwok-Yin Lai;Wai Lam
#t 2001
#c 3
#% 165111
#% 169718
#% 190581
#% 219050
#% 219051
#% 219052
#% 260001
#% 262050
#% 280817
#% 458379
#% 466572
#! We investigate two meta-model approaches for the task of automatic textual document categorization. The first approach is the linear combination approach. Based on the idea of distilling the characteristics of how we estimate the merits of each component algorithm, we propose three different strategies for the linear combination approach. The linear combination approach makes use of limited knowledge in the training document set. To address this limitation, we propose the second meta-model approach, called Meta-learning Using Document Feature characteristics (MUDOF), which employs a meta-learning phase using document feature characteristics. Document feature characteristics, derived from the training document set, capture some inherent properties of a particular category. Extensive experiments have been conducted on a real-world document collection and satisfactory performance is obtained.

#index 501815
#* iJADE eMiner - A Web-Based Mining Agent Based on Intelligent Java Agent Development Environment (iJADE) on Internet Shopping
#@ Raymond S. T. Lee;James N. K. Liu
#t 2001
#c 3
#% 202011
#% 232102
#% 255165
#% 255208
#% 355728
#% 383314
#% 462045
#% 617856
#% 661023
#% 1290175
#% 1860660
#! With the rapid growth of e-commerce applications, Internet shopping is becoming part of our daily lives. Traditional Web-based product searching based on keywords searching seems insufficient and inefficient in the 'sea' of information. In this paper, we propose an innovative intelligent multi-agent based environment, namely (iJADE) - intelligent Java Agent Development Environment - to provide an integrated and intelligent agent-based platform in the e-commerce environment. In addition to contemporary agent development platforms, which focus on the autonomy and mobility of the multi-agents, iJADE provides an intelligent layer (known as the 'conscious layer') to implement various AI functionalities in order to produce 'smart' agents. From the implementation point of view, iJADE eMiner consists of two main modules: 1) a visual data mining and visualization system for automatic facial authentication based on the FAgent model, and 2) a fuzzy-neural based shopping agent (FShopper) to facilitate Web-mining on Internet shopping in cyberspace.

#index 501816
#* Combining the Strength of Pattern Frequency and Distance for Classification
#@ Jinyan Li;Kotagiri Ramamohanarao;Guozhu Dong
#t 2001
#c 3
#% 92533
#% 136350
#% 152934
#% 232106
#% 280409
#% 280439
#% 379331
#% 478133
#% 1272280
#% 1273659
#! Supervised classification involves many heuristics, including the ideas of decision tree, k-nearest neighbour (k-NN), pattern frequency, neural network, and Bayesian rule, to base induction algorithms. In this paper, we propose a new instance-based induction algorithm which combines the strength of pattern frequency and distance. We define a neighbourhood of a test instance. If the neighbourhood contains training data, we use k-NN to make decisions. Otherwise, we examine the support (frequency) of certain types of subsets of the test instance, and calculate support summations for prediction. This scheme is intended to deal with outliers: when no training data is near to a test instance, then the distance measure is not a proper predictor for classification. We present an effective method to choose an "optimal" neighbourhood factor for a given data set by using a guidance from a partial training data. In this work, we find that our algorithm maintains (sometimes exceeds) the outstanding accuracy of k-NN on data sets containing pure continuous attributes, and that our algorithm greatly improves the accuracy of k-NN on data sets containing a mixture of continuous and categorical attributes. In general, our method is much superior to C5.0.

#index 501817
#* Mining Optimal Class Association Rule Set
#@ Jiuyong Li;Hong Shen;Rodney W. Topor
#t 2001
#c 3
#% 136350
#% 152934
#% 201894
#% 227919
#% 232136
#% 248785
#% 280433
#% 280436
#% 376266
#% 458178
#% 463883
#% 631970
#% 637522
#! We define an optimal class association rule set to be the minimum rule set with the same prediction power of the complete class association rule set. Using this rule set instead of the complete class association rule set we can avoid redundant computation that would otherwise be required for mining predictive association rules and hence improve the efficiency of the mining process significantly. We present an efficient algorithm for mining the optimal class association rule set using an upward closure property of pruning weak rules before they are actually generated. We have implemented the algorithm and our experimental results show that our algorithm generates the optimal class association rule set, whose size is smaller than 1/17 of the complete class association rule set on average, in significantly less time than generating the complete class association rule set. Our proposed criterion has been shown very effective for pruning weak rules in dense databases.

#index 501818
#* A Characterized Rating Recommend System
#@ Yao-Tsung Lin;Shian-Shyong Tseng
#t 2001
#c 3
#% 36672
#% 136350
#! In recent years, due to the rapid growth of Internet usage, the problem of how to avoid inappropriate Internet contents accessing becomes more and more important. To solve the problem, a Collaborative Rating System [3, 4] based upon PICS protocol has been proposed. However, since the users usually would like to consult the opinions of the user group with similar rating tendency rather than the common opinions from the majority, it means the opinion of second majority with sufficient number of voters should also be considered. So does third majority, and so on. In order to provide a characterized rating service, a Characterized Rating Recommend System is designed to provide more precise and proper rating service for each user. Also, in this work, a questionnaire is designed to get users' opinions, and some experimental results show that the system can provide acceptable rating service.

#index 501819
#* Towards Efficient Data Re-mining (DRM)
#@ Jiming Liu;Jian Yin
#t 2001
#c 3
#% 152934
#% 201894
#% 452747
#% 481290
#% 481758
#! The problem that we tackle here is a practical one: When users interactively mine association rules, it is often the case that they have to continuously tune two thresholds: minimum support and minimum confidence, which describe the users' changing requirements. In this paper, we present an efficient data re-mining (DRM) technique for updating previously discovered association rules in light of threshold changes.

#index 501820
#* Direct and Incremental Computing of Maximal Covering Rules
#@ Marzena Kryszkiewicz
#t 2001
#c 3
#% 152934
#% 232136
#% 477636
#% 478135
#% 501193
#! In the paper we consider the knowledge in the form of association rules. The consequents derivable from the given set of association rules constitute the theory for this rule set. We apply maximal covering rules as a concise representation of the theory. We prove that maximal covering rules have precisely computable values of support and confidence, though the theory can contain rules for which these values can be only estimated. Efficient methods of direct and incremental computation of maximal covering rules are offered.

#index 501821
#* Feature Selection for Temporal Health Records
#@ Rohan A. Baxter;Graham J. Williams;Hongxing He
#t 2001
#c 3
#% 36672
#% 385564
#% 424810
#! In this paper we consider three alternative feature vector representations of patient health records. The longitudinal (temporal), irregular character of patient episode history, an integral part of a health record, provides some challenges in applying data mining techniques. The present application involves episode history of monitoring services for elderly patients with diabetes. The application task was to examine patterns of monitoring services for patients. This was approached by clustering patients into groups receiving similar patterns of care and visualising the features devised to highlight interesting patterns of care.

#index 501822
#* User-Defined Association Mining
#@ Ke Wang;Yu He
#t 2001
#c 3
#% 152934
#% 216508
#% 227919
#% 248012
#% 248784
#% 248785
#% 280409
#% 420055
#% 420059
#% 442814
#% 464712
#% 479484
#% 481290
#% 481954
#! Discovering interesting associations of events is an important data mining task. In many real applications, the notion of association, which defines how events are associated, often depends on the particular application and user requirements. This motivates the need for a general framework that allows the user to specify the notion of association of his/her own choices. In this paper we present such a framework, called the UDA mining (User-Defined Association Mining). The approach is to define a language for specifying a broad class of associations and yet efficient to be implemented. We show that (1) existing notions of association mining are instances of the UDA mining, and (2) many new ad-hoc association mining tasks can be defined in the UDA mining framework.

#index 501823
#* A Hybrid Approach to Clustering in Very Large Databases
#@ Aoying Zhou;Weining Qian;Hailei Qian;Jin Wen;Shuigeng Zhou;Ye Fan
#t 2001
#c 3
#% 248790
#% 566128
#! Current clustering methods always have such problems: 1) High I/O cost and expensive maintenance; 2) Pre-specifying the uncertain parameter k; 3) Lacking good efficiency in treating arbitrary shape under very large data set environment. In this paper, we first present a hybrid-clustering algorithm to solve these problems. It combines both distance and density strategies, and makes full use of statistics information while keeping good cluster quality. The experimental results show that our algorithm outperforms other popular algorithms in terms of efficiency, cost, and even get much more speedup as the data size scales up.

#index 501824
#* Topic Detection, Tracking, and Trend Analysis Using Self-Organizing Neural Networks
#@ Kanagasabi Rajaraman;Ah-Hwee Tan
#t 2001
#c 3
#% 111415
#% 406493
#! We address the problem of Topic Detection and Tracking (TDT) and subsequently detecting trends from a stream of text documents. Formulating TDT as a clustering problem in a class of self-organizing neural networks, we propose an incremental clustering algorithm. On this setup we show how trends can be identified. Through experimental studies, we observe that our method enables discovering interesting trends that are deducible only from reading all relevant documents.

#index 501825
#* Micro Similarity Queries in Time Series Database
#@ Xiaoming Jin;Yuchang Lu;Chunyi Shi
#t 2001
#c 3
#% 86950
#% 169805
#% 172949
#% 460862
#% 461885
#% 464195
#% 481609
#! Currently there is no model available that would facilitate the task of finding similar time series based on partial information that interest users. We studied a novel query problem class that we termed micro similarity queries (MSQ) in this paper. We present the formal definition of MSQ. A method is investigated for the purpose of efficient processing of MSQ. We evaluated the behavior of MSQ problem and our query algorithm with both synthetic data and real data. The results show that the knowledge revealed by MSQ corresponds with the subjective feeling of similarity based on singular interest.

#index 501826
#* Criteria on Proximity Graphs for Boundary Extraction and Spatial Clustering
#@ Vladimir Estivill-Castro;Ickjai Lee;Alan T. Murray
#t 2001
#c 3
#% 121114
#% 210173
#% 241124
#% 273890
#% 438137
#% 481281
#% 501353
#% 631924
#! Proximity and density information modeling of 2D point-data by Delaunay Diagrams has delivered a powerful exploratory and argument-free clustering algorithm [6] for geographical data mining [13]. The algorithm obtains cluster boundaries using a Short-Long criterion and detects non-convex clusters, high and low density clusters, clusters inside clusters and many other robust results. Moreover, its computation is linear in the size of the graph used. This paper demonstrates that the criterion remains effective for exploratory analysis and spatial data mining where other proximity graphs are used. It also establishes a hierarchy of the modeling power of several proximity graphs and presents how the argument free characteristic of the original algorithm can be traded for argument tuning. This enables higher than 2 dimensions by using linear size proximity graphs like k-nearest neighbors.

#index 501827
#* Empirical Study of Recommender Systems Using Linear Classifiers
#@ Vijay S. Iyengar;Tong Zhang
#t 2001
#c 3
#% 165111
#% 173879
#% 197394
#% 202011
#% 269218
#% 272520
#% 314933
#% 380342
#% 458379
#% 466074
#% 528152
#% 656128
#% 1650569
#% 1818269
#! Recommender systems use historical data on user preferences and other available data on users (e.g., demographics) and items (e.g., taxonomy) to predict items a new user might like. Applications of these methods include recommending items for purchase and personalizing the browsing experience on a web-site. Collaborative filtering methods have focused on using just the history of user preferences to make the recommendations. These methods have been categorized as memory-based if they operate over the entire data to make predictions and as model-based if they use the data to build a model which is then used for predictions. In this paper, we propose the use of linear classifiers in a model-based recommender system. We compare our method with another model-based method using decision trees and with memory-based methods using data from various domains. Our experimental results indicate that these linear models are well suited for this application. They outperform the commonly proposed approach using a memory-based method in accuracy and also have a better tradeoff between off-line and on-line computational requirements.

#index 501828
#* Efficient Hierarchical Clustering Algorithms Using Partially Overlapping Partitions
#@ Manoranjan Dash;Huan Liu
#t 2001
#c 3
#% 36672
#% 152902
#% 189880
#% 210173
#% 248790
#% 280402
#% 438137
#% 631985
#! Clustering is an important data exploration task. A prominent clustering algorithm is agglomerative hierarchical clustering. Roughly, in each iteration, it merges the closest pair of clusters. It was first proposed way back in 1951, and since then there have been numerous modifications. Some of its good features are: a natural, simple, and non-parametric grouping of similar objects which is capable of finding clusters of different shape such as spherical and arbitrary. But large CPU time and high memory requirement limit its use for large data. In this paper we show that geometric metric (centroid, median, and minimum variance) algorithms obey a 90-10 relationship where roughly the first 90iterations are spent on merging clusters with distance less than 10the maximum merging distance. This characteristic is exploited by partially overlapping partitioning. It is shown with experiments and analyses that different types of existing algorithms benefit excellently by drastically reducing CPU time and memory. Other contributions of this paper include comparison study of multi-dimensional vis-a-vis single-dimensional partitioning, and analytical and experimental discussions on setting of parameters such as number of partitions and dimensions for partitioning.

#index 501829
#* Learning Bayesian Networks with Hidden Variables Using the Combination of EM and Evolutionary Algorithms
#@ Fengzhan Tian;Yuchang Lu;Chunyi Shi
#t 2001
#c 3
#% 129987
#% 185079
#% 212700
#% 246835
#% 465762
#% 465882
#% 478645
#! In this paper, a new method, called EM-EA, is put forward for learning Bayesian network structures from incomplete data. This method combines the EM algorithm with an evolutionary algorithm (EA) and transforms the incomplete data to complete data using EM algorithm and then evolve network structures using the evolutionary algorithm with the complete data. In order to learn Bayesian networks with hidden variables, a new mutation operator has been introduced and the function of the crossover has been correspondingly expanded. The results of the experiments show that EM-EA is more accurate and practical than other network structure learning algorithms that deal with the incomplete data.

#index 501830
#* Evaluation of Interestingness Measures for Ranking Discovered Knowledge
#@ Robert J. Hilderman;Howard J. Hamilton
#t 2001
#c 3
#% 280436
#% 280485
#% 304180
#% 443193
#% 465666
#% 477661
#% 477962
#% 478282
#% 481290
#% 501204
#% 501502
#% 565963
#% 661269
#% 840577
#! When mining a large database, the number of patterns discovered can easily exceed the capabilities of a human user to identify interesting results. To address this problem, various techniques have been suggested to reduce and/or order the patterns prior to presenting them to the user. In this paper, our focus is on ranking summaries generated from a single dataset, where attributes can be generalized in many different ways and to many levels of granularity according to taxonomic hierarchies. We theoretically and empirically evaluate thirteen diversity measures used as heuristic measures of interestingness for ranking summaries generated from databases. The thirteen diversity measures have previously been utilized in various disciplines, such as information theory, statistics, ecology, and economics. We describe five principles that any measure must satisfy to be considered useful for ranking summaries. Theoretical results show that only four of the thirteen diversity measures satisfy all of the principles. We then analyze the distribution of the index values generated by each of the thirteen diversity measures. Empirical results, obtained using synthetic data, show that the distribution of index values generated tend to be highly skewed about the mean, median, and middle index values. The objective of this work is to gain some insight into the behaviour that can be expected from each of the measures in practice.

#index 501831
#* Automatic Hypertext Construction through a Text Mining Approach by Self-Organizing Maps
#@ Hsin-Chang Yang;Chung-Hong Lee
#t 2001
#c 3
#% 230519
#% 234978
#% 287045
#% 406493
#! In this work we developed a new automatic hypertext construction method based on a proposed text mining approach. Our method applies the self-organizing map algorithm to cluster some flat text documents in a training corpus and generate two maps. We then use these maps to identify the sources and destinations of some important hyperlinks within these training documents. The constructed hyperlinks are then inserted into the training documents to translate them into hypertext form. Such translated documents form the new corpus. Incoming documents can also be translated into hypertext form and added to the corpus through the same approach. Our method had been tested on a set of flat text documents collecting from several newswire sites. Although we only used Chinese text documents, our approach can be applied to any document that can be transformed to a set of indexed terms.

#index 501832
#* Scalable Hierarchical Clustering Method for Sequences of Categorical Values
#@ Tadeusz Morzy;Marek Wojciechowski;Maciej Zakrzewicz
#t 2001
#c 3
#% 36672
#% 210173
#% 248790
#% 248792
#% 255137
#% 280419
#% 280488
#% 281155
#% 287285
#% 375388
#% 451052
#% 459006
#% 463903
#% 479659
#% 631985
#! Data clustering methods have many applications in the area of data mining. Traditional clustering algorithms deal with quantitative or categorical data points. However, there exist many important databases that store categorical data sequences, where significant knowledge is hidden behind sequential dependencies between the data. In this paper we introduce a problem of clustering categorical data sequences and present an efficient scalable algorithm to solve the problem. Our algorithm implements the general idea of agglomerative hierarchical clustering and uses frequently occurring subsequences as features describing data sequences. The algorithm not only discovers a set of high quality clusters containing similar data sequences but also provides descriptions of the discovered clusters.

#index 501833
#* A Similarity Indexing Method for the Data Warehousing - Bit-Wise Indexing Method
#@ Wei-Chou Chen;Shian-Shyong Tseng;Lu-Ping Chang;Mon-Fong Jiang
#t 2001
#c 3
#% 135476
#% 227861
#% 443174
#% 443269
#% 462217
#% 482713
#% 1784203
#% 1784263
#! Data warehouse is an information provider that collects necessary data from individual source databases to support the analytical processing of decision-support functions. Recently, research about the indexing technologies of data warehousing has been proposed to help efficient on-line analytical processing (OLAP). In the past decades, some novel indexing technologies of data warehousing were proposed to retrieve the information precisely. However, the concept of similarity indexing technology in the increasingly larger data warehousing was seldom been discussed. In this paper, the performance issue of approximation indexing technology in the data warehousing is discussed and a new similarity indexing method, called bit-wise indexing method, and the corresponding efficient algorithms are proposed for retrieving the similar cases of a case-based reasoning system using a data warehouse to be the storage space. Some experiments are made for comparing the performance with two other methods and the results show the efficiency of the proposed method.

#index 501834
#* Importance of Individual Variables in the k -Means Algorithm
#@ Juha Vesanto
#t 2001
#c 3
#% 269634
#% 1042868
#! In this paper, quantization errors of individual variables in k-means quantization algorithm are investigated with respect to scaling factors, variable dependency, and distribution characteristics. It is observed that Z-norm standardation limits average quantization errors per variable to unit range. Two measures, quantization quality and effective number of quantization points are proposed for evaluating the goodness of quantization of individual variables. Both measures are invariant with respect to scaling/variances of variables. By comparing these measures between variables, a sense of the relative importance of variables is gained.

#index 501835
#* Representing Large Concept Hierarchies Using Lattice Data Structure
#@ Yanee Kachai;Kitsana Waiyamai
#t 2001
#c 3
#% 51391
#% 199515
#% 316709
#! With the rapid growth in size and number of available databases, the manipulation of large concept hierarchies that cannot be fit in main memory becomes more and more frequent. Several representations of concept hierarchies are possible, for example tree, lattice, table, linked list, etc. In this paper, we propose an efficient implementation technique to manipulate large concept hierarchies. We use a lattice data structure to represent concept hierarchies and encode such a lattice into a boolean transitive closure matrix. A set of lattice operators are defined and implemented as abstract data types on the top of an object-relational database management system, and are used to perform generalization and specialization operations. We show the efficiency of the lattice operators to perform generalization and specialization in large concept hierarchies and compare their performance with the START WITH and CONNECT BY clauses of SQL.

#index 501836
#* FFS - An I/O-Efficient Algorithm for Mining Frequent Sequences
#@ Minghua Zhang;Ben Kao;Chi Lap Yip;David Wai-Lok Cheung
#t 2001
#c 3
#% 152934
#% 227917
#% 259993
#% 287242
#% 443194
#% 459006
#% 459020
#% 463903
#% 479971
#! This paper studies the problem of mining frequent sequences in transactional databases. In [1], Agrawal and Srikant proposed the AprioriAll algorithm for extracting frequently occurring sequences. AprioriAll is an iterative algorithm. It scans the database a number of times depending on the length of the longest frequent sequences in the database. The I/O cost is thus substantial if the database contains very long frequent sequences. In this paper, we propose a new I/O-efficient algorithm FFS. Experiment results show that FFS saves I/O cost significantly compared with AprioriAll. The I/O saving is obtained at a cost of a mild overhead in CPU cost.

#index 501837
#* A Scalable Algorithm for Rule Post-pruning of Large Decision Trees
#@ Trong Dung Nguyen;Tu Bao Ho;Hiroshi Shimodaira
#t 2001
#c 3
#% 73374
#% 136350
#% 229811
#% 376266
#% 449559
#% 449566
#% 465922
#! Decision tree learning has become a popular and practical method in data mining because of its high predictive accuracy and ease of use. However, a set of if-then rules generated from large trees may be preferred in many cases because of at least three reasons: (i) large decision trees are difficult to understand as we may not see their hierarchical structure or get lost in navigating them, (ii) the tree structure may cause individual subconcepts to be fragmented (this is sometimes known as the "replicated subtree" problem), (iii) it is easier to combine new discovered rules with existing knowledge in a given domain. To fulfill that need, the popular decision tree learning system C4.5 applies a rule post-pruning algorithm to transform a decision tree into a rule set. However, by using a global optimization strategy, C4.5rules functions extremely slow on large datasets. On the other hand, rule post-pruning algorithms that learn a set of rules by the separate-and-conquer strategy such as CN2, IREP, or RIPPER can be scalable to large datasets, but they suffer from the crucial problem of overpruning, and do not often achieve a high accuracy as C4.5. This paper proposes a scalable algorithm for rule post-pruning of large decision trees that employs incremental pruning with improvements in order to overcome the overpruning problem. Experiments show that the new algorithm can produce rule sets that are as accurate as those generated by C4.5 and is scalable for large datasets.

#index 501838
#* A Toolbox Approach to Flexible and Efficient Data Mining
#@ Ole Møller Nielsen;Peter Christen;Markus Hegland;Tatiana Semenova;Timothy Hancock
#t 2001
#c 3
#% 187084
#% 210164
#% 269634
#% 273931
#% 344236
#% 388549
#% 393792
#% 438135
#% 443082
#! This paper describes a flexible and efficient toolbox based on the scripting language Python, capable of handling common tasks in data mining. Using either a relational database or flat files the toolbox gives the user a uniform view of a data collection. Two core features of the toolbox are caching of database queries and parallelism within a collection of independent queries. Our toolbox provides a number of routines for basic data mining tasks on top of which the user can add more functions - mainly domain and data collection dependent - for complex and time consuming data mining tasks.

#index 501839
#* Efficient Mining of Niches and Set Routines
#@ Guozhu Dong;Kaustubh Deshpande
#t 2001
#c 3
#% 248791
#% 280409
#% 310550
#% 443313
#% 477784
#% 478133
#% 479627
#% 501204
#% 501520
#% 501540
#% 1271849
#! It is widely recognized that successful businesses usually fall into set routines and become limited by their past. To remain successful, they need to discover new opportunities and niches. Niches are surprising rules that contradict the set routines; they capture significant, representative client sectors that deserve new, more profitable treatments; they are not merely strong-rule and exception pairs. In this paper we study the efficient mining of set routines and niches. We also introduce a semantic approach to select a set of representative patterns, and present an efficient incremental algorithm to implement the approach.

#index 501840
#* Discovery of Frequent Tree Structured Patterns in Semistructured Web Documents
#@ Tetsuhiro Miyahara;Takayoshi Shoudai;Tomoyuki Uchida;Kenichi Takahashi;Hiroaki Ueda
#t 2001
#c 3
#% 248809
#% 291299
#% 443349
#% 462235
#% 501349
#% 501661
#! Many documents such as Web documents or XML files have no rigid structure. Such semistructured documents have been rapidly increasing. We propose a new method for discovering frequent tree structured patterns in semistructured Web documents. We consider the data mining problem of finding all maximally frequent tag tree patterns in semistructured data such as Web documents. A tag tree pattern is an edge labeled tree which has hyperedges as variables. An edge label is a tag or a keyword inWeb documents, and a variable can be substituted by any tree. So a tag tree pattern is suited for representing tree structured patterns in semistructured Web documents. We present an algorithm for finding all maximally frequent tag tree patterns. Also we report some experimental results on XML documents by using our algorithm.

#index 501841
#* Optimizing the Induction of Alternating Decision Trees
#@ Bernhard Pfahringer;Geoffrey Holmes;Richard Kirkby
#t 2001
#c 3
#% 209021
#% 290482
#% 302391
#% 312727
#% 466240
#% 466722
#! The alternating decision tree brings comprehensibility to the performance enhancing capabilities of boosting. A single interpretable tree is induced wherein knowledge is distributed across the nodes and multiple paths are traversed to form predictions. The complexity of the algorithm is quadratic in the number of boosting iterations and this makes it unsuitable for larger knowledge discovery in database tasks. In this paper we explore various heuristic methods for reducing this complexity while maintaining the performance characteristics of the original algorithm. In experiments using standard, artificial and knowledge discovery datasets we show that a range of heuristic methods with log linear complexity are capable of achieving similar performance to the original method. Of these methods, the random walk heuristic is seen to outperform all others as the number of boosting iterations increases. The average case complexity of this method is linear.

#index 501960
#* Temporal Data Mining Using Hidden Markov-Local Polynomial Models
#@ Weiqiang Lin;Mehmet A. Orgun;Graham J. Williams
#t 2001
#c 3
#% 341682
#% 477479
#% 481609
#% 481611
#% 497125
#% 498457
#! This study proposes a data mining framework to discover qualitative and quantitative patterns in discrete-valued time series (DTS). In our method, there are three levels for mining similarity and periodicity patterns. At the first level, a structural-based search based on distance measure models is employed to find pattern structures; the second level performs a value-based search on the discovered patterns using local polynomial analysis; and then the third level based on hidden Markov-local polynomial models (HMLPMs), finds global patterns from a DTS set.We demonstrate our method on the analysis of "Exchange Rates Patterns" between the U.S. dollar and the United Kingdom Pound.

#index 501961
#* Concept Approximation in Concept Lattice
#@ Keyun Hu;Yuefei Sui;Yuchang Lu;Ju Wang;Chunyi Shi
#t 2001
#c 3
#% 217723
#% 366687
#% 384416
#% 501365
#% 505699
#% 505713
#! In this paper we present a novel approach to the concept approximations in concept lattice. Using the similar idea of rough set theory and unique properties of concept lattice, upper and lower approximations of any object or attribute set can be found by exploiting meet-(union-)irreducible elements in concept lattice, the approximations can be performed on the fly. We show that our approach is more natural and effective than existing approach.

#index 501962
#* Determining Progression in Glaucoma Using Visual Fields
#@ Andrew Turpin;Eibe Frank;Mark Hall;Ian H. Witten;Chris A. Johnson
#t 2001
#c 3
#% 156186
#% 197394
#% 269218
#% 290482
#! The standardized visual field assessment, which measures visual function in 76 locations of the central visual area, is an important diagnostic tool in the treatment of the eye disease glaucoma. It helps determine whether the disease is stable or progressing towards blindness, with important implications for treatment. Automatic techniques to classify patients based on this assessment have had limited success, primarily due to the high variability of individual visual field measurements. The purpose of this paper is to describe the problem of visual field classification to the data mining community, and assess the success of data mining techniques on it. Preliminary results show that machine learning methods rival existing techniques for predicting whether glaucoma is progressing--though we have not yet been able to demonstrate improvements that are statistically significant. It is likely that further improvement is possible, and we encourage others to work on this important practical data mining problem.

#index 501963
#* Sequential Index Structure for Content-Based Retrieval
#@ Maciej Zakrzewicz
#t 2001
#c 3
#% 317933
#% 321455
#% 427199
#% 463903
#% 466953
#! Data mining applied to databases of data sequences generates a number of sequential patterns, which often require additional processing. The post-processing usually consists in searching the source databases for data sequences which contain a given sequential pattern or a part of it. This type of content-based querying is not well supported by RDBMSs, since the traditional optimization techniques are focused on exact-match querying. In this paper, we introduce a new bitmap-oriented index structure, which efficiently optimizes content-based queries on dense databases of data sequences. Our experiments show a significant improvement over traditional database accessing methods.

#index 501964
#* A Rough Set-Based Clustering Method with Modification of Equivalence Relations
#@ Shoji Hirano;Tomohiro Okuzaki;Yutaka Hata;Shusaku Tsumoto;Kouhei Tsumoto
#t 2001
#c 3
#% 366687
#% 374537
#! This paper presents a clustering method for nominal and numerical data based on rough set theory. We represent relative similarity between objects as a weighted sum of two types of distances: the Hamming distance for nominal data and the Mahalanobis distance for numerical data. On assigning initial equivalence relations to every object, modification of slightly different equivalence relations is performed to suppress excessive generation of categories. The optimal clustering result can be obtained by evaluating the cluster validity over all clusters generated with various values of similarity thresholds. After classification has been performed, features of each class are extracted based on the concept of value reduct. Experimental results on artificial data and amino acid data show that this method can deal well with both types of attributes.

#index 501965
#* Direct Domain Knowledge Inclusion in the PA3 Rule Induction Algorithm
#@ Pedro de Almeida
#t 2001
#c 3
#% 126854
#% 376266
#% 443158
#% 446083
#% 700605
#% 1290045
#% 1860303
#! Inclusion of domain knowledge in a process of knowledge discovery in databases is a complex but very important part of successful knowledge discovery solutions. In real-life data mining development, nonstructured domain knowledge involvement in the data preparation phase and in the final interpretation/evaluation phase tends to dominate. This paper presents an experiment of direct domain knowledge integration in the algorithm that will search for interesting patterns in the data. In the context of stock market prediction work, a recent rule induction algorithm, PA3, was adapted to include domain theories directly in the internal rule development. Tests performed over several Portuguese stocks show a significant increase in prediction performance over the same process using the standard version of PA3. We believe that a similar methodology can be applied to other symbolic induction algorithms and in other working domains to improve the efficiency of prediction (or classification) in knowledge-intensive data mining tasks.

#index 501966
#* Semantic Expectation-Based Causation Knowledge Extraction: A Study on Hong Kong Stock Movement Analysis
#@ Boon Toh Low;Ki Chan;Lei-Lei Choi;Man-Yee Chin;Sin-Ling Lay
#t 2001
#c 3
#% 45624
#% 566038
#% 814969
#% 814972
#! Human beings generally analyze information with some kinds of semantic expectations. This not only speeds up the processing time, it also helps to put the analysis in the correct context and perspective. To capitalize on this type of intelligent human behavior, this paper proposes a semantic expectation-based knowledge extraction methodology (SEKE) for extracting causation relations from text. In particular, we study the application of a causation semantic template on the Hong Kong Stock market movement (Hang Seng Index) with English financial news from Reuters, South China Morning Post and Hong Kong Standard. With one-month data input and over a two-month testing period, the system shows that it can correctly analyzes single reason sentences with about 76% precision and 74% recall rates. If partial reason extraction (two out of one reason) is included and weighted by a factor of 0.5, the performance is improved to about 83% and 81% respectively. As the proposed framework is language independent, we expect cross lingual knowledge extraction can work better with this semantic expectation-based framework.

#index 501967
#* An Efficient Data Compression Approach to the Classification Task
#@ Claudia Diamantini;Maurizio Panti
#t 2001
#c 3
#% 92533
#% 114667
#% 246831
#% 269217
#% 280460
#% 280481
#% 338591
#% 420054
#% 443743
#% 1860299
#! The paper illustrates a data compression approach to classification, based on a stochastic gradient algorithm for the minimization of the average misclassification risk performed by a Labeled Vector Quantizer. The main properties of the approach can be summarized in terms of both the efficiency of the learning process, and the efficiency and accuracy of the classification process. The approach is compared with the strictly related nearest neighbor rule, and with two data reduction algorithms, SVM and IB2, on a set of real data experiments taken from the UCI repository.

#index 501968
#* Neighborhood Dependencies for Prediction
#@ Renaud Bassée;Jef Wijsen
#t 2001
#c 3
#% 210160
#% 227953
#% 280449
#% 290482
#% 316709
#% 384978
#! We introduce the construct of neighborhood dependency (ND) to express regularities like: "Families with similar size and income, tend to own cars of similar size." Arguably, the discovery of such regularities is useful for prediction purposes. We have implemented and tested an algorithm for mining NDs. The discovered NDs are then used in the P-neighborhood method to predict unknown values.

#index 501969
#* An Improved Learning Algorithm for Augmented Naive Bayes
#@ Huajie Zhang;Charles X. Ling
#t 2001
#c 3
#% 156186
#% 246832
#! Data mining applications require learning algorithms to have high predictive accuracy, scale up to large datasets, and produce comprehensible outcomes. Naive Bayes classifier has received extensive attention due to its efficiency, reasonable predictive accuracy, and simplicity. However, the assumption of attribute dependency given class of Naive Bayes is often violated, producing incorrect probability that can affect the success of data mining applications. We extend Naive Bayes classifier to allow certain dependency relations among attributes. Comparing to previous extensions of Naive Bayes, our algorithm is more efficient (more so in problems with a large number of attributes), and produces simpler dependency relation for better comprehensibility, while maintaining very similar predictive accuracy.

#index 501970
#* Mining E-Commerce Data: The Good, the Bad, and the Ugly
#@ Ron Kohavi
#t 2001
#c 3
#! Electronic commerce provides all the right ingredients for successful data mining (the Good). Web logs, however, are at a very low granularity level, and attempts to mine e-commerce data using only web logs often result in little interesting insight (the Bad). Getting the data into minable formats requires significant pre-processing and data transformations (the Ugly). In the ideal e-commerce architecture, high level events are logged, transformations are automated, and data mining results can easily be understood by business people who can take action quickly and efficiently. Lessons, stories, and challenges based on mining real data at Blue Martini Software will be presented.

#index 501971
#* Applying Pattern Mining to Web Information Extraction
#@ Chia-Hui Chang;Shao-Chen Lui;Yen-Chin Wu
#t 2001
#c 3
#% 115467
#% 232650
#% 235941
#% 240955
#% 271065
#% 273925
#% 275915
#! Information extraction (IE) from semi-structured Web documents is a critical issue for information integration systems on the Internet. Previous work in wrapper induction aim to solve this problem by applying machine learning to automatically generate extractors. For example, WIEN, Stalker, Softmealy, etc. However, this approach still requires human intervention to provide training examples. In this paper, we propose a novel idea to IE, by repeated pattern mining and multiple pattern alignment. The discovery of repeated patterns are realized through a data structure call PAT tree. In addition, incomplete patterns are further revised by pattern alignment to comprehend all pattern instances. This new track to IE involves no human effort and content-dependent heuristics. Experimental results show that the constructed extraction rules can achieves 97 percent extraction over fourteen popular search engines.

#index 501972
#* Mining Sequence Patterns from Wind Tunnel Experimental Data for Flight Control
#@ Zhenyu Liu;Wesley W. Chu;Adam Huang;Chris Folk;Chih-Ming Ho
#t 2001
#c 3
#% 232136
#% 232147
#% 286670
#% 458756
#% 459006
#% 459008
#% 503866
#% 545884
#% 632088
#! This paper presents a sequence pattern mining technique to mine data generated from a wind tunnel experiment. The goal is to discover the nonlinear input-output relationship for a delta wing aircraft. In contrast to categorical datasets, the output variable(s) in this dataset is continuous and takes distinct values, which is common in physical experiments. Directly applying existing decision tree or rule induction mining methods fails to discover sufficient knowledge. Therefore, we propose to extend current techniques by constructing sequence patterns that represent the output variations in certain ranges of selective inputs. Similar sequence patterns are clustered based on a weighted variance measure. Rules can then be derived from similar sequences to predict the output. This technique has been applied to the experimental data and generates rules useful for flight control.

#index 501973
#* Feature Selection for Meta-learning
#@ Alexandros Kalousis;Melanie Hilario
#t 2001
#c 3
#% 92542
#% 126842
#% 169653
#% 191910
#% 243728
#% 385564
#% 420065
#% 449588
#% 459716
#% 466722
#% 478107
#% 478269
#% 565970
#% 637522
#% 661322
#% 1051405
#% 1273390
#% 1274562
#! The selection of an appropriate inducer is crucial for performing effective classification. In previous work we presented a system called NOEMON which relied on a mapping between dataset characteristics and inducer performance to propose inducers for specific datasets. Instance-based learning was applied to meta-learning problems, each one associated with a specific pair of inducers. The generated models were used to provide a ranking of inducers on new datasets. Instance-based learning assumes that all the attributes have the same importance. We discovered that the best set of discriminating attributes is different for every pair of inducers.We applied a feature selection method on the meta-learning problems, to get the best set of attributes for each problem. The performance of the system is significantly improved.

#index 501974
#* Generating Frequent Patterns with the Frequent Pattern List
#@ Fan-Chen Tseng;Ching-Chi Hsu
#t 2001
#c 3
#% 227917
#% 227919
#% 300120
#% 316709
#% 443164
#% 463903
#% 481290
#% 481754
#% 481779
#! The generation of frequent patterns (or frequent itemsets) has been studied in various areas of data mining. Most of the studies take the Apriori-based generation-and-test approach, which is computationally costly in the generation of candidate frequent patterns. Methods like frequent pattern trees has been utilized to avoid candidate set generation, but they work with more complicated data structures. In this paper, we propose another approach to mining frequent patterns without candidate generation. Our approach uses a simple linear list called Frequent Pattern List (FPL). By performing simple operations on FPLs, we can discover frequent patterns easily. Two algorithms, FPL-Construction and FPL-Mining, are proposed to construct the FPL and generate frequent patterns from the FPL, respectively.

#index 501975
#* Text Categorization Using Weight Adjusted k-Nearest Neighbor Classification
#@ Eui-Hong Han;George Karypis;Vipin Kumar
#t 2001
#c 3
#% 36672
#% 52784
#% 67565
#% 136350
#% 140588
#% 169659
#% 169718
#% 169777
#% 190429
#% 229972
#% 280817
#% 304423
#% 458379
#% 710542
#! Text categorization presents unique challenges due to the large number of attributes present in the data set, large number of training samples, attribute dependency, and multi-modality of categories. Existing classification techniques have limited applicability in the data sets of these natures. In this paper, we present a Weight Adjusted k-Nearest Neighbor (WAKNN) classification that learns feature weights based on a greedy hill climbing technique. We also present two performance optimizations of WAKNN that improve the computational performance by a few orders of magnitude, but do not compromise on the classification quality. We experimentally evaluated WAKNN on 52 document data sets from a variety of domains and compared its performance against several classification algorithms, such as C4.5, RIPPER, Naive-Bayesian, PEBLS and VSM. Experimental results on these data sets confirm that WAKNN consistently outperforms other existing classification algorithms.

#index 501976
#* Generalised RBF Networks Trained Using an IBL Algorithm for Mining Symbolic Data
#@ Liviu Vladutu;Stergios Papadimitriou;Severina Mavroudi;Anastasios Bezerianos
#t 2001
#c 3
#% 5182
#% 211820
#% 266882
#% 418113
#% 1272304
#% 1477200
#! The application of neural networks to domains involving prediction and classification of symbolic data requires a reconsideration and a careful definition of the concept of distance between patterns. Traditional distances are inadequate to access the differences between the symbolic patterns. This work proposes the utilization of a statistically extracted distance measure in the context of Generalized Radial Basis Function (GRBF) networks. The main properties of the GRBF networks are retained in the new metric space. The regularization potential of these networks can be realized with this type of distance. Furthermore, the recent engineering of neural networks offers effective solutions for learning smooth functionals that lie on high dimensional spaces.

#index 501977
#* Mining Interesting Rules in Meningitis Data by Cooperatively Using GDT-RS and RSBR
#@ Ning Zhong;Juzhen Dong
#t 2002
#c 3
#% 129980
#% 232136
#% 366687
#% 382077
#% 498104
#% 498299
#! This paper describes an application of two rough sets based systems, namely GDT-RS and RSBR respectively, for mining if-then rules in a meningitis dataset. GDT-RS (Generalized Distribution Table and Rough Set) is a soft hybrid induction system, and RSBR (Rough Sets with Boolean Reasoning) is used for discretization of real valued attributes as a preprocessing step realized before the GDT-RS starts. We argue that discretization of continuous valued attributes is an important pre-processing step in the rule discovery process. We illustrate the quality of rules discovered by GDT-RS is strongly affected by the result of discretization.

#index 501978
#* A Method to Boost Naïve Bayesian Classifiers
#@ Lili Diao;Keyun Hu;Yuchang Lu;Chunyi Shi
#t 2002
#c 3
#% 209021
#% 235377
#% 311034
#! In this paper, we introduce a new method to improve the performance of combining boosting and na茂ve Bayesian. Instead of combining boosting and Na茂ve Bayesian learning directly, which was proved to be unstatisfactory to improve performance, we select the training samples dynamically by bootstrap method for the construction of na茂ve Bayesian classifiers, and hence generate very different or unstable base classifiers for boosting. Besides, we devise a modification for the weight adjusting of boosting algorithm in order to achieve this goal: minimizing the overlapping errors of its constituent classfiers. We conducted series of experiments, which show that the new method not only has performance much better than na茂ve Bayesian classifiers or directly boosted na茂ve Bayesian ones, but also much quicker to obtain optimal performance than boosting stumps and boosting decision trees incorporated with na茂ve Bayesian learning.

#index 501979
#* An Improved Approach for the Discovery of Causal Models via MML
#@ Honghua Dai;Gang Li
#t 2002
#c 3
#% 16269
#% 44876
#% 67866
#% 101217
#% 197387
#% 1271903
#! Discovering a precise causal structure accurately reflecting the given data is one of the most essential tasks in the area of data mining and machine learning. One of the successful causal discovery approaches is the information-theoretic approach using the Minimum Message Length Principle[19]. This paper presents an improved and further experimental results of the MML discovery algorithm. We introduced a new encoding scheme for measuring the cost of describing the causal structure. Stiring function is also applied to further simplify the computational complexity and thus works more efficiently. The experimental results of the current version of the discovery system show that: (1) the current version is capable of discovering what discovered by previous system; (2) current system is capable of discovering more complicated causal models with large number of variables; (3) the new version works more efficiently compared with the previous version in terms of time complexity.

#index 501980
#* Optimal Algorithms for Finding User Access Sessions from Very Large Web Logs
#@ Zhixiang Chen;Ada Wai-Chee Fu;Frank Chi-Hung Tong
#t 2002
#c 3
#% 186340
#% 214673
#% 255208
#% 266283
#% 275360
#% 443194
#% 504568
#% 552181
#% 571039
#% 584891
#! Although efficient identification of user access sessions from very large web logs is an unavoidable data preparation task for the success of higher level web log mining, little attention has been paid to algorithmic study of this problem. In this paper we consider two types of user access sessions, interval sessions and gap sessions. We design two efficient algorithms for finding respectively those two types of sessions with the help of new data structures. We present both theoretical and empirical analysis of the algorithms and prove that both algorithms have optimal time complexity.

#index 501981
#* User Profiling for Intrusion Detection Using Dynamic and Static Behavioral Models
#@ Dit-Yan Yeung;Yuxin Ding
#t 2002
#c 3
#% 18528
#% 188076
#% 259519
#% 272632
#% 289519
#% 328112
#% 549290
#% 583730
#% 664547
#% 978636
#% 1275294
#! Intrusion detection has emerged as an important approach to network security. In this paper, we adopt an anomaly detection approach by detecting possible intrusions based on user profiles built from normal usage data. In particular, user profiles based on Unix shell commands are modeled using two different types of behavioral models. The dynamic modeling approach is based on hidden Markov models (HMM) and the principle of maximum likelihood, while the static modeling approach is based on event occurrence frequency distributions and the principle of minimum cross entropy. The novelty detection approach is adopted to estimate the model parameters using normal training data only. To determine whether a certain behavior is similar enough to the normal model and hence should be classified as normal, we use a scheme that can be justified from the perspective of hypothesis testing. Our experimental results show that static modeling outperforms dynamic modeling for this application. Moreover, the static modeling approach based on cross entropy is similar in performance to instance-based learning reported previously by others for the same dataset but with much higher computational and storage requirements than our method.

#index 501982
#* An Efficient Single-Scan Algorithm for Mining Essential Jumping Emerging Patterns for Classification
#@ Hongjian Fan;Kotagiri Ramamohanarao
#t 2002
#c 3
#% 280409
#% 300120
#% 310550
#% 546047
#! Emerging patterns (EPs), namely itemsets whose supports change significantly from one class to another, were recently proposed to capture multi-attribute contrasts between data classes, or trends over time. Previous studies show that EP/JEP(jumping emerging patterns) - based classifiers such as CAEP[2] and JEP-classifier[6] have good overall predictive accuracy. But they suffer from the huge number of mined EPs/JEPs, which makes the classifiers complex.In this study, we propose a special type of EP, essential jumping emerging patterns (eJEPs), which are believed to be high quality patterns with the most differentiating power and thus are sufficient for building accurate classifiers. Existing algorithms such as border-based algorithms and consEPMiner[7] can not directly mine such eJEPs. We present a new single-scan algorithm to effectively mine eJEPs of both data classes (both directions). Experimental results show that the classifier based exclusively on eJEPs, which uses much fewer JEPs than JEP-classifier, achieves the same or higher testing accuracy and is often also superior to other state-of-the-art classification systems such as C4.5a nd CBA.

#index 501983
#* Interactive Construction of Classification Rules
#@ Jianchao Han;Nick Cercone
#t 2002
#c 3
#% 172812
#% 217561
#% 310517
#% 310531
#% 725448
#! We introduce an interactive classifier construction system, CVizT, in which the entire process is visualized based on a multidimensional visualization technique, Table Lens. The CVizT system is a fully interactive approach. The appropriate visualization-based interaction capabilities are provided for the user to include human perception into the construction process. Our experiments with data sets from the UCI repository demonstrates that the CVizT system is straightforward and easily learned. The user's preference and domain knowledge can also be integrated into the construction process.

#index 501984
#* Mining Relationship Graphs for Effective Business Objectives
#@ Kok-Leong Ong;Wee Keong Ng;Ee-Peng Lim
#t 2002
#c 3
#% 420117
#% 481290
#% 585954
#% 661023
#! Modern organization has two types of customer profiles: active and passive. Active customers contribute to the business goals of an organization, while passive customers are potential candidates that can be converted to active ones. Existing KDD techniques focused mainly on past data generated by active customers. The insights discovered apply well to active ones but may scale poorly with passive customers. This is because there is no attempt to generate know-how to convert passive customers into active ones. We propose an algorithm to discover relationship graphs using both types of profile. Using relationship graphs, an organization can be more effective in realizing its goals.

#index 501985
#* GEC: An Evolutionary Approach for Evolving Classifiers
#@ William W. Hsu;Ching-Chi Hsu
#t 2002
#c 3
#% 114994
#% 160830
#% 232106
#% 471428
#% 689505
#! Using an evolutionary approach for evolving classifiers can simplify the classification task. It requires no domain knowledge of the data to be classified nor the requirement to decide which attribute to select for partitioning. Our method, called the Genetic Evolved Classifier (GEC), uses a simple structured genetic algorithm to evolve classifiers. Besides being able to evolve rules to classify data in to multi-classes, it also provides a simple way to partition continuous data into discrete intervals, i.e., transform all types of attribute values into enumerable types. Experiment results shows that our approach produces promising results and is comparable to methods like C4.5, Fuzzy-ID3 (F-ID3), and probabilistic models such as modified Na茂ve-Bayesian classifiers.

#index 501986
#* M-FastMap: A Modified FastMap Algorithm for Visual Cluster Validation in Data Mining
#@ Michael K. Ng;Joshua Zhexue Huang
#t 2002
#c 3
#% 32926
#% 33306
#% 36672
#% 80995
#% 176971
#% 201893
#% 248792
#% 420057
#% 420081
#% 481281
#% 501678
#% 511800
#% 631984
#% 1200254
#! This paper presents M-FastMap, a modified FastMap algorithm for visual cluster validation in data mining. In the visual cluster validation with FastMap, clusters are first generated with a clustering algorithm from a database. Then, the FastMap algorithm is used to project the clusters onto a 2-dimensional (2D) or 3-dimensional (3D) space and the clusters are visualized with different colors and/or symbols on a 2D (or 3D) display. From the display a human can visually examine the separation of clusters. This method follows the principle that if a cluster is separate from others in the projected 2D (or 3D) space, it is also separate from others in the original high dimensional space (the opposite is not true). The modified FastMap algorithm improves the quality of visual cluster validation by optimizing the separation of clusters on the 2D or (3D) space in the selection of pivot objects (or projection axis). The comparison study has shown that the modified FastMap algorithm can produce better visualization results than the original FastMap algorithm.

#index 501987
#* Discovering Numeric Association Rules via Evolutionary Algorithm
#@ Jacinto Mata Vázquez;José Luis Álvarez Macías;José Cristóbal Riquelme Santos
#t 2002
#c 3
#% 152934
#% 201894
#% 210160
#% 227953
#% 280458
#% 300120
#% 369236
#% 459020
#% 481290
#% 481754
#! Association rules are one of the most used tools to discover relationships among attributes in a database. Nowadays, there are many efficient techniques to obtain these rules, although most of them require that the values of the attributes be discrete. To solve this problem, these techniques discretize the numeric attributes, but this implies a loss of information. In a general way, these techniques work in two phases: in the first one they try to find the sets of attributes that are, with a determined frequency, within the database (frequent itemsets), and in the second one, they extract the association rules departing from these sets. In this paper we present a technique to find the frequent itemsets in numeric databases without needing to discretize the attributes. We use an evolutionary algorithm to find the intervals of each attribute that conforms a frequent itemset. The evaluation function itself will be the one that decide the amplitude of these intervals. Finally, we evaluate the tool with synthetic and real databases to check the efficiency of our algorithm.

#index 501988
#* Enhancing Effectiveness of Outlier Detections for Low Density Patterns
#@ Jian Tang;Zhixiang Chen;Ada Wai-Chee Fu;David Wai-Lok Cheung
#t 2002
#c 3
#% 201876
#% 210173
#% 248790
#% 300136
#% 300183
#% 420064
#% 479791
#% 479799
#% 479986
#% 481281
#! Outlier detection is concerned with discovering exceptional behaviors of objects in data sets.It is becoming a growingly useful tool in applications such as credit card fraud detection, discovering criminal behaviors in e-commerce, identifying computer intrusion, detecting health problems, etc. In this paper, we introduce a connectivity-based outlier factor (COF) scheme that improves the effectiveness of an existing local outlier factor (LOF) scheme when a pattern itself has similar neighbourhood density as an outlier. We give theoretical and empirical analysis to demonstrate the improvement in effectiveness and the capability of the COF scheme in comparison with the LOF scheme.

#index 501989
#* An Efficient Algorithm for Incremental Update of Concept Spaces
#@ Felix Cheung;Ben Kao;David Wai-Lok Cheung;Chi-Yuen Ng
#t 2002
#c 3
#% 27049
#% 115462
#% 169777
#% 185288
#% 204668
#% 227784
#% 229068
#% 387427
#! The vocabulary problem in information retrieval arises because authors and indexers often use different terms for the same concept. A thesaurus defines mappings between different but related terms. It is widely used in modern information retrieval systems to solve the vocabulary problem. Chen et al. proposed the concept space approach to automatic thesaurus construction.A concept space contains the associations between every pair of terms. Prev ious research studies show that concept space is a useful tool for helping information searchers in revising their queries in order to get better results from information retrieval systems. The construction of a concept space, however, is very computationally intensive. In this paper, we propose and evaluate an efficient algorithm for the incremental update of concept spaces. In our model, only strong associations are maintained, since they are most useful in thesauri construction. Our algorithm uses a pruning technique to avoid computing weak associations to achieve efficiency.

#index 501990
#* Incremental Extraction of Keyterms for Classifying Multilingual Documents in the Web
#@ Lee-Feng Chien;Chien-Kang Huang;Hsin-Chen Chiao;Shih-Jui Lin
#t 2002
#c 3
#% 115467
#% 232650
#% 249143
#% 262045
#% 1273824
#! With the rapid growth of the Web, there is a need of high-performance techniques for document collection and classification. The goal of our research is to develop a platform to discover English, traditional and simplified Chinese documents from the Web in the Greater China area and classify them into a large number of subject classes. Three major challenges are encountered. First, the collection (i.e., the Web) is dynamic: new documents are added in and the features of subject classes change constantly. Second, the documents should be classified in a large-scale taxonomy. Third, the collection contains documents written in different languages. A PAT-tree-based approach is developed to deal with document classification in dynamic collections. It uses PAT tree as a working structure to extract keyterms from documents in each subject class and then update the features of the class accordingly. The feedback will contribute to the classification of the incoming documents immediately. In addition, we make use of a manually-constructed keyterms to serve as the base of document classification in a large-scale taxonomy. Two sets of experiments were done to evaluate the classification performance in a dynamic collection and in a large-scale taxonomy respectively. Both of the experiments yielded encouraging results. We further suggest an approach extended from the PAT-tree-based working structure to deal with classification in multilingual documents.

#index 501991
#* Adding Personality to Information Clustering
#@ Ah-Hwee Tan;Hong Pan
#t 2002
#c 3
#% 85272
#% 118771
#% 185921
#% 219052
#! This article presents a new information management method called user-configurable clustering that integrates the flexibility of clustering systems in handling novel data and the ease of use of categorization systems in providing structure. Based on a predictive self-organizing network that performs synchronized clustering of information and preference vectors, a user can influence the clustering of information vectors by encoding his/her preferences as preference vectors. We illustrate a sample session to show how a user may create and personalize an information portfolio according to his/her preferences and how the system discovers novel information groupings while organizing familiar information according to user-defined themes.

#index 501992
#* Privacy Preserving Data Mining: Challenges and Opportunities
#@ Ramakrishnan Srikant
#t 2002
#c 3
#! The goal of privacy preserving data mining is to develop accurate models without access to precise information in individual data records, thus finessing the conflict between privacy and data mining. In this talk, I will give an introduction to the techniques underlying privacy preserving data mining, and then discuss several application domains. In particular, recent events have led to an increased interest in applying data mining toward security related problems, leading to interesting technical challenges at the intersection of privacy, security and data mining.

#index 501993
#* Automatic Information Extraction for Multiple Singular Web Pages
#@ Chia-Hui Chang;Shih-Chien Kuo;Kuo-Yu Hwang;Tsung-Hsin Ho;Chih-Lung Lin
#t 2002
#c 3
#% 235941
#% 240955
#% 271065
#% 275915
#% 330784
#! The World Wide Web is now undeniably the richest and most dense source of information, yet its structure makes it difficult to make use of that information in a systematic way. This paper extends a pattern discovery approach called IEPAD to the rapid generation of information extractors that can extract structured data from semi-structured Web documents. IEPAD is proposed to automate wrapper generation from a multiple-record Web page without user-labeled examples. In this paper, we consider another case when multiple Web pages are available but each input Web page contains only one record (called singular Web pages). To solve this case, a hierarchical multiple string alignment is proposed to allow wrapper induction for multiple singular Web pages.

#index 501994
#* Evaluation of Techniques for Classifying Biological Sequences
#@ Mukund Deshpande;George Karypis
#t 2002
#c 3
#% 235941
#% 266284
#% 280488
#% 310539
#% 376266
#! In recent years we have witnessed an exponential increase in the amount of biological information, either DNA or protein sequences, that has become available in public databases. This has been followed by an increased interest in developingcomp utational techniques to automatically classify these large volumes of sequence data into various categories corresponding to either their role in the chromosomes, their structure, and/or their function. In this paper we evaluate some of the widely-used sequence classification algorithms and develop a framework for modeling sequences in a fashion so that traditional machine learning algorithms, such as support vector machines, can be applied easily. Our detailed experimental evaluation shows that the SVM-based approaches are able to achieve higher classification accuracy compared to the more traditional sequence classification algorithms such as Markov model based techniques and K-nearest neighbor based approaches.

#index 501995
#* Distribution Discovery: Local Analysis of Temporal Rules
#@ Xiaoming Jin;Yuchang Lu;Chunyi Shi
#t 2002
#c 3
#% 1267
#% 172386
#% 232106
#% 280408
#% 459006
#% 463903
#% 479627
#% 481416
#% 487661
#% 487664
#% 630974
#! In recent years, there bas been increased interest in using data mining techniques to extract temporal rules from temporal sequences. Local temporal rules, which only a subsequence exhibits, are actually very common in practice. Efficient discovery of the time duration in which temporal rules are valid could benefit KDD of many real applications. In this paper, we present a novel problem class that is the discovery of the distribution of temporal rules. We simplify the mining problem and depict a model that could represent this knowledge clearly, uniquely and efficiently. Our methods include four online dividing strategies for different mining interest, an incremental algorithm for measuring rule-sets, and an algorithm for mining this knowledge. We have analyzed the behavior of the problem and our algorithms with both synthetic data and real data. The results correspond with the definition of our problem and reveal a kind of novel knowledge.

#index 501996
#* Mining Interesting Association Rules: A Data Mining Language
#@ Show-Jane Yen;Yue-Shi Lee
#t 2002
#c 3
#% 201894
#% 340289
#% 443448
#% 481290
#! Mining association rules is to discover customer purchasing behaviors from a transaction database, such that the quality of business decision can be improved. However, the size of the transaction database can be very large. It is very time consuming to find all the association rules from a large database, and users may be only interested in some information. Hence, a data mining language needs to be provided such that users can query only interesting knowledge to them from a large database of customer transactions. In this paper, a data mining language is presented. From the data mining language, users can specify the interested items and the criteria of the association rules to be discovered. Also, the efficient data mining techniques are proposed to extract the association rules according to the user requirements.

#index 501997
#* On the Efficiency of Association-Rule Mining Algorithms
#@ Vikram Pudi;Jayant R. Haritsa
#t 2002
#c 3
#% 273898
#% 300124
#% 314053
#% 342643
#% 462219
#% 481290
#% 481754
#% 481758
#% 487512
#! In this paper, we first focus our attention on the question of how much space remains for performance improvement over current association rule mining algorithms. Our strategy is to compare their performance against an "Oracle algorithm" that knows in advance the identities of all frequent itemsets in the database and only needs to gather their actual supports to complete the mining process. Our experimental results show that current mining algorithms do not perform uniformly well with respect to the Oracle for all database characteristics and support thresholds. In many cases there is a substantial gap between the Oracle's performance and that of the current mining algorithms. Second, we present a new mining algorithm, called ARMOR, that is constructed by making minimal changes to the Oracle algorithm. ARMOR consistently performs within a factor of two of the Oracle on both real and synthetic datasets over practical ranges of support specifications.

#index 501998
#* Self-Similarity for Data Mining and Predictive Modeling - A Case Study for Network Data
#@ Jafar Adibi;Wei-Min Shen;Eaman Noorbakhsh
#t 2002
#c 3
#% 44598
#% 149237
#% 188026
#% 220801
#% 246836
#% 280482
#% 292235
#% 300160
#% 478464
#% 664599
#% 1502092
#! Recently there are a handful study and research on observing self-similarity and fractals in natural structures and scientific database such as traffic data from networks. However, there are few works on employing such information for predictive modeling, data mining and knowledge discovery. In this paper we study, analyze our experiments and observation of self-similar structure embedded in Network data for prediction through Self Similar Layered Hidden Markov Model (SSLHMM). SSLHMM is a novel alternative of Hidden Markov Models (HMM) which proven to be useful in a variety of real world applications. SSLHMM leverage HMM power and extend such capability to self-similar structures and exploit this property to reduce the complexity of predictive modeling process. We show that SSLHMM approach can captures self-similar information and provides more accurate and interpretable model comparing to conventional techniques.

#index 501999
#* Efficient Utilization of Materialized Views in a Data Warehouse
#@ Don-Lin Yang;Man-Lin Huang;Ming-Chuan Hung
#t 2002
#c 3
#% 210182
#% 210208
#% 238397
#% 268126
#% 284470
#% 300290
#% 316709
#% 334026
#% 464878
#% 479646
#% 482111
#% 617880
#% 631946
#! View Materialization is an effective method to increase query efficiency in a data warehouse. However, one encounters the problem of space insufficiency if all possible views are materialized in advance. Reducing query time by means of selecting a proper set of materialized views with a lower cost is crucial for efficient data warehousing. In addition, the costs of data warehouse creation, query, and maintenance have to be taken into account while views are materialized. The purpose of this research is to select a proper set of materialized views under the storage and cost constraints and to help speedup the entire data warehousing process. We propose a cost model for data warehouse query and maintenance along with an efficient view selection algorithm, which uses the gain and loss indices. The main contribution of our paper is to speedup the selection process of materialized views. The second one is to reduce the total cost of data warehouse query and maintenance.

#index 502000
#* Naviz: Website Navigational Behavior Visualizer
#@ Bowo Prasetyo;Iko Pramudiono;Katsumi Takahashi;Masaru Kitsuregawa
#t 2002
#c 3
#% 186341
#% 330789
#% 445742
#% 459006
#% 588670
#! Navigational behavior of Website visitors can be extracted from web access log files with data mining techniques such a sequential pattern mining. Visualization of the discovered patterns is very helpful to understand how visitors navigate over the various pages on the site. Currently several web log visulization tools have been developed. However those tools are far from satisfactory. They do not provide global view of visitor access as well as individual traversal path effertively. Here we introduce Naviz, a system of interactive web log visulization that is designed to overcome those drawbacks. It combines two-dimensional graph of visitor access traversals that considers appropriate web traversal properties, i.e. hierarchization regarding traversal traffic and grouping of related pages, and facilities for filtering traversal paths by specifying visited pages and path attributes, such as number of hops, support and confidence. The tool also provides support for modern dynamic web pages. we apply the tool to visualize results of data mining study on web log data of Mobile Townpage, a directory service of phone numbers in Japan for i-Mode mobile internet users. The results indicate that our system can easily handle thousands of discovered ptterns to discover interesting navigational behavior such as success paths, exit paths and lost paths.

#index 502121
#* Efficient Algorithms for Incremental Update of Frequent Sequences
#@ Minghua Zhang;Ben Kao;David Wai-Lok Cheung;Chi Lap Yip
#t 2002
#c 3
#% 152934
#% 259993
#% 280467
#% 287242
#% 459006
#% 463903
#% 464204
#% 464996
#% 489397
#% 511333
#% 589303
#! Most of the works proposed so far on mining frequent sequences assume that the underlying database is static. However, in real life, the database is modified from time to time. This paper studies the problem of incremental update of frequent sequences when the database changes. We propose two efficient incremental algorithms GSP+ and MFS+. Throught experiments, we compare the performance of GSP+ and MFS+ with GSP and MFS -- two efficient algorithms for mining frequent sequences. We show that GSP+ and MFS+ effectively reduce the CPU costs of their counterparts with only a small or even negative additional expense on I/O cost.

#index 502122
#* On Data Clustering Analysis: Scalability, Constraints, and Validation
#@ Osmar R. Zaïane;Andrew Foss;Chi-Hoon Lee;Weinan Wang
#t 2002
#c 3
#% 58646
#% 104472
#% 203462
#% 210173
#% 248790
#% 248792
#% 273890
#% 316709
#% 361966
#% 420081
#% 430746
#% 438137
#% 464890
#% 465004
#% 478277
#% 479799
#% 481281
#% 481413
#% 566699
#% 631985
#% 1011582
#! Clustering is the problem of grouping data based on similarity. While this problem has attracted the attention of many researchers for many years, we are witnessing a resurgence of interest in new clustering techniques. In this paper we discuss some very recent clustering approaches and recount our experience with some of these algorithms. We also present the problem of clustering in the presence of constraints and discuss the issue of clustering validation.

#index 502123
#* Efficient Rule Retrieval and Postponed Restrict Operations for Association Rule Mining
#@ Jochen Hipp;Christoph Mangold;Ulrich Güntzer;Gholamreza Nakhaeizadeh
#t 2002
#c 3
#% 152934
#% 210160
#% 216500
#% 227917
#% 232108
#% 248813
#% 274146
#% 280519
#% 310520
#% 320944
#% 420100
#% 466141
#% 481758
#% 481954
#! Knowledge discovery in databases is a complex, iterative, and highly interactive process. When mining for association rules, typically interactivity is largely smothered by the execution times of the rule generation algorithms. Our approach is to accept a single, possibly expensive run, but all subsequent mining queries are supposed to be answered interactively by accessing a sophisticated rule cache. However there are two critical aspects. First, access to the cache must be efficient and comfortable. Therefore we enrich the basic association mining framework by descriptions of items through application dependent attributes. Furthermore we extend current mining query languages to deal with these attributes through 驴 and 驴 quantifiers. Second, the cache must be prepared to answer a broad variety of queries without rerunning the mining algorithm. A main contribution of this paper is that we show how to postpone restrict operations on the transactions from rule generation to rule retrieval from the cache. That is, without actually rerunning the algorithm, we efficiently construct those rules from the cache that would have been generated if the mining algorithm were run on only a subset of the transactions. In addition we describe how we implemented our ideas on a conventional relational database system. We evaluate our prototype concerning response times in a pilot application at DaimlerChrysler. It turns out to satisfy easily the demands of interactive data mining.

#index 502124
#* Efficient Constraint-Based Exploratory Mining on Large Data Cubes
#@ Cuiping Li;Shengen Li;Shan Wang;Xiaoyong Du
#t 2002
#c 3
#% 210182
#% 248785
#% 248807
#% 459025
#% 464989
#% 479957
#% 480630
#% 480820
#% 481588
#% 570891
#% 631970
#! Analysts often explore data cubes to identify anomalous regions that may represent problem areas or new opportunities. Discovery-driven exploration (proposed by S. Sarawagi et al [5]) automatically detects and marks the exceptions for the user and reduces the reliance on manual discovery. However, when the data is large, it is hard to materialize the whole cube due to the limitations of both space and time. So, exploratory mining on complete cube cells needs to construct the data cube dynamically. That will take a very long time. In this paper, we investigate optimization methods by pushing several constraints into the mining process. By enforcing several user-defined constraints, we first restrict the multidimensional space to a small constrained-cube and then mine exceptions on it. Two efficient constrained-cube construction algorithms, the NAIVE algorithm and the AGOA algorithm, were proposed. Experimental results indicate that this kind of constraint-based exploratory mining method is efficient and scalable.

#index 502125
#* Adaptive Generalized Estimation Equation with Bayes Classifier for the Job Assignment Problem
#@ Yulan Liang;King-Ip Lin;Arpad Kelemen
#t 2002
#c 3
#% 116149
#% 197394
#% 316709
#% 466087
#% 551723
#! We propose combining advanced statistical approaches with data mining techniques to build classifiers to enhance decision-making models for the job assignment problem. Adaptive Generalized Estimation Equation (AGEE) approaches with Gibbs sampling under Bayesian framework and adaptive Bayes classifiers based on the estimations of AGEE models which uses modified Naive Bayes algorithm are proposed. The proposed classifiers have several important features. Firstly, it accounts for the correlation among the outputs and the indeterministic subjective noise into the estimation of parameters. Secondly, it reduces the number of attributes used to predict the class. Moreover, it drops the assumption of independence made by the Naive Bayes classifier. We apply our techniques to the problem of assigning jobs to Navy officers, with the goal of enhancing happiness for both the Navy and the officers. The classification results were compared with nearest neighbor, Multi-Layer Perceptron and Support Vector Machine approaches.

#index 502126
#* A Function-Based Classifier Learning Scheme Using Genetic Programming
#@ Jung-Yi Lin;Been-Chian Chien;Tzung-Pei Hong
#t 2002
#c 3
#% 110936
#% 124073
#% 183492
#% 207002
#% 231244
#% 249662
#% 266823
#% 282854
#% 449588
#% 710542
#% 1776231
#% 1776343
#% 1777076
#% 1777130
#% 1781055
#% 1809513
#% 1860187
#! Classification is an important research topic in knowledge discovery and data mining. Many different classifiers have been motivated and developed of late years. In this paper, we propose an effective scheme for learning multicategory classifiers based on genetic programming. For a k-class classification problem, a training strategy called adaptive incremental learning strategy and a new fitness function are used to generate k discriminant functions. We urge the discriminant functions to map the domains of training data into a specified interval, and thus data will be assigned into one of the classes by the values of functions. Furthermore, a Z-value measure is developed for resolving the conflicts. The experimental results show that the proposed GP-based classification learning approach is effective and performs a high accuracy of classification.

#index 502127
#* DELISP: Efficient Discovery of Generalized Sequential Patterns by Delimited Pattern-Growth Technology
#@ Ming-Yen Lin;Suh-Yin Lee;Sheng-Shun Wang
#t 2002
#c 3
#% 236697
#% 310559
#% 316552
#% 329537
#% 420063
#% 459006
#% 463903
#% 464996
#% 477791
#% 479971
#% 501216
#! An active research in data mining is the discovery of sequential patterns, which finds all frequent sub-sequences in a sequence database. Most of the studies specify no time constraints such as maximum/minimum gaps between adjacent elements of a pattern in the mining so that the resultant patterns may be uninteresting. In addition, a data sequence containing a pattern is rigidly defined as only when each element of the pattern is contained in a distinct element of the sequence. This limitation might lose useful patterns for some applications because sometimes items of an element might be spread across adjoining elements within a specified time period or time window. Therefore, we propose a pattern-growth approach for mining the generalized sequential patterns. Our approach features in reducing the size of sub-databases by bounded and windowed projection techniques. Bounded projections keep only time-gap valid sub-sequences and windowed projections save non-redundant sub-sequences satisfying the sliding time window constraint. Furthermore, the delimited growth technique directly generates constraint-satisfactory patterns and speeds up the growing process. The empirical evaluations show that the proposed approach has good linear scalability and outperforms the well-known GSP algorithm in the discovery of generalized sequential patterns.

#index 502128
#* A New Mechanism of Mining Network Behavior
#@ Shun-Chieh Lin;Shian-Shyong Tseng;Yao-Tsung Lin
#t 2002
#c 3
#% 36672
#% 463903
#! In this work, a new mechanism, which consists of Preprocessing Phase, Two-Layer Pattern Discovering Phase (2LPD), and Pattern Explanation Phase, is proposed to discover unknown patterns. Two heuristics are proposed to detect outlier users in 2LPD Phase. Next, we are also concerned about subsequences of user's behaviors in this phase. As the patterns which are previously unknown have been discovered in 2LPD Phase, they will be incrementally feedbacked to knowledge base for further detection. Through this incremental learning mechanism, the known patterns can be increased.

#index 502129
#* A Confidence-Lift Support Specification for Interesting Associations Mining
#@ Wen-Yang Lin;Ming-Cheng Tseng;Ja-Hwung Su
#t 2002
#c 3
#% 152934
#% 227917
#% 227919
#% 248012
#% 280487
#% 393792
#% 466653
#% 477957
#% 480154
#% 481588
#% 487848
#% 632029
#! Recently, the weakness of the canonical support-confidence framework for associations mining has been widely studied in the literature. One of the difficulties in applying association rules mining to real world applications is the setting of support constraint. A high support constraint avoids the combinatorial explosion in discovering frequent itemsets, but at the expense of missing interesting patterns of low support. Instead of seeking the way for setting the appropriate support constraint, all current approaches leave the users in charge of the support setting, which, however, puts the users in a dilemma. This paper is an effort to answer this long-standing open question. Based on the notion of confidence and lift measures, we propose an automatic support specification for mining high confidence and positive lift associations without consulting the users. Experimental results show that this specification is good at discovering the low support, but high confidence and positive lift associations, and is effective in reducing the spurious frequent itemsets.

#index 502130
#* Value Added Association Rules
#@ Tsau Young Lin;Y. Y. Yao;Eric Louie
#t 2002
#c 3
#% 248785
#% 366687
#% 418139
#% 447910
#% 474159
#% 474170
#% 998745
#! Value added product is an industrial term referring a minor addition to some major products. In this paper, we borrow the term to denote a minor semantic addition to the well known association rules. We consider the addition of numerical values to the attribute values, such as sale price, profit, degree of fuzziness, level of security and so on. Such additions lead to the notion of random variables (as added value to attributes) in the data model and hence the probabilistic considerations of data mining.

#index 502131
#* SNNB: A Selective Neighborhood Based Naïve Bayes for Lazy Learning
#@ Xie Zhipeng;Wynne Hsu;Liu Zongtian;Mong-Li Lee
#t 2002
#c 3
#% 136350
#% 246243
#% 246831
#% 321059
#% 458372
#% 1476310
#% 1499572
#% 1650277
#% 1811362
#! Na茂ve Bayes is a probability-based classification method which is based on the assumption that attributes are conditionally mutually independent given the class label. Much research has been focused on improving the accuracy of Na茂ve Bayes via eager learning. In this paper, we propose a novel lazy learning algorithm, Selective Neighbourhood based Na茂ve Bayes (SNNB). SNNB computes different distance neighborhoods of the input new object, lazily learns multiple Na茂ve Bayes classifiers, and uses the classifier with the highest estimated accuracy to make decision. The results of our experiments on 26 datasets show that our proposed SNNB algorithm is efficient and it outperforms Na茂ve Bayes, and state-of-the-art classification methods NBTree, CBA, and C4.5 in terms of accuracy.

#index 502132
#* Pruning Redundant Association Rules Using Maximum Entropy Principle
#@ Szymon Jaroszewicz;Dan A. Simovici
#t 2002
#c 3
#% 152934
#% 280433
#% 280436
#% 280458
#% 310496
#% 477784
#% 478594
#% 998772
#% 1272359
#! Data mining algorithms produce huge sets of rules, practically impossible to analyze manually. It is thus important to develop methods for removing redundant rules from those sets. We present a solution to the problem using the Maximum Entropy approach. The problem of efficiency of Maximum Entropy computations is addressed by using closed form solutions for the most frequent cases. Analytical and experimental evaluation of the proposed technique indicates that it efficiently produces small sets of interesting association rules.

#index 502133
#* WebFrame: In Pursuit of Computationally and Cognitively Efficient Web Mining
#@ Tong Zheng;Yonghe Niu;Randy Goebel
#t 2002
#c 3
#% 28144
#% 195970
#% 247316
#% 266283
#% 268184
#% 284823
#% 310543
#% 376343
#% 392362
#% 630984
#% 641126
#! The goal of web mining is relatively simple: provide both computationally and cognitively efficient methods for improving the value of information to users of the WWW. The need for computational efficiency is well-recognized by the data mining community, which sprung from the database community concern for efficient manipulation of large datasets. The motivation for cognitive efficiency is more elusive but at least as important. In as much as cognitive efficiency can be informally construed as ease of understanding, then what is important is any tool or technique that presents cognitively manageable abstractions of large datasets.We present our initial development of a framework for gathering, analyzing, and redeploying web data. Not dissimilar to conventional data mining, the general idea is that good use of web data first requires the careful selection of data (both usage and content data), the deployment of appropriate learning methods, and the evaluation of the results of applying the results of learning in a web application. Our framework includes tools for building, using, and visualizing web abstractions.We present an example of the deployment of our framework to navigation improvement. The abstractions we develop are called Navigation Compression Models (NCMs), and we show a method for creating them, using them, and visualizing them to aid in their understanding.

#index 502134
#* k-nearest Neighbor Classification on Spatial Data Streams Using P-trees
#@ Maleq Khan;Qin Ding;William Perrizo
#t 2002
#c 3
#% 4868
#% 310500
#% 316709
#% 346513
#% 482610
#! Classification of spatial data streams is crucial, since the training dataset changes often. Building a new classifier each time can be very costly with most techniques. In this situation, k-nearest neighbor (KNN) classification is a very good choice, since no residual classifier needs to be built ahead of time. KNN is extremely simple to implement and lends itself to a wide variety of variations. We propose a new method of KNN classification for spatial data using a new, rich, data-mining-ready structure, the Peano-count-tree (P-tree). We merely perform some AND/OR operations on P-trees to find the nearest neighbors of a new sample and assign the class label. We have fast and efficient algorithms for the AND/OR operations, which reduce the classification time significantly. Instead of taking exactly the k nearest neighbors we form a closed-KNN set. Our experimental results show closed-KNN yields higher classification accuracy as well as significantly higher speed.

#index 502135
#* The Lorenz Dominance Order as a Measure of Interestingness in KDD
#@ Robert J. Hilderman
#t 2002
#c 3
#% 340763
#% 392618
#% 452747
#% 661269
#! Ranking summaries generated from databases is useful within the context of descriptive data mining tasks where a single data set can be generalized in many different ways and to many levels of granularity. Our approach to generating summaries is based upon a data structure, associated with an attribute, called a domain generalization graph (DGG). A DGG for an attribute is a directed graph where each node represents a domain of values created by partitioning the original domain for the attribute, and each edge represents a generalization relation between these domains. Given a set of DGGs associated with a set of attributes, a generalization space can be defined as all possible combinations of domains, where one domain is selected from each DGG for each combination. This generalization space describes, then, all possible summaries consistent with the DGGs that can be generated from the selected attributes. When the number of attributes to be generalized is large or the DGGs associated with the attributes are complex, the generalization space can be very large, resulting in the generation of many summaries. The number of summaries can easily exceed the capabilities of a domain expert to identify interesting results. In this paper, we show that the Lorenz dominance order can be used to rank the summaries prior to presentation to the domain expert. The Lorenz dominance order defines a partial order on the summaries, in most cases, and in some cases, defines a total order. The rank order of the summaries represents an objective evaluation of their relative interestingness and provides the domain expert with a starting point for further subjective evaluation of the summaries.

#index 502136
#* A Case for Analytical Customer Relationship Management
#@ Jaideep Srivastava;Jau-Hwang Wang;Ee-Peng Lim;San-Yih Hwang
#t 2002
#c 3
#% 243449
#% 269634
#% 341700
#% 352846
#! The Internet has emerged as a low cost, low latency and high bandwidth customer communication channel. Its interactive nature provides an organization the ability to enter into a close, personalized dialog with individual customers. The simultaneous maturation of data management technologies like data warehousing, and data mining, have created the ideal environment for making customer relationship management (CRM) a much more systematic effort than it has been in the past. In this paper we described how data analytics can be used to make various CRM functions like customer segmentation, communication targeting, retention, and loyalty much more effective. We briefly describe the key technologies needed to implement analytical CRM, and the organizational issues that must be carefully handled to make CRM a reality. Our goal is to illustrate problems that exist with current CRM efforts, and how using data analytics techniques can address them. Our hope is to get the data mining community interested in this important application domain.

#index 502137
#* Extracting Characteristic Structures among Words in Semistructured Documents
#@ Kazuyoshi Furukawa;Tomoyuki Uchida;Kazuya Yamada;Tetsuhiro Miyahara;Takayoshi Shoudai;Yasuaki Nakamura
#t 2002
#c 3
#% 291299
#% 300120
#% 316709
#% 443349
#% 462235
#% 481290
#% 501661
#% 501667
#% 501840
#% 502140
#! Electronic documents such as SGML/HTML/XML files and LaTeX files have been rapidly increasing, by the rapid progress of network and storage technologies. Many electronic documents have no rigid structure and are called semistructured documents. Since a lot of semistructured documents contain large plain texts, we focus on the structural characteristics among words in semistructured documents. The aim of this paper is to present a text mining technique for semistructured documents. We consider a problem of finding all frequent structured patterns among words in semistructured documents. Let (W1,W2, . . . , Wk) be a list of words which are sorted in lexicographical order and let k 驴 2 be an integer. Firstly, we define a tree-association pattern on (W1,W2, ..., Wk). A tree-association pattern on (W1,W2, . . . , Wk) is a sequence 驴t1; t2; ... ; tk-1驴 of labeled rooted trees such that, for i = 1, 2, ..., k - 1, (1) ti consists of only one node having the pair of two words Wi and Wi+1 as its label, or (2) ti is a labeled rooted tree which has just two leaves labeled with Wi and Wi+1, respectively. Next, we present a text mining algorithm for finding all frequent tree-association patterns in semistructured documents. Finally, by reporting experimental results on our algorithm, we show that our algorithm is effective for extracting structural characteristics in semistructured documents.

#index 502138
#* Network Data Mining and Analysis: The NEMESIS Project
#@ Minos N. Garofalakis;Rajeev Rastogi
#t 2002
#c 3
#% 44876
#% 302725
#% 333946
#% 333954
#% 356227
#% 408396
#% 480124
#% 480306
#% 1829875
#! Modern communication networks generate large amounts of operational data, including traffic and utilization statistics and alarm/fault data at various levels of detail. These massive collections of network-management data can grow in the order of several Terabytes per year, and typically hide "knowledge" that is crucial to some of the key tasks involved in effectively managing a communication network (e.g., capacity planning and traffic engineering). In this short paper, we provide an overview of some of our recent and ongoing work in the context of the NEMESIS project at Bell Laboratories that aims to develop novel data warehousing and mining technology for the effective storage, exploration, and analysis of massive network-management data sets. We first give some highlights of our work on Model-Based Semantic Compression (MBSC), a novel data-compression framework that takes advantage of attribute semantics and data-mining models to perform lossy compression of massive network-data tables. We discuss the architecture and some of the key algorithms underlying SPARTAN, a model-based semantic compression system that exploits predictive data correlations and prescribed error tolerances for individual attributes to construct concise and accurate Classification and Regression Tree (CaRT) models for entire columns of a table. We also summarize some of our ongoing work on warehousing and analyzing network-fault data and discuss our vision of how data-mining techniques can be employed to help automate and improve fault-management in modern communication networks. More specifically, we describe the two key components of modern fault-management architectures, namely the event-correlation and the root-cause analysis engines, and propose the use of mining ideas for the automated inference and maintenance of the models that lie at the core of these components based on warehoused network data.

#index 502139
#* Clustering Large Categorical Data
#@ François-Xavier Jollois;Mohamed Nadif
#t 2002
#c 3
#% 131258
#% 196334
#% 230131
#% 420081
#! Clustering methods often come down to the optimization of a numeric criterion defined from a distance or from a dissimilarity measure. It is possible to show that this problem is often equivalent to the estimation of the parameters of a probabilistic model under the classification likelihood approach. For instance, we know that the inertia criterion optimized under the k-means algorithm corresponds to the hypothesis of a population arising from a Gaussian mixture. In this paper, we propose an adapted mixture model for categorical data. Using the classification likelihood approach, we develop the Classification EM algorithm (CEM) to estimate the parameters of the mixture model. With our probabilistic model, the data are not denatured and the estimated parameters readily indicate the characteristics of the clusters. This probabilistic approach gives an interpretation of the criterion optimized by the k-modes algorithm which is an extension of k-means to categorical attributes and allows us to study the behavior of this algorithm.

#index 502140
#* Discovery of Frequent Tag Tree Patterns in Semistructured Web Documents
#@ Tetsuhiro Miyahara;Yusuke Suzuki;Takayoshi Shoudai;Tomoyuki Uchida;Kenichi Takahashi;Hiroaki Ueda
#t 2002
#c 3
#% 47555
#% 291299
#% 312860
#% 443349
#% 462235
#% 501840
#% 501971
#% 502137
#% 548955
#! Many Web documents such as HTML files and XML files have no rigid structure and are called semistructured data. In general, such semistructuredWeb documents are represented by rooted trees with ordered children. We propose a new method for discovering frequent tree structured patterns in semistructured Web documents by using a tag tree pattern as a hypothesis. A tag tree pattern is an edge labeled tree with ordered children which has structured variables. An edge label is a tag or a keyword in such Web documents, and a variable can be substituted by an arbitrary tree. So a tag tree pattern is suited for representing tree structured patterns in such Web documents. First we show that it is hard to compute the optimum frequent tag tree pattern. So we present an algorithm for generating all maximally frequent tag tree patterns and give the correctness of it. Finally, we report some experimental results on our algorithm. Although this algorithm is not efficient, experiments show that we can extract characteristic tree structured patterns in those data.

#index 502141
#* Concise Representation of Frequent Patterns Based on Generalized Disjunction-Free Generators
#@ Marzena Kryszkiewicz;Marcin Gajek
#t 2002
#c 3
#% 232136
#% 310494
#% 316709
#% 333877
#% 338594
#% 420062
#% 466491
#% 549576
#! Frequent patterns are often used for solving data mining problems. They are applied e.g. in discovery of association rules, epsiode rules, sequential patterns and clusters. Nevertheless, the number of frequent itemsets is usually huge. In the paper, we overview briefly four lossless representations of frequent itemsets proposed recently and offer a new lossless one that is based on generalized disjunction-free generators. We prove on the theoreticl basis that the new representation is more concise than three of four preceding representations. In practice it is much more concise than the fourth representation too. An algorithm retermining the new representation is proposed.

#index 502142
#* News Sensitive Stock Trend Prediction
#@ Gabriel Pui Cheong Fung;Jeffrey Xu Yu;Wai Lam
#t 2002
#c 3
#% 172949
#% 190581
#% 269217
#% 280404
#% 280413
#% 280817
#% 287218
#% 458379
#% 1012237
#! Stock market prediction with data mining techniques is one of the most important issues to be investigated. In this paper, we present a system that predicts the changes of stock trend by analyzing the influence of non-quantifiable information (news articles). In particular, we investigate the immediate impact of news articles on the time series based on the Efficient Markets Hypothesis. Several data mining and text mining techniques are used in a novel way. A new statistical based piecewise segmentation algorithm is proposed to identify trends on the time series. The segmented trends are clustered into two categories, Rise and Drop, according to the slope of trends and the coefficient of determination. We propose an algorithm, which is called guided clustering, to filter news articles with the help of the clusters that we have obtained from trends. We also propose a new differentiated weighting scheme that assigns higher weights to the features if they occur in the Rise (Drop) news-article cluster but do not occur in its opposite Drop (Rise).

#index 502143
#* Extracting Causation Knowledge from Natural Language Texts
#@ Ki Chan;Boon Toh Low;Wai Lam;Kai-Pui Lam
#t 2002
#c 3
#% 111487
#% 459647
#% 478258
#% 501966
#% 817583
#! SEKE2 is a semantic expectation-based knowledge extraction system for extracting causation relations from natural language texts. It is inspired by capitalizing the human behavior of analyzing information with semantic expectations. The framework of SEKE2 consists of different kinds of generic templates organized in a hierarchical fashion. All kinds of templates are domain independent. They are robust and enable flexible changes for different domains and expected semantics. By associating a causation semantic template with a set of sentence templates, SEKE2 can extract causation knowledge from complex sentences without full-fledged syntactic parsing. To demonstrate the flexibility of SEKE2 for different domains, we study the application of causation semantic templates on two domain areas of news stories, namely, Hong Kong stock market movement and global warming.

#index 502144
#* Cluster-Based Algorithms for Dealing with Missing Values
#@ Yoshikazu Fujikawa;Tu Bao Ho
#t 2002
#c 3
#% 21534
#% 92537
#% 269634
#% 316709
#% 449588
#% 551615
#% 1499572
#! We first survey existing methods to deal with missing values and report the results of an experimental comparative evaluation in terms of their processing cost and quality of imputing missing values. We then propose three cluster-based mean-and-mode algorithms to impute missing values. Experimental results show that these algorithms with linear complexity can achieve comparative quality as sophisticated algorithms and therefore are applicable to large datasets.

#index 502145
#* Association Rule Mining on Remotely Sensed Images Using P-trees
#@ Qin Ding;Qiang Ding;William Perrizo
#t 2002
#c 3
#% 152934
#% 201894
#% 210160
#% 227917
#% 252304
#% 300120
#% 318051
#% 481290
#% 481588
#% 482610
#% 527021
#% 527160
#% 584926
#% 1272326
#! Association Rule Mining, originally proposed for market basket data, has potential applications in many areas. Remote Sensed Imagery (RSI) data is one of the promising application areas. Extracting interesting patterns and rules from datasets composed of images and associated ground data, can be of importance in precision agriculture, community planning, resource discovery and other areas. However, in most cases the image data sizes are too large to be mined in a reasonable amount of time using existing algorithms. In this paper, we propose an approach to derive association rules on RSI data using Peano Count Tree (P-tree) structure. P-tree structure, proposed in our previous work, provides a lossless and compressed representation of image data. Based on P-trees, an efficient association rule mining algorithm P-ARM with fast support calculation and significant pruning techniques are introduced to improve the efficiency of the rule mining process. P-ARM algorithm is implemented and compared with FP-growth and Apriori algorithms. Experimental results showed that our algorithm is superior for association rule mining on RSI spatial data.

#index 502146
#* Efficiently Mining Gene Expression Data via Integrated Clustering and Validation Techniques
#@ Vincent S. M. Tseng;Ching-Pin Kao
#t 2002
#c 3
#% 36672
#% 210173
#% 248790
#% 269534
#% 443082
#% 631985
#! In recent years, the microarray techniques have received extensive attentions due to its wide applications in biomedical industry. The main advantage of microarray technique is it allows simultaneous studies of the expressions of thousands of genes in a single experiment. Analyzing the microarray data is a challenge that arises the applications of various clustering methods used for data mining. Although a number of clustering methods have been proposed, they can not meet the requirements of automation, high quality and high efficiency at the same time in analyzing gene expression data. In this paper, we propose an automatic and efficient clustering approach for mining gene expression data produced via microarray techniques. Through performance experiments on real data sets, the proposed method is shown to achieve higher efficiency, clustering quality and automation than other clustering methods.

#index 502147
#* Top Down FP-Growth for Association Rule Mining
#@ Ke Wang;Liu Tang;Jiawei Han;Junqiang Liu
#t 2002
#c 3
#% 152934
#% 280487
#% 300120
#% 463903
#% 480154
#% 481758
#% 481779
#! In this paper, we propose an efficient algorithm, called TD-FP-Growth (the shorthand for Top-Down FP-Growth), to mine frequent patterns. TD-FP-Growth searches the FP-tree in the top-down order, as opposed to the bottom-up order of previously proposed FP-Growth. The advantage of the topdown search is not generating conditional pattern bases and sub-FP-trees, thus, saving substantial amount of time and space. We extend TD-FP-Growth to mine association rules by applying two new pruning strategies: one is to push multiple minimum supports and the other is to push the minimum confidence. Experiments show that these algorithms and strategies are highly effective in reducing the search space.

#index 502148
#* SETM*-MaxK: An Efficient SET-Based Approach to Find the Largest Itemset
#@ Ye-In Chang;Yu-Ming Hsieh
#t 2002
#c 3
#% 248813
#% 330332
#% 443082
#% 443164
#% 463883
#% 481290
#! In this paper, we propose the SETM*-MaxK algorithm to find the largest itemset based on a high-level set-based approach, where a large itemset is a set of items appearing in a sufficient number of transactions. The advantage of the set-based approach, like the SETM algorithm, is simple and stable over the range of parameter values. In the SETM*-MaxK algorithm, we efficiently find the Lk based on Lw, where Lk denotes the set of large k-itemsets with minimum support, Lk 驴 0, Lk+1 = 0 and w = 2驴log2k驴-1, instead of step by step. From our simulation, we show that the proposed SETM*-MaxK algorithm requires shorter time to achieve its goal than the SETM algorithm.

#index 564620
#* Scaling Up the Rule Generation of C4.5
#@ Zijian Zheng
#t 1998
#c 3

#index 564623
#* Mining Functional Dependency Rule of Relational Database
#@ Xiaopeng Tao;Ning Wang;Shuigeng Zhou;Aoying Zhou;Yunfa Hu
#t 1999
#c 3
#% 443082
#! This paper defines a kind of rule, functional dependency rule. The functional dependency degree of relational database can be depicted by this kind of rule. We give a algorithm to mine this kind of rule and prove some theorem to ensure the high efficiency and the correction of the algorithm. At last, we point some experiment result to support our conclusion.

#index 564627
#* A Method to Boost Support Vector Machines
#@ Lili Diao;Keyun Hu;Yuchang Lu;Chunyi Shi
#t 2002
#c 3
#% 190581
#% 235377
#% 706248
#! Combining boosting and Support Vector Machine (SVM) is proved to be beneficial, but it is too complex to be feasible. This paper introduces an efficient way to boost SVM. It embraces the idea of active learning to dynamically select "important" samples into training sample set for constructing base classifiers. This method maintains a small training sample set with settled size in order to control the complexity of each base classifier. Other than construct each base SVM classifier directly, it uses the training samples only for finding support vectors. This way to combine boosting and SVM is proved to be accurate and efficient by experimental results.

#index 564629
#* Discovery of Ordinal Association Rules
#@ Sylvie Guillaume
#t 2002
#c 3
#% 210160
#% 227917
#% 232136
#% 443092
#% 655888
#! Most rule-interest measures are suitable for binary attributes and using an unsupervised usual algorithm for the discovery of association rules requires a transformation for other kinds of attributes. Given that the complexity of these algorithms increases exponentially with the number of attributes, this transformation can lead us, on the one hand to a combinatorial explosion, and on the other hand to a prohibitive number of weakly significant rules with many redundancies. To fill the gap, we propose in this study a new objective rule-interest measure called intensity of inclination which evaluates the implication between two ordinal attributes (numeric or ordinal categorical attributes). This measure allows us to extract a new kind of knowledge : ordinal association rules. An evaluation of an application to some banking data ends up the study.

#index 566862
#* Mining Market Basket Data Using Share Measures and Characterized Itemsets
#@ Robert J. Hilderman;Colin L. Carter;Howard J. Hamilton;Nick Cercone
#t 1998
#c 3

#index 566863
#* Study of a Mixed Similarity Measure for Classification and Clustering
#@ Tu Bao Ho;Ngoc Binh Nguyen;Takafumi Morita
#t 1999
#c 3
#% 36672
#% 136350
#% 196334
#! This paper presents a st udy on mixed similarity mea su res (MSM) th at allows doing classification and cluste ring in many sit uations with out discreti eat.ion. For supervised classification we do experimental com parative studies of cl as sifiers bu ilt by dec isio n t ree induction system C4.5 and k ne a rest n eighbor ru le usin g MS:-'L Fo r unsu per vised clustering we first intro duce an extension of k-means algorithm for m ixed numeric and symbolic da ta, t hen evaluate clusters obtained by th is algorithm with natural classes. Exp erimental studies allow us to draw conclusions (meta-knowledge) that are significant in pract ice about t he mutu al use of discreti zation techniques and MSM.

#index 566864
#* Computer Assisted Discovery of First Principle Equations from Numeric Data (Abstract)
#@ Hiroshi Motoda
#t 1999
#c 3
#% 266091
#% 546011
#% 1271832

#index 566865
#* H-Rule Mining in Heterogeneous Databases
#@ Yuping Yang;Mukesh Singhal
#t 1999
#c 3
#% 152934
#% 210160
#% 227953
#% 463919
#% 479449
#% 481290
#% 481935
#! We examined the problem of applying association rules in a heterogeneous database. Due to heterogeneity, we have to generalize the notion of association rule to define a new heterogeneous association rule (h-rule) which denotes data association between various types of data in different subsystems of a heterogeneous and multimedia database, such as music pieces vs. photo pictures, etc. Boolean association rule and quantitative association rule are special cases of h-rule. H-rule integrates previously defined rule concepts and expands association rule mining from single dataset mining to database mining.

#index 566866
#* An Efficient Approach for Incremental Association Rule Mining
#@ Pauray S. M. Tsai;Chih-Chong Lee;Arbee L. P. Chen
#t 1999
#c 3
#% 152934
#% 340289
#% 464204
#% 511333
#! In this paper, we study the issue of maintaining association rules in a large database of sales transactions. The maintenance of association rules can be mapped into the problem of maintaining large itemsets in the database. Because the mining of association rules is time-consuming, we need an efficient approach to maintain the large itemsets when the database is updated. In this paper, we present efficient approaches to solve the problem. Our approaches store the itemsets that are not large at present but may become large itemsets after updating the database, so that the cost of processing the updated database can be reduced. Moreover, we discuss the cases where the large itemsets can be obtained without scanning the original database. Experimental results show that our algorithms outperform other algorithms, especially when the original database need not be scanned in our algorithms.

#index 566869
#* Patterns Discovery Based on Time-Series Decomposition
#@ Jeffrey Xu Yu;Michael K. Ng;Joshua Zhexue Huang
#t 2001
#c 3
#% 287239
#% 463903
#% 464839
#% 480156
#% 631926
#% 1393642
#! Complete or partial periodicity search in time-series databases is an interesting data mining problem. Most previous studies on finding periodic or partial periodic patterns focused on data structures and computing issues. Analysis of long-term or short-term trends over different time windows is a great interest. This paper presents a new approach to discovery of periodic patterns from time-series with trends based on time-series decomposition. First, we decompose time series into three components, seasonal, trend and noise. Second, with an existing partial periodicity search algorithm, we search either partial periodic patterns from trends without seasonal component or partial periodic patterns for seasonal components. Different patterns from any combination of the three decomposed time-series can be found using this approach. Examples show that our approach is more flexible and suitable to mine periodic patterns from time-series with trends than the previous reported methods.

#index 566870
#* An Incremental Hierarchical Data Clustering Algorithm Based on Gravity Theory
#@ Chien-Yu Chen;Shien-Ching Hwang;Yen-Jen Oyang
#t 2002
#c 3
#% 36672
#% 65440
#% 152902
#% 210173
#% 232768
#% 290482
#% 296738
#% 316709
#% 478608
#% 479658
#% 1200254
#! One of the main challenges in the design of modern clustering algorithms is that, in many applications, new data sets are continuously added into an already huge database. As a result, it is impractical to carry out data clustering from scratch whenever there are new data instances added into the database. One way to tackle this challenge is to incorporate a clustering algorithm that operates incrementally. Another desirable feature of clustering algorithms is that a clustering dendrogram is generated. This feature is crucial for many applications in biological, social, and behavior studies, due to the need to construct taxonomies. This paper presents the GRIN algorithm, an incremental hierarchical clustering algorithm for numerical data sets based on gravity theory in physics. The GRIN algorithm delivers favorite clustering quality and generally features O(n) time complexity. One main factor that makes the GRIN algorithm be able to deliver favorite clustering quality is that the optimal parameters settings in the GRIN algorithm are not sensitive to the distribution of the data set. On the other hand, many modern clustering algorithms suffer unreliable or poor clustering quality when the data set contains highly skewed local distributions so that no optimal values can be found for some global parameters. This paper also reports the experiments conducted to study the characteristics of the GRIN algorithm.

#index 566871
#* Toward Bayesian Classifiers with Accurate Probabilities
#@ Charles X. Ling;Huajie Zhang
#t 2002
#c 3
#% 246832
#% 321055
#% 349550
#% 466086
#% 1378224
#% 1650316
#! In most data mining applications, accurate ranking and probability estimation are essential. However, many traditional classifiers aim at a high classification accuracy (or low error rate) only, even though they also produce probability estimates. Does high predictive accuracy imply a better ranking and probability estimation? Is there any better evaluation method for those classifiers than the classification accuracy, for the purpose of data mining applications? The answer is the area under the ROC (Receiver Operating Characteristics) curve, or simply AUC. We show that AUC provides a more discriminating evaluation for the ranking and probability estimation than the accuracy does. Further, we show that classifiers constructed to maximise the AUC score produce not only higher AUC values, but also higher classification accuracies. Our results are based on experimental comparison between error-based and AUC-based learning algorithms for TAN (Tree-Augmented Naive Bayes).

#index 760604
#* Mining Multimedia and Complex Data: Kdd Workshop Mdm 2002, Pakdd Workshop Kdmcd 2002: Revised Papers (Lecture Notes in Artificial Intelligence)
#@ Simeon J. Simoff;Chabane Djeraba;Osmar Zaiane
#t 2003
#c 3

#index 925170
#* Advances in Knowledge Discovery and Data Mining: 8th Pacific-Asia Conference, PAKDD 2004, Sydney, Australia, May 26-28, 2004, Proceedings (Lecture Notes ... / Lecture Notes in Artificial Intelligence)
#@ Honghua Dai;Ramakrishnan Srikant;Chengqi Zhang
#t 2004
#c 3

#index 927854
#* Advances in Knowledge Discovery and Data Mining: 9th Pacific-Asia Conference, PAKDD 2005, Hanoi, Vietnam, May 18-20, 2005, Proceedings (Lecture Notes in ... / Lecture Notes in Artificial Intelligence)
#@ Tu Bao Ho;David Cheung;Huan Liu
#t 2005
#c 3

#index 934243
#* Advances in Knowledge Discovery and Data Mining: 10th Pacific-Asia Conference, PAKDD 2006, Singapore, April 9-12, 2006, Proceedings (Lecture Notes in Computer ... / Lecture Notes in Artificial Intelligence)
#@ Wee Keong Ng;Masaru Kitsuregawa;Jianzhong Li
#t 2006
#c 3

#index 934244
#* Data Mining for Biomedical Applications: PAKDD 2006 Workshop, BioDM 2006, Singapore, April 9, 2006, Proceedings (Lecture Notes in Computer Science / Lecture Notes in Bioinformatics)
#@ Jinyan Li;Qiang Yang;Ah-Hwee Tan
#t 2006
#c 3

#index 1173244
#* New Frontiers in Applied Data Mining: PAKDD 2008 International Workshops, Osaka, Japan, May 20-23, 2008. Revised Selected Papers
#@ Sanjay Chawla;Takashi Washio;Shin-Ichi Minato;Shusaku Tsumoto;Takashi Onoda;Seiji Yamada;Akihiro Inokuchi
#t 2009
#c 3

#index 1195944
#* Proceedings of the 13th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining
#@ Thanaruk Theeramunkong;Boonserm Kijsirikul;Nick Cercone;Tu-Bao Ho
#t 2009
#c 3

#index 1195945
#* KDD for BSN --- Towards the Future of Pervasive Sensing
#@ Guang-Zhong Yang
#t 2009
#c 3
#! With increasing sophistication and miniaturisation of wireless sensor technologies, integrated microsensors no more than a few millimetres in size combined with onboard processing and wireless data transfer has become a reality. The provision of ubiquitous and pervasive monitoring of physical, physiological, and biochemical parameters in any environment and without activity restriction and behaviour modification is the primary motivation of Body Sensor Network (BSN) research. The general scope of BSN is broad, ranging from monitoring of patients with chronic disease and care for the elderly, to general well-being monitoring and performance evaluation in sports. It also has important applications in gaming and human-computer-interaction. One of the significant challenges of BSN is the provision of context aware sensing with effective multi-sensor fusion, data inferencing, mining, and trend analysis. Other research issues currently being addressed include novel miniaturised bioelectrical, biochemical, biophysical, and mechanical sensors; low power RF transceiver, energy scavenging, and battery technologies; biocompatibility, materials, system integration and miniaturisation; autonomic sensor networks and light-weight communication protocols and standards. This talk will address some of the key research topics and current advances in BSN, particularly those related to the KDD community. It will also cover the use of bio-inspired design for providing distributed inferencing and ultra-low power on-node processing, demonstrating how this alternate paradigm based on the strategies used by biological systems can be used to deal with the challenges of scale, complexity, heterogeneity, and uncertainty involved in pervasive sensing.

#index 1195946
#* Finding Hidden Structures in Relational Databases
#@ Jeffrey Xu Yu
#t 2009
#c 3
#! Relational database management systems have been widely used over decades. An important research issue is to find hidden structural information in large relational databases. By hidden structural information we mean the information that cannot be easily found using a traditional query language SQL. In this talk, we discuss how to find hidden structural information in a relational database by viewing a relational database as a large directed graph where nodes represent tuples and edges represent foreign key references between tuples in the database. We discuss how to find trees and communities in such a large graph for user-given keywords. We also discuss how to find frequent and additional keywords associated with the structures identified in a relational database using SQL.

#index 1195947
#* The Future of Search: An Online Content Perspective
#@ Andrew Tomkins
#t 2009
#c 3
#! Nonprofessional creation of public online content has outstripped professional content creation of all forms, both online and offline. And two orders of magnitude more content is created daily to flow through social networks, with as much as two more orders of magnitude still to come as user engagement increases. Content is diversifying in creation, consumption, and nature. Web search engines provide rapid targeted access to this page content, and increasingly to other information such as news articles, weather, movie showtimes, and product and restaurant listings. In this talk, I'll discuss these trends from the standpoint of the search engine, I'll cover some research results in this area, and I'll close with some challenges for the future.

#index 1195948
#* DTU: A Decision Tree for Uncertain Data
#@ Biao Qin;Yuni Xia;Fang Li
#t 2009
#c 3
#% 106656
#% 136350
#% 190581
#% 501515
#% 551723
#% 654487
#% 823402
#% 900065
#% 903016
#% 915307
#% 926881
#% 972278
#% 1030773
#% 1030783
#% 1032001
#% 1063728
#% 1206933
#% 1393138
#! Decision Tree is a widely used data classification technique. This paper proposes a decision tree based classification method on uncertain data. Data uncertainty is common in emerging applications, such as sensor networks, moving object databases, medical and biological bases. Data uncertainty can be caused by various factors including measurements precision limitation, outdated sources, sensor errors, network latency and transmission problems. In this paper, we enhance the traditional decision tree algorithms and extend measures, including entropy and information gain, considering the uncertain data interval and probability distribution function. Our algorithm can handle both certain and uncertain datasets. The experiments demonstrate the utility and robustness of the proposed algorithm as well as its satisfactory prediction accuracy.

#index 1195949
#* Efficient Privacy-Preserving Link Discovery
#@ Xiaoyun He;Jaideep Vaidya;Basit Shafiq;Nabil Adam;Evimaria Terzi;Tyrone Grandison
#t 2009
#c 3
#% 70370
#% 300184
#% 512307
#% 794298
#% 819234
#% 853532
#% 853540
#% 1052669
#% 1722551
#! Link discovery is a process of identifying association(s) among different entities included in a complex network structure. These association(s) may represent any interaction among entities, for example between people or even bank accounts. The need for link discovery arises in many applications including law enforcement, counter-terrorism, social network analysis, intrusion detection, and fraud detection. Given the sensitive nature of information that can be revealed from link discovery, privacy is a major concern from the perspective of both individuals and organizations. For example, in the context of financial fraud detection, linking transactions may reveal sensitive information about other individuals not involved in any fraud. It is known that link discovery can be done in a privacy-preserving manner by securely finding the transitive closure of a graph. We propose two very efficient techniques to find the transitive closure securely. The two protocols have varying levels of security and performance. We analyze the performance and usability of the proposed approach in terms of both analytical and experimental results.

#index 1195950
#* On Link Privacy in Randomizing Social Networks
#@ Xiaowei Ying;Xintao Wu
#t 2009
#c 3
#% 730089
#% 956511
#% 1063476
#% 1127360
#% 1206763
#% 1415851
#! Many applications of social networks require relationship anonymity due to the sensitive, stigmatizing, or confidential nature of relationship. Recent work showed that the simple technique of anonymizing graphs by replacing the identifying information of the nodes with random ids does not guarantee privacy since the identification of the nodes can be seriously jeopardized by applying subgraph queries. In this paper, we investigate how well an edge based graph randomization approach can protect sensitive links. We show via theoretical studies and empirical evaluations that various similarity measures can be exploited by attackers to significantly improve their confidence and accuracy of predicted sensitive links between nodes with high similarity values.

#index 1195951
#* Sentence-Level Novelty Detection in English and Malay
#@ Agus T. Kwee;Flora S. Tsai;Wenyin Tang
#t 2009
#c 3
#% 248218
#% 397133
#% 643014
#% 882738
#% 893432
#% 1043035
#! Novelty detection (ND) is a process for identifying information from an incoming stream of documents. Although there are many studies of ND on English language documents, however, to the best of our knowledge, none has been reported on Malay documents. This issue is important because there are many documents with a mixture of both English and Malay languages. This paper examines multilingual sentence-level ND in English and Malay documents using TREC 2003 and TREC 2004 Novelty Track data. We describe the text processing for multilingual ND, which consists of language translation, stop words removal, automatic stemming, and novel sentence detection. We compare the results for sentence-level ND on English and Malay documents and find that the results are fairly similar. Therefore, after preprocessing is performed on Malay documents, our ND algorithm appears to be robust in detecting novel sentences, and can possibly be extended to other alphabet-based languages.

#index 1195952
#* Text Categorization Using Fuzzy Proximal SVM and Distributional Clustering of Words
#@ Mani Arun Kumar;Madan Gopal
#t 2009
#c 3
#% 260001
#% 262059
#% 266215
#% 269217
#% 342598
#% 458379
#% 722930
#% 881477
#% 889088
#! Text Categorization (TC) remains as a potential application area for linear support vector machines (SVMs). Among the numerous linear SVM formulations, we bring forward linear PSVM together with recently proposed distributional clustering (DC) of words to realize its potential in TC realm. DC has been presented as an efficient alternative to conventionally used feature selection in TC. It has been shown that, DC together with linear SVM drastically brings down the dimensionality of text documents without any compromise in classification performance. In this paper we use linear PSVM and its extension Fuzzy PSVM (FPSVM) together with DC for TC. We present experimental results comparing PSVM/FPSVM with linear SVM light and SVMlin on popular WebKB text corpus. Through numerous experiments on subsets of WebKB, we reveal the merits of PSVM and FPSVM over other linear SVMs.

#index 1195953
#* Cool Blog Classification from Positive and Unlabeled Examples
#@ Kritsada Sriphaew;Hiroya Takamura;Manabu Okumura
#t 2009
#c 3
#% 209021
#% 234992
#% 464641
#% 466229
#% 564957
#% 727883
#% 729621
#% 1083647
#% 1114196
#% 1155745
#% 1279298
#% 1499473
#! We address the problem of cool blog classification using only positive and unlabeled examples. We propose an algorithm, called PUB, that exploits the information of unlabeled data together with the positive examples to predict whether the unseen blogs are cool or not. The algorithm uses the weighting technique to assign a weight to each unlabeled example which is assumed to be negative in the training set, and the bagging technique to obtain several weak classifiers, each of which is learned on a small training set generated by randomly sampling some positive examples and some unlabeled examples, which are assumed to be negative. Each of the weak classifiers must achieve admissible performance measure evaluated based on the whole labeled positive examples or has the best performance measure within iteration limit. The majority voting function on all weak classifiers is employed to predict the class of a test instance. The experimental results show that PUB can correctly predict the classes of unseen blogs where this situation cannot be handled by the traditional learning from positive and negative examples. The results also show that PUB outperforms other algorithms for learning from positive and unlabeled examples in the task of cool blog classification.

#index 1195954
#* Thai Word Segmentation with Hidden Markov Model and Decision Tree
#@ Poramin Bheganan;Richi Nayak;Yue Xu
#t 2009
#c 3
#% 136350
#% 757402
#% 757825
#% 815134
#! The Thai written language is one of the languages that does not have word boundaries. In order to discover the meaning of the document, all texts must be separated into syllables, words, sentences, and paragraphs. This paper develops a novel method to segment the Thai text by combining a non-dictionary based technique with a dictionary-based technique. This method first applies the Thai language grammar rules to the text for identifying syllables. The hidden Markov model is then used for merging possible syllables into words. The identified words are verified with a lexical dictionary and a decision tree is employed to discover the words unidentified by the lexical dictionary. Documents used in the litigation process of Thai court proceedings have been used in experiments. The results which are segmented words, obtained by the proposed method outperform the results obtained by other existing methods.

#index 1195955
#* An Efficient Method for Generating, Storing and Matching Features for Text Mining
#@ Shing-Kit Chan;Wai Lam
#t 2009
#c 3
#% 190581
#% 464434
#% 816081
#% 816181
#% 855119
#% 1223735
#! Log-linear models have been widely used in text mining tasks because it can incorporate a large number of possibly correlated features. In text mining, these possibly correlated features are generated by conjunction of features. They are usually used with log-linear models to estimate robust conditional distributions. To avoid manual construction of conjunction of features, we propose a new algorithmic framework called F-tree for automatically generating and storing conjunctions of features in text mining tasks. This compact graph-based data structure allows fast one-vs-all matching of features in the feature space which is crucial for many text mining tasks. Based on this hierarchical data structure, we propose a systematic method for removing redundant features to further reduce memory usage and improve performance. We do large-scale experiments on three publicly-available datasets and show that this automatic method can get state-of-the-art performance achieved by manual construction of features.

#index 1195956
#* Robust Graph Hyperparameter Learning for Graph Based Semi-supervised Classification
#@ Krikamol Muandet;Sanparith Marukatat;Cholwich Nattee
#t 2009
#c 3
#% 565545
#% 876068
#! Graph-based semi-supervised learning has attracted much attention in recent years. Many successful methods rely on graph structure to propagate labels from labeled data to unlabeled data. Although graph structure affects the performance of the system, only few works address its construction problem. In this work, the graph structure is constructed by adjusting the hyperparameter controlling the connection weights between nodes. The idea is to learn the hyperparameters for graphs that yields low leave-one-out prediction error on labeled data while retaining high stability of the prediction on unlabeled data. The problem is solved efficiently using the gradient-based optimization technique. Experimental results indicate that the proposed technique yields improvement of generalization error as well as stability of the labeling function.

#index 1195957
#* Regularized Local Reconstruction for Clustering
#@ Jun Sun;Zhiyong Shen;Bai Su;Yidong Shen
#t 2009
#c 3
#% 274589
#% 313959
#% 722902
#% 723241
#% 724227
#% 755463
#% 757953
#% 961204
#% 1034714
#% 1108909
#% 1816812
#! Motivated by the local reconstruction approach to discovering low dimensional structure in high dimensional data, we propose a novel clustering algorithm that effectively utilizes local reconstruction information. We obtain the local reconstruction weights by minimizing the reconstruction error between each data point and the reconstruction from its neighbors. An entropy regularization term is incorporated into the reconstruction objective function so that the smoothness of the reconstruction weights can be explicitly controlled. The reconstruction weights are then used to obtain the clustering result by employing spectral clustering techniques. Experimental results on a number of datasets demonstrate that our algorithm performs well relative to other approaches, which validate the effectiveness of our approach for clustering.

#index 1195958
#* Clustering with Lower Bound on Similarity
#@ Mohammad Al Hasan;Saeed Salem;Benjarath Pupacdi;Mohammed J. Zaki
#t 2009
#c 3
#% 226620
#% 275929
#% 341672
#% 378388
#% 408396
#% 425021
#% 1015261
#! We propose a new method, called SimClus, for clustering with lower bound on similarity. Instead of accepting k the number of clusters to find, the alternative similarity-based approach imposes a lower bound on the similarity between an object and its corresponding cluster representative (with one representative per cluster). SimClus achieves a O (logn ) approximation bound on the number of clusters, whereas for the best previous algorithm the bound can be as poor as O (n ). Experiments on real and synthetic datasets show that our algorithm produces more than 40% fewer representative objects, yet offers the same or better clustering quality. We also propose a dynamic variant of the algorithm, which can be effectively used in an on-line setting.

#index 1195959
#* Approximate Spectral Clustering
#@ Liang Wang;Christopher Leckie;Kotagiri Ramamohanarao;James Bezdek
#t 2009
#c 3
#% 313959
#% 336073
#% 466675
#% 732552
#% 837604
#% 847159
#% 870225
#% 877528
#% 1035364
#% 1074026
#% 1861495
#! While spectral clustering has recently shown great promise, computational cost makes it infeasible for use with large data sets. To address this computational challenge, this paper considers the problem of approximate spectral clustering, which enables both the feasibility (of approximately clustering in very large and unloadable data sets) and acceleration (of clustering in loadable data sets), while maintaining acceptable accuracy. We examine and propose several schemes for approximate spectral grouping, and make an empirical comparison of those schemes in combination with several sampling strategies. Experimental results on several synthetic and real-world data sets show that approximate spectral clustering can achieve both the goals of feasibility and acceleration.

#index 1195960
#* An Integration of Fuzzy Association Rules and WordNet for Document Clustering
#@ Chun-Ling Chen;Frank S. Tseng;Tyne Liang
#t 2009
#c 3
#% 118771
#% 154897
#% 198058
#% 577257
#% 577355
#% 722358
#% 785433
#% 848749
#% 1271243
#! With the rapid growth of text documents, document clustering has become one of the main techniques for organizing large amount of documents into a small number of meaningful clusters. However, there still exist several challenges for document clustering, such as high dimensionality, scalability, accuracy, meaningful cluster labels, and extracting semantics from texts. In order to improve the quality of document clustering results, we propose an effective Fuzzy Frequent Itemset-based Document Clustering (F2IDC) approach that combines fuzzy association rule mining with the background knowledge embedded in WordNet. A term hierarchy generated from WordNet is applied to discovery fuzzy frequent itemsets as candidate cluster labels for grouping documents. We have conducted experiments to evaluate our approach on Reuters-21578 dataset. The experimental result shows that our proposed method outperforms the accuracy quality of FIHC, HFTC, and UPGMA.

#index 1195961
#* Nonlinear Data Analysis Using a New Hybrid Data Clustering Algorithm
#@ Ureerat Wattanachon;Jakkarin Suksawatchon;Chidchanok Lursinsap
#t 2009
#c 3
#% 36672
#% 210173
#% 248790
#% 296375
#% 296738
#% 729437
#% 789008
#% 1861495
#! Existing clustering algorithms, such as single-link clustering, k-means, CURE, and CSM are designed to find clusters based on pre-defined parameters specified by users. These algorithms may be unsuccessful if the choice of parameters is inappropriate with respect to the data set being clustered. Most of these algorithms work very well for compact and hyperspherical clusters. In this paper, a new hybrid clustering algorithm called Self-Partition and Self-Merging (SPSM) is proposed. The SPSM algorithm partitions the input data set into several subclusters in the first phase and, then, removes the noisy data in the second phase. In the third phase, the normal subclusters are continuously merged to form the larger clusters based on the inter-cluster distance and intra-cluster distance criteria. From the experimental results, the SPSM algorithm is very efficient to handle the noisy data set, and to cluster the data sets of arbitrary shapes of different density.

#index 1195962
#* A Polynomial-Delay Polynomial-Space Algorithm for Extracting Frequent Diamond Episodes from Event Sequences
#@ Takashi Katoh;Hiroki Arimura;Kouichi Hirata
#t 2009
#c 3
#% 207408
#% 420063
#% 481290
#% 778732
#% 902449
#% 1099559
#% 1411030
#% 1698279
#! In this paper, we study the problem of mining frequent diamond episodes efficiently from an input event sequence with sliding a window. Here, a diamond episode is of the form a ***E ***b , which means that every event of E follows an event a and is followed by an event b . Then, we design a polynomial-delay and polynomial-space algorithm PolyFreqDmd that finds all of the frequent diamond episodes without duplicates from an event sequence in O (|Σ |2 n ) time per an episode and in O (|Σ | + n ) space, where Σ and n are an alphabet and the length the event sequence, respectively. Finally, we give experimental results on artificial event sequences with varying several mining parameters to evaluate the efficiency of the algorithm.

#index 1195963
#* A Statistical Approach for Binary Vectors Modeling and Clustering
#@ Nizar Bouguila;Khalid Daoudi
#t 2009
#c 3
#% 93228
#% 207019
#% 227486
#% 230131
#% 232117
#% 243727
#% 321060
#% 380342
#% 424807
#% 771842
#% 772864
#% 796212
#% 798820
#% 823343
#% 889076
#% 1013662
#% 1100129
#% 1246228
#% 1675755
#% 1916895
#! This paper presents an approach for Binary feature selection. Our selection technique is based on a principled statistical model using a finite mixture of distributions. In contrast with classic feature selection algorithms that have been proposed in supervised settings, where training data are available and completely labeled, our approach is fully unsupervised. Through some applications, we found that our feature selection model improves the clustering results.

#index 1195964
#* Multi-resolution Boosting for Classification and Regression Problems
#@ Chandan K. Reddy;Jin-Hyeong Park
#t 2009
#c 3
#% 262085
#% 435222
#% 551723
#% 722756
#% 736300
#% 833868
#% 1100105
#! Various forms of boosting techniques have been popularly used in many data mining and machine learning related applications. Inspite of their great success, boosting algorithms still suffer from a few open-ended problems that require closer investigation. The efficiency of any such ensemble technique significantly relies on the choice of the weak learners and the form of the loss function. In this paper, we propose a novel multi-resolution approach for choosing the weak learners during additive modeling. Our method applies insights from multi-resolution analysis and chooses the optimal learners at multiple resolutions during different iterations of the boosting algorithms. We demonstrate the advantages of using this novel framework for classification tasks and show results on different real-world datasets obtained from the UCI machine learning repository. Though demonstrated specifically in the context of boosting algorithms, our framework can be easily accommodated in general additive modeling techniques.

#index 1195965
#* Interval Data Classification under Partial Information: A Chance-Constraint Approach
#@ Sahely Bhadra;J. Saketha Nath;Aharon Ben-Tal;Chiranjib Bhattacharyya
#t 2009
#c 3
#% 722901
#% 991783
#% 1023856
#% 1663129
#! This paper presents a Chance-constraint Programming approach for constructing maximum-margin classifiers which are robust to interval-valued uncertainty in training examples. The methodology ensures that uncertain examples are classified correctly with high probability by employing chance-constraints. The main contribution of the paper is to pose the resultant optimization problem as a Second Order Cone Program by using large deviation inequalities, due to Bernstein. Apart from support and mean of the uncertain examples these Bernstein based relaxations make no further assumptions on the underlying uncertainty. Classifiers built using the proposed approach are less conservative, yield higher margins and hence are expected to generalize better than existing methods. Experimental results on synthetic and real-world datasets show that the proposed classifiers are better equipped to handle interval-valued uncertainty than state-of-the-art.

#index 1195966
#* Negative Encoding Length as a Subjective Interestingness Measure for Groups of Rules
#@ Einoshin Suzuki
#t 2009
#c 3
#% 61792
#% 136350
#% 156181
#% 256610
#% 310496
#% 369349
#% 442814
#% 449508
#% 577214
#% 769893
#% 934581
#! We propose an interestingness measure for groups of classification rules which are mutually related based on the Minimum Description Length Principle. Unlike conventional methods, our interestingness measure is based on a theoretical background, has no parameter, is applicable to a group of any number of rules, and can exploit an initial hypothesis. We have integrated the interestingness measure with practical heuristic search and built a rule-group discovery method CLARDEM (Classification Rule Discovery method based on an Extended-Mdlp). Extensive experiments using both real and artificial data confirm that CLARDEM can discover the correct concept from a small noisy data set and an approximate initial concept with high "discovery accuracy".

#index 1195967
#* The Studies of Mining Frequent Patterns Based on Frequent Pattern Tree
#@ Show-Jane Yen;Yue-Shi Lee;Chiu-Kuang Wang;Jung-Wei Wu;Liang-Yu Ouyang
#t 2009
#c 3
#% 201894
#% 300120
#% 329598
#% 443448
#% 481290
#% 729418
#! Mining frequent patterns is to discover the groups of items appearing always together excess of a user specified threshold. Many approaches have been proposed for mining frequent pattern. However, either the search space or memory space is huge, such that the performance for the previous approach degrades when the database is massive or the threshold for mining frequent patterns is low. In order to decrease the usage of memory space and speed up the mining process, we study some methods for mining frequent patterns based on frequent pattern tree. The concept of our approach is to only construct a FP-tree and traverse a subtree of the FP-tree to generate all the frequent patterns for an item without constructing any other subtrees. After traversing a subtree for an item, our approach merges and removes the subtree to reduce the FP-tree smaller and smaller. We propose four methods based on this concept and compare the four methods with the famous algorithm FP-Growth which also construct a FP-tree and recursively mines frequent patterns by building conditional FP-tree.

#index 1195968
#* Discovering Periodic-Frequent Patterns in Transactional Databases
#@ Syed Khairuzzaman Tanbeer;Chowdhury Farhan Ahmed;Byeong-Soo Jeong;Young-Koo Lee
#t 2009
#c 3
#% 152934
#% 300120
#% 796210
#% 809533
#% 1000871
#% 1411136
#% 1727241
#% 1737157
#! Since mining frequent patterns from transactional databases involves an exponential mining space and generates a huge number of patterns, efficient discovery of user-interest-based frequent pattern set becomes the first priority for a mining algorithm. In many real-world scenarios it is often sufficient to mine a small interesting representative subset of frequent patterns. Temporal periodicity of pattern appearance can be regarded as an important criterion for measuring the interestingness of frequent patterns in several applications. A frequent pattern can be said periodic-frequent if it appears at a regular interval given by the user in the database. In this paper, we introduce a novel concept of mining periodic-frequent patterns from transactional databases. We use an efficient tree-based data structure, called Periodic-frequent pattern tree (PF-tree in short), that captures the database contents in a highly compact manner and enables a pattern growth mining technique to generate the complete set of periodic-frequent patterns in a database for user-given periodicity and support thresholds. The performance study shows that mining periodic-frequent patterns with PF-tree is time and memory efficient and highly scalable as well.

#index 1195969
#* Quantifying Asymmetric Semantic Relations from Query Logs by Resource Allocation
#@ Zhiyuan Liu;Yabin Zheng;Maosong Sun
#t 2009
#c 3
#% 194299
#% 232713
#% 310567
#% 342961
#% 590523
#% 642982
#% 728105
#% 730051
#% 734594
#% 869500
#% 894253
#% 918685
#% 946523
#% 956641
#% 987193
#% 989578
#% 1055789
#% 1096052
#% 1712595
#! In this paper we present a bipartite-network-based resource allocation(BNRA) method to extract and quantify semantic relations from large scale query logs of search engine. Firstly, we construct a query-URL bipartite network from query logs of search engine. By BNRA, we extract asymmetric semantic relations between queries from the bipartite network. Asymmetric relation indicates that two related queries could be assigned different semantic relevance strength against each other, which is more conforming to reality. We verify the validity of the method with query logs from Chinese search engine Sogou. It demonstrates BNRA could effectively quantify semantic relations from We further construct query semantic networks, and introduce several measures to analyze the networks. BNRA is not only `language oblivious' and `content oblivious', but could also be easily implemented in a paralleled manner, which provides commercial search engines a feasible solution to handle large scale query logs.

#index 1195970
#* Acquiring Semantic Relations Using the Web for Constructing Lightweight Ontologies
#@ Wilson Wong;Wei Liu;Mohammed Bennamoun
#t 2009
#c 3
#% 913795
#% 940029
#% 975019
#% 1002276
#% 1019100
#% 1036510
#% 1078036
#% 1280225
#% 1413195
#% 1655423
#! Common techniques for acquiring semantic relations rely on static domain and linguistic resources, predefined patterns, and the presence of syntactic cues. We propose a hybrid approach which brings together established and novel techniques in lexical simplification, word disambiguation and association inference for acquiring coarse-grained relations between potentially ambiguous and composite terms using only dynamic Web resources. Our experiments using terms from two different domains demonstrate potential preliminary results.

#index 1195971
#* Detecting Abnormal Events via Hierarchical Dirichlet Processes
#@ Xian-Xing Zhang;Hua Liu;Yang Gao;Derek Hao Hu
#t 2009
#c 3
#% 126894
#% 313937
#% 720010
#% 724287
#% 775535
#% 790610
#% 803032
#% 812382
#% 832134
#% 915260
#% 1074008
#% 1114487
#% 1279288
#% 1289281
#% 1289473
#% 1759404
#% 1856622
#! Detecting abnormal event from video sequences is an important problem in computer vision and pattern recognition and a large number of algorithms have been devised to tackle this problem. Previous state-based approaches all suffer from the problem of deciding the appropriate number of states and it is often difficult to do so except using a trial-and-error approach, which may be infeasible in real-world applications. Yet in this paper, we have proposed a more accurate and flexible algorithm for abnormal event detection from video sequences. Our three-phase approach first builds a set of weak classifiers using Hierarchical Dirichlet Process Hidden Markov Model (HDP-HMM), and then proposes an ensemble learning algorithm to filter out abnormal events. In the final phase, we will derive abnormal activity models from the normal activity model to reduce the FP (False Positive) rate in an unsupervised manner. The main advantage of our algorithm over previous ones is to naturally capture the underlying feature in abnormal event detection via HDP-HMM. Experimental results on a real-world video sequence dataset have shown the effectiveness of our algorithm.

#index 1195972
#* Active Learning for Causal Bayesian Network Structure with Non-symmetrical Entropy
#@ Guoliang Li;Tze-Yun Leong
#t 2009
#c 3
#% 129987
#% 197387
#% 277480
#% 297171
#% 528332
#% 1289266
#% 1650279
#! Causal knowledge is crucial for facilitating comprehension, diagnosis, prediction, and control in automated reasoning. Active learning in causal Bayesian networks involves interventions by manipulating specific variables, and observing the patterns of change over other variables to derive causal knowledge. In this paper, we propose a new active learning approach that supports interventions with node selection. Our method admits a node selection criterion based on non-symmetrical entropy from the current data and a stop criterion based on structure entropy of the resulting networks. We examine the technical challenges and practical issues involved. Experimental results on a set of benchmark Bayesian networks are promising. The proposed method is potentially useful in many real-life applications where multiple instances are collected as a data set in each active learning step.

#index 1195973
#* A Comparative Study of Bandwidth Choice in Kernel Density Estimation for Naive Bayesian Classification
#@ Bin Liu;Ying Yang;Geoffrey I. Webb;Janice Boughton
#t 2009
#c 3
#% 312728
#% 379343
#% 420054
#% 926881
#% 961134
#% 1156097
#% 1650665
#! Kernel density estimation (KDE) is an important method in nonparametric learning. While KDE has been studied extensively in the context of accuracy of distribution estimation, it has not been studied extensively in the context of classification. This paper studies nine bandwidth selection schemes for kernel density estimation in Naive Bayesian classification context, using 52 machine learning benchmark datasets. The contributions of this paper are threefold. First, it shows that some commonly used and very sophisticated bandwidth selection schemes do not give good performance in Naive Bayes. Surprisingly, some very simple bandwidth selection schemes give statistically significantly better performance. Second, it shows that kernel density estimation can achieve statistically significantly better classification performance than a commonly used discretization method in Naive Bayes, but only when appropriate bandwidth selection schemes are applied. Third, this study gives bandwidth distribution patterns for the investigated bandwidth selection schemes.

#index 1195974
#* Analysis of Variational Bayesian Matrix Factorization
#@ Shinichi Nakajima;Masashi Sugiyama
#t 2009
#c 3
#% 220711
#% 840924
#% 856208
#% 891559
#% 959453
#% 1100108
#% 1650268
#% 1862599
#! Recently, the variational Bayesian approximation was applied to probabilistic matrix factorization and shown to perform very well in experiments. However, its good performance was not completely understood beyond its experimental success. The purpose of this paper is to theoretically elucidate properties of a variational Bayesian matrix factorization method. In particular, its mechanism of avoiding overfitting is analyzed. Our analysis relies on the key fact that the matrix factorization model induces non-identifiability, i.e., the mapping between factorized matrices and the original matrix is not one-to-one. The positive-part James-Stein shrinkage operator and the Marcenko-Pastur law--the limiting distribution of eigenvalues of the central Wishart distribution--play important roles in our analysis.

#index 1195975
#* Variational Bayesian Approach for Long-Term Relevance Feedback
#@ Sabri Boutemedjet;Djemel Ziou
#t 2009
#c 3
#% 578684
#% 734592
#% 772864
#% 855610
#% 891559
#% 1100129
#% 1650569
#% 1775694
#! This paper presents a Bayesian approach to address two important issues of image recommendation that are: (1) change in long-term needs of users and (2) evolution of image collections. Users are offered a new interaction modality which allows them to provide either positive or negative relevance feedback (RF) data to express their recent needs. Then, an efficient variational Online learning algorithm updates both user and product collection models by favoring recent RF data. The proposed method is general and can be applied in collaborative filtering. Experimental results demonstrate the importance of maintaining most up-to-date user models on the rating's prediction accuracy.

#index 1195976
#* Detecting Link Hijacking by Web Spammers
#@ Young-Joo Chung;Masashi Toyoda;Masaru Kitsuregawa
#t 2009
#c 3
#% 330609
#% 772018
#% 824694
#% 869469
#% 869471
#% 893125
#% 957996
#% 957998
#% 1016177
#% 1914862
#! Since current search engines employ link-based ranking algorithms as an important tool to decide a ranking of sites, Web spammers are making a significant effort to manipulate the link structure of the Web, so called, link spamming. Link hijacking is an indispensable technique for link spamming to bring ranking scores from normal sites to target spam sites. In this paper, we propose a link analysis technique for finding link hijacked sites using modified PageRank algorithms. We performed experiments on the large scale Japanese Web archive and evaluated the accuracy of our method. Detection precision of our approach was improved about 25% from a naive approach.

#index 1195977
#* A Data Driven Ensemble Classifier for Credit Scoring Analysis
#@ Nan-Chen Hsieh;Lun-Ping Hung;Chia-Ling Ho
#t 2009
#c 3
#% 251145
#% 739101
#% 769893
#% 816267
#% 950502
#% 1001522
#% 1036181
#% 1345707
#% 1728991
#% 1861209
#! This study focuses on predicting whether a credit applicant can be categorized as good, bad or borderline from information initially supplied. Given its importance, many researchers have recently worked on an ensemble of classifiers. However, to the best of our knowledge, unrepresentative samples drastically reduce the accuracy of the deployment classifier. Few have attempted to preprocess the input samples into more homogeneous cluster groups and then fit the ensemble classifier accordingly. For this reason, we introduce the concept of class-wise classification as a preprocessing step in order to obtain an efficient ensemble classifier. This strategy would work better than a direct ensemble of classifiers without the preprocessing step. The proposed ensemble classifier is constructed by incorporating several data mining techniques, mainly involving optimal associate binning to discretize continuous values; neural network, support vector machine, and Bayesian network are used to augment the ensemble classifier. In particular, the Markov blanket concept of Bayesian network allows for a natural form of feature selection, which provides a basis for mining association rules.

#index 1195978
#* A Multi-partition Multi-chunk Ensemble Technique to Classify Concept-Drifting Data Streams
#@ Mohammad M. Masud;Jing Gao;Latifur Khan;Jiawei Han;Bhavani Thuraisingham
#t 2009
#c 3
#% 273900
#% 310500
#% 342600
#% 449529
#% 729932
#% 769888
#% 840891
#% 1020400
#% 1117009
#! We propose a multi-partition, multi-chunk ensemble classifier based data mining technique to classify concept-drifting data streams. Existing ensemble techniques in classifying concept-drifting data streams follow a single-partition, single-chunk approach, in which a single data chunk is used to train one classifier. In our approach, we train a collection of v classifiers from r consecutive data chunks using v -fold partitioning of the data, and build an ensemble of such classifiers. By introducing this multi-partition, multi-chunk ensemble technique, we significantly reduce classification error compared to the single-partition, single-chunk ensemble approaches. We have theoretically justified the usefulness of our algorithm, and empirically proved its effectiveness over other state-of-the-art stream classification techniques on synthetic data and real botnet traffic.

#index 1195979
#* Parameter Estimation in Semi-Random Decision Tree Ensembling on Streaming Data
#@ Peipei Li;Qianhui Liang;Xindong Wu;Xuegang Hu
#t 2009
#c 3
#% 136350
#% 256615
#% 273900
#% 310500
#% 400847
#% 481945
#% 727888
#% 729965
#% 1062824
#% 1117009
#% 1250172
#! The induction error in random tree ensembling results mainly from the strength of decision trees and the dependency between base classifiers. In order to reduce the errors due to both factors, a Semi-Random Decision Tree Ensembling (SRDTE) for mining streaming data is proposed based on our previous work on SRMTDS. The model contains semi-random decision trees that are independent in the generation process and have no interaction with each other in the individual decisions of classification. The main idea is to minimize correlation among the classifiers. We claim that the strength of decision trees is closely related to the estimation values of the parameters, including the height of a tree, the count of trees and the parameter of n min in the Hoeffding Bounds. We analyze these parameters of the model and design strategies for better adaptation to streaming data. The main strategies include an incremental generation of sub-trees after seeing real training instances, a data structure for quick search and a voting mechanism for classification. Our evaluation in the 0-1 loss function shows that SRDTE has improved the performance in terms of predictive accuracy and robustness. We have applied SRDTE to e-business data streams and proved its feasibility and effectiveness.

#index 1195980
#* Exploiting the Block Structure of Link Graph for Efficient Similarity Computation
#@ Pei Li;Yuanzhe Cai;Hongyan Liu;Jun He;Xiaoyong Du
#t 2009
#c 3
#% 202011
#% 258598
#% 281209
#% 387427
#% 577273
#% 818218
#% 853532
#% 853537
#% 893124
#! In many real-world domains, link graph is one of the most effective ways to model the relationships between objects. Measuring the similarity of objects in a link graph is studied by many researchers, but an effective and efficient method is still expected. Based on our observation of link graphs from real domains, we find the block structure naturally exists. We propose an algorithm called BlockSimRank , which partitions the link graph into blocks, and obtains similarity of each node-pair in the graph efficiently. Our method is based on random walk on two-layer model, with time complexity as low as O (n 4/3) and less memory need. Experiments show that the accuracy of BlockSimRank is acceptable when the time cost is the lowest.

#index 1195981
#* Online Feature Selection Algorithm with Bayesian l 1 Regularization
#@ Yunpeng Cai;Yijun Sun;Jian Li;Steve Goodison
#t 2009
#c 3
#% 126894
#% 132676
#% 424806
#% 445219
#% 576218
#% 722929
#% 770774
#% 770857
#% 824957
#% 891559
#% 912639
#% 975162
#% 1042718
#% 1377404
#% 1855989
#! We propose a novel online-learning based feature selection algorithm for supervised learning in the presence of a huge amount of irrelevant features. The key idea of the algorithm is to decompose a nonlinear problem into a set of locally linear ones through local learning, and then estimate the relevance of features globally in a large margin framework with l 1 regularization. Unlike batch learning, the regularization parameter in online learning has to be tuned on-the-fly with the increasing of training data. We address this issue within the Bayesian learning paradigm, and provide an analytic solution for automatic estimation of the regularization parameter via variational methods. Numerical experiments on a variety of benchmark data sets are presented that demonstrate the effectiveness of the newly proposed feature selection algorithm.

#index 1195982
#* Feature Selection for Local Learning Based Clustering
#@ Hong Zeng;Yiu-Ming Cheung
#t 2009
#c 3
#% 629628
#% 724227
#% 771842
#% 916789
#% 1164349
#% 1327648
#! For most clustering algorithms, their performance will strongly depend on the data representation. In this paper, we attempt to obtain better data representations through feature selection, particularly for the Local Learning based Clustering (LLC) [1]. We assign a weight to each feature, and incorporate it into the built-in regularization of LLC algorithm to take into account of the relevance of each feature for the clustering. Accordingly, the weights are estimated iteratively with the clustering. We show that the resulting weighted regularization with an additional constraint on the weights is equivalent to a known sparse-promoting penalty, thus the weights for irrelevant features can be driven towards zero. Experiments on several benchmark datasets demonstrate the effectiveness of the proposed method.

#index 1195983
#* RV-SVM: An Efficient Method for Learning Ranking SVM
#@ Hwanjo Yu;Youngdae Kim;Seungwon Hwang
#t 2009
#c 3
#% 269218
#% 309208
#% 387427
#% 420077
#% 563100
#% 577224
#% 717415
#% 722929
#% 734915
#% 754400
#% 823348
#% 823360
#% 840846
#% 879588
#% 881477
#% 944095
#% 961189
#% 983819
#% 987227
#% 987241
#% 1778986
#! Learning ranking (or preference) functions has become an important data mining task in recent years, as various applications have been found in information retrieval. Among rank learning methods, ranking SVM has been favorably applied to various applications, e.g., optimizing search engines, improving data retrieval quality. In this paper, we first develop a 1-norm ranking SVM that is faster in testing than the standard ranking SVM, and propose Ranking Vector SVM (RV-SVM) that revises the 1-norm ranking SVM for faster training . The number of variables in the RV-SVM is significantly smaller, thus the RV-SVM trains much faster than the other ranking SVMs. We experimentally compared the RV-SVM with the state-of-the-art rank learning method provided in SVM-light. The RV-SVM uses much less support vectors and trains much faster for nonlinear kernels than the SVM-light. The accuracies of RV-SVM and SVM-light are comparable on relatively large data sets. Our implementation of RV-SVM is posted at http://iis.postech.ac.kr/rv-svm.

#index 1195984
#* A Kernel Framework for Protein Residue Annotation
#@ Huzefa Rangwala;Christopher Kauffman;George Karypis
#t 2009
#c 3
#% 190581
#% 269217
#% 770846
#% 833950
#% 841958
#% 950264
#% 1038934
#% 1041247
#% 1108836
#! Over the last decade several prediction methods have been developed for determining structural and functional properties of individual protein residues using sequence and sequence-derived information. Most of these methods are based on support vector machines as they provide accurate and generalizable prediction models. We developed a general purpose protein residue annotation toolkit (Pro SAT ) to allow biologists to formulate residue-wise prediction problems. Pro SAT formulates annotation problem as a classification or regression problem using support vector machines. For every residue Pro SAT captures local information (any sequence-derived information) around the reside to create fixed length feature vectors. Pro SAT implements accurate and fast kernel functions, and also introduces a flexible window-based encoding scheme that allows better capture of signals for certain prediction problems. In this work we evaluate the performance of Pro SAT on the disorder prediction and contact order estimation problems, studying the effect of the different kernels introduced here. Pro SAT shows better or at least comparable performance to state-of-the-art prediction systems. In particular Pro SAT has proven to be the best performing transmembrane-helix predictor on an independent blind benchmark. Availability: http://bio.dtc.umn.edu/prosat

#index 1195985
#* Dynamic Exponential Family Matrix Factorization
#@ Kohei Hayashi;Jun-Ichiro Hirayama;Shin Ishii
#t 2009
#c 3
#% 458673
#% 722904
#% 853532
#% 853535
#% 875959
#% 1089780
#% 1378224
#% 1858962
#! We propose a new approach to modeling time-varying relational data such as e-mail transactions based on a dynamic extension of matrix factorization. To estimate effectively the true relationships behind a sequence of noise-corrupted relational matrices, their dynamic evolutions are modeled in a space of low-rank matrices. The observed matrices are assumed as to be sampled from an exponential family distribution that has the low-rank matrix as natural parameters. We apply the sequential Bayesian framework to track the variations of true parameters. In the experiments using both artificial and real-world datasets, we demonstrate our method can appropriately estimate time-varying true relations based on noisy observations, more effectively than existing methods.

#index 1195986
#* A Nonparametric Bayesian Learning Model: Application to Text and Image Categorization
#@ Nizar Bouguila;Djemel Ziou
#t 2009
#c 3
#% 165110
#% 344447
#% 424085
#% 722904
#% 755467
#% 760805
#% 812535
#% 840903
#% 889076
#% 1013662
#% 1855694
#% 1856154
#! In this paper a nonparametric Bayesian infinite mixture model is introduced. The adoption of this model is motivated by its flexibility. Indeed, it does not require the specification of the number of mixture components to be given in advance and estimates it in a principled manner. Our approach relies on the estimation of the posterior distribution of clusterings using Gibbs sampler. Through applications involving text and image categorization, we show that categorization via infinite mixture models offers a more powerful and robust performance than classic finite mixtures.

#index 1195987
#* Safe-Level-SMOTE: Safe-Level-Synthetic Minority Over-Sampling TEchnique for Handling the Class Imbalanced Problem
#@ Chumphol Bunkhumpornpat;Krung Sinapiromsaran;Chidchanok Lursinsap
#t 2009
#c 3
#% 136350
#% 162358
#% 260149
#% 280437
#% 309208
#% 316709
#% 466268
#% 466674
#% 765519
#% 1271973
#% 1378224
#% 1708211
#! The class imbalanced problem occurs in various disciplines when one of target classes has a tiny number of instances comparing to other classes. A typical classifier normally ignores or neglects to detect a minority class due to the small number of class instances. SMOTE is one of over-sampling techniques that remedies this situation. It generates minority instances within the overlapping regions. However, SMOTE randomly synthesizes the minority instances along a line joining a minority instance and its selected nearest neighbours, ignoring nearby majority instances. Our technique called Safe-Level-SMOTE carefully samples minority instances along the same line with different weight degree, called safe level. The safe level computes by using nearest neighbour minority instances. By synthesizing the minority instances more around larger safe level, we achieve a better accuracy performance than SMOTE and Borderline-SMOTE.

#index 1195988
#* Using Highly Expressive Contrast Patterns for Classification - Is It Worthwhile?
#@ Elsa Loekito;James Bailey
#t 2009
#c 3
#% 210160
#% 280409
#% 342717
#% 379331
#% 546047
#% 881486
#% 881499
#% 1117080
#% 1411103
#! Classification is an important task in data mining. Contrast patterns, such as emerging patterns, have been shown to be powerful for building classifiers, but they rarely exist in sparse data. Recently proposed disjunctive emerging patterns are highly expressive, and can potentially overcome this limitation. Simple contrast patterns only allow simple conjunctions, whereas disjunctive patterns additionally allow expressions of disjunctions. This paper investigates whether expressive contrasts are beneficial for classification. We adopt a statistical methodology for eliminating noisy patterns. Our experiments identify circumstances where expressive patterns can improve over previous contrast pattern based classifiers. We also present some guidelines for i) using expressive patterns based on the nature of the given data, ii) how to choose between the different types of contrast patterns for building a classifier.

#index 1195989
#* Arif Index for Predicting the Classification Accuracy of Features and Its Application in Heart Beat Classification Problem
#@ Muhammad Arif;Fayyaz A. Afsar;Muhammad Usman Akram;Adnan Fida
#t 2009
#c 3
#% 104472
#% 397597
#% 430746
#% 462243
#% 511813
#% 957327
#% 1861495
#! In this paper, Arif Index is proposed that can be used to assess the discrimination power of features in pattern classification problems. Discrimination power of features play an important role in the classification accuracy of a particular classifier applied to the pattern classification problem. Optimizing the performance of a classifier requires a prior knowledge of maximum achievable accuracy in pattern classification using a particular set of features. Moreover, it is also desirable to know that this set of features is separable by a decision boundary of any arbitrary complexity or not. Proposed index varies linearly with the overlap of features of different classes in the feature space and hence can be used in predicting the classification accuracy of the features that can be achieved by some optimal classifier. Using synthetic data, it is shown that the predicted accuracy and Arif index are very strongly correlated with each other (R 2 = 0.99). Implementation of the index is simple and time efficient. Index was tested on Arrhythmia beat classification problem and predicted accuracy was found to be in consistent with the reported results.

#index 1195990
#* UCI++: Improved Support for Algorithm Selection Using Datasetoids
#@ Carlos Soares
#t 2009
#c 3
#% 191911
#% 431102
#% 565970
#% 1100127
#% 1117465
#% 1173720
#! As companies employ a larger number of models, the problem of algorithm (and parameter) selection is becoming increasingly important. Two approaches to obtain empirical knowledge that is useful for that purpose are empirical studies and metalearning. However, most empirical (meta)knowledge is obtained from a relatively small set of datasets. In this paper, we propose a method to obtain a large number of datasets which is based on a simple transformation of existing datasets, referred to as datasetoids . We test our approach on the problem of using metalearning to predict when to prune decision trees. The results show significant improvement when using datasetoids. Additionally, we identify a number of potential anomalies in the generated datasetoids and propose methods to solve them.

#index 1195991
#* Accurate Synthetic Generation of Realistic Personal Information
#@ Peter Christen;Agus Pudjijono
#t 2009
#c 3
#% 131061
#% 317975
#% 318940
#% 324015
#% 420072
#% 913783
#% 972264
#% 972308
#% 1083744
#% 1675764
#! A large portion of data collected by many organisations today is about people, and often contains personal identifying information, such as names and addresses. Privacy and confidentiality are of great concern when such data is being shared between organisations or made publicly available. Research in (privacy-preserving) data mining and data linkage is suffering from a lack of publicly available real-world data sets that contain personal information, and therefore experimental evaluations can be difficult to conduct. In order to overcome this problem, we have developed a data generator that allows flexible creation of synthetic data containing personal information with realistic characteristics, such as frequency distributions, attribute dependencies, and error probabilities. Our generator significantly improves earlier approaches, and allows the generation of data for individuals, families and households.

#index 1195992
#* An Efficient Approximate Protocol for Privacy-Preserving Association Rule Mining
#@ Murat Kantarcioglu;Robert Nix;Jaideep Vaidya
#t 2009
#c 3
#% 152934
#% 300184
#% 381870
#% 512307
#% 577289
#% 637062
#% 653942
#% 727904
#% 772829
#% 810010
#% 819234
#% 954159
#% 1021945
#% 1722551
#! The secure scalar product (or dot product) is one of the most used sub-protocols in privacy-preserving data mining. Indeed, the dot product is probably the most common sub-protocol used. As such, a lot of attention has been focused on coming up with secure protocols for computing it. However, an inherent problem with these protocols is the extremely high computation cost --- especially when the dot product needs to be carried out over large vectors. This is quite common in vertically partitioned data, and is a real problem. In this paper, we present ways to efficiently compute the approximate dot product. We implement the dot product protocol and demonstrate the quality of the approximation. Our dot product protocol can be used to securely and efficiently compute association rules from data vertically partitioned between two parties.

#index 1195993
#* Information Extraction from Thai Text with Unknown Phrase Boundaries
#@ Peerasak Intarapaiboon;Ekawit Nantajeewarawat;Thanaruk Theeramunkong
#t 2009
#c 3
#% 278109
#% 889107
#! Using sliding-window rule application and extraction filtering techniques, we propose a framework for extracting semantic frames from Thai textual phrases with unknown boundaries based on patterns of triggering terms. A supervised rule learning algorithm is used for constructing multi-slot extraction rules from hand-tagged training phrases. A filtering module is introduced for predicting rule application across phrase boundaries based on instantiation features of rule internal wildcards. The framework is applied to text documents in three domains with different target-phrase density and average lengths. The experimental results show that the filtering module improves precision and preserves high recall satisfactorily, yielding extraction performance comparable to frame extraction with manually identified phrase boundaries.

#index 1195994
#* A Corpus-Based Approach for Automatic Thai Unknown Word Recognition using Ensemble Learning Techniques
#@ Jakkrit Techo;Cholwich Nattee;Thanaruk Theeramunkong
#t 2009
#c 3
#% 551723
#% 756843
#% 983565
#! This paper presents a corpus-based approach for automatic unknown word recognition in Thai. This approach applies an ensemble learning technique to generate a model for classifying unknown word candidates using features obtained from a corpus. We propose a technique called "group-based evaluation by ranking". It clusters the unknown word candidates into groups based on the occuring locations. The candidate with the highest accuracy is then identified as an unknown word. In this task, the number of positive instances is dominantly smaller than that of negative instances, forming an unbalanced data set. To improve the prediction accuracy, we apply a boosting technique with "voting under group-based evaluation by ranking". We have conducted experiments on real-world data to evaluate the performance of the proposed approach. The experiments compared the accuracy of our technique with an ordinary naïve Bayes technique. Our technique achieves the accuracy 90.93±0.50% when the first rank is selected and 97.90±0.26% when the candidates up to the tenth rank are considered. This is 6.79% to 8.45% improvement.

#index 1195995
#* A Hybrid Approach to Improve Bilingual Multiword Expression Extraction
#@ Jianyong Duan;Mei Zhang;Lijing Tong;Feng Guo
#t 2009
#c 3
#% 196896
#% 565531
#% 722797
#% 741138
#% 748700
#% 855199
#% 1264296
#% 1294839
#! We propose a hybrid approach for bilingual multiword expression extraction. There are two phases in the extraction process. In the first phase, lots of candidates are extracted from the corpus by statistic methods. The algorithm of multiple sequence alignment is sensitive to the flexible multiword. In the second phase, error-driven rules and patterns are extracted from corpus. These trained rules are used to filter the candidates. Some related experiments are designed for achieving the best performance because there are lots of parameters in this system. Experimental results showed our approach gains good performance.

#index 1195996
#* Addressing the Variability of Natural Language Expression in Sentence Similarity with Semantic Structure of the Sentences
#@ Palakorn Achananuparp;Xiaohua Hu;Christopher C. Yang
#t 2009
#c 3
#% 747891
#% 815295
#% 838508
#% 855269
#% 858036
#% 939699
#% 957908
#% 971758
#% 980527
#% 987236
#% 989634
#% 1107641
#% 1250629
#% 1299562
#% 1299586
#% 1392432
#! In this paper, we present a new approach that incorporates semantic structure of sentences, in a form of verb-argument structure, to measure semantic similarity between sentences. The variability of natural language expression makes it difficult for existing text similarity measures to accurately identify semantically similar sentences since sentences conveying the same fact or concept may be composed lexically and syntactically different. Inversely, sentences which are lexically common may not necessarily convey the same meaning. This poses a significant impact on many text mining applications' performance where sentence-level judgment is involved. The evaluation has shown that, by processing sentence at its semantic level, the performance of similarity measures is significantly improved.

#index 1195997
#* Scalable Web Mining with Newistic
#@ Ovidiu Dan;Horatiu Mocian
#t 2009
#c 3
#% 118736
#% 280817
#% 508257
#% 754106
#% 763708
#% 805848
#% 807309
#% 815133
#% 816141
#% 956521
#% 995468
#! Newistic is a web mining platform that collects and analyses documents crawled from the Internet. Although it currently processes news articles, it can be easily adapted to any other form of text. Data mining functions performed by the system are categorization, clustering and named entity extraction. The main design concern of the system is scalability, which is achieved by a modular architecture that allows multiple instances of the same component to be run in parallel. This paper presents a novel algorithm for analysing web pages which tries to determine the title and text of a news item directly from the HTML code, discarding noise such as menus, ads, or copyright notices. Another contribution of this paper is the application of the Quality Threshold clustering algorithm for document clustering. Additionally, the algorithm has been optimized to increase its speed.

#index 1195998
#* Building a Text Classifier by a Keyword and Unlabeled Documents
#@ Qiang Qiu;Yang Zhang;Junping Zhu
#t 2009
#c 3
#% 252011
#% 311027
#% 464641
#% 466083
#% 577235
#% 727862
#% 727883
#% 729621
#% 800568
#% 836145
#% 843873
#% 1100060
#% 1250186
#% 1279298
#% 1699593
#! Traditional approaches for building text classifiers usually require a lot of labeled documents, which are expensive to obtain. In this paper, we study the problem of building a text classifier from a keyword and unlabeled documents, so as to avoid labeling documents manually. Firstly, we expand the keyword into a set of query terms and retrieve a set of documents from the set of unlabeled documents. Then, from the documents retrieved, we mine a set of positive documents. Thirdly, with the help of these positive documents, more positive documents could be extracted from the unlabeled documents. And finally, we train a PU text classifier with these positive documents and unlabeled documents. Our experiment result on 20Newsgroup dataset shows that the proposed approach could help to build excellent text classifiers.

#index 1195999
#* A Discriminative Approach to Topic-Based Citation Recommendation
#@ Jie Tang;Jing Zhang
#t 2009
#c 3
#% 92145
#% 415107
#% 450888
#% 766409
#% 891060
#% 987287
#% 1083734
#! In this paper, we present a study of a novel problem, i.e. topic-based citation recommendation, which involves recommending papers to be referred to. Traditionally, this problem is usually treated as an engineering issue and dealt with using heuristics. This paper gives a formalization of topic-based citation recommendation and proposes a discriminative approach to this problem. Specifically, it proposes a two-layer Restricted Boltzmann Machine model, called RBM-CS, which can discover topic distributions of paper content and citation relationship simultaneously. Experimental results demonstrate that RBM-CS can significantly outperform baseline methods for citation recommendation.

#index 1196000
#* Romanization of Thai Proper Names Based on Popularity of Usages
#@ Akegapon Tangverapong;Atiwong Suchato;Proadpran Punyabukkana
#t 2009
#c 3
#! The lack of standards for Romanization of Thai proper names makes searching activity a challenging task. This is particularly important when searching for people-related documents based on orthographic representation of their names using either solely Thai or English alphabets. Romanization based directly on the names' pronunciations often fails to deliver exact English spellings due to the non-1-to-1 mapping from Thai to English spelling and personal preferences. This paper proposes a Romanization approach where popularity of usages is taken into consideration. Thai names are parsed into sequences of grams, units of syllable-sized or larger governed by pronunciation and spelling constraints in both Thai and English writing systems. A Gram lexicon is constructed from a corpus of more than 130,000 names. Statistical models are trained accordingly based on the Gram lexicon. The proposed method significantly outperformed the current Romanization approach. Approximately 46% to 75% of the correct English spellings are covered when the number of proposed hypotheses increases from 1 to 15.

#index 1196001
#* Budget Semi-supervised Learning
#@ Zhi-Hua Zhou;Michael Ng;Qiao-Qiao She;Yuan Jiang
#t 2009
#c 3
#% 224113
#% 1393155
#! In this paper we propose to study budget semi-supervised learning , i.e., semi-supervised learning with a resource budget, such as a limited memory insufficient to accommodate and/or process all available unlabeled data. This setting is with practical importance because in most real scenarios although there may exist abundant unlabeled data, the computational resource that can be used is generally not unlimited. Effective budget semi-supervised learning algorithms should be able to adjust behaviors considering the given resource budget. Roughly, the more resource, the more exploitation on unlabeled data. As an example, in this paper we show that this is achievable by a simple yet effective method.

#index 1196002
#* When does Co-training Work in Real Data?
#@ Charles X. Ling;Jun Du;Zhi-Hua Zhou
#t 2009
#c 3
#% 136350
#% 252011
#% 316509
#% 429833
#% 466888
#% 815908
#% 816079
#% 832574
#% 926881
#! Co-training, a paradigm of semi-supervised learning, may alleviate effectively the data scarcity problem (i.e., the lack of labeled examples) in supervised learning. The standard two-view co-training requires the dataset be described by two views of attributes, and previous theoretical studies proved that if the two views satisfy the sufficiency and independence assumptions, co-training is guaranteed to work well. However, little work has been done on how these assumptions can be empirically verified given datasets. In this paper, we first propose novel approaches to verify empirically the two assumptions of co-training based on datasets. We then propose simple heuristic to split a single view of attributes into two views, and discover regularity on the sufficiency and independence thresholds for the standard two-view co-training to work well. Our empirical results not only coincide well with the previous theoretical findings, but also provide a practical guideline to decide when co-training should work well based on datasets.

#index 1196003
#* Classification of Audio Signals Using a Bhattacharyya Kernel-Based Centroid Neural Network
#@ Dong-Chul Park;Yunsik Lee;Dong-Min Woo
#t 2009
#c 3
#% 1393195
#% 1860645
#% 1860851
#% 1862134
#! A novel approach for the classification of audio signals using a Bhattacharyya Kernel-based Centroid Neural Network (BK-CNN) is proposed and presented in this paper. The proposed classifier is based on Centroid Neural Network (CNN) and also exploits advantages of the kernel method for mapping input data into a higher dimensional feature space. Furthermore, since the feature vectors of audio signals are modelled by Gaussian Probability Density Function (GPDF), the classification procedure is performed by considering Bhattacharyya distance as the distance measure of the proposed classifier. Experiments and results on various audio data sets demonstrate that the proposed classification scheme based on BK-CNN outperforms conventional algorithms including Self-Organizing Map(SOM) and CNN.

#index 1196004
#* Sparse Kernel Learning and the Relevance Units Machine
#@ Junbin Gao;Jun Zhang
#t 2009
#c 3
#% 266881
#% 528020
#% 722760
#% 916787
#% 961154
#% 1026330
#% 1154332
#% 1377878
#% 1861282
#! The relevance vector machine(RVM) is a state-of-the-art constructing sparse regression kernel model [1,2,3,4]. It not only generates a much sparser model but provides better generalization performance than the standard support vector machine (SVM). In RVM and SVM, relevance vectors (RVs) and support vectors (SVs) are both selected from the input vector set. This may limit model flexibility. In this paper we propose a new sparse kernel model called Relevance Units Machine (RUM). RUM follows the idea of RVM under the Bayesian framework but releases the constraint that RVs have to be selected from the input vectors. RUM treats relevance units as part of the parameters of the model. As a result, a RUM maintains all the advantages of RVM and offers superior sparsity. The new algorithm is demonstrated to possess considerable computational advantages over well-known the state-of-the-art algorithms.

#index 1196005
#* Pairwise Constrained Clustering for Sparse and High Dimensional Feature Spaces
#@ Su Yan;Hai Wang;Dongwon Lee;C. Lee Giles
#t 2009
#c 3
#% 313959
#% 464291
#% 464608
#% 464888
#% 769881
#% 770782
#% 879615
#! Clustering high dimensional data with sparse features is challenging because pairwise distances between data items are not informative in high dimensional space. To address this challenge, we propose two novel semi-supervised clustering methods that incorporate prior knowledge in the form of pairwise cluster membership constraints. In particular, we project high-dimensional data onto a much reduced-dimension subspace, where rough clustering structure defined by the prior knowledge is strengthened. Metric learning is then performed on the subspace to construct more informative pairwise distances. We also propose to propagate constraints locally to improve the informativeness of pairwise distances. When the new methods are evaluated using two real benchmark data sets, they show substantial improvement using only limited prior knowledge.

#index 1196006
#* Clustering Documents Using a Wikipedia-Based Concept Representation
#@ Anna Huang;David Milne;Eibe Frank;Ian H. Witten
#t 2009
#c 3
#% 375017
#% 627609
#% 727861
#% 987328
#% 1002315
#% 1033867
#% 1074073
#% 1117027
#% 1130858
#% 1176863
#% 1250362
#! This paper shows how Wikipedia and the semantic knowledge it contains can be exploited for document clustering. We first create a concept-based document representation by mapping the terms and phrases within documents to their corresponding articles (or concepts) in Wikipedia. We also developed a similarity measure that evaluates the semantic relatedness between concept sets for two documents. We test the concept-based representation and the similarity measure on two standard text document datasets. Empirical results show that although further optimizations could be performed, our approach already improves upon related techniques.

#index 1196007
#* An Instantiation of Hierarchical Distance-Based Conceptual Clustering for Propositional Learning
#@ Ana Funes;Cesar Ferri;Jose Hernández-Orallo;Maria José Ramírez-Quintana
#t 2009
#c 3
#% 5182
#% 296738
#% 324276
#% 451052
#% 1108857
#! In this work we analyse the relationship between distance and generalisation operators for real numbers, nominal data and tuples in the context of hierarchical distance-based conceptual clustering (HDCC). HDCC is a general approach to conceptual clustering that extends the traditional algorithm for hierarchical clustering by producing conceptual generalisations of the discovered clusters. This makes it possible to combine the flexibility of changing distances for several clustering problems and the advantage of having concepts which are crucial for tasks as summarisation and descriptive data mining in general. In this work we propose a set of generalisation operators and distances for the data types mentioned before and we analyse the properties by them satisfied on the basis of three different levels of agreement between the clustering hierarchy obtained from the linkage distance and the hierarchy obtained by using generalisation operators.

#index 1196008
#* Computing Substitution Matrices for Genomic Comparative Analysis
#@ Minh Duc Cao;Trevor I. Dix;Lloyd Allison
#t 2009
#c 3
#% 965081
#! Substitution matrices describe the rates of mutating one character in a biological sequence to another character, and are important for many knowledge discovery tasks such as phylogenetic analysis and sequence alignment. Computing substitution matrices for very long genomic sequences of divergent or even unrelated species requires sensitive algorithms that can take into account differences in composition of the sequences. We present a novel algorithm that addresses this by computing a nucleotide substitution matrix specifically for the two genomes being aligned. The method is founded on information theory and in the expectation maximisation framework. The algorithm iteratively uses compression to align the sequences and estimates the matrix from the alignment, and then applies the matrix to find a better alignment until convergence. Our method reconstructs, with high accuracy, the substitution matrix for synthesised data generated from a known matrix with introduced noise. The model is then successfully applied to real data for various malaria parasite genomes, which have differing phylogenetic distances and composition that lessens the effectiveness of standard statistical analysis techniques.

#index 1196009
#* Mining Both Positive and Negative Impact-Oriented Sequential Rules from Transactional Data
#@ Yanchang Zhao;Huaifeng Zhang;Longbing Cao;Chengqi Zhang;Hans Bohlscheid
#t 2009
#c 3
#% 152934
#% 310559
#% 329537
#% 463903
#% 464822
#% 464996
#% 577256
#% 767654
#% 799740
#% 1040761
#% 1155719
#% 1390144
#! Traditional sequential pattern mining deals with positive correlation between sequential patterns only, without considering negative relationship between them. In this paper, we present a notion of impact-oriented negative sequential rules , in which the left side is a positive sequential pattern or its negation, and the right side is a predefined outcome or its negation. Impact-oriented negative sequential rules are formally defined to show the impact of sequential patterns on the outcome, and an efficient algorithm is designed to discover both positive and negative impact-oriented sequential rules. Experimental results on both synthetic data and real-life data show the efficiency and effectiveness of the proposed technique.

#index 1196010
#* Aggregated Subset Mining
#@ Albrecht Zimmermann;Björn Bringmann
#t 2009
#c 3
#% 209021
#% 269217
#% 495270
#% 833126
#% 1116995
#% 1663621
#! The usual data mining setting uses the full amount of data to derive patterns for different purposes. Taking cues from machine learning techniques, we explore ways to divide the data into subsets, mine patterns on them and use post-processing techniques for acquiring the result set. Using the patterns as features for a classification task to evaluate their quality, we compare the different subset compositions, and selection techniques. The two main results --- that small independent sets are better suited than large amounts of data, and that uninformed selection techniques perform well --- can to a certain degree be explained by quantitative characteristics of the derived pattern sets.

#index 1196011
#* Hot Item Detection in Uncertain Data
#@ Thomas Bernecker;Hans-Peter Kriegel;Matthias Renz;Andreas Zuefle
#t 2009
#c 3
#% 152937
#% 501988
#% 654487
#% 823402
#% 824728
#% 864396
#% 1016202
#% 1103015
#% 1206646
#% 1393138
#% 1669490
#! An object o of a database $\mathcal{D}$ is called a hot item , if there is a sufficiently large population of other objects in $\mathcal{D}$ that are similar to o . In other words, hot items are objects within a dense region of other objects and provide a basis for many density-based data mining techniques. Intuitively, objects that share their attribute values with a lot of other objects could be potentially interesting as they show a typical occurrence of objects in the database. Also, there are a lot of application domains, e.g. sensor databases, traffic management or recognition systems, where objects have vague and uncertain attributes. We propose an approach for the detection of potentially interesting objects (hot items ) of an uncertain database in a probabilistic way. An efficient algorithm is presented which detects hot items , where to each object o a confidence value is assigned that reflects the likelihood that o is a hot item . In an experimental evaluation we show that our method can compute the results very efficiently compared to its competitors.

#index 1196012
#* Spanning Tree Based Attribute Clustering
#@ Yifeng Zeng;Jorge Cordero Hernandez;Shuyuan Lin
#t 2009
#c 3
#% 64124
#% 778215
#% 813902
#% 1010466
#! Attribute clustering has been previously employed to detect statistical dependence between subsets of variables. We propose a novel attribute clustering algorithm motivated by research of complex networks, called the Star Discovery algorithm. The algorithm partitions and indirectly discards inconsistent edges from a maximum spanning tree by starting appropriate initial modes, therefore generating stable clusters. It discovers sound clusters through simple graph operations and achieves significant computational savings. We compare the Star Discovery algorithm against earlier attribute clustering algorithms and evaluate the performance in several domains.

#index 1196013
#* The Effect of Varying Parameters and Focusing on Bus Travel Time Prediction
#@ João M. Moreira;Carlos Soares;Alípio M. Jorge;Jorge Freire Sousa
#t 2009
#c 3
#% 420140
#% 720010
#! Travel time prediction is an important tool for the planning tasks of mass transit and logistics companies. In this paper we investigate the use of regression methods for the problem of predicting the travel time of buses in a Portuguese public transportation company. More specifically, we empirically evaluate the impact of varying parameters on the performance of different regression algorithms, such as support vector machines (SVM), random forests (RF) and projection pursuit regression (PPR). We also evaluate the impact of the focusing tasks (example selection, domain value definition and feature selection) in the accuracy of those algorithms. Concerning the algorithms, we observe that 1) RF is quite robust to the choice of parameters and focusing methods; 2) the choice of parameters for SVM can be made independently of focusing methods while 3) for PPR they should be selected simultaneously. For the focusing methods, we observe that a stronger effect is obtained using example selection, particularly in combination with SVM.

#index 1196014
#* Transfer Learning Action Models by Measuring the Similarity of Different Domains
#@ Hankui Zhuo;Qiang Yang;Lei Li
#t 2009
#c 3
#% 320415
#% 850430
#% 944137
#% 1164379
#% 1269766
#% 1272008
#! AI planning requires action models to be given in advance. However, it is both time consuming and tedious for a human to encode the action models by hand using a formal language such as PDDL, as a result, learning action models is important for AI planning. On the other hand, the data being used to learn action models are often limited in planning domains, which makes the learning task very difficult. In this paper, we present a new algorithm to learn action models from plan traces by transferring useful information from other domains whose action models are already known. We present a method of building a metric to measure the shared information and transfer this information according to this metric. The larger the metric is, the bigger the information is transferred. In the experiment result, we show that our proposed algorithm is effective.

#index 1196015
#* On Optimal Rule Mining: A Framework and a Necessary and Sufficient Condition of Antimonotonicity
#@ Yannick Bras;Philippe Lenca;St&#233/phane Lallich
#t 2009
#c 3
#% 152934
#% 299985
#% 300120
#% 310558
#% 342667
#% 443393
#% 452846
#% 466483
#% 481290
#% 631970
#% 727897
#% 751575
#% 823417
#% 863384
#% 867057
#% 1099013
#% 1411120
#% 1707794
#! Many studies have shown the limits of support/confidence framework used in Apriori-like algorithms to mine association rules. There are a lot of efficient implementations based on the antimonotony property of the support but candidate set generation is still costly. In addition many rules are uninteresting or redundant and one can miss interesting rules like nuggets. One solution is to get rid of frequent itemset mining and to focus as soon as possible on interesting rules. For that purpose algorithmic properties were first studied, especially for the confidence. They allow all confidence rules to be found without a preliminary support pruning. More recently, in the case of class association rules, the concept of optimal rules gave a pruning strategy compatible with more measures. However, all these properties have been demonstrated for a limited number of interestingness measures. We present a new formal framework which allows us to make the link between analytic and algorithmic properties of the measures. We apply this framework to optimal rules, and we demonstrate a necessary and sufficient condition of existence for this pruning strategy, which can be applied to any measure.

#index 1196016
#* Discovering Action Rules That Are Highly Achievable from Massive Data
#@ Einoshin Suzuki
#t 2009
#c 3
#% 136350
#% 174161
#% 232106
#% 246831
#% 310548
#% 431157
#% 478140
#% 481290
#% 549322
#% 629649
#% 808913
#% 831299
#% 844380
#! In this paper, we propose a novel algorithm which discovers a set of action rules for converting negative examples into positive examples. Unlike conventional action rule discovery methods, our method AARUDIA (Achievable Action RUle DIscovery Algorithm) considers the effects of actions and the achievability of the class change for disk-resident data. In AARUDIA, effects of actions are specified using domain rules and the achievability is inferred with Naive Bayes classifiers. AARUDIA takes a new breadth-first search method which manages actionable literals and stable literals, and exploits the achievability to reduce the number of discovered rules. Experimental results with inflated real-world data sets are promising and demonstrate the practicality of AARUDIA.

#index 1196017
#* Extracting Fuzzy Rules for Detecting Ventricular Arrhythmias Based on NEWFM
#@ Dong-Kun Shin;Sang-Hong Lee;Joon S. Lim
#t 2009
#c 3
#% 794111
#% 1377774
#% 1699304
#! In the heart disease, the important problem of ECG arrhythmia is to discriminate ventricular arrhythmias from normal cardiac rhythm. This paper presents novel method based on the neural network with weighted fuzzy membership functions (NEWFM) for the discrimination of ventricular tachycardia (VT) and ventricular fibrillation (VF) from normal sinus rhythm (NSR). This paper uses two pre-processes, the Haar wavelet function and extraction feature method are carried out in order. By using these methods, six features can be generated, which are the input data of NEWFM. NEWFM classifies NSR and VT/VF beats by the trained bounded sum of weighted fuzzy membership functions (BSWFMs) using six input features from the Creighton University Ventricular Tachyarrhythmia Data Base (CUDB). The results are better than Amann's phase space reconstruction (PSR) algorithm, accuracy and specificity rates of 90.4% and 93.3%, respectively.

#index 1196018
#* Trace Mining from Distributed Assembly Databases for Causal Analysis
#@ Shohei Hido;Hirofumi Matsuzawa;Fumihiko Kitayama;Masayuki Numao
#t 2009
#c 3
#% 340291
#% 420067
#% 434348
#% 481588
#% 829974
#! Hierarchical structures of components often appear in industry, such as the components of cars. We focus on association mining from the hierarchically assembled data items that are characterized with identity labels such as lot numbers. Massive and physically distributed product databases make it difficult to directly find the associations of deep-level items. We propose a top-down algorithm using virtual lot numbers to mine association rules from the hierarchical databases. Virtual lot numbers delegate the identity information of the subcomponents to upper-level lot numbers without modifications to the databases. Our pruning method reduces the number of enumerated items and avoids redundant access to the databases. Experiments show that the algorithm works an order of magnitude faster than a naive approach.

#index 1196019
#* Let's Tango --- Finding the Right Couple for Feature-Opinion Association in Sentiment Analysis
#@ Kam Tong Chan;Irwin King
#t 2009
#c 3
#% 727877
#% 769892
#% 1035591
#% 1261566
#! One approach in opinion mining is to perform sentiment classification at the sentence level. User's view on a discovered product feature is predicted by the opinion words, e.g. adjectives, appeared in the same sentence. A number of previous works has been proposed and these approaches typically treat the feature and word relations identically. Blindly using sentiments of all opinion words to perform classification would lead to false results. In this paper, we investigate the relationship between features and opinion words using the corpus-based approach. We proposed a Feature-Opinion Association (FOA) algorithm to match these two in sentences to improve sentiment analysis results. We construct a feature-based sentiment lexicon using the proposed algorithm in the sentiment identification process. Extensive experiments based on a commercial product review site show that our method is quite effective in obtaining a more accurate result.

#index 1196020
#* An Efficient Candidate Pruning Technique for High Utility Pattern Mining
#@ Chowdhury Farhan Ahmed;Syed Khairuzzaman Tanbeer;Byeong-Soo Jeong;Young-Koo Lee
#t 2009
#c 3
#% 481290
#% 729418
#% 945869
#% 1017083
#% 1019450
#% 1411136
#% 1707858
#! High utility pattern mining extracts more useful and realistic knowledge from transaction databases compared to the traditional frequent pattern mining by considering the non-binary frequency values of items in transactions and different profit values for every item. However, the existing high utility pattern mining algorithms suffer from the level-wise candidate generation-and-test problem and need several database scans to mine the actual high utility patterns. In this paper, we propose a novel tree-based candidate pruning technique HUC-Prune (high utility candidates prune) to efficiently mine high utility patterns without level-wise candidate generation-and-test. It exploits a pattern growth mining approach and needs maximum three database scans in contrast to several database scans of the existing algorithms. Extensive experimental results show that our technique is very efficient for high utility pattern mining and it outperforms the existing algorithms.

#index 1196021
#* Grouped ECOC Conditional Random Fields for Prediction of Web User Behavior
#@ Yong Zhen Guo;Kotagiri Ramamohanarao;Laurence A. Park
#t 2009
#c 3
#% 464434
#% 630984
#% 1155659
#% 1272365
#! Web page prefetching has shown to provide reduction in Web access latency, but is highly dependent on the accuracy of the Web page prediction method. Conditional Random Fields (CRFs) with Error Correcting Output Coding (ECOC) have shown to provide highly accurate and efficient Web page prediction on large-size websites. However, the limited class information provided to the binary-label sub-CRFs in ECOC-CRFs will also lead to inferior accuracy when compared to the single multi-label CRFs. Although increasing the minimum Hamming distance of the ECOC matrix can help to improve the accuracy of ECOC-CRFs, it is still not an ideal method. In this paper, we introduce the grouped ECOC-CRFs that allow us to obtain a prediction accuracy closer to that of single multi-label CRFs by grouping the binary ECOC vectors. We show in our experiments that by using the grouping method, we can maintain the efficiency of the ECOC-CRFs while providing significant increase in Web page prediction accuracy over ECOC-CRFs.

#index 1196022
#* CLHQS: Hierarchical Query Suggestion by Mining Clickthrough Log
#@ Depin Chen;Ning Liu;Zhijun Yin;Yang Tong;Jun Yan;Zheng Chen
#t 2009
#c 3
#% 251405
#% 318412
#% 591792
#% 869651
#% 987372
#% 1083721
#! Most commercial search engines provide query suggestion in a ranked list for more effective search. However, a ranked list may not be an ideal way to satisfy users' various information demands. In this paper, we propose a novel query suggestion method named CLHQS (Clickthrough-Log based Hierarchical Query Suggestion). It organizes the suggested queries into a well-structured hierarchy. Users can easily generalize, extend or specialize their queries within the hierarchy. The query hierarchy is mined from the clickthrough log data in the following way. First, we generate a candidate set through the query-url graph analysis. Second, the pair-wise relationships are inspected for each pair of candidate queries. Finally, we construct the suggested query hierarchy using these relationships. Experiments on a real-world clickthrough log validate the effectiveness of our proposed CLHQS approach.

#index 1196023
#* X-Tracking the Changes of Web Navigation Patterns
#@ Long Wang;Christoph Meinel
#t 2009
#c 3
#% 280409
#% 288885
#% 480126
#% 729919
#% 783498
#% 799787
#% 823356
#! In this paper, we firstly investigate the possible changes on web usage behaviors and then propose an x-tracking method to detect these changes. The changes on web navigation patterns are depicted from microscopic and macroscopic levels: the former is for the "internal" and "external" changes which show the variations on the semantics and external physical features respectively, while the latter is modeled for the changes of the popularity on "local" and "global" time line. The x-tracking method we propose is to detect the newly emerged patterns (EP) based on "internal" feature, which is the premise to compute the changes on other features by tracking their internal unchanged patterns (IUP). Experiments show that the x-tracked changes are condensed, efficient and informative.

#index 1196024
#* Tree-Based Method for Classifying Websites Using Extended Hidden Markov Models
#@ Majid Yazdani;Milad Eftekhar;Hassan Abolhassani
#t 2009
#c 3
#% 248810
#% 337226
#% 577236
#% 766437
#% 818916
#% 950070
#! One important problem proposed recently in the field of web mining is website classification problem. The complexity together with the necessity to have accurate and fast algorithms yield to many attempts in this field, but there is a long way to solve these problems efficiently, yet. The importance of the problem encouraged us to work on a new approach as a solution. We use the content of web pages together with the link structure between them to improve the accuracy of results. In this work we use Naïve-bayes models for each predefined webpage class and an extended version of Hidden Markov Model is used as website class models. A few sample websites are adopted as seeds to calculate models' parameters. For classifying the websites we represent them with tree structures and we modify the Viterbi algorithm to evaluate the probability of generating these tree structures by every website model. Because of the large amount of pages in a website, we use a sampling technique that not only reduces the running time of the algorithm but also improves the accuracy of the classification process. At the end of this paper, we provide some experimental results which show the performance of our algorithm compared to the previous ones.

#index 1196025
#* Emotion Recognition of Pop Music Based on Maximum Entropy with Priors
#@ Hui He;Bo Chen;Jun Guo
#t 2009
#c 3
#% 211044
#% 854646
#% 855283
#% 938687
#% 1584663
#% 1775480
#! Efficient and intelligent music retrieval has become a very important topic nowadays. Analysis of lyrics must be a complement of acoustic methods for music retrieval. One basic aspect of music retrieval is music emotion recognition by learning from lyrics. This problem is different from traditional text classification in that more linguistic or semantic information is required for better emotion analysis. Thereby, we focus on how to extract meaningful features and how to modeling them for music emotion recognition. First, we investigate the lyrics corpus based on Zipf's Law using word as a unit, and results roughly obey Zipf's Law. Then, we study three kinds of preprocessing methods and a series of language grams under the well-known n-gram language model framework to extract more semantic features. At last, we employ three supervised learning methods, Naïve Bayes, maximum entropy classification, and support vector machine, to examine the classification performance. Besides that, we also improve ME with Gaussian and Laplace priors to model features for music emotion recognition. Experiment al results show that feature extraction methods improved music emotion recognition accuracy. ME with priors obtained the best.

#index 1196026
#* Simultaneously Finding Fundamental Articles and New Topics Using a Community Tracking Method
#@ Tieyun Qian;Jaideep Srivastava;Zhiyong Peng;Phillip C. Sheu
#t 2009
#c 3
#% 268079
#% 290830
#% 722904
#% 769906
#% 823344
#% 881498
#% 1116997
#% 1348084
#! In this paper, we study the relationship between fundamental articles and new topics and present a new method to detect recently formed topics and its typical articles simultaneously. Based on community partition, the proposed method first identifies the emergence of a new theme by tracking the change of the community where the top cited nodes lie. Next, the paper with a high citation number belonging to this new topic is recognized as a fundamental article. Experimental results on real dataset show that our method can detect new topics with only a subset of data in a timely manner, and the identified papers for these topics are found to have a long lifespan and keep receiving citations in the future.

#index 1196027
#* Towards a Novel Association Measure via Web Search Results Mining
#@ Xiaojun Wan;Jianguo Xiao
#t 2009
#c 3
#% 281186
#% 325502
#% 766433
#% 869500
#% 939627
#% 956570
#% 1250629
#% 1261588
#% 1269907
#! Web-based association measure aims to evaluate the semantic similarity between two queries (i.e. words or entities) by leveraging the search results returned by search engines. Existing web-relevance similarity measure usually considers all search results for a query as a coarse-grained single topic and measures the similarity between the term vectors constructed by concatenating all search results into a single document for each query. This paper proposes a novel association measure named WSRCM based on web search results clustering and matching to evaluate the semantic similarity between two queries at a fine-grained level. WSRCM first discovers the subtopics in the search results for each query and then measures the consistency between the sets of subtopics for two queries. Each subtopic for a query is expected to describe a unique facet of the query, and two queries sharing more subtopics are deemed more semantically related. Experimental results demonstrate the encouraging performance of the proposed measure.

#index 1196028
#* A New Local Distance-Based Outlier Detection Approach for Scattered Real-World Data
#@ Ke Zhang;Marcus Hutter;Huidong Jin
#t 2009
#c 3
#% 300136
#% 300183
#% 477821
#% 479791
#% 501988
#% 1083673
#% 1669935
#! Detecting outliers which are grossly different from or inconsistent with the remaining dataset is a major challenge in real-world KDD applications. Existing outlier detection methods are ineffective on scattered real-world datasets due to implicit data patterns and parameter setting issues. We define a novel Local Distance-based Outlier Factor (LDOF) to measure the outlier-ness of objects in scattered datasets which addresses these issues. LDOF uses the relative location of an object to its neighbours to determine the degree to which the object deviates from its neighbourhood. We present theoretical bounds on LDOF's false-detection probability. Experimentally, LDOF compares favorably to classical KNN and LOF based outlier detection. In particular it is less sensitive to parameter values.

#index 1196029
#* Mining Outliers with Faster Cutoff Update and Space Utilization
#@ Chi-Cheong Szeto;Edward Hung
#t 2009
#c 3
#% 300183
#% 479791
#% 729912
#% 881495
#% 1019141
#% 1051998
#! It is desirable to find unusual data objects by Ramaswamy et al's distance-based outlier definition because only a metric distance function between two objects is required. It does not need any neighborhood distance threshold required by many existing algorithms based on the definition of Knorr and Ng. Bay and Schwabacher proposed an efficient algorithm ORCA, which can give near linear time performance, for this task. To further reduce the running time, we propose in this paper two algorithms RC and RS using the following two techniques respectively: (i) faster cutoff update, and (ii) space utilization after pruning. We tested RC, RS and RCS (a hybrid approach combining both RC and RS) on several large and high-dimensional real data sets with millions of objects. The experiments show that the speed of RCS is as fast as 1.4 to 2.3 times that of ORCA, and the improvement of RCS is relatively insensitive to the increase in the data size.

#index 1196030
#* Outlier Detection in Axis-Parallel Subspaces of High Dimensional Data
#@ Hans-Peter Kriegel;Peer Kröger;Erich Schubert;Arthur Zimek
#t 2009
#c 3
#% 300136
#% 480132
#% 1083673
#% 1103018
#% 1165480
#! We propose an original outlier detection schema that detects outliers in varying subspaces of a high dimensional feature space. In particular, for each object in the data set, we explore the axis-parallel subspace spanned by its neighbors and determine how much the object deviates from the neighbors in this subspace. In our experiments, we show that our novel subspace outlier detection is superior to existing full-dimensional approaches and scales well to high dimensional databases.

#index 1196031
#* K-Dominant Skyline Computation by Using Sort-Filtering Method
#@ Md. Anisuzzaman Siddique;Yasuhiko Morimoto
#t 2009
#c 3
#% 333854
#% 465167
#% 806212
#% 875012
#% 993954
#% 1052680
#% 1206643
#! Skyline queries are useful in many applications such as multi-criteria decision making, data mining, and user preference queries. A skyline query returns a set of interesting data objects that are not dominated in all dimensions by any other objects. For a high-dimensional database, sometimes it returns too many data objects to analyze intensively. To reduce the number of returned objects and to find more important and meaningful objects, we consider a problem of k-dominant skyline queries. Given an n-dimensional database, an object p is said to k-dominates another object q if there are $(\textbf{k} {\leq} \textbf{n})$ dimensions in which p is better than or equal to q. A k-dominant skyline object is an object that is not k-dominated by any other objects. In contrast, conventional skyline objects are n-dominant objects. We propose an efficient method for computing k-dominant skyline queries. Intensive performance study using real and synthetic datasets demonstrated that our method is efficient and scalable.

#index 1196032
#* Effective Boosting of Naïve Bayesian Classifiers by Local Accuracy Estimation
#@ Zhipeng Xie
#t 2009
#c 3
#% 136350
#% 235377
#% 302391
#% 424997
#% 501524
#% 1499573
#! This paper investigates an effective boosting method for naïve Bayesian classifiers. Existing work has shown that the boosted naïve Bayesian classifier is not so effective in error rate reduction as the boosted decision tree (or boosted decision stump). This phenomenon may be caused by the combination of a couple of facts. To solve the problem, the local accuracies of a naïve Bayesian base classifier should be used to replace the global accuracy (or global error rate) in the traditional boosting methods. Based on the analysis, we propose an effective boosted naïve Bayesian method which uses a C4.5 decision tree as the local-accuracy evaluator for each base classifier. At each round, two classifiers are constructed: one for the naïve Bayesian base classifier, while the other for the C4.5 evaluator. The estimated local accuracy plays an important role, not only in updating the weights of training examples but also in determining the vote weights of base classifiers. Finally, it has been shown by experimental comparison that our method has achieved much lower error rate on average in a set of domains than the AdaBoost.M1 of naïve Bayesian classifiers.

#index 1196033
#* COMUS: Ontological and Rule-Based Reasoning for Music Recommendation System
#@ Seungmin Rho;Seheon Song;Eenjun Hwang;Minkoo Kim
#t 2009
#c 3
#% 877321
#% 1061950
#% 1177049
#% 1696350
#! In this paper, we propose Context-based Music Recommendation (COMUS) ontology for modeling user's musical preferences and context for supporting reasoning about the user's desired emotion and preferences. The COMUS provides an upper Music Ontology that captures concepts about the general properties of music such as title, artists and genre and also provides extensibility for adding domain-specific ontologies, such as Music Feature, Mood and Situation, in a hierarchical manner. The COMUS is music dedicated ontology in OWL constructed by incorporating domain specific classes for music recommendation into the Music Ontology. Using this context ontology, we believe that the use of logical reasoning rules by checking the consistency of context information, and reasoning over the high-level, implicit context from the low-level, explicit information. As a novelty, our ontology can express detailed and complicated relations among the music, moods and situations, enabling users to find appropriate music for the application. We present some of the experiments we performed as a case-study for music recommendation.

#index 1196034
#* Spatial Weighting for Bag-of-Visual-Words and Its Application in Content-Based Image Retrieval
#@ Xin Chen;Xiaohua Hu;Xiajiong Shen
#t 2009
#c 3
#% 318785
#% 350323
#% 718465
#% 724320
#% 760805
#% 860956
#% 883972
#% 945194
#% 990321
#% 996168
#% 1038747
#% 1730622
#! It is a challenging and important task to retrieve images from a large and highly varied image data set based on their visual contents. Problems like how to fill the semantic gap between image features and the user have attracted a lot of attention from the research community. Recently, the 'bag of visual words' approach exhibits very good performance in content-based image retrieval (CBIR). However, since the 'bag of visual words' approach represents an image as an unordered collection of local descriptors which only use the intensity information, the resulting model provides little insight about the spatial constitution and color information of the image. In this paper, we develop a novel image representation method which uses Gaussian mixture model (GMM) to provide spatial weighting for visual words and apply this method to facilitate content based image retrieval. Our approach is a simple and more efficient compared with the order-less 'bag of visual words' approach. In our method, firstly, we extract visual tokens from the image data set and cluster them into a lexicon of visual words. Then, we represent the spatial constitution of an image as a mixture of n Gaussians in the feature space and decompose the image into n regions. The spatial weighting scheme is achieved by weighting visual words according to the probability of each visual word belonging to each of the n regions in the image. The cosine similarity between spatial weighted visual word vectors is used as distance measurement between regions, while the image-level distance is obtained by averaging the pair-wise distances between regions. We compare the performance of our method with the traditional 'bag of visual words' and 'blobworld' approaches under the same image retrieval scenario. Experimental results demonstrate that the our method is able to tell images apart in the semantic level and improve the performance of CBIR.

#index 1196035
#* Item Preference Parameters from Grouped Ranking Observations
#@ Hideitsu Hino;Yu Fujimoto;Noboru Murata
#t 2009
#c 3
#% 213009
#% 961137
#! Given a set of rating data for a set of items, determining the values of items is a matter of importance. Various probability models have been proposed to solve this task. The Plackett-Luce model is one of such models, which parametrizes the value of each item by a real valued preference parameter. In this paper, the Plackett-Luce model is generalized to cope with the grouped ranking observations such as movies or restaurants ratings. Since the maximization of the likelihood of the proposed model is computationally intractable, the lower bound of the likelihood which is easy to evaluate is derived, and the em algorithm is adopted to the maximization of the lower bound.

#index 1196036
#* Cross-Channel Query Recommendation on Commercial Mobile Search Engine: Why, How and Empirical Evaluation
#@ Shunkai Fu;Bingfeng Pi;Ying Zhou;Michel C. Desmarais;Weilei Wang;Song Han;Xunrong Rao
#t 2009
#c 3
#% 330617
#% 869651
#% 1047411
#! Mobile search not only inherits some features of traditional search on PC, but also has many of its own special characteristics. In this paper, we firstly share some unique features about mobile search and discuss why vertical search is preferred. Providing multiple vertical searches is proved to be convenient to users but causes some minor problem as well. This plays as the initiative for us to propose cross-channel query recommendation. Secondly, we briefly introduce how to realize the cross-channel recommendation effectively and efficiently online. Finally, we analyze the performance of the proposed method from three different but related metrics: expected effect, off-line evaluation and on-line evaluation. All three studies together indicate that the proposed cross-channel recommendation is quite useful. Being the first study about query recommendation on mobile search, it is believed that the findings, proposed solution and collected feedback as presented here will be beneficial to both researchers and industry companies while considering how to provide better mobile search service.

#index 1196037
#* Data Mining for Intrusion Detection: From Outliers to True Intrusions
#@ Goverdhan Singh;Florent Masseglia;Céline Fiot;Alice Marascu;Pascal Poncelet
#t 2009
#c 3
#% 479191
#% 978636
#% 981000
#% 1196038
#! Data mining for intrusion detection can be divided into several sub-topics, among which unsupervised clustering has controversial properties. Unsupervised clustering for intrusion detection aims to i) group behaviors together depending on their similarity and ii) detect groups containing only one (or very few) behaviour. Such isolated behaviours are then considered as deviating from a model of normality and are therefore considered as malicious. Obviously, all atypical behaviours are not attacks or intrusion attempts. Hence, this is the limits of unsupervised clustering for intrusion detection. In this paper, we consider to add a new feature to such isolated behaviours before they can be considered as malicious. This feature is based on their possible repetition from one information system to another.

#index 1196038
#* A Multi-resolution Approach for Atypical Behaviour Mining
#@ Alice Marascu;Florent Masseglia
#t 2009
#c 3
#% 116390
#% 300136
#% 334990
#% 342625
#% 479791
#% 577251
#% 823365
#% 1669935
#! Atypical behaviours are the basis of a valuable knowledge in domains related to security (e.g. fraud detection for credit card [1], cyber security [4] or safety of critical systems [6]). Atypicity generally depends on the isolation level of a (set of) records, compared to the dataset. One possible method for finding atypic records aims to perform two steps. The first step is a clustering (grouping the records by similarity) and the second step is the identification of clusters that do not correspond to a satisfying number of records. The main problem is to adjust the method and find the good level of atypicity. This issue is even more important in the domain of data streams, where a decision has to be taken in a very short time and the end-user does not want to try several settings. In this paper, we propose Mrab , a self-adjusting approach intending to automatically discover atypical behaviours (in the results of a clustering algorithm) without any parameter. We provide the formal framework of our method and our proposal is tested through a set of experiments.

#index 1196039
#* Change Analysis in Spatial Data by Combining Contouring Algorithms with Supervised Density Functions
#@ Chun Sheng Chen;Vadeerat Rinsurongkawong;Christoph F. Eick;Michael D. Twa
#t 2009
#c 3
#% 317362
#% 881538
#% 972333
#% 989663
#% 1035440
#! Detecting changes in spatial datasets is important for many fields. In this paper, we introduce a methodology for change analysis in spatial datasets that combines contouring algorithms with supervised density estimation techniques. The methodology allows users to define their own criteria for features of interest and to identify changes in those features between two datasets. Change analysis is performed by comparing interesting regions that have been derived using contour clustering. A novel clustering algorithm called DCONTOUR is introduced for this purpose that computes contour polygons that describe the boundary of a supervised density function at a given density threshold. Relationships between old and new data are analyzed relying on polygon operations. We evaluate our methodology in a case study that analyzes changes in earthquake patterns.

#index 1196040
#* Centroid Neural Network with Spatial Constraints
#@ Dong-Chul Park
#t 2009
#c 3
#% 374537
#% 375388
#% 939131
#% 1778779
#% 1778870
#% 1781473
#% 1788241
#% 1856061
#% 1860645
#% 1860851
#! A Centroid Neural Network with spatial constraints (CNN-S) is proposed in this paper. The spatial constraints are applied to the Centroid Neural Network(CNN) algorithm to reduce noise in Magnetic Resonance(MR) images. MR image segmentation is performed to illustrate the application of the proposed algorithm. The proposed algorithm incorporates a novel approach of using the weights of attributes to evaluate the roles of the latter. Experiments and results on MR images from Internet Brain Segmentation Repository(IBSR) show that the proposed algorithm provides a superior performance over other algorithms such as Fuzzy C-Means(FCM)and Fuzzy C-Means with spatial constraints(FCM-S).

#index 1196041
#* Diversity in Combinations of Heterogeneous Classifiers
#@ Kuo-Wei Hsu;Jaideep Srivastava
#t 2009
#c 3
#% 92533
#% 136350
#% 209021
#% 400847
#% 451221
#% 482502
#% 551723
#% 551901
#% 552056
#% 926881
#% 949241
#% 1023380
#% 1393031
#% 1650665
#! In this paper, we introduce the use of combinations of heterogeneous classifiers to achieve better diversity. Conducting theoretical and empirical analyses of the diversity of combinations of heterogeneous classifiers, we study the relationship between heterogeneity and diversity. On the one hand, the theoretical analysis serves as a foundation for employing heterogeneous classifiers in Multi-Classifier Systems or ensembles. On the other hand, experimental results provide empirical evidence. We consider synthetic as well as real data sets, utilize classification algorithms that are essentially different, and employ various popular diversity measures for evaluation. Two interesting observations will contribute to the future design of Multi-Classifier Systems and ensemble techniques. First, the diversity among heterogeneous classifiers is higher than that among homogeneous ones, and hence using heterogeneous classifiers to construct classifier combinations would increase the diversity. Second, the heterogeneity primarily results from different classification algorithms rather than the same algorithm with different parameters.

#index 1196042
#* Growth Analysis of Neighbor Network for Evaluation of Damage Progress
#@ Ken-Ichi Fukui;Kazuhisa Sato;Junichiro Mizusaki;Kazumi Saito;Masahiro Kimura;Masayuki Numao
#t 2009
#c 3
#% 361966
#% 577220
#% 736135
#% 823342
#% 1032048
#! We constructed two types of neighbor networks, i.e., TOP k and k -MNN (Mutually Nearest Neighbor) networks, on observed AE (Acoustic Emission) data produced by damages in SOFC (Solid Oxide Fuel Cell). Afterwards, we analyzed growth properties of the neighbor networks for evaluation of damage progress. The results show that the power index of degree dynamically changes as damage progress phase changes. Also we found the decrease of cluster coefficient and shrinking effective diameter in k-MNN network reflect the occurrence of various combination of damages.

#index 1196043
#* A Parallel Algorithm for Finding Related Pages in the Web by Using Segmented Link Structures
#@ Xiaoyan Shen;Junliang Chen;Xiangwu Meng;Yujie Zhang;Chuanchang Liu
#t 2009
#c 3
#% 248810
#% 268073
#% 281209
#% 641968
#% 821872
#% 963669
#% 975037
#% 1269897
#% 1675201
#! In this paper, a simple but powerful algorithm: block co-citation algorithm is proposed to automatically find related pages for a given web page, by using HTML segmentation technologies and parallel hyperlink structure analysis. First, all hyperlinks in a web page are segmented into several blocks according to the HTML structure and text style information. Second, for each page, the similarity between every two hyperlinks in the same block of the page is computed according to several information, then the total similarity from one page to the other is obtained after all web pages are processed. For a given page u, the pages which have the highest total similarity to u are selected as the related pages of u. At last, the block co-citation algorithm is implemented in parallel to analyze a corpus of 37482913 pages sampled from a commercial search engine and demonstrates its feasibility and efficiency.

#index 1196044
#* Boosting Biomedical Information Retrieval Performance through Citation Graph: An Empirical Study
#@ Xiaoshi Yin;Xiangji Huang;Qinmin Hu;Zhoujun Li
#t 2009
#c 3
#% 255170
#% 255179
#% 268079
#% 290830
#% 723304
#% 783644
#% 799636
#% 987251
#! This paper presents an empirical study of the combination of content-based information retrieval results with linkage-based document importance scores to improve retrieval performance on TREC biomedical literature datasets. In our study, content-based information comes from the state-of-the-art probability model based Okapi information retrieval system. On the other hand, linkage-based information comes from a citation graph generated from REFERENCES sections of a biomedical literature dataset. Three well-known linkage-based ranking algorithms (PageRank, HITS and InDegree) are applied on the citation graph to calculate document importance scores. We use TREC 2007 Genomics dataset for evaluation, which contains 162,259 biomedical literatures. Our approach achieves the best document-based MAP among all results that have been reported so far. Our major findings can be summarized as follows. First, without hyperlinks, linkage information extracted from REFERENCES sections can be used to improve the effectiveness of biomedical information retrieval. Second, performance of the integrated system is sensitive to linkage-based ranking algorithms, and a simpler algorithm, InDegree, is more suitable for biomedical literature retrieval.

#index 1196045
#* Similarity-Based Feature Selection for Learning from Examples with Continuous Values
#@ Yun Li;Su-Jun Hu;Wen-Jie Yang;Guo-Zi Sun;Fang-Wu Yao;Geng Yang
#t 2009
#c 3
#% 132927
#% 169659
#% 243728
#% 345824
#% 444004
#% 465758
#% 629619
#% 722929
#% 796212
#% 1788309
#! In many real world problems, such as machine learning and data mining, feature selection is often used to choose a small subset of features which is sufficient to predict the target labels well. In this paper, we will propose a feature selection algorithm based on similarity and extension matrix. Extension matrix is an important theory in learning from examples and it is originally designed to deal with discrete feature values. However, in the paper it is extended to cope with continuous values and designed as search strategy. The evaluation criterion for feature selection is based on the similarity between classes, which is obtained from the similarity between examples in different classes using min-max learning rule. The algorithm is proved in theory and shown its higher performance than two other classic general algorithms over several real-world benchmark data sets and facial image sets with different poses and expressions for gender classification.

#index 1196046
#* Application-Independent Feature Construction from Noisy Samples
#@ Dominique Gay;Nazha Selmaoui;Jean-François Boulicaut
#t 2009
#c 3
#% 136350
#% 280409
#% 338594
#% 342610
#% 478302
#% 727901
#% 788222
#% 799777
#% 926881
#% 948224
#% 1072809
#% 1100110
#% 1107640
#% 1117089
#% 1261429
#% 1411040
#% 1663722
#% 1692971
#% 1742003
#! When training classifiers, presence of noise can severely harm their performance. In this paper, we focus on "non-class" attribute noise and we consider how a frequent fault-tolerant (FFT) pattern mining task can be used to support noise-tolerant classification. Our method is based on an application independent strategy for feature construction based on the so-called *** -free patterns. Our experiments on noisy training data shows accuracy improvement when using the computed features instead of the original ones.

#index 1196047
#* Estimating Optimal Feature Subsets Using Mutual Information Feature Selector and Rough Sets
#@ Sombut Foitong;Pornthep Rojanavasu;Boonwat Attachoo;Ouen Pinngern
#t 2009
#c 3
#% 366687
#% 500375
#% 1860915
#! Mutual Information (MI) is a good selector of relevance between input and output feature and have been used as a measure for ranking features in several feature selection methods. Theses methods cannot estimate optimal feature subsets by themselves, but depend on user defined performance. In this paper, we propose estimation of optimal feature subsets by using rough sets to determine candidate feature subset which receives from MI feature selector. The experiment shows that we can correct nonlinear problems and problems in situation of two or more combined features are dominant features, maintain an improve classification accuracy.

#index 1196048
#* Speeding Up Similarity Search on a Large Time Series Dataset under Time Warping Distance
#@ Pongsakorn Ruengronghirunya;Vit Niennattrakul;Chotirat Ann Ratanamahatana
#t 2009
#c 3
#% 86950
#% 248796
#% 460862
#% 480146
#% 654456
#% 795273
#% 809264
#% 1411039
#! Time series data are a ubiquitous data type appearing in many domains such as statistics, finance, multimedia, etc. Similarity search and measurement on time series data are typically different from on other data types since time series data have the associations among adjacent dimensions. Accordingly, the classic Euclidean distance metric is not an accurate similarity measure for time series. Therefore, Dynamic Time Warping (DTW) has become a better choice for similarity measurement on time series in various applications regardless of its high computational cost. To speed up the calculation, many research works attempt to speed up DTW calculation using indexing method, which always has a tradeoff between indexing efficiency and I/O cost. In this paper, we propose a novel method to balance this tradeoff under indexed sequential access using Sequentially Indexed Structure (SIS), an approach to time series indexing with low computational cost and small overheads on I/O. Finally, we conduct experiments to demonstrate our superiority in speed performance over the best existing method.

#index 1196049
#* A Novel Fractal Representation for Dimensionality Reduction of Large Time Series Data
#@ Poat Sajjipanon;Chotirat Ann Ratanamahatana
#t 2009
#c 3
#% 310537
#% 662750
#% 759098
#% 769896
#% 795273
#% 799393
#! Recent research has attempted to speed up time series data mining tasks which focus on dimensionality reduction, indexing, and lower bounding function, among many others. For large time series data, current dimensionality reduction techniques cannot reduce the total dimensions of time series data by a large margin without losing their global characteristics. In this paper, we introduce a novel Fractal Representation which uses merely three real values to represent a whole time series data sequence. Moreover, our proposed representation can be efficiently used under Euclidean distance. We demonstrate effectiveness and utility of our novel Fractal Representation on classification problems and our proposed method outperforms existing methods in terms of speed performance and accuracy. Our results reconfirm that this representation can effectively represent global characteristics of the data, especially in larger time series data.

#index 1196050
#* Clustering Data Streams in Optimization and Geography Domains
#@ Ling-Yin Wei;Wen-Chih Peng
#t 2009
#c 3
#% 800179
#% 889089
#% 989603
#% 989622
#% 1393158
#% 1411125
#% 1688300
#! In this paper, we formulate a dual clustering problem in spatial data streams. A spatial data stream consists of data points with attributes in the optimization and geography domains. We aim at partitioning these objects into disjoint clusters such that at each time window (1) objects in the same cluster satisfy the transitively r-connected relation in the optimization and geography domains, and (2) the number of clusters is as minimal as possible. We propose a Hierarchical-Based Clustering algorithm (HBC). Specifically, objects are represented as a graph structure, called RGraph, where each node represents an object and edges indicate their similarity relationships. In light of RGraph, algorithm HBC iteratively merges clusters. Experimental results show the performance of the algorithm.

#index 1196051
#* CBDT: A Concept Based Approach to Data Stream Mining
#@ Stefan Hoeglinger;Russel Pears;Yun Sing Koh
#t 2009
#c 3
#% 310500
#% 342600
#% 345857
#% 577271
#% 729932
#% 769927
#% 810542
#% 824795
#! Data Stream mining presents unique challenges compared to traditional mining on a random sample drawn from a stationary statistical distribution. Data from real-world data streams are subject to concept drift due to changes that take place continuously in the underlying data generation mechanism. Concept drift complicates the process of mining data as models that are learnt need to be updated continuously to reflect recent changes in the data while retaining relevant information that has been learnt from the past. In this paper, we describe a Concept Based Decision Tree (CBDT) learner and compare it with the CVDFT algorithm, which uses a sliding time window. Our experimental results show that CBDT outperforms CVFDT in terms of both classification accuracy and memory consumption.

#index 1196052
#* Meaningful Subsequence Matching under Time Warping Distance for Data Stream
#@ Vit Niennattrakul;Chotirat Ann Ratanamahatana
#t 2009
#c 3
#% 316709
#% 795273
#% 989656
#% 1063497
#% 1066734
#! Since the era of data explosion, research on mining data stream has become more and more active, particularly focusing on improving time and space complexity in similarity subsequence matching problems for data stream. Recently, SPRING algorithm and its variance have been proposed to solve the subsequence matching problem under time warping distance. Unfortunately, these algorithms produce meaningless results since no normalization is taken into account before distance calculation. In this work, we propose a novel subsequence matching algorithm which fully supports global constraint, uniform scaling, and normalization called MSM (Meaningful Subsequence Matching). As expected, our MSM algorithm is much faster and much more accurate than the current existing algorithms in terms of computational cost and accuracy by a very large margin.

#index 1196053
#* An Aggregate Ensemble for Mining Concept Drifting Data Streams with Noise
#@ Peng Zhang;Xingquan Zhu;Yong Shi;Xindong Wu
#t 2009
#c 3
#% 204531
#% 310500
#% 342600
#% 342639
#% 729932
#% 769888
#% 823408
#% 840891
#% 881543
#% 926881
#% 1083714
#% 1116999
#% 1117009
#! Recent years have witnessed a large body of research work on mining concept drifting data streams, where a primary assumption is that the up-to-date data chunk and the yet-to-come data chunk share identical distributions, so classifiers with good performance on the up-to-date chunk would also have a good prediction accuracy on the yet-to-come data chunk. This "stationary assumption", however, does not capture the concept drifting reality in data streams. More recently, a "learnable assumption" has been proposed and allows the distribution of each data chunk to evolve randomly. Although this assumption is capable of describing the concept drifting in data streams, it is still inadequate to represent real-world data streams which usually suffer from noisy data as well as the drifting concepts. In this paper, we propose a Realistic Assumption which asserts that the difficulties of mining data streams are mainly caused by both concept drifting and noisy data chunks. Consequently, we present a new Aggregate Ensemble (AE) framework, which trains base classifiers using different learning algorithms on different data chunks. All the base classifiers are then combined to form a classifier ensemble through model averaging. Experimental results on synthetic and real-world data show that AE is superior to other ensemble methods under our new realistic assumption for noisy data streams.

#index 1196054
#* On Pairwise Kernels: An Efficient Alternative and Generalization Analysis
#@ Hisashi Kashima;Satoshi Oyama;Yoshihiro Yamanishi;Koji Tsuda
#t 2009
#c 3
#% 743284
#% 770816
#% 806956
#% 833012
#% 833069
#% 833088
#! Pairwise classification has many applications including network prediction, entity resolution, and collaborative filtering. The pairwise kernel has been proposed for those purposes by several research groups independently, and become successful in various fields. In this paper, we propose an efficient alternative which we call Cartesian kernel . While the existing pairwise kernel (which we refer to as Kronecker kernel) can be interpreted as the weighted adjacency matrix of the Kronecker product graph of two graphs, the Cartesian kernel can be interpreted as that of the Cartesian graph which is more sparse than the Kronecker product graph. Experimental results show the Cartesian kernel is much faster than the existing pairwise kernel, and at the same time, competitive with the existing pairwise kernel in predictive performance.We discuss the generalization bounds by the two pairwise kernels by using eigenvalue analysis of the kernel matrices.

#index 1196055
#* A Family-Based Evolutional Approach for Kernel Tree Selection in SVMs
#@ Ithipan Methasate;Thanaruk Theeramunkong
#t 2009
#c 3
#% 425040
#% 763697
#% 811632
#% 961190
#% 986819
#% 1186530
#% 1393208
#% 1861020
#! Finding a kernel mapping function is a key step towards construction of a high-performanced SVM-based classifier. While some recent methods exploited an evolutional approach to construct a suitable multifunction kernel, most of them searched randomly and diversely. In this paper, the concept of a family of identical-structured kernel trees is proposed to enable exploration of structure space using genetic programming whereas to pursue investigation of parameter space on a certain tree using evolutional strategy. To control balance between structure and parameter search towards an optimal kernel, the trade-off strategy is introduced. By experiments on a number of benchmark datasets from UCI and text classification datasets, the proposed method is shown to be able to find a better optimal solution than other search methods.

#index 1196056
#* An Online Incremental Learning Vector Quantization
#@ Ye Xu;Shen Furao;Osamu Hasegawa;Jinxi Zhao
#t 2009
#c 3
#% 356892
#% 775643
#% 821883
#% 843902
#% 895837
#% 999173
#! As described in this paper, we propose online incremental learning vector quantization (ILVQ) for supervised classification tasks. As a prototype-based classifier, ILVQ needs no prior knowledge of the number of prototypes in the network or their initial value, as do most current prototype-based algorithms. It adopts a threshold-based insertion scheme to determine the number of prototypes needed for each class dynamically according to the distribution of training data. In addition, this insertion policy insures the fulfillment of the incremental learning goal, including both between-class incremental learning and within-class incremental learning. A technique for removing useless prototypes is used to eliminate noise interrupting the input data. Unlike other LVQ-based methods, the learning result won't be affected by the sequence of input patterns that come into the ILVQ. Results of experiments described herein show that the proposed ILVQ can accommodate the non-stationary data environment and can provide good recognition performance and storage efficiency.

#index 1196057
#* On Mining Rating Dependencies in Online Collaborative Rating Networks
#@ Hady W. Lauw;Ee-Peng Lim;Ke Wang
#t 2009
#c 3
#% 728195
#% 813966
#! The trend of social information processing sees e-commerce and social web applications increasingly relying on user-generated content, such as rating, to determine the quality of objects and to generate recommendations for users. In a rating system, a set of reviewers assign to a set of objects different types of scores based on specific evaluation criteria. In this paper, we seek to determine, for each reviewer and for each object, the dependency between scores on any two given criteria. A reviewer is said to have high dependency between a pair of criteria when his or her rating scores on objects based on the two criteria exhibit strong correlation. On the other hand, an object is said to have high dependency between a pair of criteria when the rating scores it receives on the two criteria exhibit strong correlation. Knowing reviewer dependency and object dependency is useful in various applications including recommendation, customization, and score moderation. We propose a model, called Interrelated Dependency , which determines both types of dependency simultaneously, taking into account the interrelatedness between the two types of dependency. We verify the efficacy of this model through experiments on real-life data.

#index 1196058
#* Learning to Extract Relations for Relational Classification
#@ Steffen Rendle;Christine Preisach;Lars Schmidt-Thieme
#t 2009
#c 3
#% 577263
#% 729913
#% 729982
#% 1047784
#% 1411056
#! Relational classifiers use relations between objects to predict the class values. In some cases the relations are explicitly given. In other cases the dataset contains implicit relations, e.g. the relation is hidden inside of noisy attribute values. To apply relational classifiers for this task, the relations have to be extracted. Manually extracting relations by a domain expert is an expensive and time consuming task. In this paper we show how extracting relations in datasets with noisy attribute values can be learned. Our method LRE uses a regression model to learn and predict weighted binary relations. We show that LRE is able to extract both equivalence relations and non-constrained relations. Secondly we show that relational classifiers using relations automatically extracted by LRE achieve comparable classification quality as classifiers using manually labeled relations.

#index 1390141
#* Proceedings of the 7th Pacific-Asia conference on Advances in knowledge discovery and data mining
#@ Kyu-Young Wang;Jongwoo Jeon;Kyuseok Shim;Jaideep Srivastava
#t 2003
#c 3

#index 1390142
#* Data mining as an automated service
#@ P. S. Bradley
#t 2003
#c 3
#% 36672
#% 152934
#% 189880
#% 232102
#% 248790
#% 269634
#% 310570
#% 379238
#% 420077
#% 420084
#% 466083
#% 729437
#! An automated data mining service offers an out-sourced, cost-effective analysis option for clients desiring to leverage their data resources for decision support and operational improvement. In the context of the service model, typically the client provides the service with data and other information likely to aid in the analysis process (e.g. domain knowledge, etc.). In return, the service provides analysis results to the client. We describe the required processes, issues, and challenges in automating the data mining and analysis process when the high-level goals are: (1) to provide the client with a high quality, pertinent analysis result; and (2) to automate the data mining service, minimizing the amount of human analyst effort required and the cost of delivering the service. We argue that by focusing on client problems within market sectors, both of these goals may be realized.

#index 1390143
#* Trends and challenges in the industrial applications of KDD
#@ Ramasamy Uthurusamy
#t 2003
#c 3

#index 1390144
#* Finding event-oriented patterns in long temporal sequences
#@ Xingzhi Sun;Maria E. Orlowska;Xiaofang Zhou
#t 2003
#c 3
#% 172892
#% 252401
#% 300120
#% 310559
#% 329537
#% 342642
#% 420063
#% 459006
#% 461903
#% 463903
#% 464996
#% 481290
#% 481754
#! A major task of traditional temporal event sequence mining is to find all frequent event patterns from a long temporal sequence. In many real applications, however, events are often grouped into different types, and not all types are of equal importance. In this paper, we consider the problem of efficient mining of temporal event sequences which lead to an instance of a specific type of event. Temporal constraints are used to ensure sensibility of the mining results. We will first generalise and formalise the problem of event-oriented temporal sequence data mining. After discussing some unique issues in this new problem, we give a set of criteria, which are adapted from traditional data mining techniques, to measure the quality of patterns to be discovered. Finally we present an algorithm to discover potentially interesting patterns.

#index 1390145
#* Mining frequent episodes for relating financial events and stock trends
#@ Anny Ng;Ada Wai-Chee Fu
#t 2003
#c 3
#% 300120
#% 443194
#% 463903
#% 641150
#% 660658
#! It is expected that stock prices can be affected by the local and overseas political and economic events. We extract events from the financial news of Chinese local newspapers which are available on the web, the news are matched against stock prices databases and a new method is proposed for the mining of frequent temporal patterns.

#index 1390146
#* An efficient algorithm of frequent connected subgraph extraction
#@ Mingsheng Hong;Haofeng Zhou;Wei Wang;Baile Shi
#t 2003
#c 3
#% 43862
#% 152934
#% 184048
#% 201894
#% 227917
#% 300120
#% 342604
#% 443514
#% 464996
#% 466644
#% 481290
#% 520902
#% 604724
#% 629708
#% 1268739
#% 1271949
#% 1289265
#! Mining frequent patterns from datasets is one of the key success stories of data mining research. Currently, most of the works focus on independent data, such as the items in the marketing basket. However, the objects in the real world often have close relationship with each other. How to extract frequent patterns from these relations is the objective in this paper. We use graphs to model the relations, and select a simple type for analysis. Combining the graph theory and algorithms to generate frequent patterns, a new algorithm Topology, which can mine these graphs efficiently, has been proposed. We evaluate the performance of the algorithm by doing experiments with synthetic datasets and real data. The experimental results show that Topology can do the job well. At the end of this paper, the potential improvement is mentioned.

#index 1390147
#* Classifier construction by graph-based induction for graph-structured data
#@ Warodom Geamsakul;Takashi Matsuda;Tetsuya Yoshida;Hiroshi Motoda;Takashi Washio
#t 2003
#c 3
#% 136350
#% 160857
#% 184048
#% 449588
#% 520902
#% 543941
#! A machine learning technique called Graph-Based Induction (GBI) efficiently extracts typical patterns from graph-structured data by stepwise pair expansion (pairwise chunking). It is very efficient because of its greedy search. Meanwhile, a decision tree is an effective means of data classification from which rules that are easy to understand can be obtained. However, a decision tree could not be produced for the data which is not explicitly expressed with attribute-value pairs. In this paper, we proposes a method of constructing a classifier (decision tree) for graph-structured data by GBI. In our approach attributes, namely substructures useful for classification task, are constructed by GBI on the fly while constructing a decision tree. We call this technique Decision Tree - Graph-Based Induction (DT-GBI). DT-GBI was tested against a DNA dataset from UCI repository. Since DNA data is a sequence of symbols, representing each sequence by attribute-value pairs by simply assigning these symbols to the values of ordered attributes does not make sense. The sequences were transformed into graph-structured data and the attributes (substructures) were extracted by GBI to construct a decision tree. Effect of adjusting the number of times to run GBI at each node of a decision tree is evaluated with respect to the predictive accuracy. The results indicate the effectiveness of DT-GBI for constructing a classifier for graph-structured data.

#index 1390148
#* Comparison of the performance of center-based clustering algorithms
#@ Bin Zhang
#t 2003
#c 3
#% 114667
#% 232102
#% 299535
#% 329531
#! Center-based clustering algorithms like K-means, and EM are one of the most popular classes of clustering algorithms in use today. The author developed another variation in this family - K-Harmonic Means (KHM). It has been demonstrated using a small number of "benchmark" datasets that KHM is more robust than K-means and EM. In this paper, we compare their performance statistically. We run K-means, K-Harmonic Means and EM on each of 3600 pairs of (dataset, initialization) to compare the statistical average and variation of the performance of these algorithms. The results are that, for low dimensional datasets, KHM performs consistently better than KM, and KM performs consistently better than EM over a large variation of clustered-ness of the datasets and a large variation of initializations. Some of the reasons that contributed to this difference are explained.

#index 1390149
#* Automatic extraction of clusters from hierarchical clustering representations
#@ Jörg Sander;Xuejie Qin;Zhiyong Lu;Nan Niu;Alex Kovarsky
#t 2003
#c 3
#% 36672
#% 273890
#% 443083
#% 479799
#% 481281
#! Hierarchical clustering algorithms are typically more effective in detecting the true clustering structure of a data set than partitioning algorithms. However, hierarchical clustering algorithms do not actually create clusters, but compute only a hierarchical representation of the data set. This makes them unsuitable as an automatic pre-processing step for other algorithms that operate on detected clusters. This is true for both dendrograms and reachability plots, which have been proposed as hierarchical clustering representations, and which have different advantages and disadvantages. In this paper we first investigate the relation between dendrograms and reachability plots and introduce methods to convert them into each other showing that they essentially contain the same information. Based on reachability plots, we then introduce a technique that automatically determines the significant clusters in a hierarchical cluster representation. This makes it for the first time possible to use hierarchical clustering as an automatic pre-processing step that requires no user interaction to select clusters from a hierarchical cluster representation.

#index 1390150
#* Large scale unstructured document classification using unlabeled data and syntactic information
#@ Seong-Bae Park;Byoung-Tak Zhang
#t 2003
#c 3
#% 252011
#% 269207
#% 280903
#% 316509
#% 458379
#% 466580
#% 740416
#% 742368
#% 853701
#! Most document classification systems consider only the distribution of content words of the documents, ignoring the syntactic information underlying the documents though it is also an important factor. In this paper, we present an approach for classifying large scale unstructured documents by incorporating both lexical and syntactic information of documents. For this purpose, we use the co-training algorithm, a partially supervised learning algorithm, in which two separated views for the training data are employed and the small number of labeled data are augmented by a large number of unlabeled data. Since both lexical and syntactic information can play roles of separated views for the unstructured documents, the co-training algorithm enhances the performance of document classification using both of them and a large number of unlabeled documents. The experimental results on Reuters-21578 corpus and TREC-7 filtering documents show the effectiveness of unlabeled documents and the use of both lexical and syntactic information.

#index 1390151
#* Extracting shared topics of multiple documents
#@ Xiang Ji;Hongyuan Zha
#t 2003
#c 3
#% 281209
#% 342659
#% 348165
#% 387791
#% 397137
#% 397214
#% 466675
#% 741106
#% 1478826
#! In this paper, we present a weighted graph based method to simultaneously compare the textual content of two or more documents and extract the shared (sub)topics of them, if available. A set of documents are modelled with a set of pairwise weighted bipartite graphs. A generalized mutual reinforcement principle is applied to the pairwise bipartite graphs to calculate the saliency scores of sentences in each documents based on pairwise weighted bipartite graphs. Sentences with advantaged saliency are selected, and they together convey the dominant shared topic. If there are more than one shared subtopics among the documents, a spectral min-max cut algorithm can be used to partition a derived sentence similarity graph into several subgraphs. For a subgraph, if all documents contribute some sentences(nodes) to it, then these sentences(nodes) in the subgraph may convey a shared subtopic. The generalized mutual reinforcement principle is applied to them to verify and extract the shared subtopic.

#index 1390152
#* An empirical study on dimensionality optimization in text mining for linguistic knowledge acquisition
#@ Yu-Seop Kim;Jeong-Ho Chang;Byoung-Tak Zhang
#t 2003
#c 3
#% 280819
#% 419892
#% 678676
#% 815225
#! In this paper, we try to find empirically the optimal dimensionality in data-driven models, Latent Semantic Analysis (LSA) model and Probabilistic Latent Semantic Analysis (PLSA) model. These models are used for building linguistic semantic knowledge which could be used in estimating contextual semantic similarity for the target word selection in English-Korean machine translation. We also facilitate k-Nearest Neighbor learning algorithm. We diversify our experiments by analyzing the covariance between the value of k in k-NN learning and accuracy of selection, in addition to that between the dimensionality and the accuracy. While we could not find regular tendency of relationship between the dimensionality and the accuracy, however, we could find the optimal dimensionality having the most sound distribution of data during experiments.

#index 1390153
#* A semi-supervised algorithm for pattern discovery in information extraction from textual data
#@ Tianhao Wu;William M. Pottenger
#t 2003
#c 3
#% 278109
#% 279755
#% 375017
#% 404772
#% 853843
#% 858459
#! In this article we present a semi-supervised algorithm for pattern discovery in information extraction from textual data. The patterns that are discovered take the form of regular expressions that generate regular languages. We term our approach 'semi-supervised' because it requires significantly less effort to develop a training set than other approaches. From the training data our algorithm automatically generates regular expressions that can be used on previously unseen data for information extraction. Our experiments show that the algorithm has good testing performance on many features that are important in the fight against terrorism.

#index 1390154
#* Mining patterns of dyspepsia symptoms across time points using constraint association rules
#@ Annie Lau;Siew Siew Ong;Ashesh Mahidadia;Achim Hoffmann;Johanna Westbrook;Tatjana Zrimec
#t 2003
#c 3
#% 152934
#% 172386
#% 172512
#% 232136
#% 248785
#% 316709
#% 395603
#% 413550
#% 443502
#% 459006
#% 463903
#% 481290
#% 631970
#! In this paper, we develop and implement a framework for constraint-based association rule mining across subgroups in order to help a domain expert find useful patterns in a medical data set that includes temporal data. This work is motivated by the difficulties experienced in the medical domain to identify and track dyspepsia symptom clusters within and across time. Our framework, Apriori with Subgroup and Constraint (ASC), is built on top of the existing Apriori framework. We have identified four different types of phase-wise constraints for subgroups: constraint across subgroups, constraint on subgroup, constraint on pattern content and constraint on rule. ASC has been evaluated in a real-world medical scenario; analysis was conducted with the interaction of a domain expert. Although the framework is evaluated using a data set from the medical domain, it should be general enough to be applicable in other domains.

#index 1390155
#* Predicting protein structural class from closed protein sequences
#@ N. Rattanakronkul;T. Wattarujeekrit;K. Waiyamai
#t 2003
#c 3
#% 136350
#% 232102
#% 232136
#% 279120
#% 316709
#% 1306891
#! ProsMine is a system for automatically predicting protein structural class from sequence, based on using a combination of data mining techniques. Contrary to our previous protein structural class prediction system, where only enzyme proteins can be predicted, ProsMine can predict the structural class for all of the proteins. We investigate the most effective way to represent protein sequences in our new prediction system. Based on the lattice theory, our idea is to discover the set of Closed Sequences from the protein sequence database and use those appropriate Closed Sequences as protein features. A sequence is said to be "closed" for a given protein sequence database if it is the maximal subsequence of all the protein sequences in that database. Efficient algorithms have been proposed for discovering closed sequences and selecting appropriate closed sequence for each protein structural class. Experimental results, using data extracted from SWISS-PROT and CATH databases, showed that ProsMine yielded better accuracy compared to our previous work even for the most specific level (Homologous-Superfamily Level) of the CATH protein structure hierarchy, which consists of 637 possible classes.

#index 1390156
#* Learning rules to extract protein interactions from biomedical text
#@ Tu Minh Phuong;Doheon Lee;Kwang Hyung Lee
#t 2003
#c 3
#% 278109
#% 311037
#% 469402
#% 707780
#! We present a method for automatic extraction of protein interactions from scientific abstracts by combing machine learning and knowledge-based strategies. This method uses sample sentences, which are parsed by a link grammar parser, to learn extraction rules automatically. By incorporating heuristic rules based on morphological clues and domain specific knowledge, this method can remove the interactions that are not between proteins and improve the performance of extraction process. We present experimental results for a test set of MEDLINE abstracts. The results are encouraging and demonstrate the feasibility of our method to perform accurate extraction without need of manual rule building.

#index 1390157
#* Predicting protein interactions in human by homologous interactions in yeast
#@ Hyongguen Kim;Jong Park;Kyungsook Han
#t 2003
#c 3
#! As the genes of the human genome become known, one of the challenges is to identify all their interactions. Protein interactions are known for several organisms due to recent improvements in the detection methods for protein interaction, but they are limited to low-order species only. Direct determination of all the interactions occurring between the complete set of human genes remains difficult, even with current large-scale detection methods for protein interaction. This paper presents protein interactions between all human genes using the concept of homologous interaction. We believe this is the first attempt to map a whole human interactome.

#index 1390158
#* Mining the customer's up-to-moment preferences for e-commerce recommendation
#@ Yi-Dong Shen;Qiang Yang;Zhong Zhang;Hongjun Lu
#t 2003
#c 3
#% 220706
#% 266281
#% 273898
#% 280852
#% 282005
#% 420116
#% 420117
#% 420121
#% 464204
#% 481290
#% 1650569
#! Most existing data mining approaches to e-commerce recommendation are past data model-based in the sense that they first build a preference model from a past dataset and then apply the model to current customer situations. Such approaches are not suitable for applications where fresh data should be collected instantly since it reflects changes to customer preferences over some products. This paper targets those e-commerce environments in which knowledge of customer preferences may change frequently. But due to the very large size of past datasets the preference models cannot be updated instantly in response to the changes. We present an approach to making real time online recommendations based on an up-to-moment dataset which includes not only a gigantic past dataset but the most recent data that may be collected just moments ago.

#index 1390159
#* A graph-based optimization algorithm for website topology using interesting association rules
#@ Edmond H. Wu;Michael K. Ng
#t 2003
#c 3
#% 152934
#% 233808
#% 266283
#% 316709
#% 433773
#% 452821
#% 481290
#% 630984
#% 766058
#% 1273676
#% 1273768
#% 1414321
#! The Web serves as a global information service center that contains vast amount of data. The Website structure should be designed effectively so that users can efficiently find their information. The main contribution of this paper is to propose a graph-based optimization algorithm to modify Website topology using interesting association rules. The interestingness of an association rule A ⇒ B is defined based on the probability measure between two sets of Web pages A and B in the Website. If the probability measure between A and B is low (high), then the association rule A ⇒ B has high (low) interest. The hyperlinks in the Website can be modified to adapt user access patterns according to association rules with high interest. We present experimental results and demonstrate that our method is effective.

#index 1390160
#* A Markovian approach for web user profiling and clustering
#@ Younes Hafri;Chabane Djeraba;Peter Stanchev;Bruno Bachimont
#t 2003
#c 3
#% 219740
#% 232117
#% 443531
#% 466416
#% 476708
#! The objective of this paper is to propose an approach that extracts automatically web user profiling based on user navigation paths. Web user profiling consists of the best representative behaviors, represented by Markov models (MM). To achieve this objective, our approach is articulated around three notions: (1) Applying probabilistic exploration using Markov models. (2) Avoiding the problem of Markov model high-dimensionality and sparsity by clustering web documents, based on their content, before applying the Markov analysis. (3) Clustering Markov models, and extraction of their gravity centers. On the basis of these three notions, the approach makes possible the prediction of future states to be visited in k steps and navigation sessions monitoring, based on both content and traversed paths. The original application of the approach concerns the exploitation of multimedia archives in the perspective of the Copyright Deposit that preserves French's WWW documents. The approach may be the exploitation tool for any web site.

#index 1390161
#* Extracting user interests from bookmarks on the web
#@ Jason J. Jung;Geun-Sik Jo
#t 2003
#c 3
#% 44876
#% 387427
#% 1395427
#! This paper regards bookmarking as the most important information to extract user preferences among user behaviors. Bookmarks are categorized on Bayesian networks by an ontology. Considering the relationships between categories, evidential supports are mutually propagated to improve the coverage of the potential preferences. Consequently, we have attempted to define bookmarking behaviors and apply them to the weight updating on users' preference map. We have measured the causal rate in order to improve accuracy of evidential supports and retrieved relational information between the behavioral patterns and user preferences throught temporally analyzing these patterns. For experiments, we made a dataset organized as 2718 bookmarks and had monitored 12 users' behaviors for 30 days.

#index 1390162
#* Mining frequent instances on workflows
#@ Gianluigi Greco;Antonella Guzzo;Giuseppe Manco;Domenico Saccà
#t 2003
#c 3
#% 152934
#% 185412
#% 203029
#% 246009
#% 248013
#% 271243
#% 346653
#% 397368
#% 408396
#% 420087
#% 443393
#% 459021
#% 463903
#% 464836
#% 480665
#% 481290
#% 502140
#% 565496
#% 572313
#% 577218
#! A workflow is a partial or total automation of a business process, in which a collection of activities must be executed by humans or machines, according to certain procedural rules. This paper deals with an aspect of workflows which has not so far received much attention: providing facilities for the human system administrator to monitor the actual behavior of the workflow system in order to predict the "most probable" workflow executions. In this context, we develop a data mining algorithm for identifying frequent patterns, i.e., the workflow substructures that have been scheduled more frequently by the system. Several experiments show that our algorithm outperforms the standard approaches adapted to mining frequent instances.

#index 1390163
#* Real time video data mining for surveillance video streams
#@ JungHwan Oh;JeongKyu Lee;Sanjaykumar Kote
#t 2003
#c 3
#% 34077
#% 36672
#% 300182
#% 316279
#% 341263
#% 1774632
#! We extend our previous work [1] of the general framework for video data mining to further address the issue such as how to mine video data using motions in video streams. To extract and characterize these motions, we use an accumulation of quantized pixel differences among all frames in a video segment. As a result, the accumulated motions of segment are represented as a two dimensional matrix. Further, we develop how to capture the location of motions occurring in a segment using the same matrix generated for the calculation of the amount. We study how to cluster those segmented pieces using the features (the amount and the location of motions) we extract by the matrix above. We investigate an algorithm to find whether a segment has normal or abnormal events by clustering and modeling normal events, which occur mostly. In addition to deciding normal or abnormal, the algorithm computes Degree of Abnormality of a segment, which represents to what extent a segment is distant to the existing segments in relation with normal events. Our experimental studies indicate that the proposed techniques are promising.

#index 1390164
#* Distinguishing causal and acausal temporal relations
#@ Kamran Karimi;Howard J. Hamilton
#t 2003
#c 3
#% 31424
#% 297171
#% 494976
#% 637726
#! In this paper we propose a solution to the problem of distinguishing between causal and acausal temporal sets of rules. The method, called the Temporal Investigation Method for Enregistered Record Sequences (TIMERS), is explained and introduced formally. The input to TIMERS consists of a sequence of records, where each record is observed at regular intervals. Sets of rules are generated from the input data using different window sizes and directions of time. The set of rules may describe an instantaneous relationship, where the decision attribute depends on condition attributes seen at the same time instant. We investigate the temporal characteristics of the system by changing the direction of time when generating temporal rules to see whether a set of rules is causal or acausal. The results are used to declare a verdict as to the nature of the system: instantaneous, causal, or acausal.

#index 1390165
#* Online Bayes point machines
#@ Edward Harrington;Ralf Herbrich;Jyrki Kivinen;John Platt;Robert C. Williamson
#t 2003
#c 3
#% 73372
#% 209021
#% 351094
#% 425046
#% 722761
#% 722814
#% 729437
#! We present a new and simple algorithm for learning large margin classifiers that works in a truly online manner. The algorithm generates a linear classifier by averaging the weights associated with several perceptron-like algorithms run in parallel in order to approximate the Bayes point. A random subsample of the incoming data stream is used to ensure diversity in the perceptron solutions. We experimentally study the algorithm's performance on online and batch learning settings. The online experiments showed that our algorithm produces a low prediction error on the training sequence and tracks the presence of concept drift. On the batch problems its performance is comparable to the maximum margin algorithm which explicitly maximises the margin.

#index 1390166
#* Exploiting hierarchical domain values for Bayesian learning
#@ Yiqiu Han;Wai Lam
#t 2003
#c 3
#% 246831
#% 262059
#% 309141
#% 397661
#% 445523
#% 464634
#% 466078
#! This paper proposes a framework for exploiting hierarchical structures of feature domain values in order to improve classification performance under Bayesian learning framework. Inspired by the statistical technique called shrinkage, we investigate the variances in the estimation of parameters for Bayesian learning. We develop two algorithms by maintaining a balance between precision and robustness to improve the estimation. We have evaluated our methods using two real-world data sets, namely, a weather data set and a yeast gene data set. The results demonstrate that our models benefit from exploring the hierarchical structures.

#index 1390167
#* A new restricted Bayesian network classifier
#@ Hongbo Shi;Zhihai Wang;Geoffrey I. Webb;Houkuan Huang
#t 2003
#c 3
#% 44876
#% 240222
#% 246832
#% 290482
#% 321059
#% 1650277
#! On the basis of examining the existing restricted Bayesian network classifiers, a new Bayes-theorem-based and more strictly restricted Bayesian-network-based classification model DLBAN is proposed, which can be viewed as a double-level Bayesian network augmented naive Bayes classification. The experimental results show that the DLBAN classifier is better than the TAN classifier in the most cases.

#index 1390168
#* AGRID: an efficient algorithm for clustering large high-dimensional datasets
#@ Zhao Yanchang;Song Junde
#t 2003
#c 3
#% 210173
#% 248790
#% 248792
#% 273890
#% 316709
#% 420078
#% 420081
#% 422225
#% 438137
#% 479799
#% 481281
#% 566128
#% 631985
#! The clustering algorithm GDILC relies on density-based clustering with grid and is designed to discover clusters of arbitrary shapes and eliminate noises. However, it is not scalable to large high-dimensional datasets. In this paper, we improved this algorithm in five important directions. Through these improvements, AGRID is of high scalability and can process large high-dimensional datasets. It can discover clusters of various shapes and eliminate noises effectively. Besides, it is insensitive to the order of input and is a non-parametric algorithm. The high speed and accuracy of the AGRID clustering algorithm was shown in our experiments.

#index 1390169
#* Multi-level clustering and reasoning about its clusters using region connection calculus
#@ Ickjai Lee;Mary-Anne Williams
#t 2003
#c 3
#% 127107
#% 210173
#% 248790
#% 421040
#% 527035
#% 566128
#% 712001
#% 719768
#% 1289200
#! Spatial clustering provides answers for "where?" and "when?" and evokes "why?" for further explorations. In this paper, we propose a divisive multi-level clustering method that requires O(n log n) time. It reveals a cluster hierarchy for the "where?" and "when?" queries. Experimental results demonstrate that it identifies quality multi-level clusters. In addition, we present a solid framework for reasoning about multi-level clusters using Region Connection Calculus for the "why?" query. In this framework, we can derive their possible causes and positive associations between them with ease.

#index 1390170
#* An efficient cell-based clustering method for handling large, high-dimensional data
#@ Jae-Woo Chang
#t 2003
#c 3
#% 210173
#% 248792
#% 316709
#% 566128
#! In this paper, we propose an efficient cell-based clustering method for handling a large of amount of high-dimensional data. Our clustering method provides an efficient cell creation algorithm using a space-partitioning technique and a cell insertion algorithm to construct clusters as cells with more density than a given threshold. To achieve good retrieval performance on clusters, we also propose a new filtering-based index structure using an approximation technique. In addition, we compare the performance of our cell-based clustering method with the CLIQUE method in terms of cluster construction time, precision, and retrieval time. The experimental results show that our clustering method achieves better performance on cluster construction time and retrieval time.

#index 1390171
#* Enhancing SWF for incremental association mining by itemset maintenance
#@ Chia-Hui Chang;Shi-Hsan Yang
#t 2003
#c 3
#% 152934
#% 310559
#% 329598
#% 338580
#% 342689
#% 443164
#% 462219
#% 464204
#% 464989
#% 481754
#% 511333
#! Incremental association mining refers to the maintenance and utilization of the knowledge discovered in the previous mining operations for later association mining. Sliding window filtering (SWF) is a technique proposed to filter false candidate 2-itemsets by segmenting a transaction database into partitions. In this paper, we extend SWF by incorporating previously discovered information and propose two algorithms to boost the performance for incremental mining. The first algorithm FI_SWF (SWF with Frequent Itemset) reuses the frequent itemsets of previous mining task to reduce the number of new candidate itemsets that have to be checked. The second algorithm CI_SWF (SWF with Candidate Itemset) reuses the candidate itemsets from the previous mining task. Experiments show that the new proposed algorithms are significantly faster than SWF.

#index 1390172
#* Reducing rule covers with deterministic error bounds
#@ Vikram Pudi;Jayant R. Haritsa
#t 2003
#c 3
#% 172386
#% 273898
#% 280433
#% 310494
#% 462238
#% 466490
#% 481290
#% 501204
#% 501997
#% 631970
#% 632077
#% 993960
#! The output of boolean association rule mining algorithms is often too large for manual examination. For dense datasets, it is often impractical to even generate all frequent itemsets. The closed itemset approach handles this information overload by pruning "uninteresting" rules following the observation that most rules can be derived from other rules. In this paper, we propose a new framework, namely, the generalized closed (or g-closed) itemset framework. By allowing for a small tolerance in the accuracy of itemset supports, we show that the number of such redundant rules is far more than what was previously estimated. Our scheme can be integrated into both levelwise algorithms (Apriori) and two-pass algorithms (ARMOR). We evaluate its performance by measuring the reduction in output size as well as in response time. Our experiments show that incorporating g-closed itemsets provides significant performance improvements on a variety of databases.

#index 1390173
#* Evolutionary approach for mining association rules on dynamic databases
#@ P. Deepa Shenoy;K. G. Srinivasa;K. R. Venugopal;L. M. Patnaik
#t 2003
#c 3
#% 152934
#% 168999
#% 318994
#% 434348
#% 443016
#% 443448
#% 443466
#% 443468
#% 464204
#! A large volume of transaction data is generated everyday in a number of applications. These dynamic data sets have immense potential for reflecting changes in customer behaviour patterns. One of the strategies of data mining is association rule discovery, which correlates the occurrence of certain attributes in the database leading to the identification of large data itemsets. This paper seeks to generate large itemsets in a dynamic transaction database using the principles of Genetic Algorithms. Intra transactions, Inter transactions and distributed transactions are considered for mining association rules. Further, we analyze the time complexities of single scan DMARG(Dynamic Mining of Association Rules using Genetic Algorithms), with Fast UPdate (FUP) algorithm for intra transactions and E-Apriori for inter transactions. Our study shows that DMARG outperforms both FUP and E-Apriori in terms of execution time and scalability, without compromising the quality or completeness of rules generated. The problem of mining association rules in the distributed environment is explored in DDMARG(Distributed and Dynamic Mining of Association Rules using Genetic Algorithms).

#index 1390174
#* Position coded pre-order linked WAP-tree for web log sequential pattern mining
#@ Yi Lu;C. I. Ezeife
#t 2003
#c 3
#% 316709
#% 337714
#% 353056
#% 459006
#% 463903
#% 571039
#! Web access pattern tree algorithm mines web log access sequences by first storing the original web access sequence database on a prefix tree (WAP-tree). WAP-tree algorithm then mines frequent sequences from the WAP-tree by recursively re-constructing intermediate WAP-trees, starting with their suffix subsequences. This paper proposes an efficient approach for using the preorder linked WAP-trees with binary position codes assigned to each node, to mine frequent sequences, which eliminates the need to engage in numerous re-construction of intermediate WAP-trees during mining. Experiments show huge performance advantages for sequential mining using prefix linked WAP-tree technique.

#index 1390175
#* An integrated system of mining HTML texts and filtering structured documents
#@ Bo-Hyun Yun;Myung-Eun Lim;Soo-Hyun Park
#t 2003
#c 3
#% 70230
#% 275915
#% 278109
#% 283136
#% 301259
#% 511733
#% 747945
#! This paper presents a method of mining HTML documents into structured documents and of filtering structured documents by using both slot weighting and token weighting. The goal of a mining algorithm is to find slot-token patterns in HTML documents. In order to express user interests in structured document filtering, slot and token are considered. Our preference computation algorithm applies vector similarity and Bayesian probability to filter structured documents. The experimental results show that it is important to consider hyperlinking and unlablelling in mining HTML texts; slot and token weighting can enhance the performance of structured document filtering.

#index 1390176
#* A new sequential mining approach to XML document similarity computation
#@ Ho-Pong Leung;Fu-Lai Chung;Stephen Chi-Fai Chan
#t 2003
#c 3
#% 205024
#% 300153
#% 463903
#% 466651
#% 480496
#% 480649
#! There exist several methods to measuring the structural similarity among XML documents. The data mining approach seems to be a novel, interesting and promising one. In view of the deficiencies encountered by ignoring the hierarchical information in encoding the paths for mining, we propose a new sequential pattern mining scheme for XML document similarity computation. It makes use of the hierarchical information to computing the document structural similarity. In addition, it includes a post-processing step to reuse the mined patterns to estimate the similarity of unmatched elements so that another metric to qualify the similarity between XML documents can be introduced. Encouraging experimental results were obtained and reported.

#index 1390177
#* Optimization of fuzzy rules for classification using genetic algorithm
#@ Myung Won Kim;Joung Woo Ryu;Samkeun Kim;Joong Geun Lee
#t 2003
#c 3
#% 136350
#% 154901
#% 295905
#% 1272280
#% 1780725
#! In this paper, we propose an efficient fuzzy rule generation algorithm based on fuzzy decision tree for high accuracy and better comprehensibility. We combine the comprehensibility of rules generated based on decision tree such as ID3 and C4.5 and the expressive power of fuzzy sets for dealing with quantitative data. Particularly, fuzzy rules allow us to effectively classify patterns of non-axis-parallel decision boundaries, which are difficult to do using attribute-based classification methods. We also investigate the use of genetic algorithm to optimize fuzzy decision trees in accuracy and comprehensibility by determining an appropriate set of membership functions for quantitative data. We have experimented our algorithm with several benchmark test data including manually generated two-class patterns, the iris data, the Wisconsin breast cancer data, and the credit screening data. The experiment results show that our method is more efficient in performance and comprehensibility of rules compared with methods including C4.5 and FID (Fuzzy ID3).

#index 1390178
#* Fast pattern selection for support vector classifiers
#@ Hyunjung Shin;Sungzoon Cho
#t 2003
#c 3
#% 190581
#% 264161
#% 269218
#% 376266
#% 445243
#% 494972
#% 614375
#% 1781130
#% 1860587
#! Training SVM requires large memory and long cpu time when the pattern set is large. To alleviate the computational burden in SVM training, we propose a fast preprocessing algorithm which selects only the patterns near the decision boundary. Preliminary simulation results were promising: Up to two orders of magnitude, training time reduction was achieved including the preprocessing, without any loss in classification accuracies.

#index 1390179
#* Averaged boosting: a noise-robust ensemble method
#@ Yongdai Kim
#t 2003
#c 3
#% 209021
#% 235377
#% 302391
#% 312727
#% 331916
#% 400847
#% 424997
#% 564956
#! A new noise robust ensemble method called "Averaged Boosting (A-Boosting)" is proposed. Using the hypothetical ensemble algorithm in Hilbert space, we explain that A-Boosting can be understood as a method of constructing a sequence of hypotheses and coefficients such that the average of the product of the base hypotheses and coefficients converges to the desirable function. Empirical studies showed that A-Boosting outperforms Bagging for low noise cases and is more robust than AdaBoost to label noise.

#index 1390180
#* Improving performance of decision tree algorithms with multi-edited nearest neighbor rule
#@ Chen-Zhou Ye;Jie Yang;Li-Xiu Yao;Nian-Yi Chen
#t 2003
#c 3
#% 252403
#% 312727
#% 729437
#! The paper proposed a new method based on the multi-edited nearest neighbor rule to prevent decision tree algorithms from growing a tree of unnecessary large size and hence partially alleviate the problem of "over-training". For this purpose, two useful prosperities of the multi-edited nearest neighbor rule are investigated. Experiments show that the method proposed could drastically reduce the size of resulting trees, significantly enhance their understandability, and meanwhile improve the test accuracy when the control parameter takes an appropriate value.

#index 1390181
#* HOT: hypergraph-based outlier test for categorical data
#@ Li Wei;Weining Qian;Aoying Zhou;Wen Jin;Jeffrey X. Yu
#t 2003
#c 3
#% 2115
#% 230138
#% 248790
#% 300136
#% 300183
#% 333929
#% 342625
#% 342638
#% 477821
#% 479791
#% 479986
#% 481290
#! As a widely used data mining technique, outlier detection is a process which aims at finding anomalies with good explanations. Most existing methods are designed for numeric data. They will have problems with real-life applications that contain categorical data. In this paper, we introduce a novel outlier mining method based on a hypergraph model. Since hypergraphs precisely capture the distribution characteristics in data subspaces, this method is effective in identifying anomalies in dense subspaces and presents good interpretations for the local outlierness. By selecting the most relevant subspaces, the problem of "curse of dimensionality" in very large databases can also be ameliorated. Furthermore, the connectivity property is used to replace the distance metrics, so that the distance-based computation is not needed anymore, which enhances the robustness for handling missing-value data. The fact, that connectivity computation facilitates the aggregation operations supported by most SQL-compatible database systems, makes the mining process much efficient. Finally, experiments and analysis show that our method can find outliers in categorical data with good performance and quality.

#index 1390182
#* A method for aggregating partitions, applications in K.D.D.
#@ Pierre-Emmanuel Jouve;Nicolas Nicoloyannis
#t 2003
#c 3
#% 61552
#% 856734
#! K.D.D. (Knowledge Discovery in Databases) methods and methodologies nearly all imply the retrieval of one or several structures of a data set. In practice, using those methods may give rise to a bunch of problems (excessive computing time, parameters settings, ...). We show in this paper that some of these problems can be solved via the construction of a global structure starting from a set of sub-structures. We thus propose a method for aggregating a set of partial structures into a global one and then present how this method can be used for solving several traditional practical problems of K.D.D.

#index 1390183
#* Efficiently computing iceberg cubes with complex constraints through bounding
#@ Pauline L. H. Chou;Xiuzhen Zhang
#t 2003
#c 3
#% 210182
#% 223781
#% 273916
#% 333925
#% 420053
#! Data cubes facilitate fast On-Line Analytical Processing (OLAP). Iceberg cubes are special cubes comprise only the multi-dimensional groups satisfying some user-specified constraints. Previous algorithms have focused on iceberg cubes defined by relatively simple constraints such as "COUNT(*) ≥ δ" and "COUNT(*) ≥ δ AND AVG(Profit) ≥ α". We propose an algorithm I-Cubing that computes iceberg cubes defined by complex constraints involving multiple predicates of aggregates such as "COUNT(*) ≥ δ AND (AVG(Profit) ≥ α OR AVG(profit) ≤ β)". State-of-the-art iceberg cubing algorithms: BUC cannot handle such cases whereas H-Cubing has to incur extra cost. Our proposed bounding technique can prune for all the given constraints at once without extra cost. Experiments show that bounding has superior pruning power and I-Cubing is twice as fast as H-Cubing. Furthermore, I-Cubing performs equally well with more complex constraints.

#index 1390184
#* Extraction of tag tree patterns with contractible variables from irregular semistructured data
#@ Tetsuhiro Miyahara;Yusuke Suzuki;Takayoshi Shoudai;Tomoyuki Uchida;Sachio Hirokawa;Kenichi Takahashi;Hiroaki Ueda
#t 2003
#c 3
#% 291299
#% 312860
#% 348146
#% 443349
#% 502140
#% 563269
#% 1393869
#! Information Extraction from semistructured data becomes more and more important. In order to extract meaningful or interesting contents from semistructured data, we need to extract common structured patterns from semistructured data. Many semistructured data have irregularities such as missing or erroneous data. A tag tree pattern is an edge labeled tree with ordered children which has tree structures of tags and structured variables. An edge label is a tag, a keyword or a wild-card, and a variable can be substituted by an arbitrary tree. Especially, a contractible variable matches any subtree including a singleton vertex. So a tag tree pattern is suited for representing common tree structured patterns in irregular semistructured data. We present a new method for extracting characteristic tag tree patterns from irregular semistructured data by using an algorithm for finding a least generalized tag tree pattern explaining given data. We report some experiments of applying this method to extracting characteristic tag tree patterns from irregular semistructured data.

#index 1390185
#* Step-by-step regression: a more efficient alternative for polynomial multiple linear regression in stream cube
#@ Chao Liu;Ming Zhang;Minrui Zheng;Yixin Chen
#t 2003
#c 3
#% 70370
#% 223781
#% 397426
#% 420053
#% 659944
#% 993958
#% 993961
#! Facing tremendous and potentially infinite stream data, it is impossible to record them entirely. Thus synopses are required to be generated timely to capture the underlying model for stream management systems. Traditionally, curve fitting through Multiple Linear Regression (MLR) is a powerful and efficient modeling tool. In order to further accelerate its processing efficiency, we propose Step-by-step Regression (SR) as a more efficient alternative. As revealed in experiments, it speeds up for more than 40 times. In addition, inspired by previous work, we integrated SR into cube environment through similar compression technique to perform online analytical processing and mining over data stream. Finally, experiments show that SR not only significantly alleviates the computation pressure on the front ends of data stream management systems, but also results in a much smaller stream cube for on line analysis and real-time surveillance.

#index 1390186
#* Progressive weighted miner: an efficient method for time-constraint mining
#@ Chang-Hung Lee;Jian Chih Ou;Ming-Syan Chen
#t 2003
#c 3
#% 152934
#% 273899
#% 280487
#% 300474
#% 310541
#% 310558
#% 320944
#% 338580
#% 342610
#% 342689
#% 443082
#% 443164
#% 443194
#% 462219
#% 464204
#% 464989
#% 466650
#% 480154
#% 481290
#% 481758
#% 577215
#% 629662
#% 632076
#! The discovery of association relationship among the data in a huge database has been known to be useful in selective marketing, decision analysis, and business management. A significant amount of research effort has been elaborated upon the development of efficient algorithms for data mining. However, without fully considering the time-variant characteristics of items and transactions, it is noted that some discovered rules may be expired from users' interest. In other words, some discovered knowledge may be obsolete and of little use, especially when we perform the mining schemes on a transaction database of short life cycle products. This aspect is, however, rarely addressed in prior studies. To remedy this, we broaden in this paper the horizon of frequent pattern mining by introducing a weighted model of transaction-weighted association rules in a time-variant database. Specifically, we propose an efficient Progressive Weighted Miner (abbreviatedly as PWM) algorithm to perform the mining for this problem as well as conduct the corresponding performance studies. In algorithm PWM, the importance of each transaction period is first reflected by a proper weight assigned by the user. Then, PWM partitions the time-variant database in light of weighted periods of transactions and performs weighted mining. Algorithm PWM is designed to progressively accumulate the itemset counts based on the intrinsic partitioning characteristics and employ a filtering threshold in each partition to early prune out those cumulatively infrequent 2-itemsets. With this design, algorithm PWM is able to efficiently produce weighted association rules for applications where different time periods are assigned with different weights and lead to results of more interest.

#index 1390187
#* Mining open source software (OSS) data using association rules network
#@ Sanjay Chawla;Bavani Arunasalam;Joseph Davis
#t 2003
#c 3
#% 257744
#% 269272
#% 316709
#% 325269
#% 341700
#% 441684
#% 481290
#% 572295
#! The Open Source Software(OSS) movement has attracted considerable attention in the last few years. In this paper we report our results of mining data acquired from SourceForge.net, the largest open source software hosting website. In the process we introduce Association Rules Network(ARN), a (hyper)graphical model to represent a special class of association rules. Using ARNs we discover important relationships between the attributes of successful OSS projects. We verify and validate these relationships using Factor Analysis, a classical statistical technique related to Singular Value Decomposition(SVD).

#index 1390188
#* Parallel FP-growth on PC cluster
#@ Iko Pramudiono;Masaru Kitsuregawa
#t 2003
#c 3
#% 199538
#% 300120
#% 329598
#% 340290
#% 443091
#% 481290
#! FP-growth has become a popular algorithm to mine frequent patterns. Its metadata FP-tree has allowed significant performance improvement over previously reported algorithms. However that special data structure also restrict the ability for further extensions. There is also potential problem when FP-tree can not fit into the memory. In this paper, we report parallel execution of FP-growth. We examine the bottlenecks of the parallelization and also method to balance the execution efficiently on shared-nothing environment.

#index 1390189
#* Active feature selection using classes
#@ Huan Liu;Lei Yu;Manoranjan Dash;Hiroshi Motoda
#t 2003
#c 3
#% 136350
#% 169659
#% 243728
#% 290482
#% 385564
#% 466084
#% 466269
#% 466410
#! Feature selection is frequently used in data pre-processing for data mining. When the training data set is too large, sampling is commonly used to overcome the difficulty. This work investigates the applicability of active sampling in feature selection in a filter model setting. Our objective is to partition data by taking advantage of class information so as to achieve the same or better performance for feature selection with fewer but more relevant instances than random sampling. Two versions of active feature selection that employ class information are proposed and empirically evaluated. In comparison with random sampling, we conduct extensive experiments with benchmark data sets, and analyze reasons why class-based active feature selection works in the way it does. The results will help us deal with large data sets and provide ideas to scale up other feature selection algorithms.

#index 1390190
#* Electricity based external similarity of categorical attributes
#@ Christopher R. Palmer;Christos Faloutsos
#t 2003
#c 3
#% 63833
#% 280419
#% 570885
#% 577273
#% 631985
#! Similarity or distance measures are fundamental and critical properties for data mining tools. Categorical attributes abound in databases. The Car Make, Gender, Occupation, etc. fields in a automobile insurance database are very informative. Sadly, categorical data is not easily amenable to similarity computations. A domain expert might manually specify some or all of the similarity relationships, but this is error-prone and not feasible for attributes with large domains, nor is it useful for cross-attribute similarities, such as between Gender and Occupation. External similarity functions define a similarity between, say, Car Makes by looking at how they co-occur with the other categorical attributes. We exploit a rich duality between random walks on graphs and electrical circuits to develop REP, an external similarity function. REP is theoretically grounded while the only prior work was ad-hoc. The usefulness of REP is shown in two experiments. First, we cluster categorical attribute values showing improved inferred relationships. Second, we use REP effectively as a nearest neighbour classifier.

#index 1390191
#* Weighted proportional k-interval discretization for naive-Bayes classifiers
#@ Ying Yang;Geoffrey I. Webb
#t 2003
#c 3
#% 33968
#% 136350
#% 246831
#% 312728
#% 420054
#% 458324
#% 466429
#! The use of different discretization techniques can be expected to affect the classification bias and variance of naive-Bayes classifiers. We call such an effect discretization bias and variance. Proportional k-interval discretization (PKID) tunes discretization bias and variance by adjusting discretized interval size and number proportional to the number of training instances. Theoretical analysis suggests that this is desirable for naive-Bayes classifiers. However PKID is sub-optimal when learning from training data of small size. We argue that this is because PKID equally weighs bias reduction and variance reduction. But for small data, variance reduction can contribute more to lower learning error and thus should be given greater weight than bias reduction. Accordingly we propose weighted proportional k-interval discretization (WPKID), which establishes a more suitable bias and variance trade-off for small data while allowing additional training data to be used to reduce both bias and variance. Our experiments demonstrate that for naive-Bayes classifiers, WPKID improves upon PKID for smaller datasets with significant frequency; and WPKID delivers lower classification error significantly more often than not in comparison to three other leading alternative discretization techniques studied.

#index 1390192
#* Dealing with relative similarity in clustering: an indiscernibility based approach
#@ Shoji Hirano;Shusaku Tsumoto
#t 2003
#c 3
#% 366687
#! In this paper we propose a clustering method that works on relative proximity. The key process of this method is iterative refinement of N binary classifications, where N denotes the number of objects. First, for each of N objects, an equivalence relation that classifies all the other objects into two classes, similar and dissimilar, is assigned by refering to their relative proximity. Next, for each pair objects, we count the number of binary classifications in which the pair is included in the same class. We call this number as indiscernibility degree. If indiscernibility degree of the pair is larger than a user-defined threshold value, we modify the equivalence relations so that all of them commonly classify the pair into the same class. This process is repeated until clusters become stable. Consequently we get the clusters that follows granularity of the given threshold without using geometric measures.

#index 1390193
#* Considering correlation between variables to improve spatiotemporal forecasting
#@ Zhigang Li;Liangang Liu;Margaret H. Dunham
#t 2003
#c 3
#% 51647
#% 393812
#% 394984
#% 1860126
#% 1860471
#! The importance of forecasting cannot be overemphasized in modern environment surveillance applications, including flood control, rainfall analysis, pollution study, nuclear leakage prevention and so on. That is why we proposed STIFF (SpatioTemporal Integrated Forecasting Framework) in previous work [11], trying to answer such a challenging problem of doing forecasting in natural environment with both spatial and temporal characteristics involved. However, despite its promising performance on univariate-based data, STIFF is not sophisticated enough for more complicated environmental data derived from multiple correlated variables. Therefore in this paper we add multivariate analysis to the solution, take the correlation between different variables into account and further extend STIFF to address spatiotemporal forecasting involving multiple variables. Our experiments show that this introduction and integration of multivariate correlation not only has a more reasonable and rational interpretation of the data itself, but also produces a higher accuracy and slightly more balanced behavior.

#index 1390194
#* Correlation analysis of spatial time series datasets: a filter-and-refine approach
#@ Pusheng Zhang;Yan Huang;Shashi Shekhar;Vipin Kumar
#t 2003
#c 3
#% 316709
#% 334059
#% 359751
#% 391356
#% 394984
#% 397381
#% 443258
#% 460862
#% 481542
#% 617843
#% 631923
#% 758494
#! A spatial time series dataset is a collection of time series, each referencing a location in a common spatial framework. Correlation analysis is often used to identify pairs of potentially interacting elements from the cross product of two spatial time series datasets. However, the computational cost of correlation analysis is very high when the dimension of the time series and the number of locations in the spatial frameworks are large. The key contribution of this paper is the use of spatial autocorrelation among spatial neighboring time series to reduce computational cost. A filter-and-refine algorithm based on coning, i.e. grouping of locations, is proposed to reduce the cost of correlation analysis over a pair of spatial time series datasets. Cone-level correlation computation can be used to eliminate (filter out) a large number of element pairs whose correlation is clearly below (or above) a given threshold. Element pair correlation needs to be computed for remaining pairs. Using experimental studies with Earth science datasets, we show that the filter-and-refine approach can save a large fraction of the computational cost, particularly when the minimal correlation threshold is high.

#index 1390195
#* When to update the sequential patterns of stream data?
#@ Qingguo Zheng;Ke Xu;Shilong Ma
#t 2003
#c 3
#% 273693
#% 280467
#% 287242
#% 316709
#% 345857
#% 464204
#% 511333
#! In this paper, we first define a difference measure between the old and new sequential patterns of stream data, which is proved to be a distance. Then we propose an experimental method, called TPD (Tradeoff between Performance and Difference), to decide when to update the sequential patterns of stream data by making a tradeoff between the performance of increasingly updating algorithms and the difference of sequential patterns. The experiments for the increasingly updating algorithm IUS on the alarm data show that generally, as the size of incremental windows grows, the values of the speedup and the values of the difference will decrease and increase respectively. It is also shown experimentally that the incremental ratio determined by the TPD method does not monotonically increase or decrease but changes in a range between 20 and 30 percentage for the IUS algorithm.

#index 1390196
#* A new clustering algorithm for transaction data via caucus
#@ Jinmei Xu;Hui Xiong;Sam Yuan Sung;Vipin Kumar
#t 2003
#c 3
#% 136350
#% 259994
#% 287285
#% 300131
#% 481290
#% 483675
#% 661048
#% 1860187
#! The fast-growing large point of sale databases in stores and companies sets a pressing need for extracting high-level knowledge. Transaction clustering arises to receive attentions in recent years. However, traditional clustering techniques are not useful to solve this problem. Transaction data sets are different from the traditional data sets in their high dimensionality, sparsity and a large number of outliers. In this paper we present and experimentally evaluate a new efficient transaction clustering technique based on cluster of buyers called caucus that can be effectively used for identification of center of cluster. Experiments on real and synthetic data sets indicate that compare to prior work, caucus-based method can derive clusters of better quality as well as reduce the execution time considerably.

#index 1390197
#* DBRS: a density-based spatial clustering method with random sampling
#@ Xin Wang;Howard J. Hamilton
#t 2003
#c 3
#% 86950
#% 248790
#% 296738
#% 481281
#% 527021
#% 527160
#! In this paper, we propose a novel density-based spatial clustering method called DBRS. The algorithm can identify clusters of widely varying shapes, clusters of varying densities, clusters which depend on nonspatial attributes, and approximate clusters in very large databases. DBRS achieves these results by repeatedly picking an unclassified point at random and examining its neighborhood. A theoretical comparison of DBRS and DBSCAN, a well-known density-based algorithm, is also given in the paper.

#index 1390198
#* Optimized clustering for anomaly intrusion detection
#@ Sang Hyun Oh;Won Suk Lee
#t 2003
#c 3
#% 210173
#% 479658
#! Although conventional clustering algorithms have been used to classify data objects in a data set into the groups of similar data objects based on data similarity, they can be employed to extract the common knowledge i.e. properties of similar data objects commonly appearing in a set of transactions. The common knowledge of the activities in the transactions of a user is represented by the occurrence frequency of similar activities by the unit of a transaction as well as the repetitive ratio of similar activities in each transaction. This paper proposes an optimized clustering method for modeling the normal pattern of a user's activities. Furthermore, it also addresses how to determine the optimal values of clustering parameters for a user as well as how to maintain identified common knowledge as a concise profile. As a result, it can be used to detect any anomalous behavior in an online transaction of the user.

#index 1390199
#* Finding frequent subgraphs from graph structured data with geometric information and its application to lossless compression
#@ Yuko Itokawa;Tomoyuki Uchida;Takayoshi Shoudai;Tetsuhiro Miyahara;Yasuaki Nakamura
#t 2003
#c 3
#% 445369
#% 481290
#% 1268739
#! In this paper, we present an effective algorithm for extracting characteristic substructures from graph structured data with geometric information, such as CAD, map data and drawing data. Moreover, as an application of our algorithm, we give a method of lossless compression for such data. First, in order to deal with graph structured data with geometric information, we give a layout graph which has the total order on all vertices. As a knowledge representation, we define a layout term graph with structured variables. Secondly, we present an algorithm for finding frequent connected subgraphs in given data. This algorithm is based on levelwise strategies like Apriori algorithm by focusing on the total order on vertices. Next, we design a method of lossless compression of graph structured data with geometric information by introducing the notion of a substitution in logic programming. In general, analyzing large graph structured data is a time consuming process. If we can reduce the number of vertices without loss of information, we can speed up such a heavy process. Finally, in order to show an effectiveness of our method, we report several experimental results.

#index 1390200
#* Upgrading ILP rules to first-order Bayesian networks
#@ Ratthachat Chatpatanasiri;Boonserm Kijsirikul
#t 2003
#c 3
#% 379346
#% 396021
#% 398847
#! Inductive Logic Programming (ILP) is an efficient technique for relational data mining, but when ILP is applied in imperfect domains, the rules induced by ILP often struggle with the overfitting problem. This paper proposes a method to learn first-order Bayesian network (FOBN) which can handle imperfect data powerfully. Due to a high computation cost for directly learning FOBN, we adapt an ILP and a Bayesian network learner to construct FOBN. We propose a feature extraction algorithm to generate features from ILP rules, and use these features as the main structure of the FOBN. We also propose a propositionalisation algorithm for translating the original data into the single table format to learn the remaining parts of the FOBN structure and its conditional probability tables by a standard Bayesian network learner.

#index 1390201
#* A clustering validity assessment index
#@ Youngok Kim;Soowon Lee
#t 2003
#c 3
#% 203462
#% 296738
#% 430746
#% 466481
#! Clustering is a method for grouping objects with similar patterns and finding meaningful clusters in a data set. There exist a large number of clustering algorithms in the literature, and the results of clustering even in a particular algorithm vary according to its input parameters such as the number of clusters, field weights, similarity measures, the number of passes, etc. Thus, it is important to effectively evaluate the clustering results a priori, so that the generated clusters are more close to the real partition. In this paper, an improved clustering validity assessment index is proposed based on a new density function for intercluster similarity and a new scatter function for intra-cluster similarity. Experimental results show the effectiveness of the proposed index on the data sets under consideration regardless of the choice of a clustering algorithm.

#index 1393130
#* Proceedings of the 11th Pacific-Asia conference on Advances in knowledge discovery and data mining
#@ Zhi-Hua Zhou;Hang Li;Qiang Yang
#t 2007
#c 3

#index 1393131
#* Research frontiers in advanced data mining technologies and applications
#@ Jiawei Han
#t 2007
#c 3
#% 818916
#! Research in data mining has two general directions: theoretical foundations and advanced technologies and applications. In this talk, we will focus on the research issues for advanced technologies and applications in data mining and discuss some recent progress in this direction, including (1) pattern mining, usage, and understanding, (2) information network analysis, (3) stream data mining, (4) mining moving object data, RFID data, and data from sensor networks, (5) spatiotemporal and multimedia data mining, (6) biological data mining, (7) text and Web mining, (8) data mining for software engineering and computer system analysis, and (9) data cube-oriented multidimensional online analytical processing.

#index 1393132
#* Finding the real patterns
#@ Geoffrey Webb
#t 2007
#c 3
#% 881499
#% 1046339
#! Pattern discovery is one of the fundamental tasks in data mining. Pattern discovery typically explores a massive space of potential patterns to identify those that satisfy some user-specified criteria. This process entails a huge risk (in many cases a near certainty) that many patterns will be false discoveries. These are patterns that satisfy the specified criteria with respect to the sample data but do not satisfy those criteria with respect to the population from which those data are drawn. This talk discusses the problem of false discoveries, and presents techniques for avoiding them.

#index 1393133
#* Class noise vs attribute noise: their impacts, detection and cleansing
#@ Xindong Wu
#t 2007
#c 3
#! Noise handling is an essential task in data mining research and applications. There are three issues in dealing with noisy information sources: noise identification, noise profiling, and noise tolerant mining. During noise identification, erroneous data records are identified and ranked according to their impact or some predefined measures. Class noise and attribute noise can be distinguished at this stage. This identification allows the users to process their noisy data with different priorities based on the data properties. Noise profiling discovers patterns from previously identified errors that can be used to summarize and monitor these data errors. In noise tolerant mining, we integrate the noise profile information into data mining algorithms and boost their performances from the original noisy data. In this talk, I will present our existing and ongoing research efforts on these three issues.

#index 1393134
#* Multi-modal and multi-granular learning
#@ Bo Zhang;Ling Zhang
#t 2007
#c 3

#index 1393135
#* Hierarchical density-based clustering of categorical data and a simplification
#@ Bill Andreopoulos;Aijun An;Xiaogang Wang
#t 2007
#c 3
#% 232117
#% 248792
#% 249305
#% 273890
#% 280419
#% 290262
#% 314054
#% 338466
#% 413618
#% 420081
#% 420144
#% 438137
#% 479659
#% 577296
#% 589434
#% 770826
#% 823329
#% 980631
#! A challenge involved in applying density-based clustering to categorical datasets is that the 'cube' of attribute values has no ordering defined. We propose the HIERDENC algorithm for hierarchical density-based clustering of categorical data. HIERDENC offers a basis for designing simpler clustering algorithms that balance the tradeoff of accuracy and speed. The characteristics of HIERDENC include: (i) it builds a hierarchy representing the underlying cluster structure of the categorical dataset, (ii) it minimizes the user-specified input parameters, (iii) it is insensitive to the order of object input, (iv) it can handle outliers. We evaluate HIERDENC on small-dimensional standard categorical datasets, on which it produces more accurate results than other algorithms. We present a faster simplification of HIERDENC called the MULIC algorithm. MULIC performs better than subspace clustering algorithms in terms of finding the multi-layered structure of special datasets.

#index 1393136
#* Multi-represented classification based on confidence estimation
#@ Johannes Aßfalg;Hans-Peter Kriegel;Alexey Pryakhin;Matthias Schubert
#t 2007
#c 3
#% 67565
#% 251145
#% 252011
#% 290482
#% 464280
#% 482502
#% 501994
#% 748550
#! Complex objects are often described by multiple representations modeling various aspects and using various feature transformations. To integrate all information into classification, the common way is to train a classifier on each representation and combine the results based on the local class probabilities. In this paper, we derive so-called confidence estimates for each of the classifiers reflecting the correctness of the local class prediction and use the prediction having the maximum confidence value. The confidence estimates are based on the distance to the class border and can be derived for various types of classifiers like support vector machines, k-nearest neighbor classifiers, Bayes classifiers, and decision trees. In our experimental results, we report encouraging results demonstrating a performance advantage of our new multi-represented classifier compared to standard methods based on confidence vectors.

#index 1393137
#* Selecting a reduced set for building sparse support vector regression in the primal
#@ Liefeng Bo;Ling Wang;Licheng Jiao
#t 2007
#c 3
#% 269217
#% 269218
#% 425062
#% 734919
#% 829007
#% 916790
#% 959451
#% 959454
#% 961188
#% 1860543
#! Recent work shows that Support vector machines (SVMs) can be solved efficiently in the primal. This paper follows this line of research and shows how to build sparse support vector regression (SVR) in the primal, thus providing for us scalable, sparse support vector regression algorithm, named SSVR-SRS. Empirical comparisons show that the number of basis functions required by the proposed algorithm to achieve the accuracy close to that of SVR is far less than the number of support vectors of SVR.

#index 1393138
#* Mining frequent itemsets from uncertain data
#@ Chun-Kit Chui;Ben Kao;Edward Hung
#t 2007
#c 3
#% 341445
#% 463903
#% 481290
#% 1720764
#! We study the problem of mining frequent itemsets from uncertain data under a probabilistic framework. We consider transactions whose items are associated with existential probabilities and give a formal definition of frequent patterns under such an uncertain data model. We show that traditional algorithms for mining frequent itemsets are either inapplicable or computationally inefficient under such a model. A data trimming framework is proposed to improve mining efficiency. Through extensive experiments, we show that the data trimming technique can achieve significant savings in both CPU cost and I/O cost.

#index 1393139
#* QC4: a clustering evaluation method
#@ Daniel Crabtree;Peter Andreae;Xiaoying Gao
#t 2007
#c 3
#% 375017
#% 413608
#% 430746
#% 710338
#% 731938
#% 739899
#% 832266
#% 832282
#% 961606
#! Many clustering algorithms have been developed and researchers need to be able to compare their effectiveness. For some clustering problems, like web page clustering, different algorithms produce clusterings with different characteristics: coarse vs fine granularity, disjoint vs overlapping, flat vs hierarchical. The lack of a clustering evaluation method that can evaluate clusterings with different characteristics has led to incomparable research and results. QC4 solves this by providing a new structure for defining general ideal clusterings and new measurements for evaluating clusterings with different characteristics with respect to a general ideal clustering. The paper describes QC4 and evaluates it within the web clustering domain by comparison to existing evaluation measurements on synthetic test cases and on real world web page clustering tasks. The synthetic test cases show that only QC4 can cope correctly with overlapping clusters, hierarchical clusterings, and all the difficult boundary cases. In the real world tasks, which represent simple clustering situations, QC4 is mostly consistent with the existing measurements and makes better conclusions in some cases.

#index 1393140
#* Semantic feature selection for object discovery in high-resolution remote sensing imagery
#@ Dihua Guo;Hui Xiong;Vijay Atluri;Nabil Adam
#t 2007
#c 3
#% 340901
#% 397145
#% 443530
#% 457912
#% 642989
#% 722927
#% 727897
#% 789337
#% 893372
#% 1502531
#! Given its importance, the problem of object discovery in High-Resolution Remote-Sensing (HRRS) imagery has been given a lot of attention by image retrieval researchers. Despite the vast amount of expert endeavor spent on this problem, more effort has been expected to discover and utilize hidden semantics of images for image retrieval. To this end, in this paper, we exploit a hyperclique pattern discovery method to find complex objects that consist of several co-existing individual objects that usually form a unique semantic concept. We consider the identified groups of co-existing objects as new feature sets and feed them into the learning model for better performance of image retrieval. Experiments with real-world datasets show that, with new semantic features as starting points, we can improve the performance of object discovery in terms of various external criteria.

#index 1393141
#* Deriving private information from arbitrarily projected data
#@ Songtao Guo;Xintao Wu
#t 2007
#c 3
#% 276877
#% 299344
#% 300184
#% 333876
#% 727904
#% 810010
#% 843878
#% 844360
#% 874169
#% 1663641
#% 1663662
#! Distance-preserving projection based perturbation has gained much attention in privacy-preserving data mining in recent years since it mitigates the privacy/accuracy tradeoff by achieving perfect data mining accuracy. One apriori knowledge PCA based attack was recently investigated to show the vulnerabilities of this distance-preserving projected based perturbation approach when a sample dataset is available to attackers. As a result, non-distance-preserving projection was suggested to be applied since it is resilient to the PCA attack with the sacrifice of data mining accuracy to some extent. In this paper we investigate how to recover the original data from arbitrarily projected data and propose AKICA, an Independent Component Analysis based reconstruction method. Theoretical analysis and experimental results show that both distance-preserving and non-distance-preserving projection approaches are vulnerable to this attack. Our results offer insight into the vulnerabilities of projection based approach and suggest a careful scrutiny when it is applied in privacy-preserving data mining.

#index 1393142
#* Consistency based attribute reduction
#@ Qinghua Hu;Hui Zhao;Zongxia Xie;Daren Yu
#t 2007
#c 3
#% 154305
#% 347878
#% 425048
#% 449588
#% 450928
#% 580887
#% 722929
#% 736899
#% 784508
#% 796212
#% 819866
#% 875246
#% 1387652
#% 1690061
#! Rough sets are widely used in feature subset selection and attribute reduction. In most of the existing algorithms, the dependency function is employed to evaluate the quality of a feature subset. The disadvantages of using dependency are discussed in this paper. And the problem of forward greedy search algorithm based on dependency is presented. We introduce the consistency measure to deal with the problems. The relationship between dependency and consistency is analyzed. It is shown that consistency measure can reflects not only the size of decision positive region, like dependency, but also the sample distribution in the boundary region. Therefore it can more finely describe the distinguishing power of an attribute set. Based on consistency, we redefine the redundancy and reduct of a decision system. We construct a forward greedy search algorithm to find reducts based on consistency. What's more, we employ cross validation to test the selected features, and reduce the overfitting features in a reduct. The experimental results with UCI data show that the proposed algorithm is effective and efficient.

#index 1393143
#* A hybrid command sequence model for anomaly detection
#@ Zhou Jian;Haruhiko Shirai;Isamu Takahashi;Jousuke Kuroiwa;Tomohiro Odaka;Hisakazu Ogura
#t 2007
#c 3
#! A new anomaly detection method based on models of user behavior at the command level is proposed as an intrusion detection technique. The hybrid command sequence (HCS) model is trained from historical session data by a genetic algorithm, and then it is used as the criterion in verifying observed behavior. The proposed model considers the occurrence of multiple command sequence fragments in a single session, so that it could recognize nonsequential patterns. Experiment results demonstrate an anomaly detection rate of higher than 90%, comparable to other statistical methods and 10% higher than the original command sequence model.

#index 1393144
#* σ-algorithm: structured workflow process mining through amalgamating temporal workcases
#@ Kwanghoon Kim;Clarence A. Ellis
#t 2007
#c 3
#% 459021
#% 733140
#% 749035
#% 749036
#% 749037
#% 823352
#% 1678886
#% 1709206
#% 1709212
#% 1711192
#! Workflow Management Systems help to execute, monitor and manage work process flow and execution. These systems, as they are executing, keep a record of who does what and when (e.g. log of events). The activity of using computer software to examine these records, and deriving various structural data results is called workflow mining. The workflow mining activity, in general, needs to encompass behavioral (process/control-flow), social, informational (data-flow), and organizational perspectives; as well as other perspectives, because workflow systems are "people systems" that must be designed, deployed, and understood within their social and organizational contexts. In this paper, we especially focus on the behavioral perspective of a structured workflow model that preserves the proper nesting and the matched pair properties. That is, this paper proposes an ICN-based mining algorithm that rediscovers a structured workflow process model. We name it σ-Algorithm, because it is incrementally amalgamating a series of temporal workcases (workflow traces) according to three types of basic merging principles conceived in this paper. Where, a temporal workcase is a temporally ordered set of activity execution event logs. We also gives an example to show that how the algorithm works with the temporal workcases.

#index 1393145
#* Multiscale bilinear recurrent neural network for prediction of MPEG video traffic
#@ Min-Woo Lee;Dong-Chul Park;Yunsik Lee
#t 2007
#c 3
#% 265065
#% 1678263
#% 1756867
#% 1860966
#% 1861145
#! A MPEG video traffic prediction model in ATM networks using the Multiscale BiLinear Recurrent Neural Network (M-BLRNN) is proposed in this paper. The M-BLRNN is a wavelet-based neural network architecture based on the BiLinear Recurrent Neural Network (BLRNN). The wavelet transform is employed to decompose the time-series to a multiresolution representation while the BLRNN model is used to predict a signal at each level of resolution. The proposed M-BLRNN-based predictor is applied to real-time MPEG video traffic data. When compared with the MLPNN-based predictor and the BLRNN-based predictor, the proposed M-BLRNN-based predictor shows 16%-47% improvement in terms of the Normalized Mean Square Error (NMSE) criterion.

#index 1393146
#* An effective multi-level algorithm based on ant colony optimization for bisecting graph
#@ Ming Leng;Songnian Yu
#t 2007
#c 3
#% 121466
#% 193810
#% 220615
#% 247169
#% 342659
#% 408396
#% 466675
#% 605157
#% 771477
#% 1693345
#% 1777042
#% 1780532
#% 1839749
#! An important application of graph partitioning is data clustering using a graph model -- the pairwise similarities between all data objects form a weighted graph adjacency matrix that contains all necessary information for clustering. The min-cut bipartitioning problem is a fundamental graph partitioning problem and is NP-Complete. In this paper, we present an effective multi-level algorithm based on ant colony optimization(ACO) for bisecting graph. The success of our algorithm relies on exploiting both the ACO method and the concept of the graph core. Our experimental evaluations on 18 different graphs show that our algorithm produces encouraging solutions compared with those produced by MeTiS that is a state-of-the-art partitioner in the literature.

#index 1393147
#* A unifying method for outlier and change detection from data streams based on local polynomial fitting
#@ Zhi Li;Hong Ma;Yongbing Mei
#t 2007
#c 3
#% 397426
#% 863386
#% 864688
#! Online detection of outliers and change points from a data stream are two very exciting topics in the area of data mining. This paper explores the relationship between these two issues, and presents a unifying method for dealing with both of them. Previous approaches often use parametric techniques and try to give exact results. In contrast, we present a nonparametric method based on local polynomial fitting, and give approximate results by fuzzy partition and decision. In order to measure the possibility of being an outlier and a change point, two novel score functions are defined based on the forward and backward prediction errors. The proposed method can detect outliers and changes simultaneously, and can distinguish between them. Comparing to the conventional parametric approaches, our method is more convenient for implementation, and more appropriate for online and interactive data mining. Simulation results confirm the effectiveness of the proposed method.

#index 1393148
#* Simultaneous tuning of hyperparameter and parameter for support vector machines
#@ Shizhong Liao;Lei Jia
#t 2007
#c 3
#% 57198
#% 190581
#% 269218
#% 304818
#% 420077
#% 425040
#% 725786
#% 738970
#% 829031
#% 1377402
#% 1378391
#% 1861020
#! Automatic tuning of hyperparameter and parameter is an essential ingredient and important process for learning and applying Support Vector Machines (SVM). Previous tuning methods choose hyperparameter and parameter separately in different iteration processes, and usually search exhaustively in parameter spaces. In this paper we propose and implement a new tuning algorithm that chooses hyperparameter and parameter for SVM simultaneously and search the parameter space efficiently with a deliberate initialization of a pair of starting points. First we derive an approximate but effective radius margin bound for soft margin SVM. Then we combine multiparameters of SVM into one vector, converting the two separate tuning processes into one optimization problem. Further we discuss the implementation issue about the new tuning algorithm, and that of choosing initial points for iteration. Finally we compare the new tuning algorithm with old gradient based method and cross validation on five benchmark data sets. The experimental results demonstrate that the new tuning algorithm is effective, and usually outperforms those classical tuning algorithms.

#index 1393149
#* Entropy regularization, automatic model selection, and unsupervised image segmentation
#@ Zhiwu Lu;Xiaoqing Lu;Zhiyuan Ye
#t 2007
#c 3
#% 212389
#% 230131
#% 428926
#% 879413
#% 918076
#% 1346978
#% 1689926
#% 1858404
#% 1862522
#! In region-based image retrieval, the key problem of unsupervised image segmentation is to automatically determine the number of regions for each image in a database. Though we can solve this kind of model selection problem with some statistical criteria such as the minimum description length (MDL) through implementing the EM algorithm, the process of evaluating these criteria may incur a large computational cost. From competitive learning perspective, some more efficient approaches such as rival penalized competitive learning (RPCL) have also been developed for unsupervised image segmentation. However, the segmentation results are not satisfactory and the object of interest may be merged with other regions, since the RPCL algorithm is sensitive to the rival learning rate. In order to solve such problems, we then propose an iterative entropy regularized likelihood (ERL) learning algorithm for unsupervised image segmentation based on the finite mixture model, which can make automatic model selection through introducing entropy regularization into maximum likelihood (ML) estimation. Some segmentation experiments on the Corel image database further demonstrate that the iterative ERL learning algorithm outperforms the MDL based EM (MDL-EM) algorithm and the RPCL algorithm, and leads to some promising results.

#index 1393150
#* A timing analysis model for ontology evolutions based on distributed environments
#@ Yinglong Ma;Beihong Jin;Yuancheng Li;Kehe Wu
#t 2007
#c 3
#% 110011
#% 297770
#% 445444
#% 564210
#% 735938
#% 778641
#% 1655410
#! In order to reuse and assess ontologies, it is critical for ontology engineers to represent and manage ontology versioning and evolutions. In this paper, we propose a timing analysis model for ontology evolution management with more expressive time constraints in a distributed environment. In the model, a timing change operation sequence is called a timing evolution behavior that must satisfy all of the time constraints in a distributed environment. Using this timing analysis model, we can detect whether ontology evolutions are timing consistent in the distributed environment. Given a timing change operation sequence, we also can detect whether it is a timing evolution behavior of the distributed environment. All of these detections can be reduced to detecting whether the group of inequations has solutions. This enables us to better manage dynamic versioning and evolutions of distributed ontologies. We also developed a prototype system called TEAM that can perform our timing analysis task of distributed ontology evolutions.

#index 1393151
#* An optimum random forest model for prediction of genetic susceptibility to complex diseases
#@ Weidong Mao;Shannon Kelly
#t 2007
#c 3
#% 867974
#% 905936
#% 1732542
#! High-throughput single nucleotide polymorphism (SNP) genotyping technologies make massive genotype data, with a large number of individuals, publicly available. Accessibility of genetic data makes genome-wide association studies for complex diseases possible. One of the most challenging issues in genome-wide association studies is to search and analyze genetic risk factors resulting from interactions of multiple genes. The integrated risk factor usually have a higher risk rate than single SNPs. This paper explores the possibility of applying random forest to search disease-associated factors for given case/control samples. An optimum random forest based algorithm is proposed for the disease susceptibility prediction problem. The proposed method has been applied to publicly available genotype data on Crohn's disease and autoimmune disorders for predicting susceptibility to these diseases. The achieved accuracy of prediction is higher than those achieved by universal prediction methods such as Support Vector Machine (SVM) and previous known methods.

#index 1393152
#* Feature based techniques for auto-detection of novel email worms
#@ Mohammad M. Masud;Latifur Khan;Bhavani Thuraisingham
#t 2007
#c 3
#% 116149
#% 136350
#% 376266
#% 523873
#% 804739
#% 963799
#% 1650665
#% 1718831
#! This work focuses on applying data mining techniques to detect email worms. We apply a feature-based detection technique. These features are extracted using different statistical and behavioral analysis of emails sent over a certain period of time. The number of features thus extracted is too large. So, our goal is to select the best set of features that can efficiently distinguish between normal and viral emails using classification techniques. First, we apply Principal Component Analysis (PCA) to reduce the high dimensionality of data and to find a projected, optimal set of attributes. We observe that the application of PCA on a benchmark dataset improves the accuracy of detecting novel worms. Second, we apply J48 decision tree algorithm to determine the relative importance of features based on information gain. We are able to identify a subset of features, along with a set of classification rules that have a better performance in detecting novel worms than the original set of features or PCA-reduced features. Finally, we compare our results with published results and discuss our future plans to extend this work.

#index 1393153
#* Multiresolution-based bilinear recurrent neural network
#@ Byung-Jae Min;Dong-Chul Park;Hwan-Soo Choi
#t 2007
#c 3
#% 58636
#% 798344
#% 1760407
#% 1780652
#% 1781638
#% 1860853
#% 1860966
#! A Multiresolution-based BiLinear Recurrent Neural Network (MBLRNN) is proposed in this paper. The proposed M-BLRNN is based on the BLRNN that has been proven to have robust abilities in modeling and predicting time series. The learning process is further improved by using a multiresolution-based learning algorithm for training the BLRNN so as to make it more robust for long-term prediction of the time series. The proposed M-BLRNN is applied to long-term prediction of network traffic. Experiments and results on Ethernet network traffic data show that the proposed M-BLRNN outperforms both the traditional Multi-Layer Perceptron Type Neural Network (MLPNN) and the BLRNN in terms of the normalized mean square error (NMSE).

#index 1393154
#* Query expansion using a collection dependent probabilistic latent semantic thesaurus
#@ Laurence A. F. Park;Kotagiri Ramamohanarao
#t 2007
#c 3
#% 280819
#% 324192
#% 785354
#% 818206
#% 818209
#! Many queries on collections of text documents are too short to produce informative results. Automatic query expansion is a method of adding terms to the query without interaction from the user in order to obtain more refined results. In this investigation, we examine our novel automatic query expansion method using the probabilistic latent semantic thesaurus, which is based on probabilistic latent semantic analysis. We show how to construct the thesaurus by mining text documents for probabilistic term relationships, and we show that by using the latent semantic thesaurus, we can overcome many of the problems associated to latent semantic analysis on large document sets which were previously identified. Experiments using TREC document sets show that our term expansion method out performs the popular probabilistic pseudorelevance feedback method by 7.3%.

#index 1393155
#* Scaling up semi-supervised learning: an efficient and effective LLGC variant
#@ Bernhard Pfahringer;Claire Leschi;Peter Reutemann
#t 2007
#c 3
#% 252011
#% 311027
#% 464615
#% 466263
#% 565545
#% 748550
#% 763708
#% 792603
#% 833913
#% 840965
#% 840967
#% 842682
#% 875954
#% 875957
#% 1669879
#! Domains like text classification can easily supply large amounts of unlabeled data, but labeling itself is expensive. Semisupervised learning tries to exploit this abundance of unlabeled training data to improve classification. Unfortunately most of the theoretically well-founded algorithms that have been described in recent years are cubic or worse in the total number of both labeled and unlabeled training examples. In this paper we apply modifications to the standard LLGC algorithm to improve efficiency to a point where we can handle datasets with hundreds of thousands of training data. The modifications are priming of the unlabeled data, and most importantly, sparsification of the similarity matrix. We report promising results on large text classification problems.

#index 1393156
#* A machine learning approach to detecting instantaneous cognitive states from fMRI data
#@ Rafael Ramirez;Montserrat Puiggros
#t 2007
#c 3
#% 309208
#% 402838
#% 449588
#% 768668
#% 891664
#% 892507
#! The study of human brain functions has dramatically increased in recent years greatly due to the advent of Functional Magnetic Resonance Imaging. In this paper we apply and compare different machine learning techniques to the problem of classifying the instantaneous cognitive state of a person based on her functional Magnetic Resonance Imaging data. In particular, we present successful case studies of induced classifiers which accurately discriminate between cognitive states produced by listening to different auditory stimuli. The problem investigated in this paper provides a very interesting case study of training classifiers with extremely high dimensional, sparse and noisy data. We present and discuss the results obtained in the case studies.

#index 1393157
#* Discovering correlated items in data streams
#@ Xingzhi Sun;Ming Chang;Xue Li;Maria E. Orlowska
#t 2007
#c 3
#% 227919
#% 281144
#% 378388
#% 492912
#% 548479
#% 569754
#% 576119
#% 578560
#% 642409
#% 730046
#% 824665
#% 993960
#% 1700144
#! Recently, the problem of finding frequent items in a data stream has been well studied. However, for some applications, such as HTTP log analysis, there is a need to analyze the correlations amongst frequent items in data streams. In this paper, we investigate the problem of finding correlated items based on the concept of unexpectedness. That is, two items x and y are correlated if both items are frequent and their actual number of co-occurrences in the data stream is significantly different from the expected value, which can be computed by the frequencies of x and y. Based on the Space-Saving algorithm [1], we propose a new one-pass algorithm, namely Stream-Correlation, to discover correlated item pairs. The key part of our algorithm is to efficiently estimate the frequency of co-occurrences of items with small memory space. The possible error can be tightly bounded by controlling the memory space. Experiment results show the effectiveness and the efficiency of the algorithm.

#index 1393158
#* Incremental clustering in geography and optimization spaces
#@ Chih-Hua Tai;Bi-Ru Dai;Ming-Syan Chen
#t 2007
#c 3
#% 232102
#% 248790
#% 316709
#% 431295
#% 443082
#% 465004
#% 480812
#% 481281
#% 502122
#% 570889
#% 722810
#% 794934
#% 800179
#! Spatial clustering has been identified as an important technique in data mining owing to its various applications. In the conventional spatial clustering methods, data points are clustered mainly according to their geographic attributes. In real applications, however, the obtained data points consist of not only geographic attributes but also non-geographic ones. In general, geographic attributes indicate the data locations and non-geographic attributes show the characteristics of data points. It is thus infeasible, by using conventional spatial clustering methods, to partition the geographic space such that similar data points are grouped together. In this paper, we propose an effective and efficient algorithm, named incremental clustering toward the Bound INformation of Geography and Optimization spaces, abbreviated as BINGO, to solve the problem. The proposed BINGO algorithm combines the information in both geographic and non-geographic attributes by constructing a summary structure and possesses incremental clustering capability by appropriately adjusting this structure. Furthermore, most parameters in algorithm BINGO are determined automatically so that it is easy to be applied to applications without resorting to extra knowledge. Experiments on synthetic are performed to validate the effectiveness and the efficiency of algorithm BINGO.

#index 1393159
#* Estimation of class membership probabilities in the document classification
#@ Kazuko Takahashi;Hiroya Takamura;Manabu Okumura
#t 2007
#c 3
#% 22244
#% 269221
#% 311027
#% 342611
#% 458379
#% 464280
#% 466419
#% 577298
#% 840913
#% 869501
#% 939512
#% 1707813
#! We propose a method for estimating class membership probabilities of a predicted class, using classification scores not only for the predicted class but also for other classes in a document classification. Class membership probabilities are important in many applications in document classification, in which multiclass classification is often applied. In the proposed method, we first make an accuracy table by counting the number of correctly classified training samples in each range or cell of classification scores. We then apply smoothing methods such as a moving average method with coverage to the accuracy table. In order to determine the class membership probability of an unknown sample, we first calculate the classification scores of the sample, then find the range or cell that corresponds to the scores and output the values associated in the range or cell in the accuracy table. Through experiments on two different datasets with both Support Vector Machines and Naive Bayes classifiers, we empirically show that the use of multiple classification scores is effective in the estimation of class membership probabilities, and that the proposed smoothing methods for the accuracy table work quite well. We also show that the estimated class membership probabilities by the proposed method are useful in the detection of the misclassified samples.

#index 1393160
#* A hybrid multi-group privacy-preserving approach for building decision trees
#@ Zhouxuan Teng;Wenliang Du
#t 2007
#c 3
#% 300184
#% 333876
#% 577233
#% 577289
#% 635215
#% 729962
#% 823358
#! In this paper, we study the privacy-preserving decision tree building problem on vertically partitioned data. We made two contributions. First, we propose a novel hybrid approach, which takes advantage of the strength of the two existing approaches, randomization and the secure multi-party computation (SMC), to balance the accuracy and efficiency constraints. Compared to these two existing approaches, our proposed approach can achieve much better accuracy than randomization approach and much reduced computation cost than SMC approach. We also propose a multi-group scheme that makes it flexible for data miners to control the balance between data mining accuracy and privacy. We partition attributes into groups, and develop a scheme to conduct group-based randomization to achieve better data mining accuracy. We have implemented and evaluated the proposed schemes for the ID3 decision tree algorithm.

#index 1393161
#* A constrained clustering approach to duplicate detection among relational data
#@ Chao Wang;Jie Lu;Guangquan Zhang
#t 2007
#c 3
#% 46803
#% 152934
#% 190581
#% 310516
#% 464434
#% 577247
#% 577263
#% 729913
#% 838435
#% 1289646
#! This paper proposes an approach to detect duplicates among relational data. Traditional methods for record linkage or duplicate detection work on a set of records which have no explicit relations with each other. These records can be formatted into a single database table for processing. However, there are situations that records from different sources can not be flattened into one table and records within one source have certain (semantic) relations between them. The duplicate detection issue of these relational data records/instances can be dealt with by formatting them into several tables and applying traditional methods to each table. However, as the relations among the original data records are ignored, this approach generates poor or inconsistent results. This paper analyzes the characteristics of relational data and proposes a particular clustering approach to perform duplicate detection. This approach incorporates constraint rules derived from the characteristics of relational data and therefore yields better and more consistent results, which are revealed by our experiments.

#index 1393162
#* Understanding research field evolving and trend with dynamic Bayesian networks
#@ Jinlong Wang;Congfu Xu;Gang Li;Zhenwen Dai;Guojing Luo
#t 2007
#c 3
#% 197387
#% 277480
#% 310515
#% 600539
#% 722904
#% 769906
#% 875959
#% 881460
#% 881498
#% 919561
#% 1650580
#! In this paper, we proposes a method to understand how research fields evolve through the statistical analysis of research publications and the number of new authors in a particular field. Using a Dynamic Bayesian Network, together with the proposed transitive closure property, a more accurate model can be constructed to better represent the temporal features of how a research field evolves. Experiments on the KDD related conferences indicate that the proposed method can discover interesting models effectively and help researchers to get a better insight looking at unfamiliar research areas.

#index 1393163
#* Embedding new data points for manifold learning via coordinate propagation
#@ Shiming Xiang;Feiping Nie;Yangqiu Song;Changshui Zhang;Chunxia Zhang
#t 2007
#c 3
#% 593047
#% 770767
#% 790049
#% 836681
#% 840933
#% 848112
#% 876078
#% 1378394
#% 1665204
#! In recent years, a series of manifold learning algorithms have been proposed for nonlinear dimensionality reduction (NLDR). Most of them can run in a batch mode for a set of given data points, but lack a mechanism to deal with new data points. Here we propose an extension approach, i.e., embedding new data points into the previously-learned manifold. The core idea of our approach is to propagate the known co-ordinates to each of the new data points. We first formulate this task as a quadratic programming, and then develop an iterative algorithm for coordinate propagation. Smoothing splines are used to yield an initial coordinate for each new data point, according to their local geometrical relations. Experimental results illustrate the validity of our approach.

#index 1393164
#* Spectral clustering based null space linear discriminant analysis (SNLDA)
#@ Wenxin Yang;Junping Zhang
#t 2007
#c 3
#% 315986
#% 724227
#% 885519
#! While null space based linear discriminant analysis (NLDA) obtains a good discriminant performance, the ability easily suffers from an implicit assumption of Gaussian model with same covariance each class. Meanwhile, mixture model discriminant analysis, which is a good way for processing issues on multiple subclasses in each class, depends on human experience on the number of subclasses and has a highly complex iterative process. Considering the cons and pros of the two mentioned approaches, we therefore propose a new algorithm, called Spectral clustering based Null space Linear Discriminant Analysis (SNLDA). The main contributions of the algorithm include the following three aspects: 1) Employing a new spectral clustering method which can automatically detect the number of clusters in each class. 2) Finding a unified null space for processing multi-subclasses issues with eigen-solution technique. 3) Refining the calculation of the covariance matrix in a single sample subclass. The experimental results show the promising of the proposed SNLDA algorithm.

#index 1393165
#* On a new class of framelet kernels for support vector regression and regularization networks
#@ Wei-Feng Zhang;Dao-Qing Dai;Hong Yan
#t 2007
#c 3
#% 185955
#% 190581
#% 197394
#% 264923
#% 425040
#% 743284
#% 818166
#% 855576
#% 1781293
#% 1860761
#! Kernel-based machine learning techniques, such as support vector machines, regularization networks, have been widely used in pattern analysis. Kernel function plays an important role in the design of such learning machines. The choice of an appropriate kernel is critical in order to obtain good performance. This paper presents a new class of kernel functions derived from framelet. Framelet is a wavelet frame constructed via multiresolution analysis, and has both the merit of frame and wavelet. The usefulness of the new kernels is demonstrated through simulation experiments.

#index 1393166
#* A clustering algorithm based on mechanics
#@ Xianchao Zhang;He Jiang;Xinyue Liu;Hong Yu
#t 2007
#c 3
#% 210173
#% 248790
#% 248792
#% 273890
#% 375388
#% 438137
#% 451052
#% 462243
#% 479799
#% 481281
#% 566128
#! Existing clustering algorithms use distance, density or concept as clustering criterion. These criterions can not exactly reflect relationships among multiple objects, so that the clustering qualities are not satisfying. In this paper, a mechanics based clustering algorithm is proposed. The algorithm regards data objects as particles with masses and uses gravitation to depict relationships among data objects. Clustering is executed according to displacements of data objects caused by gravitation, and the result is optimized subjecting to Minimum Potential Energy Principle. The superiority of the algorithm is that the relationships among multiple objects are exactly reflected by gravitation, and the multiple relationships can be converted to the single ones due to force composition, so that the computation can be executed efficiently. Experiments indicate that qualities of the clustering results deduced by this algorithm are better than those of classic algorithms such as CURE and K-Means.

#index 1393167
#* DLDA/QR: a robust direct LDA algorithm for face recognition and its theoretical foundation
#@ Yu-Jie Zheng;Zhi-Bo Guo;Jian Yang;Xiao-Jun Wu;Jing-Yu Yang
#t 2007
#c 3
#% 80995
#% 91896
#% 124466
#% 124470
#% 212689
#% 224113
#% 235342
#% 729344
#% 789030
#% 803769
#% 900128
#! Feature extraction is one of the hot topics in face recognition. However, many face extraction methods will suffer from the "small sample size" problem, such as Linear Discriminant Analysis (LDA). Direct Linear Discriminant Analysis (DLDA) is an effective method to address this problem. But conventional DLDA algorithm is often computationally expensive and not scalable. In this paper, DLDA is analyzed from a new viewpoint via QR decomposition and an efficient and robust method named DLDA/QR algorithm is proposed. The proposed algorithm achieves high efficiency by introducing the QR decomposition on a small-size matrix, while keeping competitive classification accuracy. Experimental results on ORL face database demonstrate the effectiveness of the proposed method.

#index 1393168
#* gPrune: a constraint pushing framework for graph pattern mining
#@ Feida Zhu;Xifeng Yan;Jiawei Han;Philip S. Yu
#t 2007
#c 3
#% 248785
#% 300120
#% 310494
#% 466644
#% 481290
#% 580588
#% 629603
#% 629623
#% 629646
#% 629708
#% 674497
#% 727845
#% 727896
#% 729938
#% 765429
#% 766666
#% 769889
#% 769940
#% 769951
#% 813034
#% 813990
#% 823357
#% 1656291
#% 1707794
#! In graph mining applications, there has been an increasingly strong urge for imposing user-specified constraints on the mining results. However, unlike most traditional itemset constraints, structural constraints, such as density and diameter of a graph, are very hard to be pushed deep into the mining process. In this paper, we give the first comprehensive study on the pruning properties of both traditional and structural constraints aiming to reduce not only the pattern search space but the data search space as well. A new general framework, called gPrune, is proposed to incorporate all the constraints in such a way that they recursively reinforce each other through the entire mining process. A new concept, Pattern-inseparable Data-antimonotonicity, is proposed to handle the structural constraints unique in the context of graph, which, combined with known pruning properties, provides a comprehensive and unified classification framework for structural constraints. The exploration of these antimonotonicities in the context of graph pattern mining is a significant extension to the known classification of constraints, and deepens our understanding of the pruning properties of structural graph constraints.

#index 1393169
#* Modeling anticipatory event transitions
#@ Ridzwan Aminuddin;Ridzwan Suri;Kuiyu Chang;Zaki Zainudin;Qi He;Ee-Peng Lim
#t 2007
#c 3
#% 577220
#% 1728326
#! Anticipatory Event Detection (AED) attempts to monitor user anticipated events, called Anticipatory Events (AE) that have yet to occur. Central to AED is the Event Transition Graph (ETG), which defines the pre and post states of a user specified AE. A classification model can be trained on documents in the pre and post states to learn to detect an AE. However, this simplistic classification model does not make use of discriminatory keywords between the two states. We propose a simple but effective feature selection method to identify important bursty features that highly discriminate between the pre and post states of an AE. Bursty features are first computed using Kleinberg's Algorithm, then various combination of features in both states are selected. Experimental results show that bursty features can significantly improve the accuracy of AED.

#index 1393170
#* A modified relationship based clustering framework for density based clustering and outlier filtering on high dimensional datasets
#@ Turgay Tugay Bilgin;A. Yilmaz Camurcu
#t 2007
#c 3
#% 258595
#% 274612
#% 443086
#% 739636
#! In this study, we propose a modified version of relationship based clustering framework dealing with density based clustering and outlier detection in high dimensional datasets. Originally, relationship based clustering framework is based on METIS. Therefore, it has some drawbacks such as no outlier detection and difficulty of determining the number of clusters. We propose two improvements over the framework. First, we introduce a new space which consists of tiny partitions created by METIS, hence we call it micro-partition space. Second, we used DBSCAN for clustering micro-partition space. The visualization of the results are carried out by CLUSION. Our experiments have shown that, our proposed framework produces promising results on high dimensional datasets.

#index 1393171
#* A region-based skin color detection algorithm
#@ Faliang Chang;Zhiqiang Ma;Wei Tian
#t 2007
#c 3
#% 104472
#% 323304
#% 429731
#% 561884
#% 593603
#% 922066
#% 1788944
#! In this paper, a new region-based algorithm for detecting skin color in static images is described. We choose the single Gaussian skin color model in the normalized r-g space after analyzing the distributions of skin color in six different 2-D chrominance spaces. Images are first segmented into patches using a improved fuzzy C-means algorithm, in which the local characteristic is adopted to constrain fuzzy functions, and a simple method for initializing clustering centriods is adopted. Then, the percentage of skin color pixels in each patch can be obtained. According to corresponding percentages, patches are classified as skin color regions or not.

#index 1393172
#* Supportive utility of irrelevant features in data preprocessing
#@ Sam Chao;Yiping Li;Mingchui Dong
#t 2007
#c 3
#% 126894
#% 136350
#% 156186
#% 227486
#% 385564
#% 449588
#% 629619
#% 722929
#% 722933
#% 1272280
#! Many classification algorithms degrade their learning performance while irrelevant features are introduced. Feature selection is a process to choose an optimal subset of features and removes irrelevant ones. But many feature selection algorithms focus on filtering out the irrelevant attributes regarding the learned task only, not considering their hidden supportive information to other attributes: whether they are really irrelevant or potentially relevant? Since in medical domain, an irrelevant symptom is treated as the one providing neither explicit information nor supportive information for disease diagnosis. Therefore, the traditional feature selection methods may be unsuitable for handling such critical problem. In this paper, we propose a new method that selecting not only the relevant features, but also targeting at the latent useful irrelevant attributes by measuring their supportive importance to other attributes. The empirical results demonstrate a comparison of performance of various classification algorithms on twelve real-life datasets from UCI repository.

#index 1393173
#* Incremental mining of sequential patterns using prefix tree
#@ Yue Chen;Jiankui Guo;Yaqin Wang;Yun Xiong;Yangyong Zhu
#t 2007
#c 3
#% 287242
#% 329537
#% 338609
#% 459006
#% 464996
#% 479971
#% 487856
#% 502121
#% 646296
#% 769931
#% 778732
#% 1707831
#! This paper fist demonstrates that current PrefixSpan-based incremental mining algorithm IncSpan+ which is proposed in PAKDD05 cannot completely mine all sequential patterns. Then a new incremental mining algorithm of sequential patterns using prefix tree is proposed. This algorithm constructs a prefix tree to represent the sequential patterns, and then continuously scans the incremental element set to maintain the tree structure, using width pruning and depth pruning to eliminate the search space. The experiment shows this algorithm has a good performance.

#index 1393174
#* A multiple kernel support vector machine scheme for simultaneous feature selection and rule-based classification
#@ Zhenyu Chen;Jianping Li
#t 2007
#c 3
#% 425040
#% 443288
#% 823327
#% 829031
#% 1781296
#! In many applications such as bioinformatics and medical decision-making, the interpretability is important to make the model acceptable to the user and help the expert discover the novel and perhaps valuable knowledge hidden behind the data. This paper presents a novel feature selection and rule extraction method which is based on multiple kernel support vector machine (MK-SVM). This method has two outstanding properties. Firstly, the multiple kernels are described as the convex combination of the single feature basic kernels. It makes the feature selection problem in the context of SVM transformed into an ordinary multiple parameters learning problem. A 1-norm based linear programming is proposed to carry out the optimization of those parameters. Secondly, the rules are obtained in an easy way: only the support vectors necessary. It is demonstrated in theory that every support vector obtained by this method is just the vertex of the hypercube. Then a tree-like algorithm is proposed to extract the if-then rules. Three UCI datasets are used to demonstrate the effectiveness and efficiency of this approach.

#index 1393175
#* Combining supervised and semi-supervised classifier for personalized spam filtering
#@ Victor Cheng;Chun-Hung Li
#t 2007
#c 3
#% 383583
#% 842682
#% 1378224
#% 1860547
#! This paper addresses the problem of spam filtering for individual email user under the condition that only public domain labeled emails given as the training data and all emails from the user's email inbox are unlabeled. Owing to the difference of wordings and distribution of emails, conventional supervised classifier such as SVM cannot produce accurate result because it assumes the training and the testing data come from the same source and have the same distribution. We model these discrepancies as variation of decision hyperplane and come up with a criterion for selecting reliable emails with classified labels which are likely to be agreed by the user. A semi-supervised classifier then uses these emails as the training set and propagates the label information to other unlabeled emails by exploiting the distribution of them in feature space. Experimental result shows that this combined classifier strategy can classify emails for individual user with high accuracy.

#index 1393176
#* Qualitative simulation and reasoning with feature reduction based on boundary conditional entropy of knowledge
#@ Yusheng Cheng;Yousheng Zhang;Xuegang Hu;Xiaoyao Jiang
#t 2007
#c 3
#% 366687
#% 1041778
#! The present paper discusses a new definition of knowledge rough entropy based on boundary region from the aspect of Pawlak topology. This definition accurately reflects an idea that the uncertainty of set can be described by boundary region. It thus proves an important conclusion that boundary conditional entropy of knowledge monotonously reduces with the diminishing of information granularity. Combining qualitative reasoning technology with knowledge information entropy based on rough sets theory, a heuristic algorithm for feature reduction is proposed which can be used to eliminate the redundancy in the qualitative description and the qualitative differential equations are obtained. The result shows that the rough sets theory (RST) is of good reliability and prospect in qualitative reasoning and simulation.

#index 1393177
#* A hybrid incremental clustering method-combining support vector machine and enhanced clustering by committee clustering algorithm
#@ Deng-Yiv Chiu;Kong-Ling Hsieh
#t 2007
#c 3
#% 190581
#% 397148
#% 438137
#% 511813
#% 766438
#% 786671
#! In the study, a new hybrid incremental clustering method is proposed in combination with Support Vector Machine (SVM) and enhanced Clustering by Committee (CBC) algorithm. SVM classifies the incoming document to see if it belongs to the existing classes. Then the enhanced CBC algorithm is used to cluster the unclassified documents. SVM can significantly reduce the amount of calculation and the noise of clustering. The enhanced CBC algorithm can effectively control the number of clusters, improve performance and allow the number of classes to grow gradually based on the structure of current classes without clustering all of documents again. In empirical results, the proposed method outperforms the enhanced CBC clustering method and other algorithms. Also, the enhanced CBC clustering method outperforms original CBC.

#index 1393178
#* CCRM: an effective algorithm for mining commodity information from threaded Chinese customer reviews
#@ Huizhong Duan;Shenghua Bao;Yong Yu
#t 2007
#c 3
#% 400763
#% 577246
#% 577355
#% 641979
#% 766433
#% 769892
#% 791663
#% 805873
#% 1272396
#% 1705501
#% 1708349
#! This paper is concerned with the problem of mining commodity information from threaded Chinese customer reviews. Chinese online commodity forums, which are developing rapidly, provide a good environment for customers to share reviews. However, due to noises and navigational limitations, it is hard to have a clear view of a commodity from thousands of related reviews. Further more, due to different characters between Chinese and English, Researching approaches may vary a lot. This paper aims to automatically mine out key information from commodity reviews. An effective algorithm, i.e. Chinese Commodity Review Miner (CCRM) is proposed. The algorithm can be divided into two parts. First, we propose an efficient rule based algorithm for commodity feature extraction as well as a probabilistic model for feature ranking. Second, we propose a top-to-down algorithm to reorganize the extracted features into hierarchical structure. A prototype system based on CCRM is also implemented. Using CCRM, users can easily acquire the outline of a commodity, and navigate freely in it.

#index 1393179
#* A rough set approach to classifying web page without negative examples
#@ Qiguo Duan;Duoqian Miao;Kaimin Jin
#t 2007
#c 3
#% 217733
#% 275062
#% 366687
#% 464641
#% 722811
#% 729621
#% 799785
#! This paper studies the problem of building Web page classifiers using positive and unlabeled examples, and proposes a more principled technique to solving the problem based on tolerance rough set and Support Vector Machine (SVM). It uses tolerance classes to approximate concepts existed in Web pages and enrich the representation of Web pages, draws an initial approximation of negative example. It then iteratively runs SVM to build classifier which maximizes margins to progressively improve the approximation of negative example. Thus, the class boundary eventually converges to the true boundary of the positive class in the feature space. Experimental results show that the novel method outperforms existing methods significantly.

#index 1393180
#* Evolution and maintenance of frequent pattern space when transactions are removed
#@ Mengling Feng;Guozhu Dong;Jinyan Li;Yap-Peng Tan;Limsoon Wong
#t 2007
#c 3
#% 152934
#% 248791
#% 282005
#% 300120
#% 464204
#% 511333
#% 807681
#% 809268
#% 841959
#% 1390171
#% 1698978
#! This paper addresses the maintenance of discovered frequent patterns when a batch of transactions are removed from the original dataset. We conduct an in-depth investigation on how the frequent pattern space evolves under transaction removal updates using the concept of equivalence classes. Inspired by the evolution analysis, an effective and exact algorithm TRUM is proposed to maintain frequent patterns. Experimental results demonstrate that our algorithm outperforms representative state-of-the-art algorithms.

#index 1393181
#* Establishing semantic relationship in inter-query learning for content-based image retrieval systems
#@ Chun Che Fung;Kien-Ping Chung
#t 2007
#c 3
#% 219845
#% 318688
#% 334739
#% 1781579
#! Use of relevance feedback (RF) in the feature vector model has been one of the most popular approaches for fine tuning query for content-based image retrieval (CBIR) systems. This paper proposes a framework that extends the RF approach to capture the inter-query relationship between current and previous queries. By using the feature vector model, this approach avoids the need of "memorizing" actual retrieval relationship between the actual image indexes and the previous queries. This implies that the approach is more suitable for image database application where images are frequently added or removed. This paper has extended the authors' previous work [1] by applying a semantic structure to connect the previous queries both visually and semantically. In addition, active learning strategy has been used in this paper to explore images that may be semantically similar while visually different.

#index 1393182
#* Density-sensitive evolutionary clustering
#@ Maoguo Gong;Licheng Jiao;Ling Wang;Liefeng Bo
#t 2007
#c 3
#% 336076
#% 369236
#% 465882
#% 565545
#% 837615
#% 1670493
#% 1777086
#% 1777426
#! In this study, we propose a novel evolutionary algorithm-based clustering method, named density-sensitive evolutionary clustering (DSEC). In DSEC, each individual is a sequence of real integer numbers representing the cluster representatives, and each data item is assigned to a cluster representative according to a novel density-sensitive dissimilarity measure which can measure the geodesic distance along the manifold. DSEC searches the optimal cluster representatives from a combinatorial optimization viewpoint using evolutionary algorithm. The experimental results on seven artificial data sets with different manifold structure show that the novel density-sensitive evolutionary clustering algorithm has the ability to identify complex non-convex clusters compared with the K-Means algorithm, a genetic algorithm-based clustering, and a modified K-Means algorithm with the density-sensitive distance metric.

#index 1393183
#* Reducing overfitting in predicting intrinsically unstructured proteins
#@ Pengfei Han;Xiuzhen Zhang;Raymond S. Norton;Zhiping Feng
#t 2007
#c 3
#% 136350
#% 376266
#% 400847
#% 833732
#% 840845
#! Intrinsically unstructured or disordered proteins are proteins that lack fixed 3-D structure globally or contain long disordered regions. Predicting disordered regions has attracted significant research recently. In developing a decision tree based disordered region predictor, we note that many previous predictors applying 20 amino acid compositions as training parameter tend to overfit the data. In this paper we propose to alleviate overfitting in prediction of intrinsically unstructured proteins by reducing input parameters. We also compare this approach with the random forest model, which is inherently tolerant to overfitting. Our experiments suggest that reducing 20 amino acid compositions into 4 groups according to amino acid property can reduce the overfitting in decision tree model. Alternatively, ensemble-learning techniques like random forest is inherently more tolerant to this kind of overfitting and can be a promising candidate in disordered region prediction.

#index 1393184
#* Temporal relations extraction in mining hepatitis data
#@ Tu Bao Ho;Canh Hao Nguyen;Saori Kawasaki;Katsuhiko Takabayashi
#t 2007
#c 3
#% 319244
#% 729946
#% 1843690
#! Various data mining methods have been developed last few years for hepatitis study using a large temporal and relational database given to the research community. In this work we introduce a novel temporal abstraction method to this study by detecting and exploiting temporal patterns and relations between events in viral hepatitis such as "event A slightly happened before event B and B simultaneously ended with event C". We developed algorithms to first detect significant temporal patterns in temporal sequences and then to identify temporal relations between these temporal patterns. Many findings by data mining methods show to be significant by physician evaluation and match with reported results in Medline.

#index 1393185
#* Supervised learning approach to optimize ranking function for Chinese FAQ-finder
#@ Guoping Hu;Dan Liu;Qingfeng Liu;Ren-Hua Wang
#t 2007
#c 3
#% 838397
#% 838398
#% 1682061
#! In this paper, we address the optimization problem for huge Question-Answer (QA) pairs collection based Chinese FAQ-Finder system. Unlike most published researches which leaned to address word mismatching problem among questions, we focus on more fundamental problem: ranking function, which was always arbitrarily borrowed from traditional document retrieval directly. One unified ranking function with four embedded parameters is proposed and the characteristics of three different fields of QA pair and effects of two different Chinese word segmentation settings are investigated. Experiments on 1,000 question queries and 3.8 million QA pairs show that the unified ranking function can achieve 6.67% promotion beyond TFIDF baseline. One supervised learning approach is also proposed to optimize ranking function by employing 264 features, including part-of-speech, and bigram co-occurrence etc. Experiments show that 7.06% further improvement can be achieved.

#index 1393186
#* Combining convolution kernels defined on heterogeneous sub-structures
#@ Minlie Huang;Xiaoyan Zhu
#t 2007
#c 3
#% 458379
#% 464267
#% 722803
#% 722926
#% 815896
#% 939383
#% 939944
#% 995512
#% 1290081
#! Convolution kernels, constructed by convolution of sub-kernels defined on sub-structures of composite objects, are widely used in classification, where one important issue is to choose adequate sub-structures, particularly for objects such as trees, graphs, and sequences. In this paper, we study the problem of sub-structure selection for constructing convolution kernels by combining heterogeneous kernels defined on different levels of substructures. Sub-kernels defined on different levels of sub-structures are combined together to incorporate their individual strengths because each level of sub-structure reflects its own angle to view the object. Two types of combination, linear and polynomial combination, are investigated. We analyze from the perspective of feature space why combined kernels exhibit potential advantages. Experiments indicate that the method will be helpful for combining kernels defined on arbitrary levels of sub-structures.

#index 1393187
#* Privacy-preserving sequential pattern release
#@ Huidong Jin;Jie Chen;Hongxing He;Christine M. O'Keefe
#t 2007
#c 3
#% 576761
#% 577256
#% 769943
#% 788963
#% 844353
#% 881546
#% 1669970
#! We investigate situations where releasing frequent sequential patterns can compromise individual's privacy. We propose two concrete objectives for privacy protection: k-anonymity and α-dissociation. The first addresses the problem of inferring patterns with very low support, say, in [1, k]. These inferred patterns can become quasi-identifiers in linking attacks. We show that, for all but one definition of support, it is impossible to reliably infer support values for patterns with two or more negative items (items which do not occur in a pattern) solely based on frequent sequential patterns. For the remaining definition, we formulate privacy inference channels. α-dissociation handles the problem of high certainty of inferring sensitive attribute values. In order to remove privacy threats w.r.t. the two objectives, we show that we only need to examine pairs of sequential patterns with length difference of 1. We then establish a Privacy Inference Channels Sanitisation (PICS) algorithm. It can, as illustrated by experiments, reduce the privacy disclosure risk carried by frequent sequential patterns with a small computation overhead.

#index 1393188
#* Mining concept associations for knowledge discovery through concept chain queries
#@ Wei Jin;Rohini K. Srihari;Xin Wu
#t 2007
#c 3
#% 109215
#% 249110
#% 752367
#% 769887
#% 838471
#% 957808
#% 972299
#! The availability of large volumes of text documents has created the potential of a vast amount of valuable information buried in those texts. This in turn has created the need for automated methods of discovering relevant information without having to read it all. This paper focuses on detecting links between two concepts across text documents. We interpret such a query as finding the most meaningful evidence trail across documents that connect these two concepts. In this paper we propose to use link-analysis techniques over the extracted features provided by Information Extraction Engine for finding new knowledge. We compare two approaches to perform this task. One is the concept-profile approach based on traditional bag-of-words model, and the other is the graph-based approach which combines text mining, graph mining and link analysis techniques. Counterterrorism corpus is used to evaluate the performance of each model and demonstrates that the graph-based approach is preferable for finding focused information. For greater coverage of information we should use the concept-profile based approach.

#index 1393189
#* Capability enhancement of probabilistic neural network for the design of breakwater armor blocks
#@ Doo Kie Kim;Dong Hyawn Kim;Seong Kyu Chang;Sang Kil Chang
#t 2007
#c 3
#% 72542
#! In this study, the capability of probabilistic neural network (PNN) is enhanced. The proposed PNN is capable of reflecting the global probability density function (PDF) by summing the heterogeneous local PDF automatically determined in the individual standard deviation of variables. The present PNN is applied to predict the stability number of armor blocks of breakwaters using the experimental data of van der Meer, and the estimated results of PNN are compared with those of empirical formula and previous artificial neural network (ANN) model. The PNN showed better results in predicting the stability number of armor blocks of breakwaters and provided the promising probabilistic viewpoints by using the individual standard deviation in a variable.

#index 1393190
#* Named entity recognition using acyclic weighted digraphs: a semi-supervised statistical method
#@ Kono Kim;Yeohoon Yoon;Harksoo Kim;Jungyun Seo
#t 2007
#c 3
#% 742424
#% 769884
#! We propose a NE (Named Entity) recognition system using a semisupervised statistical method. In training time, the NE recognition system builds error-prone training data only using a conventional POS (Part-Of-Speech) tagger and a NE dictionary that semi-automatically is constructed. Then, the NE recognition system generates a co-occurrence similarity matrix from the error-prone training corpus. In running time, the NE recognition system constructs AWDs (Acyclic Weighted Digraphs) based on the co-occurrence similarity matrix. Then, the NE recognition system detects NE candidates and assigns categories to the NE candidates using Viterbi searching on the AWDs. In the preliminary experiments on PLO (Person, Location and Organization) recognition, the proposed system showed 81.32% on average F1-measure.

#index 1393191
#* Contrast set mining through subgroup discovery applied to brain ischaemina data
#@ Petra Kralj;Nada Lavrač;Dragan Gamberger;Antonija Krstačic
#t 2007
#c 3
#% 232136
#% 248791
#% 420126
#% 449566
#% 464617
#% 477497
#% 729935
#% 763701
#% 850431
#% 1272357
#% 1289454
#! Contrast set mining aims at finding differences between different groups. This paper shows that a contrast set mining task can be transformed to a subgroup discovery task whose goal is to find descriptions of groups of individuals with unusual distributional characteristics with respect to the given property of interest. The proposed approach to contrast set mining through subgroup discovery was successfully applied to the analysis of records of patients with brain stroke (confirmed by a positive CT test), in contrast with patients with other neurological symptoms and disorders (having normal CT test results). Detection of coexisting risk factors, as well as description of characteristic patient subpopulations are important outcomes of the analysis.

#index 1393192
#* Intelligent sequential mining via alignment: optimization techniques for very large DB
#@ Hye-Chung Kum;Joong Hyuk Chang;Wei Wang
#t 2007
#c 3
#% 463903
#% 727913
#% 785342
#% 866328
#% 938977
#! The shear volume of the results in traditional support based frequent sequential pattern mining methods has led to increasing interest in new intelligent mining methods to find more meaningful and compact results. One such approach is the consensus sequential pattern mining method based on sequence alignment, which has been successfully applied to various areas. However, the current approach to consensus sequential pattern mining has quadratic run time with respect to the database size limiting its application to very large databases. In this paper, we introduce two optimization techniques to reduce the running time significantly. First, we determine the theoretical bound for precision of the proximity matrix and reduce the time spent on calculating the full matrix. Second, we use a sample based iterative clustering method which allows us to use a much faster k-means clustering method with only a minor increase in memory consumption with negligible loss in accuracy.

#index 1393193
#* A hybrid prediction method combining RBF neural network and FAR model
#@ Yongle Lü;Rongling Lang
#t 2007
#c 3
#% 394984
#% 1860743
#! The classical autoregressive moving average model (ARMA) fails to satisfy the high request for precision in predicting nonlinear and nonstationary systems. Overcoming the difficulty, a hybrid prediction method is proposed in this paper, which organically couples the radial basis function prediction neural network (RBFPNN) and the functional-coefficient autoregressive prediction model (FARPM). An observation time series characterized by nonlinearity and nonstationarity can be technically decomposed with the wavelet analysis tool into two clusters of sequences, i.e. the smooth sequences and the stationary sequences, which can be effectively predicted with RBFPNN and FARPM respectively. Then, the integrated prediction is obtained by merging the results of RBFPNN and FARPM. It's indicated by the simulation that the prediction precision for one step, 4 steps and 12 steps can be improved at least by 41%, 60% and 60% respectively, compared to the prediction with ARMA, RBFPNN and FARPM separately.

#index 1393194
#* An advanced fuzzy C-mean algorithm for regional clustering of interconnected systems
#@ Sang-Hyuk Lee;Jin-Ho Kim;Se-Hwan Jang;Jong-Bae Park;Young-Hwan Jeon;Sung-Yong Sohn
#t 2007
#c 3
#% 136566
#% 223517
#% 284189
#% 1490675
#% 1490778
#! An advanced fuzzy C-mean(FCM) algorithm for the efficient regional clustering of multi-nodes interconnected systems is presented in this paper. Owing to physical characteristics of the interconnected systems, nodes or points in the interconnected systems have their own information indicating the network-related characteristics of the system. However, classification for the whole system into distinct several subsystems based on a similarity measure is typically needed for the efficient operation of the whole system. In this paper, therefore, a new regional clustering algorithm for interconnected systems based on the modified FCM is proposed. Moreover, the regional information on the system are taken into account in order to properly address the geometric misclustering problem such as grouping geometrically distant nodes with similar measures into a common cluster. We have presented that the proposed algorithm has produced proper classification for the interconnected system and the results are demonstrated in the example of IEEE 39-bus interconnected electricity system.

#index 1393195
#* Centroid neural network with Bhattacharyya kernel for GPDF data clustering
#@ Song-Jae Lee;Dong-Chul Park
#t 2007
#c 3
#% 309208
#% 344588
#% 375388
#% 1860645
#% 1860761
#% 1860974
#% 1861034
#! A clustering algorithm for GPDF data called Centroid Neural Network with Bhattacharyya Kernel (BK-CNN) is proposed in this paper. The proposed BK-CNN is based on the unsupervised competitive centroid neural network (CNN) and employs a kernel method for data projection. In order to cluster the GPDF data, the Bhattacharyya kernel is used to measure the distance between two probability distributions for data projection. When applied to GPDF data in an image classification model, the experiment results show that the proposed BKCNN algorithm is more efficient than other conventional algorithms such as k-means algorithm, SOM and CNN with Bhattacharyya distance.

#index 1393196
#* Concept interconnection based on many-valued context analysis
#@ Yuxia Lei;Yan Wang;Baoxiang Cao;Jiguo Yu
#t 2007
#c 3
#% 384416
#% 1699508
#! This paper proposes an interconnection approach, which is based on extended many-valued context and extended formal descriptions. An extended many-valued context Π=(G, M, Q, W, I) consists of sets G, M, Q and W and a quaternary-relation I ⊆G×M×Q×W. An extended formal description is regarded as a mapping from the set of attributes to the power set of the values, assigning to each attribute the set of allowed values under some conditions. The extended formal descriptions are naturally ordered by preciseness, and then a concept lattice is obtained according to the theory of FCA. This concept lattice is the well structure interconnection among concepts. The paper also proposed some important propositions, which are used to decide whether two concepts have semantic interconnections. In the end, the paper describes an interconnection algorithm with the time complexity O(n2).

#index 1393197
#* Text classification for Thai medicinal web pages
#@ Verayuth Lertnattee;Thanaruk Theeramunkong
#t 2007
#c 3
#% 46803
#% 190581
#% 420528
#% 458379
#% 736954
#! Automatic text classification of web texts in Asian languages is a challenging task. For text classification of Thai web pages, it is necessary to cope with a problem called word segmentation since the language has no explicit word boundary delimiter. While a set of terms for any texts can be constructed with a suitable word segmentation algorithm, Thai medicinal texts usually has some special properties, such as plentiful of unique English terms, transliterates, compound terms and typo errors, due to their technical aspect. This paper presents an evaluation of classifying Thai medicinal web documents under three factors; classification algorithm, word segmentation algorithm and term modeling. The experimental results are analyzed and compared by means of standard statistical methods. As a conclusion, all factors significantly affect classification performance especially classification algorithm. The TFIDF with term distributions, as well as SVM, achieves high performance on non-segmented and segmented Thai medicinal web collection as they efficiently utilize technical terms.

#index 1393198
#* A fast algorithm for finding correlation clusters in noise data
#@ Jiuyong Li;Xiaodi Huang;Clinton Selke;Jianming Yong
#t 2007
#c 3
#% 248792
#% 273891
#% 300131
#% 765439
#% 778729
#% 796202
#% 810047
#! Noise significantly affects cluster quality. Conventional clustering methods hardly detect clusters in a data set containing a large amount of noise. Projected clustering sheds light on identifying correlation clusters in such a data set. In order to exclude noise points which are usually scattered in a subspace, data points are projected to form dense areas in the subspace that are regarded as correlation clusters. However, we found that the existing methods for the projected clustering did not work very well with noise data, since they employ randomly generated seeds (micro clusters) to trade-off the clustering quality. In this paper, we propose a divisive method for the projected clustering that does not rely on random seeds. The proposed algorithm is capable of producing higher quality correlation clusters from noise data in a more efficient way than an agglomeration projected algorithm. We experimentally show that our algorithm captures correlation clusters in noise data better than a well-known projected clustering method.

#index 1393199
#* Application of discrimination degree for attributes reduction in concept lattice
#@ Ming Li;De-San Yang
#t 2007
#c 3
#% 384416
#% 413464
#% 1656269
#% 1731181
#! This paper presents a new concept, discrimination degree theory, which is complementary of inclusion degree. Then the theoretical and practical significance of the discrimination degree is discussed, and the concept formation theorem of discrimination degree is given. The relationship between the discrimination degree and discernibility matrix is explained in attributes reduction of formal context. Finally, under a biology formal context, concept lattice is built after attributes reduced. By comparison with the lattice which didn't reduce attributes, it shows that reduction make the complexity of building lattice distinctly simplified while the key information is still retained.

#index 1393200
#* A language and a visual interface to specify complex spatial patterns
#@ Xiaohui Li;Yan Huang
#t 2007
#c 3
#% 177755
#% 397594
#% 420709
#% 501066
#% 630974
#% 727910
#% 769914
#% 779218
#% 784509
#% 810092
#! The emerging interests in spatial pattern mining lead to the demand for a flexible spatial pattern mining language, on which easy to use and understand visual pattern language could be built. This motivates us to define a pattern mining language called CSPML to allow users to specify complex spatial patterns they are interested in mining from spatial datasets. We describe our proposed pattern mining language in this paper. Unlike general pattern languages proposed in literature, our language is specifically designed for specifying spatial patterns. An interface which allows users to specify the patterns visually is designed. The visual language is based on and goes beyond the visual language proposed in literature in the sense that users use CSPML to retrieve patterns instead of the results of a simple spatial query.

#index 1393201
#* Clustering ensembles based on normalized edges
#@ Yan Li;Jian Yu;Pengwei Hao;Zhulin Li
#t 2007
#c 3
#% 36672
#% 313959
#% 314054
#% 579655
#% 722902
#% 726725
#% 753142
#% 770836
#% 785360
#% 803762
#% 837616
#% 1374723
#% 1861495
#! The co-association (CA) matrix was previously introduced to combine multiple partitions. In this paper, we analyze the CA matrix, and address its difference from the similarity matrix using Euclidean distance. We also explore how to find a proper and better algorithm to obtain the final partition using the CA matrix. To get more robust and reasonable clustering ensemble results, a new hierarchical clustering algorithm is proposed by developing a novel concept of normalized edges to measure the similarity between clusters. The experimental results of the proposed approach are compared with those of some single runs of well-known clustering algorithms and other ensemble methods and the comparison clearly demonstrates the effectiveness of our algorithm.

#index 1393202
#* Quantum-inspired immune clonal multiobjective optimization algorithm
#@ Yangyang Li;Licheng Jiao
#t 2007
#c 3
#% 465696
#% 1022808
#% 1022816
#% 1720668
#% 1777103
#% 1777209
#% 1777214
#% 1784435
#! Based on the concept and principles of quantum computing, a quantum-inspired immune clonal multiobjective optimization algorithm (QICMOA) is proposed to solve extended 0/1 knapsack problems. In QICMOA, we select less-crowded Pareto-optimal individuals to perform cloning, recombination update. Meanwhile, the Pareto-optimal individual is proliferated and divided into a set of subpopulation groups. Individual in a subpopulation group is represented by multi-state gene quantum bits. For the novel representation, qubit individuals in subpopulation are updated by applying a new chaos update strategy. The proposed recombination realizes the information communication among individuals so as to improve the search efficiency. We compare QICMOA with SPEA, NSGA, VEGA and NPGA in solving nine 0/1 knapsack problems. The statistical results show that QICMOA has a good performance in converging to true Pareto-optimal fronts with a good distribution.

#index 1393203
#* Phase space reconstruction based classification of power disturbances using support vector machines
#@ Zhiyong Li;Weilin Wu
#t 2007
#c 3
#% 260645
#% 309208
#% 529236
#% 1677805
#% 1678228
#! Using Phase Space Reconstruction (PSR) and Support Vector Machines (SVMs), a novel approach for power disturbance classification is presented. The types of concerned disturbances include voltage sags, voltage swells, voltage interruptions, impulsive transients, harmonics and flickers. PSR is applied for disturbance feature extraction. Based on PSR, power disturbance trajectories are constructed and then converted into binary images through encoding. Four distinctive features are proposed as the inputs of SVM classifier. Simulation results show that the classification method is effective and it requires less training samples.

#index 1393204
#* Mining the impact factors of threads and participators on usenet using link analysis
#@ Hongbo Liu;Jiaxin Wang;Yannan Zhao;Zehong Yang
#t 2007
#c 3
#% 146494
#% 290830
#% 342596
#% 577356
#% 771919
#! Usenet is a world-wide distributed discussion system, and it is one of the representative resources on Internet. The structure of news-group on Usenet forms gradually along with the evolution of the news-group and could provide helpful information for the users. In this paper, we present a method to evaluate the impact factors of participators and threads based on the structure of newsgroup. Some analysis and experimental results on real data sets are also provided. The impact factors could provide useful intrinsic information of the newsgroup and can be used in some applications to help access information more efficiently on the Usenet. The method can be also applied on other discussion systems, such as web forums, bulletin board systems, and so on.

#index 1393205
#* Weighted rough set learning: towards a subjective approach
#@ Jinfu Liu;Qinghua Hu;Daren Yu
#t 2007
#c 3
#% 420064
#% 443509
#% 843876
#% 901097
#% 998622
#% 1272000
#% 1665788
#% 1788535
#! Classical rough set theory has shown powerful capability in attribute dependence analysis, knowledge reduction and decision rule extraction. However, in some applications where the subjective and apriori knowledge must be considered, such as cost-sensitive learning and class imbalance learning, classical rough set can not obtain the satisfying results due to the absence of a mechanism of considering the subjective knowledge. This paper discusses problems connected with introducing the subjective knowledge into rough set learning and proposes a weighted rough set learning approach. In this method, weights are employed to represent the subjective knowledge and a weighted information system is defined firstly. Secondly, attribute dependence analysis under the subjective knowledge is performed and weighted approximate quality is given. Finally, weighted attribute reduction algorithm and weighted rule extraction algorithm are designed. In order to validate the proposed approach, experimentations of class imbalance learning and cost-sensitive learning are constructed. The results show that the introduction of appropriate weights can evidently improve the performance of rough set learning, especially, increasing the accuracy of the minority class and the AUC for class imbalance learning and decreasing the classification cost for cost-sensitive learning.

#index 1393206
#* Multiple self-splitting and merging competitive learning algorithm
#@ Jun Liu;Kotagiri Ramamohanarao
#t 2007
#c 3
#% 466425
#% 1042844
#% 1778680
#% 1860937
#! The Self-Splitting Competitive Learning (SSCL) is a powerful algorithm that solves the difficult problems of determining the number of clusters and the sensitivity to prototype initialization in clustering. The SSCL algorithm iteratively partitions the data space into natural clusters without a priori information on the number of clusters. It starts with only a single prototype and adaptively splits it into multiple prototypes during the learning process based on a split-validity measure. It is able to discover all natural groups; each is associated with a prototype. However, one major problem of SSCL is the slow speed of learning process, because only one prototype can split each time. In this paper, we introduce multiple splitting scheme to accelerate the learning process and incorporates prototypes merging. Besides of these, Bayesian Information Criterion (BIC) score is used to evaluate the clusters. Experiments show that these techniques make the algorithm 5 times faster than SSCL on large data set with high dimensions and achieve better quality of clustering.

#index 1393207
#* A novel relative space based gene feature extraction and cancer recognition
#@ Xinguo Lu;Yaping Lin;Haijun Wang;Siwang Zhou;Xiaolong Li
#t 2007
#c 3
#% 426630
#% 607889
#% 765518
#% 1733145
#! Recognizing patient samples with gene expression profiles is used to cancer diagnosis and therapy. In the high dimensional, huge redundant and noisy gene expression data the cancerogenic factor's locality is studied. Using gene feature transformation a relative space to a cancer is built and a least spread space with least energy to the cancer is extracted. And it is proven that the cancer is able to be recognized in the least spread space and a cancer classification with least spread space (CCLSS) is proposed. In the Leukemia dataset and Colon dataset the correlation between the recognition rate and the rank of least spread space is explored, then the optimal least spread spaces to AML/ALL and to tumor colon tissue (TCT)/normal colon tissue (NCT) are extracted. At last using LOOCV the experiments with different classification algorithms are conducted and the results show CCLSS makes better precision than traditional classification algorithms.

#index 1393208
#* Experiments on kernel tree support vector machines for text categorization
#@ Ithipan Methasate;Thanaruk Theeramunkong
#t 2007
#c 3
#% 165110
#% 280817
#% 309208
#% 311027
#% 420077
#% 722818
#% 725786
#% 736954
#% 845253
#% 855508
#% 1377402
#% 1861020
#! Text categorization is one of the most interesting topic, due to the extremely increase of digital documents. The Support Vector Machine algorithm (SVM) is one of the most effective technique for solving this problem. However, SVM requires the user to choose the kernel function and parameters of the function, which directly effect to the performance of the classifiers. This paper proposes a novel method, named Kernel Tree SVM, which represents the multiple kernel function with a tree structure. The functions are selected and formed by using genetic programming (GP). Moreover, the gradient descent method is used to perform fine tune on parameter values in each tree. The method is benchmarked on WebKB and 20Newsgroup datasets. The results prove that the method can find a bettr optimal solution than the SVM tuned with the gradient method.

#index 1393209
#* A new approach for similarity queries of biological sequences in databases
#@ Hoong Kee Ng;Kang Ning;Hon Wai Leong
#t 2007
#c 3
#% 260073
#% 391311
#% 775868
#% 1019897
#! As biological databases grow larger, effective query of the biological sequences in these databases has become an increasingly important issue for researchers. There are currently not many systems for fast access of very large biological sequences. In this paper, we propose a new approach for biological sequences similarity querying in databases. The general idea is to first transform the biological sequences into vectors and then onto 2-d points in planes; then use a spatial index to index these points with self-organizing maps (SOM), and perform a single efficient similarity query (with multiple simultaneous input sequences) using a fast algorithm, the multi-point range query (MPRQ) algorithm. This approach works well because we could perform multiple sequences similarity queries and return the results with just one MPRQ query, with tremendous savings in query time. We applied our method onto DNA and protein sequences in database, and results show that our algorithm is efficient in time, and the accuracies are satisfactory.

#index 1393210
#* Anomaly intrusion detection based on dynamic cluster updating
#@ Sang-Hyun Oh;Won-Suk Lee
#t 2007
#c 3
#% 479658
#! For the effective detection of various intrusion methods into a computer, most of previous studies have been focused on the development of misuse-based intrusion detection methods. Recently, the works related to anomaly-based intrusion detection have attracted considerable attention because the anomaly detection technique can handle previously unknown intrusion methods effectively. However, most of them assume that the normal behavior of a user is fixed. Due to this reason, the new activities of the user may be regarded as anomalous events. In this paper, a new anomaly detection method based on an incremental clustering algorithm is proposed. To adaptively model the normal behavior of a user, the new profile of the user is effectively merged to the old one whenever new user transactions are added to the original data set.

#index 1393211
#* Efficiently mining closed constrained frequent ordered subtrees by using border information
#@ Tomonobu Ozaki;Takenao Ohkawa
#t 2007
#c 3
#% 413550
#% 577218
#% 729938
#% 789011
#% 1656291
#! In this paper, in order to alleviate the problem that frequent subtree miners often discover huge number of patterns, we propose two algorithms for discovering closed ordered subtrees under anti-monotone constraints about the structure of patterns. The proposed algorithms discover closed constrained subtrees by utilizing the pruning based on the occurrence matching and border patterns effectively. Experimental results show the effectiveness of the proposed algorithms.

#index 1393212
#* Approximate trace of grid-based clusters over high dimensional data streams
#@ Nam Hun Park;Won Suk Lee
#t 2007
#c 3
#% 280417
#% 659972
#% 742045
#% 824795
#% 1015261
#! Clustering in a large data set of high dimensionality has always been a serious challenge in the field of data mining. A good clustering method should provide flexible scalability to the number of dimensions as well as the size of a data set. We have proposed a grid-based clustering method called a hybrid-partition method for an on-line data stream. However, as the dimensionality of a data stream is increased, the time and space complexity of this method is increased rapidly. In this paper, a sibling list is proposed to find the clusters of a multi-dimensional data space based on the one-dimensional clusters of each dimension. Although the accuracy of identified multi-dimensional clusters may be less accurate, this one-dimensional approach can provide better scalability to the number of dimensions. This is because the one-dimensional approach requires much less memory usage than the multi-dimensional approach does. Therefore, the confined space of main memory can be more effectively utilized by the one-dimensional approach.

#index 1393213
#* BRIM: an efficient boundary points detecting algorithm
#@ Bao-Zhi Qiu;Feng Yue;Jun-Yi Shen
#t 2007
#c 3
#% 248790
#% 248792
#% 849810
#! In order to detect boundary points of clusters effectively, we propose a technique making use of a point's distribution feature of its Eps neighborhood to detect boundary points, and develop a boundary points detecting algorithm BRIM (an efficient Boundary points detecting algorithm). Experimental results show that BRIM can detect boundary points in noisy datasets containing clusters of different shapes and sizes effectively and efficiently.

#index 1393214
#* Syntactic impact on sentence similarity measure in archive-based QA system
#@ Guang Qiu;Jiajun Bu;Chun Chen;Peng Huang;Keke Cai
#t 2007
#c 3
#% 575313
#% 756211
#% 838398
#% 882738
#% 1250629
#! There's now an increase in the number of Question Answering communities where large archives of question and answer pairs are collected up over time. These archives help traditional type-specified Question Answering (QA) systems to overcome type constraints and enable a service of general types. Semantic similarity measures between sentences dominate the overall performance of such Archive-based QA systems in finding similar questions in the archive to users' requests. Available approaches to sentence similarity measurement mainly utility word-to-word similarity measures directly in a bag-of-words way. In this paper, we take the syntactic evidence into account and carry out an examination on the impact of syntactic information on the sentence similarity measurement. We also compare the performance of our syntactic information incorporated approach with some baseline retrieval models. Experiments show that our approach outperforms other models both in mean average precision (MAP) and recall.

#index 1393215
#* Semi-structure mining method for text mining with a chunk-based dependency structure
#@ Issei Sato;Hiroshi Nakagawa
#t 2007
#c 3
#% 413550
#% 463903
#% 464996
#% 478622
#% 577218
#% 1669959
#! In text mining, when we need more precise information than word frequencies such as the relationships among words, it is necessary to extract frequent patterns of words with a dependency structure in a sentence. This paper proposes a semi-structure mining method for extracting frequent patterns of words with a dependency structure from a text corpus. First, it describes the data structure representing the dependency structure. This is a tree structure in which each node has multiple items. Then, a mining algorithm for this data structure is described. Our method can extract frequent patterns that cannot be extracted by conventional methods.

#index 1393216
#* Principal curves with feature continuity
#@ Ming-Ming Sun;Jing-Yu Yang
#t 2007
#c 3
#% 298674
#% 334522
#% 344668
#% 1810968
#! Principal curves were proposed as the nonlinear generalization of PCA. However, for the tasks of feature extraction for signal representation at which PCA is adept, existing definitions of principal curves have some weakness in their theoretical bases thus fail to get reasonable results in many situations. In this paper, a new definition of principal curves - Principal Curve with Feature Continuity (PCFC) is proposed. PCFC focuses on both reconstruction error minimization and feature continuity. It builds a continuous mapping from samples to the extracted features so the features preserve the inner structures of the sample set, which benefits the researchers to learn the properties of the sample set. The existence and the differential properties of PCFC are studied and the results are presented in this paper.

#index 1393217
#* Kernel-based linear neighborhood propagation for semantic video annotation
#@ Jinhui Tang;Xian-Sheng Hua;Yan Song;Guo-Jun Qi;Xiuqing Wu
#t 2007
#c 3
#% 68722
#% 723241
#% 812389
#% 876068
#% 883851
#% 905279
#! The insufficiency of labeled training samples for representing the distribution of the entire data set (include labeled and unlabeled) is a major obstacle in automatic semantic annotation of large-scale video database. Semi-supervised learning algorithms, which attempt to learn from both labeled and unlabeled data, are promising to solve this problem. In this paper, we present a novel semi-supervised approach named Kernel based Local Neighborhood Propagation (Kernel LNP) for video annotation. This approach combines the consistency assumption and the Local Linear Embedding (LLE) method in a nonlinear kernel-mapped space, which improves a recently proposed method Local Neighborhood Propagation (LNP) by tackling the limitation of its local linear assumption on the distribution of semantics. Experiments conducted on the TRECVID data set demonstrate that this approach can obtain a more accurate result than LNP for video semantic annotation.

#index 1393218
#* Learning Bayesian networks with combination of MRMR criterion and EMI method
#@ Fengzhan Tian;Feng Liu;Zhihai Wang;Jian Yu
#t 2007
#c 3
#% 129987
#% 246834
#% 400980
#% 727885
#% 814023
#% 893460
#% 1650319
#% 1650579
#! Currently, learning Bayesian Networks (BNs) from data has become a much attention-getting issue in fields of machine learning and data mining. While there exists few efficient algorithms for learning BNs in presence of incomplete data. In this paper, we present a scoring function based on mutual information for evaluating BN structures. To decrease computational complexity, we introduce MRMR criterion into the scoring function, which enables the computation of the scoring function to involve in only two-dimensional mutual information. When the dataset is incomplete, we use EMI method to estimate the Mutual Information (MI) from the incomplete dataset. As for whether a node ordering is manually given or not, we develop two versions of algorithms, named as MRMR- E1 and MRMR-E2 respectively and evaluate them through experiments. The experimental results on Alarm network show good accuracy and efficiency of our algorithms.

#index 1393219
#* A cooperative coevolution algorithm of RBFNN for classification
#@ Jin Tian;Minqiang Li;Fuzan Chen
#t 2007
#c 3
#% 292240
#% 312728
#% 330111
#% 400346
#% 424994
#% 465922
#% 720840
#% 846520
#% 1777140
#% 1777251
#% 1777259
#% 1777347
#! This article presents a new learning algorithm, CO-RBFNN, for complex classifications, which attempts to construct the radial basis function neural network (RBFNN) models by using a cooperative coevolutionary algorithm (Co-CEA). The Co-CEA utilizes a divide-and-cooperative mechanism by which subpopulations are coevolved in separate populations of evolutionary algorithms executing in parallel. A modified K-means method is employed to divide the initial hidden nodes into modules that are represented as subpopulation of the Co-CEA. Collaborations among the modules are formed to obtain complete solutions. The algorithm adopts a matrix-form mixed encoding to represent the RBFNN hidden layer structure, the optimum of which is achieved by coevolving all parameters. Experimental results on eight UCI datasets illustrate that CO-RBFNN is able to produce a higher accuracy of classification with a much simpler network structure in fewer evolutionary trials when compared with other alternative standard algorithms.

#index 1393220
#* ANGEL: a new effective and efficient hybrid clustering technique for large databases
#@ Cheng-Fa Tsai;Chia-Chen Yen
#t 2007
#c 3
#% 248792
#% 776575
#% 1733120
#! This paper presents a new clustering algorithm named ANGEL, capable of satisfying various clustering requirements in data mining applications. As a hybrid method that employs discrete-degree and density-attractor, the proposed algorithm identifies the main structure of clusters without including the edge of clusters and, then, implements the DBSCAN algorithm to detect the arbitrary edge of the main structure of clusters. Experiment results indicate that the new algorithm accurately recognizes the entire cluster, and efficiently solves the problem of indentation for cluster. Simulation results reveal that the proposed new clustering algorithm performs better than some existing well-known approaches such as the K-means, DBSCAN, CLIQUE and GDH methods. Additionally, the proposed algorithm performs very fast and produces much smaller errors than the K-means, DBSCAN, CLIQUE and GDH approaches in most the cases examined herein.

#index 1393221
#* Exploring group moving pattern for an energy-constrained object tracking sensor network
#@ Hsiao-Ping Tsai;De-Nian Yang;Wen-Chih Peng;Ming-Syan Chen
#t 2007
#c 3
#% 162940
#% 237380
#% 324431
#% 414174
#% 772633
#% 837524
#% 861116
#% 870335
#% 889115
#% 1394403
#% 1769774
#% 1772465
#! In this paper, we investigate and utilize the characteristic of the group movement of objects to achieve energy conservation in the inherently resource-constrained wireless object tracking sensor network (OTSN). We propose a novel mining algorithm that consists of a global mining and a local mining to leverage the group moving pattern. We use the VMM model together with Probabilistic Suffix Tree (PST) in learning the moving patterns, as well as Highly Connected Component (HCS) that is a clustering algorithm based on graph connectivity for moving pattern clustering in our mining algorithm. Based on the mined out group relationship and the group moving patterns, a hierarchically prediction-based query algorithm and a group data aggregation algorithm are proposed. Our experiment results show that the energy consumption in terms of the communication cost for our system is better than that of the conventional query/update based OTSN, especially in the case that on-tracking objects have the group moving characteristics.

#index 1393222
#* ProMail: using progressive email social network for spam detection
#@ Chi-Yao Tseng;Jen-Wei Huang;Ming-Syan Chen
#t 2007
#c 3
#% 610830
#% 811373
#% 838490
#! The spam problem continues growing drastically. Owing to the ever-changing tricks of spammers, the filtering technique with continual update is imperative nowadays. In this paper, a server-oriented spam detection system ProMail, which investigates human email social network, is presented. According to recent email interaction and reputation of users, arriving emails can be classified as spam or non-spam(ham). To capture the dynamic email communication, the progressive update scheme is introduced to include latest arriving emails by the feedback mechanism and delete obsolete ones. This not only effectively limits the memory space, but also keeps the most up-to-date information. For better efficiency, it is not required to sort the scores of each email user and acquire the exact ones. Instead, the reputation procedure, SpGrade, is proposed to accelerate the progressive rating process. In addition, Pro-Mail is able to deal with huge amounts of emails without delaying the delivery time and possesses higher attack resilience against spammers. The real dataset of 1,500,000 emails is used to evaluate the performance of ProMail, and the experimental results show that ProMail is more accurate and efficient.

#index 1393223
#* Multidimensional decision support indicator (mDSI) for time series stock trend prediction
#@ Kuralmani Vellaisamy;Jinyan Li
#t 2007
#c 3
#% 414113
#% 780570
#% 816265
#% 1699340
#! This work proposes a generalized approach for predicting trends in time series data with a particular interest in stocks. In this approach, we suggest a multidimensional decision support indicator mDSI derived from a sequential data mining process to monitor trends in stocks. Available indicators in the literature often fail to agree with their predictions to their competitors because of the specific nature of features each one uses in their predictions like moving averages use means, momentums use dispersions, etc. Then again, choosing a best indicator is a challenging and also expensive one. Thus, in this paper, we introduce a compact, but robust indicator to learn the trends effectively for any given time series data. That is, it introduces a simple multdimensional indicator such as mDSI which integrates multiple decision criteria into a single index value that to eliminate conflicts and improve the overall efficiency. Experiments with mDSI on the real data further confirm its efficiency and good performance.

#index 1393224
#* A novel support vector machine ensemble based on subtractive clustering analysis
#@ Cuiru Wang;Hejin Yuan;Jun Liu;Tao Zhou;Huiling Lu
#t 2007
#c 3
#% 209021
#% 235377
#% 1579413
#! This paper put forwards a novel support vector machine ensemble construction method based on subtractive clustering analysis. Firstly, the training samples are clustered into several clusters according to their distribution with subtractive clustering algorithm. Then small quantities of representative instances from them are chosen as training subsets to construct support vector machine components. At last, the base classifiers' outputs are aggregated to obtain the final decision. Experiment results on UCI datasets show that the SVM ensemble generated by our method has higher classification accuracy than Bagging, Adaboost and k-fold cross validation algorithms.

#index 1393225
#* Keyword extraction based on pagerank
#@ Jinghua Wang;Jianyi Liu;Cong Wang
#t 2007
#c 3
#% 286069
#% 532186
#% 741840
#% 748600
#% 757276
#% 810581
#% 938761
#% 939810
#% 1272061
#! Keywords are viewed as the words that represent the topic and the content of the whole text. Keyword extraction is an important technology in many areas of document processing, such as text clustering, text summarization, and text retrieval. This paper provides a keyword extraction algorithm based on WordNet and PageRank. Firstly, a text is represented as a rough undirected weighted semantic graph with WordNet, which defines synsets as vertices and relations of vertices as edges, and assigns the weight of edges with the relatedness of connected synsets. Then we apply UW-PageRank in the rough graph to do word sense disambiguation, prune the graph, and finally apply UW-PageRank again on the pruned graph to extract keywords. The experimental results show our algorithm is practical and effective.

#index 1393226
#* Finding the optimal feature representations for Bayesian network learning
#@ LiMin Wang;ChunHong Cao;XiongFei Li;HaiJun Li
#t 2007
#c 3
#% 234992
#% 465747
#% 893463
#% 1665801
#! Naive Bayes is often used in text classification applications and experiments because of its simplicity and effectiveness. However, many different versions of Bayes model consider only one aspect of a particular word. In this paper we define an information criterion, Projective Information Gain, to decide which representation is appropriate for a specific word. Based on this, the conditional independence assumption is extended to make it more efficient and feasible and then we propose a novel Bayes model, General Naive Bayes (GNB), which can handle two representations concurrently. Experimental results and theoretical justification that demonstrate the feasibility of our approach are presented.

#index 1393227
#* Feature extraction and classification of tumor based on wavelet package and support vector machines
#@ Shulin Wang;Ji Wang;Huowang Chen;Shutao Li
#t 2007
#c 3
#% 425048
#% 575972
#% 607889
#% 833478
#% 1786751
#! DNA microarray experiments provide us with huge amount of gene expression data, which leads to a dimensional disaster for extracting features related to tumor. A wavelet package decomposition based feature extraction method for tumor classification was proposed, by which eigenvectors are extracted from gene expression profiles and used as the input of support vector machines classifier. Two well-known datasets are examined using the novel feature extraction method and support vector machines. Experiment results show that the 4-fold cross-validated accuracy of 100% is obtained for the leukemia dataset and 93.55% for the colon dataset.

#index 1393228
#* Resource allocation and scheduling problem based on genetic algorithm and ant colony optimization
#@ Su Wang;Bo Meng
#t 2007
#c 3
#! Faced with the increasing growth of container throughput and more large ships in shorter time, a key factor of success is to generate the best resource allocation plan for the future. This paper discusses a heuristic GA-ACO method which combines Genetic Algorithm and Ant Colony Optimization for resource allocation and scheduling problem in container terminals. In the first phase GA uses character string to represent chromosome for allocation plans and finds the best allocation by self-learning. In the second phase, an improved ACO algorithm is introduced to optimize the scheduling jobs based on the allocation plan from GA. We examine the performance of tugboat allocation optimization in container terminals and obtain satisfactory results.

#index 1393229
#* Image classification and segmentation for densely packed aggregates
#@ Weixing Wang
#t 2007
#c 3
#% 279302
#! This paper presents a methodology for delineating densely packed aggregate particles based on aggregate image classification. There is no earlier work on segmentation of aggregate particles has exploited these two building blocks for making robust object delineation. The proposed method has been tested experimentally for different kinds of densely packed aggregate images, which are difficult to detect by a normal edge detector. As tested, the studied algorithm can be applied into other applications too.

#index 1393230
#* Mining temporal co-orientation pattern from spatio-temporal databases
#@ Ling-Yin Wei;Man-Kwan Shan
#t 2007
#c 3
#% 778732
#% 785475
#% 838497
#% 1707861
#% 1716981
#! A spatial co-orientation pattern refers to objects that frequently occur with the same spatial orientation, e.g. left, right, below, etc., among images. In this paper, we introduce temporal co-orientation pattern mining which is the problem of temporal aspects of spatial co-orientation patterns. A temporal coorientation pattern represents how spatial co-orientation patterns change over time. Temporal co-orientation pattern mining is useful for discovering tactics from play sequences of sports video data, because the most tactic patterns of basketball competition are constituted of such spatial co-orientation patterns in time order. We propose the three-stage approach, which transforms the problem into sequential pattern mining, for mining temporal co-orientation patterns. We experimentally evaluate the performance of the proposed algorithm and analysis the effect of these stages.

#index 1393231
#* Incremental learning of support vector machines by classifier combining
#@ Yi-Min Wen;Bao-Liang Lu
#t 2007
#c 3
#% 209021
#% 280481
#% 466482
#% 729932
#% 820086
#% 1776405
#% 1860566
#! How to acquire new knowledge from new added training data while retaining the knowledge learned before is an important problem for incremental learning. In order to handle this problem, we propose a novel algorithm that enables support vector machines to accommodate new data, including samples that correspond to previously unseen classes, while it retains previously acquired knowledge. Furthermore, our new algorithm does not require access to previously used data during subsequent incremental learning sessions. The proposed algorithm trains a support vector machine that can output posterior probability information once an incremental batch training data is acquired. The outputs of all the resulting support vector machines are simply combined by averaging. Experiments are carried out on three benchmark datasets as well as a real world text categorization task. The experimental results indicate that the proposed algorithm is superior to the traditional incremental learning algorithm, Learn++. Due to the simplicity of the proposed algorithm, it can be used more effectively in practice.

#index 1393232
#* Clustering zebrafish genes based on frequent-itemsets and frequency levels
#@ Daya C. Wimalasuriya;Sridhar Ramachandran;Dejing Dou
#t 2007
#c 3
#% 397382
#% 577257
#% 818916
#% 823356
#% 823379
#% 838453
#! This paper presents a new clustering technique which is extended from the technique of clustering based on frequent-itemsets. Clustering based on frequent-itemsets has been used only in the domain of text documents and it does not consider frequency levels, which are the different levels of frequency of items in a data set. Our approach considers frequency levels together with frequent-itemsets. This new technique was applied in the domain of bio-informatics, specifically to obtain clusters of genes of zebrafish (Danio rerio) based on Expressed Sequence Tags (EST) that make up the genes. Since a particular EST is typically associated with only one gene, ESTs were first classified in to a set of classes based on their features. Then these EST classes were used in clustering genes. Further, an attempt was made to verify the quality of the clusters using gene ontology data. This paper presents the results of this application of clustering based on frequent-itemsets and frequency levels and discusses other domains in which it has potential uses.

#index 1393233
#* A practical method for approximate subsequence search in DNA databases
#@ Jung-Im Won;Sang-Kyoon Hong;Jee-Hee Yoon;Sanghyun Park;Sang-Wook Kim
#t 2007
#c 3
#% 235941
#% 443469
#% 451770
#% 471414
#% 480482
#% 607874
#% 1015330
#% 1016132
#% 1707805
#! In this paper, we propose an accurate and efficient method for approximate subsequence search in large DNA databases. The proposed method basically adopts a binary trie as its primary structure and stores all the window subsequences extracted from a DNA sequence. For approximate subsequence search, it traverses the binary trie in a breadth-first fashion and retrieves all the matched subsequences from the traversed path within the trie by a dynamic programming technique. However, the proposed method stores only window subsequences of the pre-determined length, and thus suffers from large post-processing time in case of long query sequences. To overcome this problem, we divide a query sequence into shorter pieces, perform searching for those subsequences, and then merge their results.

#index 1393234
#* An information retrieval model based on semantics
#@ Chen Wu;Quan Zhang
#t 2007
#c 3
#% 46803
#% 262096
#% 340948
#! Models of document indexing and document retrieval are mainly based on statistical NLP method. Computation of meaning is mainly based on the semantics. The former makes it possible to construct a high performance IR system easily. However, the latter is one of the significant methods which can substantially make computer well understand the language. The goal of this paper is to find the conjoined point which can combine the advantages of both schemes, and thus to propose an IR approach. Consequently, a concept-based IR model is proposed. This model is composed of two kernel schemes: the first is a domain language model, which is derived from the traditional language model. Its basic idea is to compute the conditional probability P(Q | D). The concept extracting approach, which is the second kernel scheme of the proposed model, originates from the traditional linguistics. It can help to well extract the meaning of a term. Thus, we can take the concept (the formalized meaning), instead of the lexical term, as the processing object in the proposed model, and consequently resolve the word sense ambiguity. Experiments on the TREC6 Chinese collection show that the proposed model outperforms the traditional TF-IDF methods, especially in the average precision and the overall search time.

#index 1393235
#* AttributeNets: an incremental learning method for interpretable classification
#@ Hu Wu;Yongji Wang;Xiaoyong Huai
#t 2007
#c 3
#% 432398
#% 449529
#% 797746
#% 1408558
#! Incremental learning is of more and more importance in real world data mining scenarios. Memory cost and adaptation cost are two major concerns of incremental learning algorithms. In this paper we provide a novel incremental learning method, Attribute Nets, which is efficient both in memory utilization and updating cost of current hypothesis. Attribute Nets is designed for addressing incremental classification problem. Instead of memorizing every detail of historical cases, the method only records statistical information of attribute values of learnt cases. For classification problem, Attribute Nets could generate effective results interpretable to human beings.

#index 1393236
#* Mining personalization interest and navigation patterns on portal
#@ Jing Wu;Pin Zhang;Zhang Xiong;Hao Sheng
#t 2007
#c 3
#% 397153
#% 413591
#% 727855
#% 779969
#% 783702
#% 783703
#% 832286
#% 1784871
#! Personalization services pose new challenges to interest mining on Portal. Capturing the surfing behaviors of users implicitly and mining interest navigation patterns are the top demanding tasks. Based on the analysis of mapping the personalization interest behaviors on Portal, a novel Portal-independent mechanism of interest elicitation with privacy protection is proposed, which implements both the implicit extraction of diverse behaviors and their semantic analysis. Moreover, we present a hidden Markov model extension with personalization interest description of Portal to form interest navigation patterns for different users. Then experiments have been carried out in order to validate the proposed approaches.

#index 1393237
#* Cross-lingual document clustering
#@ Ke Wu;Bao-Liang Lu
#t 2007
#c 3
#% 329531
#% 375388
#% 755815
#% 939379
#% 1264984
#! The ever-increasing numbers of Web-accessible documents are available in languages other than English. The management of these heterogeneous document collections has posed a challenge. This paper proposes a novel model, called a domain alignment translation model, to conduct cross-lingual document clustering. While most existing cross-lingual document clustering methods make use of an expensive machine translation system to fill the gap between two languages, our model aims to effectively handle the cross-lingual document clustering by learning a cross-lingual domain alignment model and a domain-specific term translation model in a collaborative way. Experimental results show our method, i.e. C-TLS, without any resources other than a bilingual dictionary can achieve comparable performance to the direct machine translation method via a machine translation system, e.g. Google language tool. Also, our method is more efficient.

#index 1393238
#* Grammar guided genetic programming for flexible neural trees optimization
#@ Peng Wu;Yuehui Chen
#t 2007
#c 3
#% 124073
#% 414645
#% 463318
#% 1022858
#% 1348962
#% 1699340
#! In our previous studies, Genetic Programming (GP), Probabilistic Incremental Program Evolution (PIPE) and Ant Programming (AP) have been used to optimal design of Flexible Neural Tree (FNT). In this paper Grammar Guided Genetic Programming (GGGP) was employed to optimize the architecture of FNT model. Based on the predefined instruction sets, a flexible neural tree model can be created and evolved. This framework allows input variables selection, over-layer connections and different activation functions for the various nodes involved. The free parameters embedded in the neural tree are optimized by particle swarm optimization algorithm. Empirical results on stock index prediction problems indicate that the proposed method is better than the neural network and genetic programming forecasting models.

#index 1393239
#* A new initialization method for clustering categorical data
#@ Shu Wu;Qingshan Jiang;Joshua Zhexue Huang
#t 2007
#c 3
#% 374537
#% 413618
#% 414554
#% 466083
#% 631985
#% 1788040
#! Performance of partitional clustering algorithms which converges to numerous local minima highly depends on initial cluster centers. This paper presents an initialization method which can be implemented to partitional clustering algorithms for categorical data sets with minimizing the numerical objective function. Experimental results show that the new initialization method is more efficient and stabler than the traditional one and can be implemented to large data sets for its linear time complexity.

#index 1393240
#* L0-constrained regression for data mining
#@ Zhili Wu;Chun-Hung Li
#t 2007
#c 3
#% 269224
#% 466084
#% 722943
#% 725523
#! L2 and L1 constrained regression methods, such as ridge regression and Lasso, have been generally known for their fitting ability. Recently, L0- constrained classifications have been used for feature selection and classifier construction. This paper proposes an L0 constrained regression method, which aims to minimize both the epsilon-insensitive fitting errors and L0 constraints on regression coefficients. Our L0-constrained regression can be efficiently approximated by successive linearization algorithm, and shows the favorable properties of selecting a compact set of fitting coefficients and tolerating small fitting errors. To make our L0 constrained regression generally applicable, the extension to nonlinear regression is also addressed in this paper.

#index 1393241
#* Application of hybrid pattern recognition for discriminating paddy seeds of different storage periods based on Vis/NIRS
#@ Li Xiaoli;Cao Fang;He Yong
#t 2007
#c 3
#% 367290
#% 1674273
#! Hybrid pattern recognition was put forward to discriminate paddy seeds of four different storage periods based on visible/near infrared reflectance spectroscopy (Vis/NIRS). The hybrid pattern recognition included extracting feature and building classifier. A total of 210 samples of paddy seeds, which belonged to four classes, were used for collecting Vis/NIR spectra (325- 1075 nm) using a field spectroradiometer. The hybrid pattern recognition was integrated with wavelet transform (WT), principal component analysis (PCA) and artificial neural networks (ANN) models. WT was used to eliminate noises and extract characteristic information from spectral data. The characteristic information could be visualized in principal components (PCs) space, in which the structures correlative with the storage periods could be discovered. The first eight PCs, which accounted for 99.94% of the raw spectral data variance, were used as input of the ANN mode, and the model yielded high discrimination accuracy rates of 100%, 100%, 100% and 90% for four classes' samples respectively.

#index 1393242
#* Density-based data clustering algorithms for lower dimensions using space-filling curves
#@ Bin Xu;Danny Z. Chen
#t 2007
#c 3
#% 45766
#% 86951
#% 273890
#% 420078
#% 462243
#! We present two new density-based algorithms for clustering data points in lower dimensions (dimensions ≤ 10). Both our algorithms compute density-based clusters and noises in O(n) CPU time, space, and I/O cost, under some reasonable assumptions, where n is the number of input points. Besides packing the data structure into buckets and using block access techniques to reduce the I/O cost, our algorithms apply space-filling curve techniques to reduce the disk access operations. Our first algorithm (Algorithm A) focuses on handling not highly clustered input data, while the second algorithm (Algorithm B) focuses on highly clustered input data. We implemented our algorithms, evaluated the effects of various space-filling curves, identified the best space-filling curve for our approaches, and conducted extensive performance evaluation. The experiments show the high performance of our algorithms. We believe that our algorithms are of considerable practical value.

#index 1393243
#* Transformation-based GMM with improved cluster algorithm for speaker identification
#@ Limin Xu;Zhenmin Tang;Keke He;Bo Qian
#t 2007
#c 3
#% 80995
#% 294252
#% 830303
#! The embedded linear transformation is a popular technique which integrates both transformation and diagonal-covariance Gaussian mixture into a unified framework to improve the performance of speaker recognition. However, the mixture number of GMM must be given in model training. The cluster expectation-maximization (EM) algorithm is a well-known technique in which the mixture number is regarded as an estimated parameter. This paper presents a new model that integrates an improved cluster algorithm into the estimating process of GMM with the embedded transformation. In the approach, the transformation matrix, the mixture number and other traditional model parameters are simultaneously estimated according to a maximum likelihood criterion. The proposed method is demonstrated on a database of three data sessions for text independent speaker identification. The experiments show that this method outperforms the traditional GMM with cluster EM algorithm.

#index 1393244
#* Using social annotations to smooth the language model for IR
#@ Shengliang Xu;Shenghua Bao;Yong Yu;Yunbo Cao
#t 2007
#c 3
#% 262096
#% 287253
#% 730071
#% 750863
#% 766430
#% 766431
#% 869504
#% 869548
#% 1655418
#% 1703142
#! In the paper, we present an exploration of using social annotations provided by the Web 2.0 sites (such as Del.icio.us) in helping web search. More specifically, we consider using the social annotations as an additional resource to strengthen existing smoothing methods for the language model for IR. The social annotations can benefit the smoothing of language model in two aspects: 1) the annotations themselves can serve as the summaries of the web pages given by the users; 2) the annotations can be seen as the links of the web pages sharing the same annotations. We propose three smoothing methods, addressing the two aspects and their combination, respectively. We call the new language model of using the proposed smoothing methods 'Language Annotation Model (LAM). Preliminary experimental results show that LAM significantly outperforms the traditional language models.

#index 1393245
#* Affection factor optimization in data field clustering
#@ Hong Yang;Jianxin Liu;Zhong Li
#t 2007
#c 3
#% 210173
#% 316709
#% 1861495
#! Although Data Field Clustering method has a lot of advantages, clustering result depends severely on affection factor that is selected in Data Field function. The purpose of the paper is to find an optimum affection factor that may not only reflect nature characteristic of clustering data sample, but also reduce influence caused by sample deviation to minimum. In this paper, an affection interval concept is defined at first. Then an optimum objective function for reducing influence of sample deviation is constructed and an approximate solution is given of optimum affection factor. In the end, a standard data set offered in the MATLAB is used to test the availability of the optimum affection factor, the result is satisfactory.

#index 1393246
#* A new algorithm for minimum attribute reduction based on binary particle swarm optimization with vaccination
#@ Dongyi Ye;Zhaojiong Chen;Jiankun Liao
#t 2007
#c 3
#% 870071
#! Computation of a minimum attribute reduct of a decision table, which is known as an NP-hard nonlinearly constrained optimization problem, is equivalently transformed in this paper into an unconstrained binary optimization problem. An improved binary particle swarm optimization algorithm combined with some immunity mechanism is then proposed to solve the transformed optimization problem. Vaccination based on the discernibility matrix of the decision table is introduced for accelerating the search process in the algorithm. Experimental results on a number of data sets show that the proposed algorithm remarkably outperforms some recent global optimization techniques based algorithms for minimum attribute reduction in both quality of solution and computational complexity.

#index 1393247
#* Graph nodes clustering based on the commute-time kernel
#@ Luh Yen;Francois Fouss;Christine Decaestecker;Pascal Francq;Marco Saerens
#t 2007
#c 3
#% 329562
#% 342659
#% 721707
#% 723542
#% 743284
#% 765545
#% 769935
#% 770829
#% 780683
#% 975021
#% 1200254
#% 1378293
#% 1786775
#% 1860974
#! This work presents a kernel method for clustering the nodes of a weighted, undirected, graph. The algorithm is based on a two-step procedure. First, the sigmoid commute-time kernel (KCT), providing a similarity measure between any couple of nodes by taking the indirect links into account, is computed from the adjacency matrix of the graph. Then, the nodes of the graph are clustered by performing a kernel kmeans or fuzzy k-means on this CT kernel matrix. For this purpose, a new, simple, version of the kernel k-means and the kernel fuzzy k-means is introduced. The joint use of the CT kernel matrix and kernel clustering appears to be quite successful. Indeed, it provides good results on a document clustering problem involving the newsgroups database.

#index 1393248
#* Identifying synchronous and asynchronous co-regulations from time series gene expression data
#@ Ying Yin;Yuhai Zhao;Bin Zhang
#t 2007
#c 3
#% 397382
#% 469422
#% 727908
#% 729972
#% 778215
#% 810066
#! The complexity of a biological system provides a great diversity of correlations among genes/gene clusters, including synchronous and asynchronous co-regulations, each of which can be further divided into two categories: activation and inhibition. Most existing methods can only identify the synchronous activation patterns, such as shifting, scaling and shifting-and-scaling, however, few focuses on capturing both synchronous and asynchronous co-regulations. In this paper, we propose a coding scheme, where two genes with the same code must be co-regulated. Based on the coding scheme, an efficient clustering algorithm is devised to simultaneously capture all known co-regulated relationships (synchronous and asynchronous) among genes/gene clusters. Furthermore, the detailed and complete co-regulation information, which facilitates the study of genetic regulatory networks, can be easily derived from the resulting clusters. Experiments from both real and synthetic microarray datasets prove the effectiveness and efficiency of our method.

#index 1393249
#* A parallel algorithm for learning Bayesian networks
#@ Kui Yu;Hao Wang;Xindong Wu
#t 2007
#c 3
#% 246834
#% 295986
#% 439903
#% 443471
#% 793242
#% 1650319
#% 1650579
#% 1650706
#! Computing the expected statistics is the main bottleneck in learning Bayesian networks in large-scale problem domains. This paper presents a parallel learning algorithm, PL-SEM, for learning Bayesian networks, based on an existing structural EM algorithm (SEM). Since the computation of the expected statistics is in the parametric learning part of the SEM algorithm, PLSEM exploits a parallel EM algorithm to compute the expected statistics. The parallel EM algorithm parallelizes the E-step and M-step. At the E-step, PLSEM parallel computes the expected statistics of each sample; and at the M-step, with the conditional independence of Bayesian networks and the expected statistics computed at the E-step, PL-SEM exploits the decomposition property of the likelihood function under the completed data to parallel estimate each local likelihood function. PL-SEM effectively computes the expected statistics, and greatly reduces the time complexity of learning Bayesian networks.

#index 1393250
#* Incorporating prior domain knowledge into a kernel based feature selection algorithm
#@ Ting Yu;Simeon J. Simoff;Donald Stokes
#t 2007
#c 3
#% 232117
#% 425048
#% 722887
#% 738970
#% 793239
#% 1673558
#! This paper proposes a new method of incorporating prior domain knowledge into a kernel based feature selection algorithm. The proposed feature selection algorithm combines the Fast Correlation-Based Filter (FCBF) and the kernel methods in order to uncover an optimal subset of features for the support vector regression. In the proposed algorithm, the Kernel Canonical Correlation Analysis (KCCA) is employed as a measurement of mutual information between feature candidates. Domain knowledge in forms of constraints is used to guide the tuning of the KCCA. In the second experiments, the audit quality research carried by Yang Li and Donald Stokes [1] provides the domain knowledge, and the result extends the original subset of features.

#index 1393251
#* Geo-spatial clustering with non-spatial attributes and geographic non-overlapping constraint: a penalized spatial distance measure
#@ Bin Zhang;Wen Jun Yin;Ming Xie;Jin Dong
#t 2007
#c 3
#% 443531
#% 465004
#% 481281
#% 566699
#% 799775
#% 1390197
#% 1861495
#! In many geography-related problems, clustering technologies are widely required to identify significant areas containing spatial objects, particularly, the object with non-spatial attributes. At most of times, the resultant geographic areas should satisfy the geographic non-overlapping constraint. That is, the areas should not be overlapped with other areas. If without non-spatial attributes, most spatial clustering approaches can obtain such results. But in the presence of non-spatial attributes, many clustering methods can not guarantee this condition, since the clustering results may be dominated in non-spatial attribute domain which can not reflect the geographic constraint. In this paper, a new spatial distance measure called penalized spatial distance (PSD) is presented, and it is proofed to satisfy the condition which can guarantee the constraint. PSD achieves this by well adjusting the spatial distance between two points according to the non-spatial attribute values between them. The clustering effectiveness of PSD incorporated with CLARANS is evaluated on both artificial data sets and a real banking analysis case. It demonstrates that PSD can effectively discover the non-spatial knowledge and contribute more reasonably to spatial clustering problem solving.

#index 1393252
#* GBKII: an imputation method for missing values
#@ Chengqi Zhang;Xiaofeng Zhu;Jilian Zhang;Yongsong Qin;Shichao Zhang
#t 2007
#c 3
#% 418112
#% 1387730
#! Missing data imputation is an actual and challenging issue in machine learning and data mining. This is because missing values in a dataset can generate bias that affects the quality of the learned patterns or the classification performances. To deal with this issue, this paper proposes a Grey-Based K-NN Iteration Imputation method, called GBKII, for imputing missing values. GBKII is an instance-based imputation method, which is referred to a non-parametric regression method in statistics. It is also efficient for handling with categorical attributes. We experimentally evaluate our approach and demonstrate that GBKII is much more efficient than the k-NN and mean-substitution methods.

#index 1393253
#* An effective gene selection method based on relevance analysis and discernibility matrix
#@ Li-Juan Zhang;Zhou-Jun Li;Huo-Wang Chen
#t 2007
#c 3
#% 243728
#% 290482
#% 464444
#% 466410
#% 720010
#% 793239
#% 972364
#% 1663725
#! Selecting a small number of discriminative genes from thousands of genes in microarray data is very important for accurate classification of diseases or phenotypes. In this paper, we provide more elaborate and complete definitions of feature relevance and develop a novel feature selection method, which is based on relevance analysis and discernibility matrix to select small enough genes and improve the classification accuracy. The extensive experimental study using microarray data shows the proposed approach is very effective in selecting genes and improving classification accuracy.

#index 1393254
#* Towards comprehensive privacy protection in data clustering
#@ Nan Zhang
#t 2007
#c 3
#% 115608
#% 316709
#% 823362
#! We address the protection of private information in data clustering. Previous work focuses on protecting the privacy of data being mined. We find that the cluster labels of individual data points can also be sensitive to data owners. Thus, we propose a privacy-preserving data clustering scheme that extracts accurate clustering rules from private data while protecting the privacy of both original data and individual cluster labels. We derive theoretical bounds on the performance of our scheme, and evaluate it experimentally with real-world data.

#index 1393255
#* A novel spatial clustering with obstacles constraints based on particle swarm optimization and K-medoids
#@ Xueping Zhang;Jiayao Wang;Mingguang Wu;Yi Cheng
#t 2007
#c 3
#% 465004
#% 623518
#% 629693
#% 900934
#% 1390197
#! In this paper, we discuss the problem of spatial clustering with obstacles constraints and propose a novel spatial clustering method based on PSO and K-Medoids, called PKSCOC, which aims to cluster spatial data with obstacles constraints. The PKSCOC algorithm can not only give attention to higher local constringency speed and stronger global optimum search, but also get down to the obstacles constraints and practicalities of spatial clustering. The results on real datasets show that the PKSCOC algorithm performs better than the IKSCOC algorithm in terms of quantization error.

#index 1393256
#* Online rare events detection
#@ Jun Hua Zhao;Xue Li;Zhao Yang Dong
#t 2007
#c 3
#% 280437
#% 342600
#% 414389
#% 451055
#% 729932
#% 765520
#% 1289281
#! Rare events detection is regarded as an imbalanced classification problem, which attempts to detect the events with high impact but low probability. Rare events detection has many applications such as network intrusion detection and credit fraud detection. In this paper we propose a novel online algorithm for rare events detection. Different from traditional accuracy-oriented approaches, our approach employs a number of hypothesis tests to perform the cost/benefit analysis. Our approach can handle online data with unbounded data volume by setting up a proper moving-window size and a forgetting factor. A comprehensive theoretical proof of our algorithm is given. We also conduct the experiments that achieve significant improvements compared with the most relevant algorithms based on publicly available real-world datasets.

#index 1393257
#* Structural learning about independence graphs from multiple databases
#@ Qiang Zhao;Hua Chen;Zhi Geng
#t 2007
#c 3
#% 269194
#% 289424
#% 388024
#% 836006
#% 1247064
#% 1291465
#% 1699248
#! In this paper, we propose an approach for structural learning of independence graphs from multiple databases or prior knowledge of conditional independencies. In our approach, we first learn a local graph from each database separately, and then we combine these local graphs together to construct a global graph over all variables. This approach can also be used in structural learning to utilize the prior knowledge of conditional independencies.

#index 1393258
#* An effective method for calculating natural adjacency relation in spatial database
#@ Renliang Zhao;Jiatian Li
#t 2007
#c 3
#% 121114
#% 274372
#% 316709
#% 643407
#! This paper explores the way in which natural adjacency relation, spatial database are closely integrated through the spatial index for spatial data querying and mining. A Delaunay triangulation approach for constructing spatial index is proposed, which overcomes the conflict between line-intersection computation and natural adjacency isn't satisfying constrained condition of Euclidean distance. Based on this approach, a spatial index prototype for discrete areal objects-Quad GridFile is designed and implemented by using Java extending Oracle Spatial. It demonstrates foundational information extraction ability for geospatial database.

#index 1393259
#* K-centers algorithm for clustering mixed type data
#@ Wei-Dong Zhao;Wei-Hui Dai;Chun-Bin Tang
#t 2007
#c 3
#% 420081
#% 1788040
#! The K-modes and K-prototypes algorithms both apply the frequency-based update method for centroids, regarding attribute values with the highest frequency but neglecting other attribute values, which affects the accuracy of clustering results. To solve this problem, the K-centers clustering algorithm is proposed to handle mixed type data. As the extension to the K-prototypes algorithms, hard and fuzzy K-centers algorithm, focusing on effects of attribute values with different frequencies on clustering accuracy, a new update method for centroids is proposed in this paper. Experiments on many UCI machine-learning databases show that the K-centers algorithm can cluster categorical and mixed-type data more efficiently and effectively than the K-modes and K-prototypes algorithms.

#index 1393260
#* Proposion and analysis of a TCP feature of P2P traffic
#@ Li-Juan Zhou;Zhi-Tang Li;Hao Tu
#t 2007
#c 3
#% 753048
#% 781694
#% 831254
#! Over the last years, the wide use of the P2P application has lead to the rapid growth of network traffic. Thus, the accurate classification of P2P traffic becomes a challenging problem. This paper proposes some new fundamental characteristics of TCP traffic to achieve its discrimination. To prove the universality of the values of our proposed features, we also present some analytic estimates of them using Pareto as the distribution of user lifetime in real P2P systems. Finally, we apply SVM to the discrimination of these features in order to automate the processing of the discrimination, and its accuracy is demonstrated as a result of some experiments.

#index 1406358
#* Proceedings of the 2007 international conference on Emerging technologies in knowledge discovery and data mining
#@ Takashi Washio;Zhi-Hua Zhou;Joshua Zhexue Huang;Xiaohua Hu;Jinyan Li;Chao Xie;Jieyue He;Deqing Zou;Kuan-Ching Li;Mário M. Freire
#t 2007
#c 3

#index 1406359
#* PAKDD 2007 industrial track workshop
#@ Joshua Zhexue Huang;Yunming Ye
#t 2007
#c 3

#index 1406360
#* A survey of open source data mining systems
#@ Xiaojun Chen;Yunming Ye;Graham Williams;Xiaofei Xu
#t 2007
#c 3
#% 269634
#% 306861
#% 316709
#% 379240
#% 379241
#% 391356
#% 438371
#% 441778
#% 596206
#% 630973
#% 745819
#! Open source data mining software represents a new trend in data mining research, education and industrial applications, especially in small and medium enterprises (SMEs). With open source software an enterprise can easily initiate a data mining project using the most current technology. Often the software is available at no cost, allowing the enterprise to instead focus on ensuring their staff can freely learn the data mining techniques and methods. Open source ensures that staff can understand exactly how the algorithms work by examining the source codes, if they so desire, and can also fine tune the algorithms to suit the specific purposes of the enterprise. However, diversity, instability, scalability and poor documentation can be major concerns in using open source data mining systems. In this paper, we survey open source data mining systems currently available on the Internet. We compare 12 open source systems against several aspects such as general characteristics, data source accessibility, data mining functionality, and usability. We discuss advantages and disadvantages of these open source data mining systems.

#index 1406361
#* Predicting the short-term market reaction to asset specific news: is time against us?
#@ Calum Robertson;Shlomo Geva;Rodney Wolff
#t 2007
#c 3
#% 136350
#% 190581
#% 733773
#! The efficient market hypothesis states that investors immediately incorporate all available information into the price of an asset to accurately reflect its value at any given time. The sheer volume of information immediately available electronically makes it difficult for a single investor to keep abreast of all information for a single stock, let alone multiple. We aim to determine how quickly investors tend to react to asset specific news by analysing the accuracy of classifiers which take the content of news to predict the short-term market reaction. The faster the market reacts to news the more cost-effective it becomes to employ content analysis techniques to aid the decisions of traders. We find that the best results are achieved by allowing investors in the US 90 minutes to react to news. In the UK and Australia the best results are achieved by allowing investors 5 minutes to react to news.

#index 1406362
#* Frequency-weighted fuzzy time-series based on fibonacci sequence for TAIEX forecasting
#@ Hia Jong Teoh;Tai-Liang Chen;Ching-Hsue Cheng
#t 2007
#c 3
#% 145308
#% 160978
#% 209745
#% 571279
#% 859451
#% 863396
#! This paper proposes a new fuzzy time-series model for promoting the stock price forecasting, which provides two refined approaches, a frequency-weighted method, and the concept of Fibonacci sequence in forecasting processes. In empirical analysis, two different types of financial datasets, TAIEX (Taiwan Stock Exchange Capitalization Weighted Stock Index) stock index and HSI (Hong Kong Heng Seng Index) stock index are used as model verification. By comparing the forecasting results with those derived from Chen's, Yu's, and Hurang's models, the authors conclude that the research goal has been reached.

#index 1406363
#* Probabilistic techniques for corporate blog mining
#@ Flora S. Tsai;Yun Chen;Kap Luk Chan
#t 2007
#c 3
#% 280819
#% 754107
#% 869516
#% 889879
#% 932742
#% 1392388
#% 1742093
#! With the proliferation of blogs, or weblogs, in the recent years, information in the blogosphere is becoming increasingly difficult to access and retrieve. Previous studies have focused on analyzing personal blogs, but few have looked at corporate blogs, the numbers of which are dramatically rising. In this paper, we use probabilistic techniques to detect keywords from corporate blogs with respect to certain topics. We then demonstrate how this method can present the blogosphere in terms of topics with measurable keywords, hence tracking popular conversations and topics in the blogosphere. By applying a probabilistic approach, we can improve information retrieval in blog search and keywords detection, and provide an analytical foundation for the future of corporate blog search and mining.

#index 1406364
#* Mining chat conversations for sex identification
#@ Cemal Köse;Özcan Özyurt;Guychmyrat Amanmyradov
#t 2007
#c 3
#% 458379
#% 587290
#% 724021
#% 779872
#% 834697
#% 1250186
#% 1390153
#% 1650665
#% 1720606
#! Chat mediums are becoming an important part of human life in societies and provide quite useful information about people such as their current interests, habits, social behaviors and tendencies. In this study, we have presented an identification system to identify the sex of a person in a Turkish chat medium. Here, the sex identification is taken as a base study in the information mining in chat mediums. This system acquires data from a chat medium, and then automatically detects the chatter's sex from the information exchanged between chatters and compares them with the known identities of the chatters. To do this task, a simple discrimination function is used to determine the sex of the chatters. A semantic analysis method is also proposed to enhance the performance of the system. The system with the semantic analyzer has achieved accuracy over 90% in the sex identification in the real chat medium.

#index 1406365
#* Mining high impact exceptional behavior patterns
#@ Longbing Cao;Yanchang Zhao;Fernando Figueiredo;Yuming Ou;Dan Luo
#t 2007
#c 3
#% 767654
#% 785435
#% 1114499
#% 1774750
#! In the real world, exceptional behavior can be seen in many situations such as security-oriented fields. Such behavior is rare and dispersed, while some of them may be associated with significant impact on the society. A typical example is the event September 11. The key feature of the above rare but significant behavior is its high potential to be linked with some significant impact. Identifying such particular behavior before generating impact on the world is very important. In this paper, we develop several types of high impact exceptional behavior patterns. The patterns include frequent behavior patterns which are associated with either positive or negative impact, and frequent behavior patterns that lead to both positive and negative impact. Our experiments in mining debt-associated customer behavior in social-security areas show the above approaches are useful in identifying exceptional behavior to deeply understand customer behavior and streamline business process.

#index 1406366
#* Practical issues on privacy-preserving health data mining
#@ Huidong Jin
#t 2007
#c 3
#% 67453
#% 300184
#% 576761
#% 721025
#% 727815
#% 727904
#% 747134
#% 769693
#% 769937
#% 769962
#% 781952
#% 782597
#% 788963
#% 800514
#% 800515
#% 818916
#% 823417
#% 832592
#% 835074
#% 844340
#% 844353
#% 864412
#% 881546
#% 951837
#% 1068533
#% 1378334
#% 1393187
#% 1669941
#% 1669970
#% 1673554
#% 1779007
#! Privacy-preserving data mining techniques could encourage health data custodians to provide accurate information for mining by ensuring that the data mining procedures and results cannot, with any reasonable degree of certainty, violate data privacy. We outline privacy-preserving data mining techniques/systems in the literature and in industry. They range from privacy-preserving data publishing, privacy-preserving (distributed) computation to privacy-preserving data mining result release. We discuss their strength and weaknesses respectively, and indicate there is no perfect technical solution yet. We also provide and discuss a possible development framework for privacy-preserving health data mining systems.

#index 1406367
#* Data mining for intelligent structure form selection based on association rules from a high rise case base
#@ Shihai Zhang;Shujun Liu;Jinping Ou
#t 2007
#c 3
#% 232102
#% 707883
#! This paper presents a uniform model for high-rise structure design information and a case base containing 1008 high-rise buildings around the world. A case management system has been implemented with functions of data recording, modification, deletion, inquiry, statistical analysis and knowledge discovery. We propose a data-mining process of mining quantitative association rules for structure form selection from the case base and a method for mining fuzzy association rules. In the fuzzy association rule mining, we present a method for fuzzy interval division and fuzzification of quantitative attributes of the real cases. We demonstrate the application of the Apriori algorithm to generate association rules that can be used in building design. This data mining approach provides a new technical support for design efficiency, quality and intelligence.

#index 1406368
#* CommonKADS methodology for developing power grid switching orders systems
#@ Ming Zhou;Jianwen Ren;Jianxun Qi;Dongxiao Niu;Gengyin Li
#t 2007
#c 3
#% 444996
#% 445041
#! Modeling knowledge and expertise is necessary but difficult in formation of switching operation orders in power systems. Switching operations of electrical components are very frequent in normal changes of operation modes and in system restoration. The switching operations have to accord with the requirements from the system security level as well as the component's switching security level. In order to assure correct switching operations, the switching orders sheet for switching operations is a compulsory mechanism. The formation of a switching-orders sheet involves a lot of expertise and knowledge that has to be represented with an effective modeling methodology. This paper presents the use of the CommonKADS methodology, a structured development approach for knowledge and expertise representation in designing and developing a power grid switching orders generation system. The practical applications have shown that the CommonKADS methodology has apparent merits in knowledge modeling and maintainability of the system.

#index 1406369
#* Discovering prediction model for environmental distribution maps
#@ Ke Zhang;Huidong Jin;Nianjun Liu;Rob Lesslie;Lei Wang;Zhouyu Fu;Terry Caelli
#t 2007
#c 3
#% 309208
#% 769966
#% 1674242
#! Currently environmental distribution maps, such as for soil fertility, rainfall and foliage, are widely used in the natural resource management and policy making. One typical example is to predict the grazing capacity in particular geographical regions. This paper uses a discovering approach to choose a prediction model for real-world environmental data. The approach consists of two steps: (1) model selection which determines the type of prediction model, such as linear or non-linear; (2) model optimisation which aims at using less environmental data for prediction but without any loss on accuracy. The latter step is achieved by automatically selecting non-redundant features without using specific models. Various experimental results on real-world data illustrate that using specific linear model can work pretty well and fewer environment distribution maps can quickly make better/comparable prediction with the benefit of lower cost of data collection and computation.

#index 1406370
#* Workshop BioDM'07: an overview
#@ Jinyan Li;Xiaohua Hu
#t 2007
#c 3
#! This edited volume contains the papers selected for presentation at the Second Workshop on Data Mining for Biomedical Applications (BioDM'07) held in Nanjing, China on 22nd of May 2007. The workshop was held in conjunction with the 11th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2007), a leading international conference in the areas of data mining and knowledge discovery. The aim of this workshop was to provide a forum for discussing research topics related to biomedical applications where data mining techniques were found to be necessary and/or useful.

#index 1406371
#* Extracting features from gene ontology for the identification of protein subcellular location by semantic similarity measurement
#@ Guoqi Li;Huanye Sheng
#t 2007
#c 3
#% 466336
#% 838571
#! It is necessary to find a computational method for prediction of protein subcellular location (SCL). Many researches have focused on the topic. Among them, methods incorporated Gene Ontology (GO) achieved higher prediction accuracy. However the former method of extracting features from GO have some disadvantages. In this paper, to increase the accuracy of the prediction, we present a novel method to extract features from GO by semantic similarity measurement, which is hopeful to overcome the disadvantages of former method. Testing on a public available dataset shows satisfied results. And this method can also be used in similar scenarios in other bioinformatics researches or data mining process.

#index 1406372
#* Detecting community structure in complex networks by optimal rearrangement clustering
#@ Rui-Sheng Wang;Yong Wang;Xiang-Sun Zhang;Luonan Chen
#t 2007
#c 3
#% 249110
#% 961165
#! Detecting community structure in biological and social networks recently attracts increasing attention in various fields including mathematics, physics and biology. Identifying communities in complex networks can help us to understand and exploit the networks more clearly and efficiently. In this paper, we introduced a method based on a combinatorial optimization problem -- traveling salesman problem (TSP) as optimal rearrangement clustering for finding community structure in complex networks. This method can explore the global topology of a network and thus is effective in detecting modularity structure. Unlike most other algorithms for community identification, an advantage of this method is that it does not need to spend much time in finding a proper k, the number of communities in a network. We applied this method to several widely well-studied networks including a protein-protein interaction network, which demonstrates that this method is effective in detecting meaningful communities or functional modules.

#index 1406373
#* The HIV data mining tool for government decision-making support
#@ Huijun Liu;Qunying Xiao;Zhengwei Zhu
#t 2007
#c 3
#! To explore more effective policies on HIV epidemic control, this paper designs a new HIV data mining tool for decision-making support at the basis of SIR epidemic dynamical model, and then make it operate in the context of Shenzhen China from 1992 to 2005. Its predicting function proves power and effective by comparing with GM(1, 1) model and general dynamical model, and its identifying function and prioritizing function also pass the test in Shenzhen context.

#index 1406374
#* Negative localized relationship among p70S6 with smad1, 2, 3 and p38 in three treated human cancer cell lines
#@ Lin Wang;Minghu Jiang;Stefan Wolfl;Yinghua Lu
#t 2007
#c 3
#! P70S6 with Smad1, 2, 3 and p38 as very hot and important multi-function proteins are widely studied now. Protein localization is fundamentally important to eukaryotic protein function and cell regulation. In this paper, the relationship among p70S6 with Smad1, 2, 3 and p38 in Three Treated Human Cancer Cell Lines was studied using western blot, FACS and nano-gold phosphoantibody microarray by reaction with our purification of nuclear and cytoplasmic protein as follows: P-p70S6 nuclear decrease whereas p-p38, p-smad1 and p-smad2/3 nuclear expression increase in BMP2-induced apoptosis U937 cells (2000ng/ml BMP2 for 3 days) and in STI571-inhibited cell growth and-induced proliferation of K562 cells (0.2 uM STI571 for 24h). P-p70S6 only cytoplasmic increases whereas p-p38, p-smad1 and p-smad2/3 cytoplasmic inhibition by nuclear decrease and cytoplasmic increase under total protein unchanged in BMP2-induced cell survival and differentiated MCF7 cells (100ng/ml BMP2 for 4h). This result implies the negative localized relationship among p70S6 with Smad1, 2, 3 and p38 in three treated human cancer cell lines.

#index 1406375
#* Cancer identification based on DNA microarray data
#@ Yihui Liu
#t 2007
#c 3
#% 832996
#% 906386
#! In this study we perform wavelet transform on the analysis of DNA microarray data. A set of wavelet features is used to measure the change of gene expression profile. Then wavelet features are input to support vector machine (SVM) to classify DNA microarray data into different diagnostic classes. Experiments are carried out on six datasets of microarray data. On a wide range of data sets, our method displays a highly competitive accuracy in comparison to the best performance of other kinds of classification models.

#index 1406376
#* Incorporating dictionary features into conditional random fields for gene/protein named entity recognition
#@ Hongfei Lin;Yanpeng Li;Zhihao Yang
#t 2007
#c 3
#% 278107
#% 464434
#% 466892
#% 855108
#% 1223727
#% 1223733
#% 1223735
#% 1288629
#! Biomedical Named Entity Recognition (BioNER) is an important preliminary step for biomedical text mining. Previous researchers built dictionaries of gene/protein names from online databases and incorporated them into machine learning models as features, but the effects were very limited. This paper gives a quality assessment of four dictionaries derived form online resources, and investigate the impacts of two factors (i.e., dictionary coverage and noisy terms) that may lead to the poor performance of dictionary features. Experiments are performed by comparing performances of the external dictionaries and a dictionary derived from GENETAG corpus, using Conditional Random Fields (CRFs) with dictionary features. We also make observations of the impacts regarding long names and short names. The results show that low coverage of long names and noises of short names are the main problems of current online resources and a high quality dictionary could substantially improve the accuracy of BioNER.

#index 1406377
#* Translation and rotation invariant mining of frequent trajectories: application to protein unfolding pathways
#@ Alexander Andreopoulos;Bill Andreopoulos;Aijun An;Xiaogang Wang
#t 2007
#c 3
#% 300174
#% 342635
#% 463903
#% 479799
#% 481290
#% 629630
#% 660658
#% 729931
#% 765451
#% 769899
#% 844292
#% 937128
#% 1188997
#! We present a framework for mining frequent trajectories, which are translated and/or rotated with respect to one another. We then discuss a multiresolution methodology, based on the wavelet transformation, for speeding up the discovery of frequent trajectories. We present experimental results using noisy protein unfolding trajectories and synthetic datasets. Our results demonstrate the effectiveness of the proposed approaches for finding frequent trajectories. A multiresolution mining strategy provides significant mining speed improvements.

#index 1406378
#* Genetic-annealing algorithm for 3D off-lattice protein folding model
#@ Xiaolong Zhang;Xiaoli Lin;Chengpeng Wan;Tingting Li
#t 2007
#c 3
#% 1734526
#! This paper presents a model used to deal with three-dimensional off-lattice AB protein folding. The model is extended from genetic-annealing algorithm that is for the two-dimensional off-lattice AB protein model. The three-dimensional model also has only two types of residues, hydrophobic and hydrophilic. Based on a physical model, the problem is converted from a nonlinear constraint-satisfied problem to an unconstrained optimization problem. Also, in contrast to earlier studies using off-lattice AB models, our results demonstrate that the proposed methods are very promising for searching the ground states of protein folding in three dimensions.

#index 1406379
#* Biclustering of microarray data based on singular value decomposition
#@ Wen-Hui Yang;Dao-Qing Dai;Hong Yan
#t 2007
#c 3
#% 397632
#% 469422
#% 778215
#% 832775
#! Biclustering is an important approach in microarray data analysis. Using biclustering algorithms, one can identify sets of genes sharing compatible expression patterns across subsets of samples. These patterns may provide clues about the main biological processes associated to different physiological states. In this study, we present a new biclustering algorithm to identify local structures from gene expression data set. Our method uses singular value decomposition (SVD) as its framework. Based on the singular value decomposition, identifying bicluster problem from gene expression matrix is transformed into two global clustering problems. After biclustering, our algorithm forms blocks of up-regulated or down-regulated in gene expression matrix, so as to infer that which genes are co-regulated and which genes possibly are functionally related. The experimental results on three benchmark datasets (Human Tissues, Lymphoma, Leukemia) demonstrate good visualization and interpretation ability.

#index 1406380
#* On the number of partial least squares components in dimension reduction for tumor classification
#@ Xue-Qiang Zeng;Guo-Zheng Li;Geng-Feng Wu;Hua-Xing Zou
#t 2007
#c 3
#% 957813
#% 1185335
#! Dimension reduction is important during the analysis of gene expression microarray data, because the high dimensionality of data sets hurts the generalization performance of classifiers. Partial Least Squares (PLS) based dimension reduction is a frequently used method, since it is specialized in handling high dimensional data set and leads to satisfying classification performance. This paper investigates the influence on generalization performance caused by the variation of the number of PLS components and the relationship between classification performance and regression quality of PLS on the training set. Experimental results show that the number of PLS components for classifiers can be automatically determined by regression quality of PLS latent variables.

#index 1406381
#* Mining biosignal data: coronary artery disease diagnosis using linear and nonlinear features of HRV
#@ Heon Gyu Lee;Ki Yong Noh;Keun Ho Ryu
#t 2007
#c 3
#% 136350
#% 309208
#% 466483
#% 1650277
#% 1693380
#! The main purpose of our study is to propose a novel methodology to develop the multi-parametric feature including linear and nonlinear features of HRV (Heart Rate Variability) diagnosing cardiovascular disease. To develop the multi-parametric feature of HRV, we used the statistical and classification techniques. This study analyzes the linear and the non-linear properties of HRV for three recumbent positions, namely the supine, left lateral and right lateral position. Interaction effect between recumbent positions and groups (normal and patients) was observed based on the HRV indices and the extracted HRV indices used to classify the CAD (Coronary Artery Disease) group from the normal people. We have carried out various experiments on linear and non-linear features of HRV indices to evaluate several classifiers, e.g., Bayesian classifiers, CMAR, C4.5 and SVM. In our experiments, SVM outperformed the other classifiers.

#index 1406382
#* High performance data mining and applications overview
#@ Chao Xie;Jieyue He
#t 2007
#c 3
#! International workshop on High Performance Data Mining and Applications (HPDMA 2007) was held in conjunction with The 11th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2007), Nanjing, China, May 2007. The workshop aimed at sharing and comparing experiences on high performance data mining methods and applications from both algorithmic and system perspectives. In summary, the workshop gave a discussion forum for researchers working on both data mining and high performance computing where the attendees discussed various aspects on high performance data mining.

#index 1406383
#* Approximately mining recently representative patterns on data streams
#@ Jia-Ling Koh;Yuan-Bin Don
#t 2007
#c 3
#% 201894
#% 481290
#% 502147
#% 729418
#% 729959
#% 730046
#% 824710
#% 993960
#% 1692982
#! Catching the recent trend of data is an important issue when mining frequent itemsets from data streams. To prevent from storing the whole transaction data within the sliding window, the frequency changing point (FCP) method was proposed for monitoring the recent occurrences of itemsets in a data stream under the assumption that exact one transaction arrives at each time point. In this paper, the FCP method is extended for maintaining recent patterns in a data stream where a block of various numbers of transactions (including zero or more transactions) is inputted within each time unit. Moreover, to avoid generating redundant information in the mining results, the recently representative patterns are discovered from the maintained structure approximately. The experimental results show that our approach reduces the run-time memory usage significantly. Moreover, the proposed GFCP algorithm achieves high accuracy of mining results and guarantees no false dismissal occurring.

#index 1406384
#* Finding frequent items in data streams using ESBF
#@ ShuYun Wang;XiuLan Hao;HeXiang Xu;YunFa Hu
#t 2007
#c 3
#% 307424
#% 322884
#% 479795
#% 492912
#% 548479
#% 569754
#% 576119
#% 642409
#% 654461
#% 730046
#% 857496
#% 993960
#% 1016146
#! In this paper, we introduce a novel data structure, ESBF (Ex- tensible and Scalable Bloom Filter), and the algorithm FI-ESBF (Finding frequent Items using ESBF) for estimating the frequent items in data streams. FI-ESBF can work with high precision while using much less memory than those of the best reported algorithm does considering the large number of distinct items in the stream. ESBF is the extension of counting Bloom Filter(CBF), By using it, we are allowed to adjust the size of memory used dynamically according to the different data distribution and the number of distinct items in the data streams, therefore the priori knowledge about the data distribution of the streams and the number of distinct elements to be stored is not required.

#index 1406385
#* A new decision tree classification method for mining high-speed data streams based on threaded binary search trees
#@ Tao Wang;Zhoujun Li;Xiaohua Hu;Yuejin Yan;Huowang Chen
#t 2007
#c 3
#% 129980
#% 136350
#% 280498
#% 310500
#% 342600
#% 378388
#% 391425
#% 449529
#% 453512
#% 459008
#% 540092
#% 654489
#% 654507
#% 729932
#% 729965
#% 729973
#% 769927
#% 824795
#% 972652
#% 998631
#% 1016144
#% 1016245
#% 1780725
#! One of most important algorithms for mining data streams is VFDT. It uses Hoeffding inequality to achieve a probabilistic bound on the accuracy of the tree constructed. Gama et al. have extended VFDT in two directions. Their system VFDTc can deal with continuous data and use more powerful classification techniques at tree leaves. In this paper, we revisit this problem and implemented a system VFDTt on top of VFDT and VFDTc. We make the following three contributions: 1) we present a threaded binary search trees (TBST) approach for efficiently handling continuous attributes. It builds a threaded binary search tree, and its processing time for values inserting is O(nlogn), while VFDT's processing time is O(n$sup2$esup). When a new example arrives, VFDTc need update O(logn) attribute tree nodes, but VFDTt just need update one necessary node.2) we improve the method of getting the best split-test point of a given continuous attribute. Comparing to the method used in VFDTc, it improves from O(nlogn) to O (n) in processing time. 3) Comparing to VFDTc, VFDTt's candidate split-test number decrease from O(n) to O(logn). Comparing to VFDT, the most relevant property of our system is an average reduction of 25.53% in processing time, while keep the same tree size and accuracy. Overall, the techniques introduced here significantly improve the efficiency of decision tree classification on data streams.

#index 1406386
#* Progressive subspace skyline clusters mining on high dimensional data
#@ Rong Hu;Yansheng Lu;Lei Zou;Chong Zhou
#t 2007
#c 3
#% 2115
#% 288976
#% 333854
#% 465167
#% 799759
#% 824671
#% 824672
#% 993954
#% 1716958
#! Skyline queries have caused much attention for it helps users make intelligent decisions over complex data. Unfortunately, too many or too few skyline objects are not desirable for users to choose. Practically, users may be interested in the skylines in the subspaces of numerous candidate attributes. In this paper, we address the important problem of recommending skyline objects as well as their neighbors in the arbitrary subspaces of high dimensional space. We define a new concept, subspace skyline cluster, which is a compact and meaningful structure to combine the advantages of skyline computation and data mining. Two algorithms Sorted-based Subspace Skyline Clusters Mining, and Threshold-based Subspace Skyline Clusters Mining are developed to progressively identify the skyline clusters. Our experiments show that our proposed approaches are both efficient and effective.

#index 1406387
#* Efficient privacy preserving distributed clustering based on secret sharing
#@ Selim V. Kaya;Thomas B. Pedersen;Erkay Savaş;Yücel Saygin
#t 2007
#c 3
#% 300184
#% 319849
#% 428404
#% 576111
#% 727929
#% 729930
#% 751578
#% 772829
#% 805092
#% 864664
#% 1279283
#% 1721181
#! In this paper, we propose a privacy preserving distributed clustering protocol for horizontally partitioned data based on a very efficient homomorphic additive secret sharing scheme. The model we use for the protocol is novel in the sense that it utilizes two noncolluding third parties. We provide a brief security analysis of our protocol from information theoretic point of view, which is a stronger security model. We show communication and computation complexity analysis of our protocol along with another protocol previously proposed for the same problem. We also include experimental results for computation and communication overhead of these two protocols. Our protocol not only out-performs the others in execution time and communication overhead on data holders, but also uses a more efficient model for many data mining applications.

#index 1406388
#* SePMa: an algorithm that mining sequential processes from hybrid log
#@ Xiaoyu Huang;Huiling Zhong;Wenxue Cai
#t 2007
#c 3
#% 203029
#% 258498
#% 543959
#% 704468
#% 733140
#! To accommodate ourselves to the changeful and complex business environment, we should be able adjust the business processes within the enterprise whenever changes happen. However, the work to design and redesign the processes is far from trivial, the designers are required to have deep knowledge of the business processes at hand, in traditional approaches it means long term investigation and high cost. To automate the procedure of process discovery, process mining is introduced. Process mining takes the run-time log generated by the process management system as its input, and outputs the process models defined for the system. Unfortunately, current work on process mining often assumes that the input log is generated by the same process, but in many occasions this requisition is hard to be satisfied. In this paper, we propose SePMa, an algorithm that mining sequential processes from hybrid log. SePMa aims at discovering sequential processes from log generated by multiple processes, both of theoretical analysis and experimental results show that SePMa has very high efficiency and effectiveness.

#index 1406389
#* Evaluate structure similarity in XML documents with merge-edit-distance
#@ Chong Zhou;Yansheng Lu;Lei Zou;Rong Hu
#t 2007
#c 3
#% 66654
#% 466651
#% 480496
#% 1349285
#% 1390176
#% 1713092
#! XML language is widely used as a standard for data representation and exchange among Web applications. In recent years, many efforts have been spent in querying, integrating and clustering XML documents. Measuring the similarity among XML documents is the foundation of such applications. In this paper, we propose a new similarity measure method among the XML documents, which is based on Merge-Edit-Distance (MED). MED upholds the distribution information of the common tree in XML document trees. We urge the distribution information is useful for determining the similarity of XML documents. A novel algorithm is also proposed to calculate MED as follows. Given two XML document trees A and B, it compresses the two trees into one merge tree C and then transforms the tree C to the common tree of A and B with the defined operations such as "Delete", "Reduce", "Combine". The cost of the operation sequence is defined as MED. The experiments on real datasets give the evidence that the proposed similarity measure is effective.

#index 1406390
#* Ensemble learning based distributed clustering
#@ Genlin Ji;Xiaohan Ling
#t 2007
#c 3
#% 479863
#% 580509
#% 745793
#% 799757
#% 837616
#% 844314
#! Data mining techniques such as clustering are usually applied to centralized data sets. At present, more and more data is generated and stored in local sites. The transmission of the entire local data set to server is often unacceptable because of performance considerations, privacy and security aspects, and bandwidth constraints. In this paper, we propose a distributed clustering model based on ensemble learning, which could analyze and mine distributed data sources to find global clustering patterns. A typical scenario of the distributed clustering is a 'two-stage' course, i.e. firstly doing clustering in local sites and then in global site. The local clustering results transmitted to server site form an ensemble and combining schemes of ensemble learning use the ensemble to generate global clustering results. In the model, generating global patterns from ensemble is mathematically converted to be a combinatorial optimization problem. As an implementation for the model, a novel distributed clustering algorithm called DK-means is presented. Experimental results show that DK-means achieves similar results to K-means which clusters centralized data set at a time and is scalable to data distribution varying in local sites, and show validity of the model.

#index 1406391
#* Deploying mobile agents in distributed data mining
#@ Xining Li;JingBo Ni
#t 2007
#c 3
#% 50726
#% 462959
#% 724049
#% 1698052
#! Mining information from distributed data sources over the Internet is a growing research area. The introduction of mobile agent paradigm opens a new door for distributed data mining and knowledge discovery applications. In this paper, we present the design of a mobile agent system, which couples a logic language based application programming interface for service discovery and database access. Our proposal aims at implementing system tools to enable intelligent mobile agents to search for distributed data services, to roams the Internet for accessing distributed data sites, to discover patterns and extract useful information from facts recorded in databases, to generate global data model through the communication and aggregation of local results, and to overcome the barriers posed by network congestion, poor security and unreliability.

#index 1406392
#* ODDC: outlier detection using distance distribution clustering
#@ Kun Niu;Chong Huang;Shubo Zhang;Junliang Chen
#t 2007
#c 3
#% 300136
#% 331909
#% 775363
#% 783516
#% 789012
#% 818916
#% 823340
#% 845217
#% 881506
#! Outlier detection is an important issue in many industrial and financial applications. Most outlier detection methods suffer from two problems: First, they need parameter tuning in accord to domain knowledge. Second, they are incapable to scale up to high dimensional space. In this paper, we propose a distance-based outlier definition and a detection algorithm ODDC (Distribution Clustering Outlier Detection). We redefine the problem by clustering in the distribution difference space rather than the original feature space. As a result, the new algorithm is stable regardless of different input and scalable to the dimensionality. Experiments on both synthetic and real datasets show that ODDC outperforms the counterpart both in effectiveness and efficiency.

#index 1406393
#* Spatial clustering with obstacles constraints using ant colony and particle swarm optimization
#@ Xueping Zhang;Jiayao Wang;Zhongshan Fan;Bin Li
#t 2007
#c 3
#% 311681
#% 465004
#% 623518
#% 629693
#% 900934
#% 1390197
#% 1777042
#! Spatial clustering is an important research topic in Spatial Data Mining (SDM). This paper proposes an Ant Colony Optimization (ACO) and Particle Swarm Optimization (PSO) method for solving Spatial Clustering with Obstacles Constraints (SCOC). In the process of doing so, we first use improved ACO to obtain the shortest obstructed distance, which is an effective method for arbitrary shape obstacles, and then we develop a novel PKSCOC based on PSO and K-Medoids to cluster spatial data with obstacles. The PKSCOC algorithm can not only give attention to higher local constringency speed and stronger global optimum search, but also get down to the obstacles constraints and practicalities of spatial clustering. The experimental results demonstrate the effectiveness and efficiency of the proposed method, which performs better than Improved K-Medoids SCOC (IKSCOC) in terms of quantization error and has higher constringency speed than Genetic K-Medoids SCOC (GKSCOC).

#index 1406394
#* A high performance hierarchical cubing algorithm and efficient OLAP in high-dimensional data warehouse
#@ Kongfa Hu;Zhenzhi Gong;Qingli Da;Ling Chen
#t 2007
#c 3
#% 223781
#% 273916
#% 333925
#% 333962
#% 342735
#% 420053
#% 654446
#% 993996
#% 1015294
#% 1016173
#! Data cube has been playing an essential role in fast OLAP (online analytical processing) in many data warehouses. The pre-computation of data cubes is critical for improving the OLAP response time of in large high-dimensional data warehouses. However, as the sizes of data warehouses grow, the time it takes to perform this pre-computation becomes a significant performance bottleneck. In a high dimensional data warehouse, it might not be practical to build all these cuboids and their indices. In this paper, we propose a hierarchical cubing algorithm to partition the high dimensional data cube into low dimensional cube segments. It permits a significant reduction of CPU and I/O overhead for many queries by restricting the number of cube segments to be processed for both the fact table and bitmap indices. Experimental results show that the proposed method is significantly more efficient than other existing cubing methods.

#index 1406395
#* Grid-based clustering algorithm based on intersecting partition and density estimation
#@ Bao-Zhi Qiu;Xiang-Li Li;Jun-Yi Shen
#t 2007
#c 3
#% 248792
#% 479799
#% 479962
#% 566128
#% 794934
#% 797760
#% 819869
#% 824934
#% 1861495
#! In order to solve the problem that traditional grid-based clustering techniques lack of the capability of dealing with data of high dimensionality, we propose an intersecting grid partition method and a density estimation method. The partition method can greatly reduce the number of grid cells generated in high dimensional data space and make the neighbor-searching easily. On basis of the two methods, we propose grid-based clustering algorithm (GCOD), which merges two intersecting grids according to density estimation. The algorithm requires only one parameter and the time complexity is linear to the size of the input data set or data dimension. The experimental results show that GCOD can discover arbitrary shapes of clusters and scale well.

#index 1406396
#* Depth first generation of frequent patterns without candidate generation
#@ Qunxiong Zhu;Xiaoyong Lin
#t 2007
#c 3
#% 152934
#% 201894
#% 227917
#% 300120
#% 310507
#% 466490
#% 481290
#% 481754
#% 481779
#% 765529
#% 938976
#% 943882
#% 945709
#% 955316
#! Mining frequent patterns has been studied popularly in data mining research. Most of the current studies adopt an FP_growth-like approach which does not bring the candidate generation. However, the cost of recursively constructing each frequent item's conditional frequent pattern tree is high. In this paper, we propose a depth first algorithm for mining frequent patterns. Efficiency of mining is achieved with the following techniques: large database is compressed into a frequent pattern tree with a children table but not a header table, which avoids costly repeated database scans, on the other hand the mining algorithm adopts a depth first method which takes advantage of this tree structure and dynamically adjusts links instead of generating a lot of redundant sub trees, which can dramatically reduces the time and space needed for the mining process. The performance study shows that our algorithm is efficient and scalable for mining frequent patterns, and is an order of magnitude faster than Trie, FP_growth, H-mine and some recently reported new frequent patterns mining methods.

#index 1406397
#* Efficient time series data classification and compression in distributed monitoring
#@ Sheng Di;Hai Jin;Shengli Li;Jing Tie;Ling Chen
#t 2007
#c 3
#% 70370
#% 86950
#% 214595
#% 460862
#% 477968
#% 481609
#% 631923
#% 632089
#% 774178
#% 822359
#% 1391414
#% 1672115
#! As a key issue in distributed monitoring, time series data are a series of values collected in terms of sequential time stamps. Requesting them is one of the most frequent requests in a distributed monitoring system. However, the large scale of these data users request may not only cause heavy loads to the clients, but also cost long transmission time. In order to solve the problem, we design an efficient two-step method: first classify various sets of time series according to their sizes, and then compress the time series with relatively large size by appropriate compression algorithms. This two-step approach is able to reduce the users' response time after requesting the monitoring data, and the compression effects of the algorithms designed are satisfactory.

#index 1406398
#* Best-match method used in co-training algorithm
#@ Hui Wang;Liping Ji;Wanli Zuo
#t 2007
#c 3
#% 252011
#% 280817
#% 304917
#% 311027
#% 316509
#% 344447
#% 458369
#% 464641
#% 466263
#% 727883
#% 754077
#% 856251
#! Since 1998 there has been significant interest in supervised learning algorithms that combine labeled and unlabeled data for text learning tasks. The co-training algorithm applied to datasets which have a natural separation of their features into two disjoint sets. In this paper, we demonstrate that when learning from labeled and unlabeled data using co-training algorithm, selecting those document examples first which have two parts of best matching features can obtain a good performance.

#index 1406399
#* A general method of mining Chinese web documents based on GA&SA and position-factors
#@ Xi Bai;Jigui Sun;Haiyan Che;Jin Wang
#t 2007
#c 3
#% 511671
#% 833412
#% 838545
#% 1681516
#% 1703144
#% 1713828
#! Clustering and classification are two important techniques of mining Web information. In this paper, a new adaptive method of mining Chinese documents from the internet is proposed. First, we give an algorithm of clustering documents which combines Genetic Algorithm(GA) and Simulated Annealing(SA) based on Boolean Model. This Algorithm avoids the disadvantage of clustering documents by using pure GA which can not be utilized accurately since GA converges too early and bogs the local optimum. Then, considering that the effect of classification with traditional Vector Space Model(VSM) is not satisfying enough since it is not related to the grades of importance of words, we add the position-factors of key words into VSM and set up a new classifier model to classify Chinese Web documents. Experimental results indicate that this adaptive method can make the process of clustering and classification more accurate and reasonable comparing to the methods which does not have the positions of words considered.

#index 1406400
#* Data management services in ChinaGrid for data mining applications
#@ Song Wu;Wei Wang;Muzhou Xiong;Hai Jin
#t 2007
#c 3
#% 318118
#% 610818
#% 822359
#% 843819
#% 898479
#% 898480
#% 1656089
#! Grid systems, as large-scale distributed computing environments, are widely used by data mining communities. This paper proposes a set of system-level Grid services to form an infrastructure supporting data-intensive applications and data mining. ChinaGrid, aiming at integrate heterogeneous massive resources distributed on China Education and Research Network (CERNET), is a national-wide Grid project supported by the Chinese government. ChinaGrid Supporting Platform (CGSP) is a Grid middleware developed for the ChinaGrid.It provides a series of system-level services of the ChinaGrid, helps to build application portals and integrate Grid resources, and supports the secondary development of Grid services. The Data Management Services (DMS) is a group of Grid services in CGSP to manage storage and data resources, support transparent data access, and guarantee high-performance data transfer on the Grid. It consists of metadata management service, storage resource management service, replication management service, storage agent and transfer client. It offers the fundamental support for data mining applications on ChinaGrid. In this paper, we introduce the design principle and implementation of DMS.

#index 1406401
#* Two-phase algorithms for a novel utility-frequent mining model
#@ Jieh-Shan Yeh;Yu-Chiang Li;Chin-Chen Chang
#t 2007
#c 3
#% 152934
#% 227917
#% 329598
#% 330332
#% 447910
#% 481290
#% 577234
#% 729418
#% 824931
#% 907641
#% 1656318
#% 1699270
#% 1707858
#! When companies seek for the combination of products which can constantly generate high profit, the association rule mining (ARM) or the utility mining will not achieve such task. ARM mines frequent itemsets without knowing the producing profit. On the other hand, the utility mining seeks high profit items but no guarantee the frequency. In this paper, we propose a novel utility-frequent mining model to identify all itemsets that can generate a user specified utility in transactions, in which the percentage of such transactions in database is not less than a minimum support threshold. A utility-frequent itemset indicates that such combination of products can constantly generate high profit. For finding all utility-frequent itemsets, there is no efficient strategy due to the nonexistence of "downward/upward closure property". In order to tackle such challenge, we propose a bottom-up two-phase algorithm, BU-UFM, for efficiently mining utility-frequent itemsets. We also introduce a novel concept, quasi-utility-frequency, which is upward closed with respect to the lattice of all itemsets. In fact, each utility-frequent itemset is also quasi-utility-frequent. A top-down two-phase algorithm, TD-UFM, for mining utility-frequent itemsets is also presented in the paper.

#index 1406402
#* Top-down and bottom-up strategies for incremental maintenance of frequent patterns
#@ Qunxiong Zhu;Xiaoyong Lin
#t 2007
#c 3
#% 152934
#% 201894
#% 300120
#% 464204
#% 481290
#% 481754
#% 481779
#% 482641
#% 938976
#% 943882
#% 945709
#% 955316
#! Mining frequent patterns has been studied popularly in data mining research. For getting the real useful frequent patterns, one must continually adjust a minimum support threshold. Costly and repeated database scans were done due to not maintaining the frequent patterns discovered. In this paper, we first propose a top-down algorithm for mining frequent patterns, and then present a hybrid algorithm which takes top-down and bottom-up strategies for incremental maintenance of frequent patterns. Efficiency is achieved with the following techniques: large database is compressed into a highly condensed and dynamic frequent pattern tree structure, which avoids repeated database scans, the top-down mining approach adopts a depth first method to avoid the recursive construction and materialization of conditional frequent pattern trees, which dramatically reduces the mining cost. The performance study shows that our algorithm is efficient and scalable for mining frequent patterns, and is an order of magnitude faster than FP_growth and Re-mining.

#index 1406403
#* GC-tree: a fast online algorithm for mining frequent closed itemsets
#@ Junbo Chen;ShanPing Li
#t 2007
#c 3
#% 429873
#% 481290
#% 629611
#% 729933
#% 843874
#% 878942
#% 881520
#! Frequent closed itemsets is a complete and condensed representaion for all the frequent itemsets, and it's important to generate non-redundant association rules. It has been studied extensively in data mining research, but most of them are done based on traditional transaction database environment and thus have performance issue under data stream environment. In this paper, a novel approach is proposed to mining closed frequent itemsets over data streams. It is an online algorithm which update frequent closed itemsets incrementally, and can output the current closed frequent itemsets in real time based on users specified thresholds. The experimental evaluation shows that our proposed method is both time and space efficient, compared with the state of art online frequent closed itemsets algorithm FCI-Stream [3].

#index 1406404
#* Integration of distributed biological data using modified K-means algorithm
#@ Jongil Jeong;Byunggul Ryu;Dongil Shin;Dongkyoo Shin
#t 2007
#c 3
#% 434347
#% 717405
#! The goals of bioinformatics are the solving of biological questions and the active driving of the work of biologists by offering search and analysis methods for research data. The internet brings us distributed environments in which we can access the databases of various research groups. However, a very large quantity of data always causes trouble, creating crucial problems, such as problems with the search for and analysis of data in these distributed environments. Data clustering can be a solution when searching for data. However, this task is very tedious because its execution time is directly proportional to the volume of data. In this paper we propose a distributed clustering scenario and a modified K-means algorithm for the efficient clustering of biological data, and demonstrate the enhancement in performance that it brings.

#index 1406405
#* A parallel algorithm for enumerating all the maximal k-plexes
#@ Bin Wu;Xin Pei
#t 2007
#c 3
#% 322619
#% 1558532
#! Finding and enumerating subgraphs of different structures in a graph or a network is one of the fundamental problems in combinatorics. One of the earliest subgraph models is clique. However, the clique approach has been criticized for its overly restrictive nature. k-plex is one of the models which are introduced by weakening the requirement of clique. The problem to enumerate all the maximal k-plexes is NP complete. We consider this problem and propose an algorithm Pemp (Parallel Enumeration of all Maximal k-Plexes) for enumerating all the maximal k-plexes. We also propose a strategy to accelerate the pruning. A diameter pruning strategy is proposed. This strategy reduces the number of small maximal k-plexes and improves the performance greatly. We also state the parallel edition of our algorithm to analysis large networks and a load balancing strategy is given. In addition, we evaluate the performance of Pemp on random graphs.

#index 1406406
#* A multi-dependency language modeling approach to information retrieval
#@ Keke Cai;Chun Chen;Jiajun Bu;Guang Qiu;Peng Huang
#t 2007
#c 3
#% 35937
#% 109190
#% 262096
#% 287253
#% 340899
#% 340948
#% 397205
#% 413593
#% 756821
#% 766428
#% 818240
#! This paper presents a multi-dependency language modeling approach to information retrieval. The approach extends the basic KL-divergence retrieval approach by introducing the hybrid dependency structure, which includes syntactic dependency, syntactic proximity dependency and co-occurrence dependency, to describe dependencies between terms. Term and dependency language models are constructed for both document and query. The relevant between a document and a query is then evaluated by using the KL-divergence between their corresponding models. The new dependency retrieval model has been compared with other traditional retrieval models. Experiment results indicate that it produces significant improvements in retrieval effectiveness.

#index 1406407
#* Factoid mining based content trust model for information retrieval
#@ Wei Wang;Guosun Zeng;Mingjun Sun;Huanan Gu;Quan Zhang
#t 2007
#c 3
#% 268079
#% 290830
#% 316798
#% 807296
#% 869519
#% 1693106
#% 1713504
#! Trust is an integral component in many kinds of human interactions and the need for trust spans all aspects of computer science. While most prior work focuses on entity-centered issues such as authentication and reputation, it does not model the information itself, which can be also regarded as quality of information. This paper discusses content trust as a factoid ranking problem. Factoid here refers to something which can reflect the truth of the content, such as the definition of one thing. We extracts factoid from documents' content and then rank them according to their likehood as a trustworthy ones. Learning methods for performing factoid ranking are proposed in this paper. Trust features for judging the trustworthiness of a factoid is given, and features for constructing the Ranking SVM models are defined. Experimental results indicate the usefulness of this approach.

#index 1406408
#* Service, security and its data management for ubiquitous computing: overview
#@ Jong Hyuk Park;Deqing Zou
#t 2007
#c 3
#! International workshop on Service, Security and its Data management for Ubiquitous Computing (SSDU-07) was held in conjunction with The 11th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2007), Nanjing, China, May 22-25, 2007. The main purpose of this workshop (SSDU-07) was to foster research in the areas of security and intelligence integrating into Ubi-com and data management technology. In addition, the workshop provided an opportunity for academic and industry professionals to discuss the latest issues and progress in the area of Ubi-com, security, data management.

#index 1406409
#* Study on trust inference and emergence of economical small-world phenomena in P2P environment
#@ Yufeng Wang;Yoshiaki Hori;Kouichi Sakurai
#t 2007
#c 3
#% 528450
#% 577367
#% 722146
#% 753425
#% 754098
#% 823842
#% 882441
#% 912553
#% 943777
#% 974926
#% 1388586
#% 1712579
#! With the increasing popularity of self-organized communication systems, distributed trust and reputation systems in particular have received increasing attention. By formalizing trust relationships, trust between parties within the community can be derived by analyzing the trust paths linking the parties together. This paper treats trust network as an emergent property. The emergence interpretation concerns both the maintenance and usage of trust network inference. Specifically, in P2P system, trust network is maintained by individual agents at micro level, and it is used (i.e., queried) as one entity at macro level. In this paper, we first discuss micro level activities, that is, we classifies trust into functional trust and referral trust to facilitate trust inference, and extend the referral trust to include factors of similarity and truthfulness, so that our approach can accommodate the personalized feature of reputation rating, and reduce trust inference error effectively; then we discuss macro level properties of trust network. Specifically, we investigate the emergence of network structural properties of trust and reputation system in terms of efficiency and cost. That is, efficiency measures how well information propagates over trust system, and cost measures how expensive it is to build this system. Preliminary simulation results show the performance improvement of P2P community and the emergence of economical small-world trust network, namely relatively high efficiency and low cost.

#index 1406410
#* A secure time synchronization protocol for sensor network
#@ Hui Li;Yanfei Zheng;Mi Wen;Kefei Chen
#t 2007
#c 3
#% 414174
#% 616979
#% 629098
#% 720260
#% 725288
#% 731097
#% 751056
#% 822471
#% 840740
#% 1851260
#! Clock synchronization is a critical issue in most wireless sensor network applications. Although the synchronization is well studied in last few years. Most of these synchronization protocols assume benign environments, but cannot survive malicious attacks in hostile environments, especially when there are compromised nodes. In this paper, we propose a secure synchronization protocol for sensor network. Our protocol combine the sender-receiver model and receiver-receiver model to verify the synchronization process between each synchronizing pair. The approach guarantees that normal nodes can synchronize their clocks to global clock even if each normal node has up to t colluding malicious neighbor nodes during synchronization phase.

#index 1406411
#* On grid-based key pre-distribution: toward a better connectivity in wireless sensor network
#@ Abedelaziz Mohaisen;YoungJae Maeng;DaeHun Nyang
#t 2007
#c 3
#% 16010
#% 414367
#% 513708
#% 616979
#% 725288
#% 751056
#% 755710
#% 772633
#% 781890
#% 799889
#% 804727
#% 809538
#% 813163
#% 840736
#% 1740392
#! In this paper, we revisit Grid-Based Key Pre-Distribution Scheme in Wireless Sensor Network to investigate improving the connectivity of the network and maintain both the security level and communication overhead. Both of the original work and our modification are based on using symmetric bivariate polynomials for generating cryptographic keys. In addition, their work relies on the usage of multi-dimensional grid to assign the polynomials on the sensor nodes allocated on the intersections of the grid and provide a needed connectivity. In this work we consider the simplification of the key establishment logic, the enhancement of connectivity in what we call the plat polynomial assignment. We present detailed discussion on the connectivity, resources usage, and security features that shows better results on the side of the connectivity, intermediate node discovery and security measurement. Finally, we provide a comparison between our results and other existing solutions including the revisited scheme.

#index 1406412
#* A distributed and cooperative black hole node detection and elimination mechanism for ad hoc networks
#@ Chang Wu Yu;Tung-Kuang Wu;Rei Heng Cheng;Shun Chao Chang
#t 2007
#c 3
#% 633034
#% 1831294
#! A mobile node in ad hoc networks may move arbitrarily and acts as a router and a host simultaneously. Such a characteristic makes nodes in MANET vulnerable to potential attacks. The black hole problem, in which some malicious nodes pretend to be intermediate nodes of a route to some given destinations and drop any packet that subsequently goes through it, is one of the major types of attack. In this paper, we propose a distributed and cooperative mechanism to tackle the black hole problem. The mechanism is distributed so that it can fit with the ad hoc nature of network, and nodes in the protocol work cooperatively together so that they can analyze, detect, and eliminate possible multiple black hole nodes in a more reliable fashion. Simulation results show that our method achieves a high black hole detection rate and good packet delivery ratio, while the overhead is comparatively lower as the network traffic increases.

#index 1406413
#* A novel adaptive and safe framework for ubicomp
#@ Xuanhua Shi;Jean-Louis Pazat
#t 2007
#c 3
#% 345130
#% 401176
#% 433332
#% 433357
#% 433623
#% 452685
#% 571867
#% 571889
#% 623566
#% 908874
#% 1699083
#% 1719152
#% 1729898
#! Although ubiquitous computing is more and more attractive, ubicomp doesn't become really pervasive. There are many reasons for this, lack of distributed infrastructure is one of them. Grid Computing is a new promising and powerful distributed infrastructure, so the merge of these two technologies is going to make ubicomp really ubiquitous. This paper presents an adaptive framework, Dynasa, which handles the safety problems for high performance computing applications in ubicomp environment based on the adaptive replication management.

#index 1406414
#* Reducing inter-piconet delay for large-scale bluetooth scatternets
#@ Chang Wu Yu;Kun-Ming Yu;Shu Ling Lin
#t 2007
#c 3
#% 194370
#% 342009
#% 342010
#% 553324
#% 609344
#% 653666
#% 731562
#% 836124
#% 971889
#% 975263
#% 1288220
#% 1800269
#% 1832648
#% 1849537
#! When more than seven devices to be connected in a Bluetooth scatternet, bridge devices are used to connect two piconets into a scatternet. To deal with possible data transmissions between different piconets, the bridge device must switch to different masters frequently. Suppose that a bridge is serving a piconet and the master in another piconet is calling it at the same time, the calling master has to wait until the bridge completes the previous service. Such transmission delay may accumulate in a long period and the performance of the whole Bluetooth network will degrade significantly. This work tries to smooth the kind of transmission delay in Bluetooth network. This work proposes two new scheduling protocols: the static schedule and the hybrid schedule. This static schedule deals with this kind of coordination among piconets distributedly by applying edge coloring technique. In case of heavy traffic load, the static schedule is expected to perform well. On the other hand, in case of light traffic load, the static schedule may results in long and unavoidable routing delay even there is no transmission between piconets; thus a naive random round-robin schedule in each piconet becomes more appropriate in case of light traffic load. Thus, in the hybrid schedule, each master in its piconet runs round-robin scheme initially; when the traffic load is heavier than a predefined threshold value, it turn to run the static schedule. Also, a new graph model, delay graphs, is proposed to model and estimate the delay time required for the proposed scheduling schemes theoretically. Finally, we conduct simulations by using ns-2 simulator and Bluehoc to demonstrate the efficiency and effectiveness of the proposed scheduling protocols.

#index 1406415
#* Security analysis and enhancement of one-way hash based low-cost authentication protocol (OHLCAP)
#@ JeaCheol Ha;SangJae Moon;Juan Manuel Gonzalez Nieto;Colin Boyd
#t 2007
#c 3
#% 725293
#% 745976
#% 1669164
#% 1684257
#% 1693571
#% 1714708
#% 1718900
#! Choi et al. recently proposed an efficient RFID authentication protocol for a ubiquitous computing environment, OHLCAP (One-Way Hash based Low-Cost Authentication Protocol). However, this paper reveals that the protocol has several security weaknesses : 1) traceability based on the leakage of counter information, 2) vulnerability to an impersonation attack by maliciously updating a random number, and 3) traceability based on a physically-attacked tag. Finally, a security enhanced group-based authentication protocol is presented.

#index 1406416
#* An effective design of an active RFID reader using a cache of tag memory data
#@ Seok-Young Jang;Sang-Hwa Chung;Won-Ju Yoon;Seong-Joon Lee
#t 2007
#c 3
#% 644230
#% 825213
#! RFID (Radio Frequency Identification) is technology that a reader automatically identifies the data in a tag with a built-in microchip via a radio frequency. The relevant standards for 433 MHz active RFID are ISO/IEC 15961, 15962, and 18000-7. Communication between a reader and a tag in the management of active RFID tag memory data as defined by the standards is not efficient. In this paper, to address efficiency concerns, we present an active RFID reader software design to improve time and transmission rating of the ISO/IEC 18000-7 commands using memory data cached within the reader. We also present a method in which cached memory data are validated before use, to address the cache coherence issue when using multiple readers. For the identification method, we designed two models; one adheres to the RF-interface standard and the other modifies some fields of the RF-interface standard. We designed an active RFID reader and analyzed its efficiency through experiments based on the two models. The experimental results show that the performance on processing time and transmission rating of RF-interface improved by average 60% over the noncache design.

#index 1406417
#* Privacy protection scheme of RFID using random number
#@ Soo-Young Kang;Im-Yeong Lee
#t 2007
#c 3
#% 745976
#% 797103
#% 863143
#% 1669164
#% 1695820
#% 1714706
#! With the development in IT technology and with the growing demands of users, a ubiquitous environment is being made. Ubiquitous stands for a convenient environment in which users can get information and services through networks with devices that can communicate. This ubiquitous environment requires device technology, and Radio Frequency IDentification(RFID) is a good example. RFID, a technology that identifies radio frequency, was developed to substitute bar-codes and has various strengths, such as high recognition rates, quick recognition speed, and large storage. Because of these strengths, it is being used in various fields such as the public, distribution, and financial sectors; but it has a weakness in privacy, as readers operating within the same frequency bandwidth can be easily tagged. By acquiring information from the tag, unauthorized people can assess into the personal information of users. The current study, therefore, provides a secure and effective protection method, which can guarantee anonymity towards users with tags.

#index 1406418
#* A hierarchical composition of LU matrix-based key distribution scheme for sensor networks
#@ Mi Wen;Yanfei Zheng;Hui Li;Kefei Chen
#t 2007
#c 3
#% 414367
#% 616979
#% 628499
#% 799889
#% 809538
#% 1549227
#% 1674033
#% 1674337
#! Key pre-distribution techniques for sensing data security provision of wireless sensor networks (WSNs) have attracted much more attention and been studied extensively. But most of these schemes are not scalable due to their linearly increased communication and key storage overhead. Furthermore, existing protocols cannot provide sufficient security when the number of compromised nodes exceeds a critical value. To address these limitations, we propose a hierarchical composition of LU matrix-based key distribution scheme for sensor networks. Our scheme guarantees that two communicating parties can establish a unique pairwise key between them and allows mutual authentication. Compared with existing protocols, our scheme has better performance in terms of network resilience, associated overhead and scalability.

#index 1406419
#* Security framework for home network: authentication, authorization, and security policy
#@ Geon Woo Kim;Deok Gyu Lee;Jong Wook Han;Sang Choon Kim;Sang Wook Kim
#t 2007
#c 3
#% 632489
#! As a number of home network services are available and home network is expanding into ubiquitous computing environment, we need to protect home network system from illegal accesses and a variety of threats. Home network is exposed to various cyber attacks of Internet, involves hacking, malicious codes, worms, viruses, DoS attacks, and eavesdropping since it is connected to Internet. So in this paper, we propose a home network security framework for guaranteeing reliability and availability including authentication, authorization and security policy system.

#index 1406420
#* Bogus data filtering in sensor networks
#@ Yong Ho Kim;Jong Hwan Park;Dong Hoon Lee;Jongin Lim
#t 2007
#c 3
#% 745681
#% 1851036
#% 1851249
#! Recently, Zhang et al. proposed a location-based threshold-endorsement scheme (LTE) to thwart bogus data injection attacks. This scheme exhibits much greater filtering power than earlier symmetric schemes and results in enhanced energy savings. In this paper, we show that LTE has a significant vulnerability. We also propose an improved scheme that mitigates this weakness and thereby achieves the original claims of Zhang et al. without lessening LTE's remarkable filtering power.

#index 1406421
#* Streaming media securely over multipath multihop wireless network
#@ Binod Vaidya;SangDuck Lee;Eung-Kon Kim;SeungJo Han
#t 2007
#c 3
#% 786054
#% 907044
#% 941561
#% 1850753
#! With the rapid growth and popularity of wireless LANs (WLANs), the development of ubiquitous services is in demand. Mobile Ad hoc Networks (MANETs) are very attractive for many environments, such as home networking, emergency response scenarios etc. However, real-time voice communication is a critical application for many of these network scenarios. In this paper, we put forward a framework for secure audio streaming over multihop wireless network. And we propose an efficient multipath routing for MANET, while using scalable speech coding and selective encryption in secure RTP. With the simulation results, the performance of the proposed scheme is evaluated.

#index 1406422
#* Flexible selection of wavelet coefficients based on the estimation error of predefined queries
#@ Jaehoon Kim;Seog Park
#t 2007
#c 3
#% 248822
#% 257637
#% 378388
#% 480465
#% 824686
#% 1015261
#% 1015280
#% 1016178
#% 1778724
#! In this paper, we introduce a data stream reduction method using lossy wavelets compression. The lossy compression means that compressed data carry as much information about the original data stream as possible while the original data size remarkably reduced. We think that wavelets technique should be an efficient method for such lossy compression. Especially we consider storing a plenty of past data stream into stable storage (flash memory or micro HDD) rather than keeping only recent streaming data allowable in memory, because data stream mining and tracking of past data stream are often required. In the general method using wavelets, a specific amount of streaming data from a sensor is periodically compressed into fixed size and the fixed amount of compressed data is stored into stable storage. However, differently from the general method, our method flexibly adjusts the compressing size based on a heuristic criterion. Experimental results with some real stream data show that wavelets technique is useful in data stream reduction and our flexible approach has lower estimation error than the general fixed approach.

#index 1406423
#* Secured web services based on extended usage control
#@ Woochul Shin;Sang Bong Yoo
#t 2007
#c 3
#% 345972
#% 530946
#% 615865
#% 750874
#% 776240
#% 831918
#% 843005
#% 864557
#% 1089127
#! With the worldwide dissemination of Internet, Web Service has become a promising paradigm of ubiquitous computing. However, one major stumbling block of using Web Service in ubiquitous environment is the lack of security enforcement. In this paper, we introduce a systematic approach to enhance Web Service with the access control, user authentication, and session management. Delegation of access right among distributed security manager has been added to the Usage Control model and formal description of access control model is defined. A set of Web service operations is devised for procedural implementation of the security model. Using the proposed operations we show how SSO (Single Sign On) can be realized in ubiquitous computing environments.

#index 1406424
#* A digital rights management architecture for multimedia in P2P
#@ Cheng Yang;Jianbo Liu;Aina Sui;Yongbin Wang
#t 2007
#c 3
#% 614671
#! P2P content sharing is often blamed for copyright infringement, making the establishment of DRM technologies an urgent need. A PDRM (P2P- based Digital Rights Management) system is proposed with the support of Next Generation Internet Project. The system is based on a trust model that focuses on content security, rights management and access control. Encryption, digital watermarking, and packaging technologies are adopted to protect the confidentiality and integrity of contents, and support copyrights verifying and piracy tracing. The structure of rights management integrates the distributed and centralized modes, which not only reduces the burdens of networks and rights server, but also provides controllability. The contents downloaded on the P2P networks can be played only with rights control. To realize access control, the password and identity authentication are used. The PDRM system is implemented to prove that it can provide a more robust Intellectual Property protection solution for P2P content delivery.

#index 1411028
#* Proceedings of the 12th Pacific-Asia conference on Advances in knowledge discovery and data mining
#@ Takashi Washio;Akihiro Inokuchi;Einoshin Suzuki;Kai Ming Ting
#t 2008
#c 3

#index 1411029
#* Graph mining: laws, generators and tools
#@ Christos Faloutsos
#t 2008
#c 3

#index 1411030
#* Efficient algorithms for mining frequent and closed patterns from semi-structured data
#@ Hiroki Arimura
#t 2008
#c 3
#% 207408
#% 232136
#% 235377
#% 248809
#% 431001
#% 431105
#% 466644
#% 478622
#% 550412
#% 577218
#% 629617
#% 629656
#% 729938
#% 745515
#% 823401
#% 876064
#% 1405123
#% 1412479
#% 1718448
#% 1722426
#! In this talk, we study effcient algorithms that find frequent patterns and maximal (or closed) patterns from large collections of semi-structured data. We review basic techniques developed by the authors, called the rightmost expansion and the PPC-extension, respectively, for designing efficient frequent and maximal/closed pattern mining algorithms for large semi-structured data. Then, we discuss their applications to design of polynomial-delay and polynomial-space algorithms for frequent and maximal pattern mining of sets, sequences, trees, and graphs.

#index 1411031
#* Supporting creativity: towards associative discovery of new insights
#@ Michael R. Berthold;Fabian Dill;Tobias Kötter;Kilian Thiel
#t 2008
#c 3
#% 65946
#% 92135
#% 120104
#% 122797
#% 187767
#% 252328
#% 327474
#% 434615
#% 469402
#% 772131
#% 772132
#% 783790
#% 789241
#% 806990
#% 902433
#% 910877
#% 961343
#% 1692830
#! In this paper we outline an approach for network-based information access and exploration. In contrast to existing methods, the presented framework allows for the integration of both semantically meaningful information as well as loosely coupled information fragments from heterogeneous information repositories. The resulting Bisociative Information Networks (BisoNets) together with explorative navigation methods facilitate the discovery of links across diverse domains. In addition to such "chains of evidence", they enable the user to go back to the original information repository and investigate the origin of each link, ultimately resulting in the discovery of previously unknown connections between information entities of different domains, subsequently triggering new insights and supporting creative discoveries.

#index 1411032
#* Cost-sensitive classifier evaluation using cost curves
#@ Robert C. Holte;Chris Drummond
#t 2008
#c 3
#% 156186
#% 310519
#% 331909
#% 449588
#% 464472
#% 829984
#% 843876
#% 875974
#% 889275
#% 893461
#% 915229
#% 1404308
#% 1504987
#% 1669881
#% 1699621
#! The evaluation of classifier performance in a cost-sensitive setting is straightforward if the operating conditions (misclassification costs and class distributions) are fixed and known. When this is not the case, evaluation requires a method of visualizing classifier performance across the full range of possible operating conditions. This talk outlines the most important requirements for cost-sensitive classifier evaluation for machine learning and KDD researchers and practitioners, and introduces a recently developed technique for classifier performance visualization - the cost curve - that meets all these requirements.

#index 1411033
#* Prospective scientific methodology in knowledge society
#@ Genshiro Kitagawa
#t 2008
#c 3
#% 365015
#% 1212796
#! Due to rapid development of information and communication technologies, the methodology of scientific research and the society itself is changing. The present grand challenge is the development of the fourth methodology for scientific researches to create knowledge based on large scale massive data. To realize this, it is necessary to develop a method of integrating various types of information and of personalization, and the Bayes modeling is becoming the key technology. In the latter half of the paper, several time series examples are presented to show the importance of careful modeling that can take into account of essential information.

#index 1411034
#* SubClass: classification of multidimensional noisy data using subspace clusters
#@ Ira Assent;Ralph Krieger;Petra Welter;Jörg Herbers;Thomas Seidl
#t 2008
#c 3
#% 79440
#% 92533
#% 136350
#% 248792
#% 269218
#% 280417
#% 316709
#% 444007
#% 466483
#% 481290
#% 729437
#% 972281
#% 1117035
#% 1673621
#! Classification has been widely studied and successfully employed in various application domains. In multidimensional noisy settings, however, classification accuracy may be unsatisfactory. Locally irrelevant attributes often occlude class-relevant information. A global reduction to relevant attributes is often infeasible, as relevance of attributes is not necessarily a globally uniform property. In a current project with an airport scheduling software company, locally varying attributes in the data indicate whether flights will be on time, delayed or ahead of schedule. To detect locally relevant information, we propose combining classification with subspace clustering (SubClass). Subspace clustering aims at detecting clusters in arbitrary subspaces of the attributes. It has proved to work well in multidimensional and noisy domains. However, it does not utilize class label information and thus does not necessarily provide appropriate groupings for classification. We propose incorporating class label information into subspace search. As a result we obtain locally relevant attribute combinations for classification. We present the SubClass classifier that successfully exploits classifying subspace cluster information. Experiments on both synthetic and real world datasets demonstrate that classification accuracy is clearly improved for noisy multidimensional settings.

#index 1411035
#* Mining quality-aware subspace clusters
#@ Ying-Ju Chen;Yi-Hong Chu;Ming-Syan Chen
#t 2008
#c 3
#% 280417
#% 765518
#% 778729
#% 785355
#% 844313
#! In this paper, we study the quality issue of subspace clusters, which is an important but unsolved challenge in the literature of subspace clustering. After binning the data set into disjoint grids/regions, current solutions of subspace clustering usually invoke a grid-based apriori-like procedure to efficiently identify dense regions level by level according to the monotonic property in so defined subspace regions. A cluster in a subspace is intuitively considered as a set of dense regions that each one is connected to another dense region in the cluster. The measure of what is a dense region is successfully studied in recent years. However, the rigid definition of subspace clusters as connected regions still needs further justification in terms of the two principal measures of clustering quality, i.e., the intra-cluster similarity and the inter-cluster dissimilarity. A true cluster is likely to be separated into two or more clusters, whereas many true clusters may be merged into a fat cluster. In this paper, we propose an innovative algorithm, called the QASC algorithm (standing for Quality-Aware Subspace Clustering) to effectively discover accurate clusters. The QASC algorithm is devised as a general solution to partition dense regions into clusters and can be easily integrated into most of grid-based subspace clustering algorithms. By conducting on extensive synthetic data sets, the experimental results reveal that QASC is effective in identifying true subspace clusters.

#index 1411036
#* A decremental approach for mining frequent itemsets from uncertain data
#@ Chun-Kit Chui;Ben Kao
#t 2008
#c 3
#% 248791
#% 463903
#% 481290
#% 1393138
#! We study the problem of mining frequent itemsets from uncertain data under a probabilistic model. We consider transactions whose items are associated with existential probabilities. A decremental pruning (DP) technique, which exploits the statistical properties of items' existential probabilities, is proposed. Experimental results show that DP can achieve significant computational cost savings compared with existing approaches, such as U-Apriori and LGS-Trimming. Also, unlike LGS-Trimming, DP does not require a user-specified trimming threshold and its performance is relatively insensitive to the population of low-probability items in the dataset.

#index 1411037
#* Multi-class named entity recognition via bootstrapping with dependency tree-based patterns
#@ Van B. Dang;Akiko Aizawa
#t 2008
#c 3
#% 301241
#% 504443
#% 742100
#% 742424
#% 815307
#% 815924
#% 817447
#% 855119
#% 983614
#% 1288552
#% 1291356
#% 1476276
#! Named Entity Recognition (NER) has become a well-known problem with many important applications, such as Question Answering, Relation Extraction and Concept Retrieval. NER based on unsupervised learning via bootstrapping is gaining researchers' interest these days because it does not require manually annotating training data. Meanwhile, dependency tree-based patterns have proved to be effective in Relation Extraction. In this paper, we demonstrate that the use of dependency trees as extraction patterns, together with a bootstrapping framework, can improve the performance of the NER system and suggest a method for efficiently computing these tree patterns. Since unsupervised NER via bootstrapping uses the entities learned from each iteration as seeds for the next iterations, the quality of these seeds greatly affects the entire learning process. We introduce the technique of simultaneous bootstrapping of multiple classes, which can dramatically improve the quality of the seeds obtained at each iteration and hence increase the quality of the final learning results. Our experiments show beneficial results.

#index 1411038
#* Towards region discovery in spatial datasets
#@ Wei Ding;Rachsuda Jiamthapthaksin;Rachana Parmar;Dan Jiang;Tomasz F. Stepinski;Christoph F. Eick
#t 2008
#c 3
#% 438137
#% 527021
#% 527188
#% 566128
#% 1035440
#% 1663627
#% 1914464
#! This paper presents a novel region discovery framework geared towards finding scientifically interesting places in spatial datasets. We view region discovery as a clustering problem in which an externally given fitness function has to be maximized. The framework adapts four representative clustering algorithms, exemplifying prototype-based, grid-based, density-based, and agglomerative clustering algorithms, and then we systematically evaluated the four algorithms in a real-world case study. The task is to find feature-based hotspots where extreme densities of deep ice and shallow ice co-locate on Mars. The results reveal that the density-based algorithm outperforms other algorithms inasmuch as it discovers more regions with higher interestingness, the grid-based algorithm can provide acceptable solutions quickly, while the agglomerative clustering algorithm performs best to identify larger regions of arbitrary shape. Moreover, the results indicate that there are only a few regions on Mars where shallow and deep ground ice co-locate, suggesting that they have been deposited at different geological times.

#index 1411039
#* Accurate and efficient retrieval of multimedia time series data under uniform scaling and time warping
#@ Waiyawuth Euachongprasit;Chotirat Ann Ratanamahatana
#t 2008
#c 3
#% 341300
#% 378534
#% 654456
#% 749216
#% 795273
#% 809264
#% 824705
#% 883467
#% 947821
#% 1016194
#% 1740014
#! In this digital age, great interest has been shifted toward multimedia data manipulations. This includes videos, images, and audios, where typical manipulations require fairly large storage and are computationally intensive. Recent research has demonstrated the utilities of time series representation in various data mining tasks, allowing considerable reduction in time and space complexity. Specifically, the utilities of Uniform Scaling (US) and Dynamic Time Warping (DTW) have been shown to be necessary in several humanrelated domains, where uniform stretching or shrinking, as well as some local variation are typical. Classic examples include a query-by-humming system and motion capture data. However, all the past work has neglected the importance of data normalization before distance calculations, and therefore does not guarantee accurate retrievals. In this work, we discuss this concern and present a technique that accurately and efficiently searches under the US with DTW for normalized time series data, where no-false-dismissals are guaranteed.

#index 1411040
#* Feature construction based on closedness properties is not that simple
#@ Dominique Gay;Nazha Selmaoui;Jean-François Boulicaut
#t 2008
#c 3
#% 280409
#% 280439
#% 338594
#% 379331
#% 431033
#% 466483
#% 607791
#% 791179
#% 865731
#% 926881
#% 989614
#% 1250571
#% 1663630
#% 1663722
#% 1710146
#% 1710149
#! Feature construction has been studied extensively, including for 0/1 data samples. Given the recent breakthrough in closedness-related constraint-based mining, we are considering its impact on feature construction for classification tasks. We investigate the use of condensed representations of frequent itemsets (closure equivalence classes) as new features. These itemset types have been proposed to avoid set counting in difficult association rule mining tasks. However, our guess is that their intrinsic properties (say the maximality for the closed itemsets and the minimality for the δ-free itemsets) might influence feature quality. Understanding this remains fairly open and we discuss these issues thanks to itemset properties on the one hand and an experimental validation on various data sets on the other hand.

#index 1411041
#* On addressing accuracy concerns in privacy preserving association rule mining
#@ Ling Guo;Songtao Guo;Xintao Wu
#t 2008
#c 3
#% 300184
#% 333876
#% 576111
#% 577233
#% 727904
#% 729937
#% 800513
#% 810010
#% 993988
#! Randomized Response techniques have been empirically investigated in privacy preserving association rule mining. In this paper, we investigate the accuracy (in terms of bias and variance of estimates) of both support and confidence estimates of association rules derived from the randomized data. We demonstrate that providing confidence on data mining results from randomized data is significant to data miners. We propose the novel idea of using interquantile range to bound those estimates derived from the randomized market basket data. The performance is evaluated using both representative real and synthetic data sets.

#index 1411042
#* Privacy-preserving linear fisher discriminant analysis
#@ Shuguo Han;Wee Keong Ng
#t 2008
#c 3
#% 91896
#% 300184
#% 577289
#% 627876
#% 729437
#% 823389
#% 989649
#% 1386180
#% 1579130
#% 1722551
#% 1861142
#% 1914481
#% 1914483
#! Privacy-preserving data mining enables two or more parties to collaboratively perform data mining while preserving the data privacy of the participating parties. So far, various data mining and machine learning algorithms have been enhanced to incorporate privacy preservation. In this paper, we propose privacy-preserving solutions for Fisher Discriminant Analysis (FDA) over horizontally and vertically partitioned data. FDA is one of the widely used discriminant algorithms that seeks to separate different classes as much as possible for discriminant analysis or dimension reduction. It has been applied to face recognition, speech recognition, and handwriting recognition. The secure solutions are designed based on two basic secure building blocks that we have proposed--the Secure Matrix Multiplication protocol and the Secure Inverse of Matrix Sum protocol--which are in turn based on cryptographic techniques. We conducted experiments to evaluate the scalability of the proposed secure building blocks and overheads to achieve privacy when performing FDA.

#index 1411043
#* Unsupervised change analysis using supervised learning
#@ Shohei Hido;Tsuyoshi Idé;Hisashi Kashima;Harunobu Kubo;Hirofumi Matsuzawa
#t 2008
#c 3
#% 44876
#% 342600
#% 342639
#% 823408
#% 881543
#% 926881
#% 1016245
#% 1055665
#! We propose a formulation of a new problem, which we call change analysis, and a novel method for solving the problem. In contrast to the existing methods of change (or outlier) detection, the goal of change analysis goes beyond detecting whether or not any changes exist. Its ultimate goal is to find the explanation of the changes.While change analysis falls in the category of unsupervised learning in nature, we propose a novel approach based on supervised learning to achieve the goal. The key idea is to use a supervised classifier for interpreting the changes. A classifier should be able to discriminate between the two data sets if they actually come from two different data sources. In other words, we use a hypothetical label to train the supervised learner, and exploit the learner for interpreting the change. Experimental results using real data show the proposed approach is promising in change analysis as well as concept drift analysis.

#index 1411044
#* ANEMI: an adaptive neighborhood expectation-maximization algorithm with spatial augmented initialization
#@ Tianming Hu;Hui Xiong;Xueqing Gong;Sam Yuan Sung
#t 2008
#c 3
#% 266484
#% 277483
#% 348612
#% 413803
#% 438137
#% 443531
#% 465004
#% 814035
#% 1294416
#! The Neighborhood Expectation-Maximization (NEM) algorithm is an iterative EM-style method for clustering spatial data. Unlike the traditional EM algorithm, NEM has the spatial penalty term incorporated in the objective function. The clustering performance of NEM depends mainly on two factors: the choice of the spatial coefficient, which is used to weigh the penalty term; and the initial state of cluster separation, to which the resultant clustering is sensitive. Existing NEM algorithms usually assign an equal spatial coefficient to every site, regardless of whether this site is in the class interior or on the class border. However, when estimating posterior probabilities, sites in the class interior should receive stronger influence from its neighbors than those on the border. In addition, initialization methods deployed for EM-based clustering algorithms generally do not account for the unique properties of spatial data, such as spatial autocorrelation. As a result, they often fail to provide a proper initialization for NEM to find a good solution in practice. To that end, this paper presents a variant of NEM, called ANEMI, which exploits an adaptive spatial coefficient determined by the correlation of explanatory attributes inside the neighborhood. Also, ANEMI runs from the initial state returned by the spatial augmented initialization method. Finally, the experimental results on both synthetic and real-world datasets validated the effectiveness of ANEMI.

#index 1411045
#* Minimum variance associations: discovering relationships in numerical data
#@ Szymon Jaroszewicz
#t 2008
#c 3
#% 15286
#% 24538
#% 152934
#% 210160
#% 227919
#% 280458
#% 290137
#% 769913
#% 769958
#% 785419
#% 876043
#% 881456
#% 881465
#% 881519
#% 905832
#% 1271849
#% 1403604
#% 1666418
#! The paper presents minimum variance patterns: a new class of itemsets and rules for numerical data, which capture arbitrary continuous relationships between numerical attributes without the need for discretization. The approach is based on finding polynomials over sets of attributes whose variance, in a given dataset, is close to zero. Sets of attributes for which such functions exist are considered interesting. Further, two types of rules are introduced, which help extract understandable relationships from such itemsets. Efficient algorithms for mining minimum variance patterns are presented and verified experimentally.

#index 1411046
#* An efficient unordered tree kernel and its application to glycan classification
#@ Tetsuji Kuboyama;Kouichi Hirata;Kiyoko F. Aoki-Kinoshita
#t 2008
#c 3
#% 121462
#% 183302
#% 244371
#% 464640
#% 778469
#% 810071
#% 1718527
#! The problem of computing unordered tree kernels based on exhaustive counts of subtrees has known to be #P-complete. In this paper, we develop an efficient and general unordered tree kernel based on bifoliate q-grams that are unordered trees with at most two leaves and just q nodes. First, we introduce a bifoliate q-gram profile as a sequence of the frequencies of all bifoliate q-grams embedded into a given tree. Then, we formulate a bifoliate tree kernel as an inner product of bifoliate q-gram profiles of two trees. Next, we design an efficient algorithm for computing the bifoliate tree kernel. Finally, we apply the bifoliate tree kernel to classifying glycan structures.

#index 1411047
#* Generation of globally relevant continuous features for classification
#@ Sylvain Létourneau;Stan Matwin;A. Fazel Famili
#t 2008
#c 3
#% 73374
#% 80995
#% 103051
#% 252402
#% 346340
#% 445215
#% 449588
#% 458259
#% 458386
#% 565244
#% 708751
#% 1272358
#! All learning algorithms perform very well when provided with a small number of highly relevant features. This paper proposes a constructive induction method to automatically construct such features. The method, named GLOREF (GLObally RElevant Features), exploits low-level interactions between the attributes in order to generate globally relevant features. The usefulness of the approach is demonstrated empirically through a large scale experiment involving 13 classifiers and 24 datasets. Results demonstrate the ability of the method in generating highly informative features and a strong positive effect on the accuracy of the classifiers.

#index 1411048
#* Mining bulletin board systems using community generation
#@ Ming Li;Zhongfei Zhang;Zhi-Hua Zhou
#t 2008
#c 3
#% 249110
#% 309845
#% 343768
#% 730002
#% 752931
#% 1702895
#! Bulletin board system (BBS) is popular on the Internet. This paper attempts to identify communities of interest-sharing users on BBS. First, the paper formulates a general model for the BBS data, consisting of a collection of user IDs described by two views to their behavior actions along the timeline, i.e., the topics of the posted messages and the boards to which the messages are posted. Based on this model which contains no explicit link information between users, a uni-party data community generation algorithm called ISGI is proposed, which employs a specifically designed hierarchical similarity function to measure the correlations between two different individual users. Then, the BPUC algorithm is proposed, which uses the generated communities to predict users' behavior actions under certain conditions for situation awareness or personalized services development. For instance, the BPUC predictions may be used to answer questions such as "what will be the likely behavior user X may take if he/she logs into the BBS tomorrow?". Experiments on a large scale, real-world BBS data set demonstrate the effectiveness of the proposed model and algorithms.

#index 1411049
#* Extreme support vector machine classifier
#@ Qiuge Liu;Qing He;Zhongzhi Shi
#t 2008
#c 3
#% 47585
#% 190581
#% 224113
#% 292664
#% 342598
#% 837668
#% 843893
#% 1860305
#% 1861158
#! Instead of previous SVM algorithms that utilize a kernel to evaluate the dot products of data points in a feature space, here points are explicitly mapped into a feature space by a Single hidden Layer Feedforward Network (SLFN) with its input weights randomly generated. In theory this formulation, which can be interpreted as a special form of Regularization Network (RN), tends to provide better generalization performance than the algorithm for SLFNs--Extreme Learning Machine (ELM) and leads to a extremely simple and fast nonlinear SVM algorithm that requires only the inversion of a potentially small matrix with the order independent of the size of the training dataset. The experimental results show that the proposed Extreme SVM can produce better generalization performance than ELM almost all of the time and can run much faster than other nonlinear SVM algorithms with comparable accuracy.

#index 1411050
#* LCM over ZBDDS: fast generation of very large-scale frequent itemsets using a compact graph-based representation
#@ Shin-Ichi Minato;Takeaki Uno;Hiroki Arimura
#t 2008
#c 3
#% 3873
#% 147928
#% 152934
#% 443350
#% 729418
#% 844195
#% 867881
#% 881486
#% 1403612
#% 1663714
#! Frequent itemset mining is one of the fundamental techniques for data mining and knowledge discovery. In the last decade, a number of efficient algorithms have been presented for frequent itemset mining, but most of them focused on only enumerating the itemsets that satisfy the given conditions, and how to store and index the mining result in order to ensure an efficient data analysis is a different matter. In this paper, we propose a fast algorithm for generating very large-scale all/closed/maximal frequent itemsets using Zero-suppressed BDDs (ZBDDs), a compact graph-based data structure. Our method, "LCM over ZBDDs," is based on one of the most efficient state-of-the-art algorithms proposed thus far. Not only does it enumerate/list the itemsets, but it also generates a compact output data structure on the main memory. The result can be efficiently postprocessed by using algebraic ZBDD operations. The original LCM is known as an output linear time algorithm, but our new method requires a sub-linear time for the number of frequent patterns when the ZBDD-based data compression works well. Our method will greatly accelerate the data mining process and this will leads to a new style of on-memory processing for dealing with knowledge discovery problems.

#index 1411051
#* Unusual pattern detection in high dimensions
#@ Minh Quoc Nguyen;Leo Mark;Edward Omiecinski
#t 2008
#c 3
#% 300136
#% 479791
#% 823340
#% 1013086
#! In this paper, we present an alternative approach to discover interesting unusual observations that can not be discovered by outlier detection techniques. The unusual pattern is determined according to the deviation of a group of observations from other observations and the number of observations in the group. To measure the degree of deviation, we introduce the concept of adaptive nearest neighbors that captures the natural similarity between two observations. The boundary points determined by the adaptive nearest neighbor algorithm are used to adjust the level of granularity. The adaptive nearest neighbors are then used to cluster the data set. Finally, we ran experiments on a real life data set to evaluate the result. According to the experiments, we discovered interesting unusual patterns that are overlooked by using outlier detection and clustering algorithms.

#index 1411052
#* Person name disambiguation in web pages using social network, compound words and latent topics
#@ Shingo Ono;Issei Sato;Minoru Yoshida;Hiroshi Nakagawa
#t 2008
#c 3
#% 280404
#% 311027
#% 747890
#% 805885
#% 817563
#% 838408
#% 855094
#% 938728
#% 1271267
#% 1650268
#% 1682082
#! The World Wide Web (WWW) provides much information about persons, and in recent years WWW search engines have been commonly used for learning about persons. However, many persons have the same name and that ambiguity typically causes the search results of one person name to include Web pages about several different persons. We propose a novel framework for person name disambiguation that has the following three components processes. Extraction of social network information by finding co-occurrences of named entities, Measurement of document similarities based on occurrences of key compound words, Inference of topic information from documents based on the Dirichlet process unigram mixture model. Experiments using an actual Web document dataset show that the result of our framework is promising.

#index 1411053
#* Mining correlated subgraphs in graph databases
#@ Tomonobu Ozaki;Takenao Ohkawa
#t 2008
#c 3
#% 207408
#% 431105
#% 481290
#% 577214
#% 629603
#% 629708
#% 727845
#% 727869
#% 727897
#% 731608
#% 769902
#% 769909
#% 769951
#% 823361
#% 841960
#% 893372
#% 915324
#% 920863
#% 954256
#% 988134
#% 989610
#% 1117006
#% 1269491
#% 1663669
#! In this paper, we bring the concept of hyperclique pattern in transaction databases into the graph mining and consider the discovery of sets of highly-correlated subgraphs in graph-structured databases. To discover frequent hyperclique patterns in graph databases efficiently, a novel algorithm named HSG is proposed. By considering the generality ordering of subgraphs, HSG employs the depth-first/breadth-first search strategy with powerful pruning techniques based on the upper bound of h-confidence measure. The effectiveness of HSG is assessed through the experiments with real world datasets.

#index 1411054
#* A minimal description length scheme for polynomial regression
#@ Aleksandar Pečkov;Sašo Džeroski;Ljupčo Todorovski
#t 2008
#c 3
#% 798763
#% 926881
#% 1810265
#! The paper addresses the task of polynomial regression, i.e., the task of inducing polynomials from numeric data that can be used to predict the value of a selected numeric variable. As in other learning tasks, we face the problem of finding an optimal trade-off between the complexity of the induced model and its predictive error. One of the approaches to finding this optimal trade-off is the minimal description length (MDL) principle. In this paper, we propose an MDL scheme for polynomial regression, which includes coding schemes for polynomials and the errors they make on data. We empirically compare this principled MDL scheme to an ad-hoc MDL scheme and show that it performs better. The improvements in performance are such that the polynomial regression approach we propose is now comparable in performance to other commonly used methods for regression, such as model trees.

#index 1411055
#* Handling numeric attributes in hoeffding trees
#@ Bernhard Pfahringer;Geoffrey Holmes;Richard Kirkby
#t 2008
#c 3
#% 1331
#% 2152
#% 248820
#% 310500
#% 319831
#% 333931
#% 452821
#% 482104
#% 729965
#% 737348
#% 1272280
#% 1673597
#! For conventional machine learning classification algorithms handling numeric attributes is relatively straightforward. Unsupervised and supervised solutions exist that either segment the data into predefined bins or sort the data and search for the best split points. Unfortunately, none of these solutions carry over particularly well to a data stream environment. Solutions for data streams have been proposed by several authors but as yet none have been compared empirically. In this paper we investigate a range of methods for multi-class tree-based classification where the handling of numeric attributes takes place as the tree is constructed. To this end, we extend an existing approximation approach, based on simple Gaussian approximation. We then compare this method with four approaches from the literature arriving at eight final algorithm configurations for testing. The solutions cover a range of options from perfectly accurate and memory intensive to highly approximate. All methods are tested using the Hoeffding tree classification algorithm. Surprisingly, the experimental comparison shows that the most approximate methods produce the most accurate trees by allowing for faster tree growth.

#index 1411056
#* Scaling record linkage to non-uniform distributed class sizes
#@ Steffen Rendle;Lars Schmidt-Thieme
#t 2008
#c 3
#% 201889
#% 310516
#% 469887
#% 577263
#% 587758
#% 729913
#% 838435
#% 844289
#% 915242
#% 915276
#% 915340
#% 1250576
#! Record linkage is a central task when information from different sources is integrated. Record linkage models use so-called blockers for reducing the search space by discarding obviously different record pairs. In practice, important problems have Zipf distributed class sizes with some large classes where blocking is not applicable any more. Therefore we propose two novel meta algorithms for scaling arbitrary record linkage models to such data sets. The first one parallelizes problems by creating overlapping subproblems and the second one reduces the search space for large classes effectively. Our evaluation shows that both scaling techniques are effective and are able to scale state-of-the-art models to challenging datasets.

#index 1411057
#* Large-scale k-means clustering with user-centric privacy preservation
#@ Jun Sakuma;Shigenobu Kobayashi
#t 2008
#c 3
#% 576761
#% 577233
#% 723903
#% 729930
#% 743280
#% 823389
#% 1068712
#% 1386180
#% 1721181
#! A k-means clustering with new privacy-preserving concept, user-centric privacy preservation, is presented. In this framework, users can conduct data mining using their private information with storing them in their local storages. After the computation, they obtain only mining result without disclosing private information to others. The number of parties that join conventional privacy-preserving data mining has been assumed to be two. In our framework, we assume large numbers of parties join the protocol, therefore, not only scalability but also asynchronism and fault-tolerance is important. Considering this, we propose a k-mean algorithm combined with a decentralized cryptographic protocol and a gossip-based protocol. The computational complexity is O(log n) with respect to the number of parties n and experimental results show that our protocol is scalable even with one million parties.

#index 1411058
#* Semi-supervised local fisher discriminant analysis for dimensionality reduction
#@ Masashi Sugiyama;Tsuyoshi Idé;Shinichi Nakajima;Jun Sese
#t 2008
#c 3
#% 80995
#% 331916
#% 464640
#% 961279
#% 1074038
#! When only a small number of labeled samples are available, supervised dimensionality reduction methods tend to perform poorly due to overfitting. In such cases, unlabeled samples could be useful in improving the performance. In this paper, we propose a semi-supervised dimensionality reduction method which preserves the global structure of unlabeled samples in addition to separating labeled samples in different classes from each other. The proposed method has an analytic form of the globally optimal solution and it can be computed based on eigendecompositions. Therefore, the proposed method is computationally reliable and efficient. We show the effectiveness of the proposed method through extensive simulations with benchmark data sets.

#index 1411059
#* An efficient algorithm for finding similar short substrings from large scale string data
#@ Takeaki Uno
#t 2008
#c 3
#% 31489
#% 143306
#% 300105
#% 303079
#% 544200
#% 593957
#% 717472
#% 833451
#! Finding similar substrings/substructures is a central task in analyzing huge amounts of string data such as genome sequences, web documents, log data, etc. In the sense of complexity theory, the existence of polynomial time algorithms for such problems is usually trivial since the number of substrings is bounded by the square of their lengths. However, straightforward algorithms do not work for practical huge databases because of their computation time of high degree order. This paper addresses the problems of finding pairs of strings with small Hamming distances from huge databases composed of short strings. By solving the problem for all the substrings of fixed length, we can efficiently find candidates of similar non-short substrings. We focus on the practical efficiency of algorithms, and propose an algorithm running in almost linear time of the database size. We prove that the computation time of its variant is bounded by linear of the database size when the length of short strings to be found is constant. Slight modifications of the algorithm adapt to the edit distance and mismatch tolerance computation. Computational experiments for genome sequences show the efficiency of the algorithm. An implementation is available at the author's homepage.

#index 1411060
#* Ambiguous frequent itemset mining and polynomial delay enumeration
#@ Takeaki Uno;Hiroki Arimura
#t 2008
#c 3
#% 172892
#% 207408
#% 232136
#% 248791
#% 342610
#% 769957
#% 844394
#% 1405138
#% 1407139
#% 1656269
#! Mining frequently appearing patterns in a database is a basic problem in recent informatics, especially in data mining. Particularly, when the input database is a collection of subsets of an itemset, called transaction, the problem is called the frequent itemset mining problem, and it has been extensively studied. The items in a frequent itemset appear in many records simultaneously, thus they can be considered to be a cluster with respect to these records. However, in this sense, the condition that every item appears in each record is quite strong. We should allow for several missing items in these records. In this paper, we approach this problem from the algorithm theory, and consider the model that can be solved efficiently and possibly valuable in practice. We introduce ambiguous frequent itemsets which allow missing items in their occurrence records. More precisely, for given thresholds ? and s, an ambiguous frequent itemset P has a transaction set τ, | τ | ≥ σ, such that on average, transactions in τ include ratio θ of items of P. We formulate the problem of enumerating ambiguous frequent itemsets, and propose an efficient polynomial delay polynomial space algorithm. The practical performance is evaluated by computational experiments. Our algorithm can be naturally extended to the weighted version of the problem. The weighted version is a natural extension of the ordinary frequent itemset to weighted transaction databases, and is equivalent to finding submatrices with large average weights in their cells. An implementation is available at the author's homepage.

#index 1411061
#* Characteristic-based descriptors for motion sequence recognition
#@ Liang Wang;Xiaozhe Wang;Christopher Leckie;Kotagiri Ramamohanarao
#t 2008
#c 3
#% 235342
#% 277841
#% 592062
#% 724289
#% 775269
#% 799394
#% 812594
#% 836851
#% 836906
#% 844337
#% 883878
#% 893724
#% 1013661
#% 1030809
#% 1561854
#% 1860941
#! This paper proposes an approach based on characteristic descriptors for recognition of articulated and deformable human motions from image sequences. After extracting human movement silhouettes from motion videos, we apply Tensor Subspace Analysis to embed normalized dynamic silhouette sequences into low-dimensional forms of multivariate time series. Structure-based statistical features are then extracted from such multivariate time series to summarize motion patterns (as descriptors) in a compact manner. A multi-class Support Vector Machine classifier is used to learn and predict the motion sequence categories. The proposed method is evaluated on two real-world state-of-the-art video data sets, and the results have shown the power of our method for recognizing human motion sequences with intra- and interperson variations on both temporal and spatial scales.

#index 1411062
#* Protecting privacy in incremental maintenance for distributed association rule mining
#@ W. K. Wong;David W. Cheung;Edward Hung;Huan Liu
#t 2008
#c 3
#% 300184
#% 443085
#% 464204
#% 481290
#% 511333
#% 575969
#% 577289
#% 772829
#% 954159
#% 1068712
#! Distributed association rule mining algorithms are used to discover important knowledge from databases. Privacy concerns can prevent parties from sharing the data. New algorithms are required to solve traditional mining problems without disclosing (original or derived) information of their own data to other parties. Research results have been developed on (i) incrementally maintaining the discovered association rules, and (ii) computing the distributed association rules while preserving privacy. However, no study has been conducted on the problem of the maintenance of the discovered rules with privacy protection when new sites join the old sites. We propose an algorithm SIMDAR for this problem. Some techniques we developed can even further reduce the cost in a normal association rule mining algorithm with privacy protection. Experimental results showed that SIMDAR can significantly reduce the workload at the old sites by up to 80%.

#index 1411063
#* SEM: mining spatial events from the web
#@ Kaifeng Xu;Rui Li;Shenghua Bao;Dingyi Han;Yong Yu
#t 2008
#c 3
#% 232650
#% 262042
#% 262043
#% 330677
#% 378508
#% 397132
#% 577297
#% 740900
#% 766433
#% 815280
#% 855313
#% 869516
#% 881504
#% 956497
#% 987205
#! This paper is concerned with the problem of mining spatial events from the general Web. General search engine is inconvenient when searching vertical information (e.g., locations, experts) since it is designed for general purpose. For example, when finding the battlefields of World War II, listing the Web pages by relevance is not enough to tell users the spatial information clearly. A categorized result along with a map indicating these battlefields would be much easier to read. To present such a result, we propose a novel algorithm called Spatial Event Miner (SEM) to mine spatial event information from the general Web. Given a simple keyword query, SEM first collects and ranks a set of relevant locations from the Web. Then, to describe the events happened in the collected locations, SEM detects and sums up salient phrases as event topics from the context of these locations. For each specific location, the hottest event topics are also listed for quick understanding. Finally, a clear spatial distribution on the events of a given query is presented to the users. A prototype system based on SEM is also implemented. Preliminary experimental results on a set of 40 queries show that the proposed approach can capture the spatial event information effectively.

#index 1411064
#* BOAI: fast alternating decision tree induction based on bottom-up evaluation
#@ Bishan Yang;Tengjiao Wang;Dongqing Yang;Lei Chang
#t 2008
#c 3
#% 136350
#% 235377
#% 273900
#% 400847
#% 459008
#% 466240
#% 479640
#% 479787
#% 481945
#% 926881
#! Alternating Decision Tree (ADTree) is a successful classification model based on boosting and has a wide range of applications. The existing ADTree induction algorithms apply a "top-down" strategy to evaluate the best split at each boosting iteration, which is very time-consuming and thus is unsuitable for modeling on large data sets. This paper proposes a fast ADTree induction algorithm (BOAI) based on "bottom-up" evaluation, which offers high performance on massive data without sacrificing classification accuracy. BOAI uses a pre-sorting technique and dynamically evaluates splits by a bottom-up approach based on VW-group. With these techniques, huge redundancy in sorting and computation can be eliminated in the tree induction procedure. Experimental results on both real and synthetic data sets show that BOAI outperforms the best existing ADTree induction algorithm by a significant margin. In the real case study, BOAI also provides better performance than TreeNet and Random Forests, which are considered as efficient classification models.

#index 1411065
#* Feature selection by nonparametric Bayes error minimization
#@ Shuang-Hong Yang;Bao-Gang Hu
#t 2008
#c 3
#% 126894
#% 169659
#% 227486
#% 720010
#% 722758
#% 722929
#% 722943
#% 770774
#% 812229
#% 889150
#% 891559
#% 900314
#% 975162
#% 1562601
#! This paper presents an algorithmic framework for feature selection, which selects a subset of features by minimizing the nonparametric Bayes error. A set of existing algorithms as well as new ones can be derived naturally from this framework. For example, we show that the Relief algorithm greedily attempts to minimize the Bayes error estimated by k-Nearest-Neighbor method. This new interpretation not only reveals the secret behind Relief but also offers various opportunities to improve it or to establish new alternatives. In particular, we develop a new feature weighting algorithm, named Parzen-Relief, which minimizes the Bayes error estimated by Parzen method. Additionally, to enhance its ability to handle imbalanced and multiclass data, we integrate the class distribution with the max-margin objective function, leading to a new algorithm, named MAP-Relief. Comparison on benchmark data sets confirms the effectiveness of the proposed algorithms.

#index 1411066
#* A framework for modeling positive class expansion with single snapshot
#@ Yang Yu;Zhi-Hua Zhou
#t 2008
#c 3
#% 190581
#% 341700
#% 448194
#% 464641
#% 466408
#% 577235
#% 727880
#% 729437
#% 876068
#% 926881
#% 983814
#% 1378224
#% 1699593
#! In many real-world data mining tasks, the coverage of the target concept may change as the time changes. For example, the coverage of "learned knowledge" of a student today may be different from his/er "learned knowledge" tomorrow, since the "learned knowledge" of the student is in expanding everyday. In order to learn a model capable of making accurate predictions, the evolution of the concept must be considered, and thus, a series of data sets collected at different time is needed. However, in many cases there is only a single data set instead of a series of data sets. In other words, only a single snapshot of the data along the time axis is available. In this paper, we show that for positive class expansion, i.e., the coverage of the target concept is in expanding as illustrated in the above "learned knowledge" example, we can learn an accurate model from the single snapshot data with the help of domain knowledge given by user. The effectiveness of the proposed framework is validated in experiments.

#index 1411067
#* A decomposition algorithm for learning Bayesian network structures from data
#@ Yifeng Zeng;Jorge Cordero Hernandez
#t 2008
#c 3
#% 44876
#% 64124
#% 380725
#% 400980
#% 646240
#% 729990
#% 800408
#% 893460
#% 913244
#% 919561
#% 1650289
#% 1673041
#! It is a challenging task of learning a large Bayesian network from a small data set. Most conventional structural learning approaches run into the computational as well as the statistical problems. We propose a decomposition algorithm for the structure construction without having to learn the complete network. The new learning algorithm firstly finds local components from the data, and then recover the complete network by joining the learned components. We show the empirical performance of the decomposition algorithm in several benchmark networks.

#index 1411068
#* Learning classification rules for multiple target attributes
#@ Bernard Ženko;Sašo Džeroski
#t 2008
#c 3
#% 191680
#% 236497
#% 449566
#% 458178
#% 466073
#% 926881
#% 961134
#% 1272357
#% 1742013
#! Among predictive models, 'if-then' rule sets are one of the most expressive and human readable model representations. Most of the existing approaches for rule learning focus on predicting a single target attribute/class. In practice, however, we encounter many problems where the task is to predict not one, but several related target attributes. We employ the predictive clustering approach to learn rules for simultaneous prediction of multiple target attributes. We propose a new rule learning algorithm, which (unlike existing rule learning approaches) generalizes to multiple target prediction. We empirically evaluate the new method and show that rule sets for multiple target prediction yield comparable accuracy to the respective collection of single target rule sets. The size of the multiple target rule set, however, is much smaller than the total size of the collection of single target rule sets.

#index 1411069
#* A mixture model for expert finding
#@ Jing Zhang;Jie Tang;Liu Liu;Juanzi Li
#t 2008
#c 3
#% 200694
#% 387427
#% 413573
#% 457933
#% 466574
#% 766409
#% 768898
#% 769895
#% 769967
#% 869504
#% 879570
#% 956501
#% 987261
#% 1117023
#% 1390152
#% 1650298
#% 1656345
#! This paper addresses the issue of identifying persons with expertise knowledge on a given topic. Traditional methods usually estimate the relevance between the query and the support documents of candidate experts using, for example, a language model. However, the language model lacks the ability of identifying semantic knowledge, thus results in some right experts cannot be found due to not occurrence of the query terms in the support documents. In this paper, we propose a mixture model based on Probabilistic Latent Semantic Analysis (PLSA) to estimate a hidden semantic theme layer between the terms and the support documents. The hidden themes are used to capture the semantic relevance between the query and the experts. We evaluate our mixture model in a real-world system, ArnetMiner. Experimental results indicate that the proposed model outperforms the language models.

#index 1411070
#* On privacy in time series data mining
#@ Ye Zhu;Yongjian Fu;Huirong Fu
#t 2008
#c 3
#% 106318
#% 172949
#% 176172
#% 300184
#% 310545
#% 346201
#% 577233
#% 769962
#% 772829
#% 810010
#% 814194
#% 823389
#% 823400
#% 823413
#% 881476
#% 964073
#% 1860500
#! Traditional research on preserving privacy in data mining focuses on time-invariant privacy issues. With the emergence of time series data mining, traditional snapshot-based privacy issues need to be extended to be multi-dimensional with the addition of time dimension. We find current techniques to preserve privacy in data mining are not effective in preserving time-domain privacy. We present data flow separation attack on privacy in time series data mining, which is based on blind source separation techniques from statistical signal processing. Our experiments with real data show that this attack is effective. By combining the data flow separation method and the frequency matching method, an attacker can identify data sources and compromise time-domain privacy. We propose possible countermeasures to the data flow separation attack in the paper.

#index 1411071
#* Exploiting propositionalization based on random relational rules for semi-supervised learning
#@ Grant Anderson;Bernhard Pfahringer
#t 2008
#c 3
#% 224755
#% 269218
#% 310868
#% 333790
#% 398847
#% 400847
#% 425004
#% 449508
#% 466240
#% 550387
#% 550398
#% 768665
#% 840965
#% 850431
#% 1393155
#% 1393855
#% 1415860
#% 1455666
#% 1707847
#% 1728454
#! In this paper we investigate an approach to semi-supervised learning based on randomized propositionalization, which allows for applying standard propositional classification algorithms like support vector machines to multi-relational data. Randomization based on random relational rules can work both with and without a class attribute and can therefore be applied simultaneously to both the labeled and the unlabeled portion of the data present in semi-supervised learning. An empirical investigation compares semi-supervised propositionalization to standard propositionalization using just the labeled data portion, as well as to a variant that also just uses the labeled data portion but includes the label information in an attempt to improve the resulting propositionalization. Preliminary experimental results indicate that propositionalization generated on the full dataset, i.e. the semisupervised approach, tends to outperform the other two more standard approaches.

#index 1411072
#* On discrete data clustering
#@ Nizar Bouguila;Walid ElGuebaly
#t 2008
#c 3
#% 120270
#% 275111
#% 304483
#% 840903
#% 984498
#% 1855694
#% 1856154
#! Finite mixture modeling have been applied for different data mining tasks. The majority of the work done concerning finite mixture models has focused on mixtures for continuous data. However, many applications involve and generate discrete data for which discrete mixtures are better suited. In this paper, we investigate the problem of discrete data modeling using finite mixture models. We propose a novel mixture that we call the multinomial generalized Dirichlet mixture. We designed experiments involving spatial color image databases modeling and summarization to show the robustness, flexibility and merits of our approach.

#index 1411073
#* Automatic training example selection for scalable unsupervised record linkage
#@ Peter Christen
#t 2008
#c 3
#% 464641
#% 577235
#% 577247
#% 659991
#% 729913
#% 778320
#% 928146
#% 1064741
#% 1070283
#% 1558464
#% 1675764
#! Linking records from two or more databases is an increasingly important data preparation step in many data mining projects, as linked data can enable studies that are not feasible otherwise, or that would require expensive collection of specific data. The aim of such linkages is to match all records that refer to the same entity. One of the main challenges in record linkage is the accurate classification of record pairs into matches and non-matches. Many modern classification techniques are based on supervised machine learning and thus require training data, which is often not available in real world situations. A novel two-step approach to unsupervised record pair classification is presented in this paper. In the first step, training examples are selected automatically, and they are then used in the second step to train a binary classifier. An experimental evaluation shows that this approach can outperform k-means clustering and also be much faster than other classification techniques.

#index 1411074
#* Analyzing PETs on imbalanced datasets when training and testing class distributions differ
#@ David Cieslak;Nitesh Chawla
#t 2008
#c 3
#% 136350
#% 260149
#% 580510
#% 765519
#% 765521
#% 875965
#% 1085130
#% 1271973
#! Many machine learning applications like finance, medicine, and risk management suffer from class imbalance: cases of interest occur rarely. Further complicating these applications is that the training and testing samples might differ significantly in their respective class distributions. Sampling has been shown to be a strong solution to imbalance and additionally offers a rich parameter space from which to select classifiers. This paper is concerned with the interaction between Probability Estimation Trees (PETs) [1], sampling, and performance metrics as testing distributions fluctuate substantially. A set of comprehensive analyses is presented, which anticipate classifier performance through a set of widely varying testing distributions.

#index 1411075
#* Improving the robustness to outliers of mixtures of probabilistic PCAs
#@ Nicolas Delannay;Cédric Archambeau;Michel Verleysen
#t 2008
#c 3
#% 272536
#% 278040
#% 304879
#% 424831
#% 875949
#% 1502480
#% 1650268
#% 1862524
#! Principal Component Analysis, when formulated as a probabilistic model, can be made robust to outliers by using a Student-t assumption on the noise distribution instead of a Gaussian one. On the other hand, mixtures of PCA is a model aimed to discover nonlinear dependencies in data by finding clusters and identifying local linear submanifolds. This paper shows how mixtures of PCA can be made robust to outliers too. Using a hierarchical probabilistic model, parameters are set by likelihood maximization. The method is shown to be effectively robust to outliers, even in the context of high-dimensional data.

#index 1411076
#* Exploratory hot spot profile analysis using interactive visual drill-down self-organizing maps
#@ Denny Denny;Graham J. Williams;Peter Christen
#t 2008
#c 3
#% 391311
#% 486316
#% 818916
#% 1064738
#! Real-life datasets often contain small clusters of unusual subpopulations. These clusters, or 'hot spots', are usually sparse and of special interest to an analyst. We present a methodology for identifying hot spots and ranking attributes that distinguish them interactively, using visual drill-down Self-Organizing Maps. The methodology is particularly useful for understanding hot spots in high dimensional datasets. Our approach is demonstrated using a large real life taxation dataset.

#index 1411077
#* Maintaining optimal multi-way splits for numerical attributes in data streams
#@ Tapio Elomaa;Petri Lehtinen
#t 2008
#c 3
#% 129980
#% 136350
#% 298270
#% 310500
#% 342600
#% 458174
#% 729965
#% 729973
#% 738958
#% 810542
#% 874178
#! In the batch learning setting it suffices to take into account only a reduced number of threshold candidates in discretizing the value range of a numerical attribute for many commonly-used attribute evaluation functions. We show that the same techniques are also efficiently applicable in the on-line learning scheme. Only constant time per example is needed for determining the changes on data grouping. Hence, one can apply multi-way splits, e.g., in the standard approach to decision tree learning from data streams. We also briefly consider modifications needed to cope with drifting concepts. Our empirical evaluation demonstrates that often the reduction in threshold candidates obtained is high for the important attributes. In a data stream logarithmic growth in the number of potential cut points and the reduced number of threshold candidates is observed.

#index 1411078
#* Efficient mining of high utility itemsets from large datasets
#@ Alva Erwin;Raj P. Gopalan;N. R. Achuthan
#t 2008
#c 3
#% 152934
#% 300120
#% 746545
#% 829993
#% 945869
#% 1017083
#% 1071659
#! High utility itemsets mining extends frequent pattern mining to discover itemsets in a transaction database with utility values above a given threshold. However, mining high utility itemsets presents a greater challenge than frequent itemset mining, since high utility itemsets lack the anti-monotone property of frequent itemsets. Transaction Weighted Utility (TWU) proposed recently by researchers has anti-monotone property, but it is an overestimate of itemset utility and therefore leads to a larger search space. We propose an algorithm that uses TWU with pattern growth based on a compact utility pattern tree data structure. Our algorithm implements a parallel projection scheme to use disk storage when the main memory is inadequate for dealing with large datasets. Experimental evaluation shows that our algorithm is more efficient compared to previous algorithms and can mine larger datasets of both dense and sparse data containing long patterns.

#index 1411079
#* Tradeoff analysis of different Markov blanket local learning approaches
#@ Shunkai Fu;Michel C. Desmarais
#t 2008
#c 3
#% 240222
#% 400980
#% 729990
#% 844415
#% 1406869
#! Discovering the Markov blanket of a given variable can be viewed as a solution for optimal feature subset selection. Since 1996, several algorithms have been proposed to do local search of the Markov blanket, and they are proved to be much more efficient than the traditional approach where the whole Bayesian Network has to be learned first. In this paper, we compare those known published algorithms, including KS, GS, IAMB and its variants, PCMB, and one newly proposed called BFMB. We analyze the theoretical basis and practical values of each algorithm with the aim that it will help applicants to determine which ones to take in their specific scenarios.

#index 1411080
#* Forecasting urban air pollution using HMM-fuzzy model
#@ M. Maruf Hossain;Md. Rafiul Hassan;Michael Kirley
#t 2008
#c 3
#% 248113
#% 376589
#% 409161
#% 418211
#! In this paper, we introduce a Computational Intelligence (CI)-based method to model an hourly air pollution forecasting system that can forecast concentrations of airborne pollutant variables. We have used a hybrid approach of Hidden Markov Model (HMM) with fuzzy logic (HMM-fuzzy) to model hourly air pollution at a location related to its traffic volume and meteorological variable. The forecasting performance of this hybrid model is compared with other common tool based on Artificial Neural Network (ANN) and other fuzzy tool where rules are extracted using subtractive clustering. This research demonstrates that the HMM-fuzzy approach is effectively able to model an hourly air pollution forecasting system.

#index 1411081
#* Relational pattern mining based on equivalent classes of properties extracted from samples
#@ Nobuhiro Inuzuka;Jun-Ichi Motoyama;Shinpei Urazawa;Tomofumi Nakano
#t 2008
#c 3
#% 340736
#% 398844
#% 481290
#% 550406
#% 550412
#! This paper extends the bottom-up relational miner Mapix[9]. It takes a relational database consists of multiple relational tables including a target relation, and enumerates patterns with which a large part of instances in the target relation match. The patterns are given as logical formulae. Although a well-known system Warmr generates and tests possible patterns, it has limitation in its efficiency. Mapix took a bottom-up approach and gained efficiency at the cost of variety of patterns. It searches and propositionalizes features appeared in instances. Patterns produced is only simple combinations of attributed. The proposed algorithm EquivPix (an equivalent-class-based miner using property items extracted from examples) keeps the merits of bottom-up approach, i.e. time-efficiency and prohibition of duplicated patterns, and it widens pattern variation. EquivPix introduces equivalent classes on properties extracted and also two combination operators of them.

#index 1411082
#* Evaluating standard techniques for implicit diversity
#@ Ulf Johansson;Tuve Löfström;Lars Niklasson
#t 2008
#c 3
#% 451221
#! When performing predictive modeling, ensembles are often utilized in order to boost accuracy. The problem of how to maximize ensemble accuracy is, however, far from solved. In particular, the relationship between ensemble diversity and accuracy is, especially for classification, not completely understood. More specifically, the fact that ensemble diversity and base classifier accuracy are highly correlated, makes it necessary to balance these properties instead of just maximizing diversity. In this study, three standard techniques to obtain implicit diversity in neural network ensembles are evaluated using 14 UCI data sets. The experiments show that standard resampling; i.e. dividing the training data by instances, produces more diverse models, but at the expense of base classifier accuracy, thus resulting in less accurate ensembles. Building ensembles using neural networks with heterogeneous architectures improves test set accuracies, but without actually increasing the diversity. The results regarding resampling using features are inconclusive, the ensembles become more diverse, but the level of test set accuracies is unchanged. For the setups evaluated, ensemble training accuracy and base classifier training accuracy are positively correlated with ensemble test accuracy, but the opposite holds for diversity; i.e. ensembles with low diversity are generally more accurate.

#index 1411083
#* A simple characterization on serially constructible episodes
#@ Takashi Katoh;Kouichi Hirata
#t 2008
#c 3
#% 420063
#% 778732
#% 1663695
#! In this paper, we introduce a parallel-free episode that always has an arc between vertices with the same label and a serially constructible episode that is embedded into every parallel-free episode containing all of the serial episodes occurring in it. Then, we show that an episode is parallel-free if and only if it is serially constructible.

#index 1411084
#* Bootstrap based pattern selection for support vector regression
#@ Dongil Kim;Sungzoon Cho
#t 2008
#c 3
#% 190581
#% 269218
#% 309208
#% 614375
#% 741674
#% 881477
#% 959871
#% 1020161
#% 1669895
#! Support Vector Machine (SVM) results in a good generalization performance by employing the Structural Risk Minimization (SRM) principle. However, one drawback is O(n3) training time complexity. In this paper, we propose a pattern selection method designed specifically for Support Vector Regression (SVR). In SVR training, only a few patterns called support vectors are used to construct the regression model while other patterns are not used at all. The proposed method tries to select patterns which are likely to become support vectors. With multiple bootstrap samples, we estimate the likelihood of each pattern to become a support vector. The proposed method automatically determines the appropriate number of patterns selected by estimating the expected number of support vectors. Through the experiments involving twenty datasets, the proposed method resulted in the best accuracy among the competing methods.

#index 1411085
#* Tracking topic evolution in on-line postings: 2006 IBM innovation Jam data
#@ Mei Kobayashi;Raylene Yung
#t 2008
#c 3
#% 782758
#% 875959
#% 881498
#% 948784
#! Participants in on-line discussion forums and decision makers are interested in understanding real-time communications between large numbers of parties on the internet and intranet. As a first step towards addressing this challenge, we developed a prototype to quickly identify and track topics in large, dynamic data sets based on assignment of documents to time slices, fast approximation of cluster centroids to identify discussion topics, and inter-slice correspondence mappings of topics. To verify our method, we conducted implementation studies with data from Innovation Jam 2006, an on-line brainstorming session, in which participants around the globe posted more than 37,000 opinions. Results from our prototype are consistent with the text in the postings, and would have required considerable effort to discover manually.

#index 1411086
#* PAID: packet analysis for anomaly intrusion detection
#@ Kuo-Chen Lee;Jason Chang;Ming-Syan Chen
#t 2008
#c 3
#% 346478
#% 380725
#% 577250
#% 728274
#% 821933
#% 864876
#% 1385153
#% 1726264
#! Due to the growing threat of network attacks, detecting and measuring the network abuse are increasingly important. Network intrusion detection is the most frequently deployed approach. Detection frequently relies on only signature matching methods, and therefore suffers from lower accuracy and higher false alarm rates. This investigation presents a data-mining model (PAID) that constructs a packet header anomaly detection system with a Bayesian approach. The model accurately and automatically detects new malicious network attempts. On the DARPA evaluation data set, our method yields an accuracy of over 99.2% and a false positive rate of 0.03% for a DoS attack. Experimental results validate the feasibility of PAID to detect network intrusion.

#index 1411087
#* A comparison of different off-centered entropies to deal with class imbalance for decision trees
#@ Philippe Lenca;Stéphane Lallich;Thanh-Nghi Do;Nguyen-Khang Pham
#t 2008
#c 3
#% 136350
#% 191910
#% 280437
#% 449588
#% 765519
#% 770791
#% 998622
#% 1250597
#% 1272000
#! In data mining, large differences in prior class probabilities known as the class imbalance problem have been reported to hinder the performance of classifiers such as decision trees. Dealing with imbalanced and cost-sensitive data has been recognized as one of the 10 most challenging problems in data mining research. In decision trees learning, many measures are based on the concept of Shannon's entropy. A major characteristic of the entropies is that they take their maximal value when the distribution of the modalities of the class variable is uniform. To deal with the class imbalance problem, we proposed an off-centered entropy which takes its maximum value for a distribution fixed by the user. This distribution can be the a priori distribution of the class variable modalities or a distribution taking into account the costs of misclassification. Others authors have proposed an asymmetric entropy. In this paper we present the concepts of the three entropies and compare their effectiveness on 20 imbalanced data sets. All our experiments are founded on the C4.5 decision trees algorithm, in which only the function of entropy is modified. The results are promising and show the interest of off-centered entropies to deal with the problem of class imbalance.

#index 1411088
#* FIsViz: a frequent itemset visualizer
#@ Carson Kai-Sang Leung;Pourang P. Irani;Christopher L. Carmichael
#t 2008
#c 3
#% 221380
#% 280511
#% 434613
#% 443086
#% 481290
#% 577222
#% 729976
#% 731405
#% 789001
#% 844316
#% 915241
#% 918228
#% 1411089
#% 1669912
#% 1707826
#! Since its introduction, frequent itemset mining has been the subject of numerous studies. However, most of them return frequent itemsets in the form of textual lists. The common cliché that "a picture is worth a thousand words" advocates that visual representation can enhance user understanding of the inherent relations in a collection of objects such as frequent itemsets. Many visualization systems have been developed to visualize raw data or mining results. However, most of these systems were not designed for visualizing frequent itemsets. In this paper, we propose a frequent itemset visualizer (FIsViz). FIsViz provides many useful features so that users can effectively see and obtain implicit, previously unknown, and potentially useful information that is embedded in data of various real-life applications.

#index 1411089
#* A tree-based approach for frequent pattern mining from uncertain data
#@ Carson Kai-Sang Leung;Mark Anthony F. Mateo;Dale A. Brajczuk
#t 2008
#c 3
#% 248785
#% 300120
#% 399794
#% 481290
#% 731405
#% 793418
#% 915241
#% 1030778
#% 1393138
#% 1411088
#% 1707794
#% 1720764
#! Many frequent pattern mining algorithms find patterns from traditional transaction databases, in which the content of each transaction--namely, items--is definitely known and precise. However, there are many real-life situations in which the content of transactions is uncertain. To deal with these situations, we propose a tree-based mining algorithm to efficiently find frequent patterns from uncertain data, where each item in the transactions is associated with an existential probability. Experimental results show the efficiency of our proposed algorithm.

#index 1411090
#* Connectivity based stream clustering using localised density exemplars
#@ Sebastian Lühr;Mihai Lazarescu
#t 2008
#c 3
#% 268018
#% 321455
#% 438137
#% 479658
#% 740767
#% 1015261
#% 1016200
#! Advances in data acquisition have allowed large data collections of millions of time varying records in the form of data streams. The challenge is to effectively process the stream data with limited resources while maintaining sufficient historical information to define the changes and patterns over time. This paper describes an evidence-based approach that uses representative points to incrementally process stream data by using a graph based method to cluster points based on connectivity and density. Critical cluster features are archived in repositories to allow the algorithm to cope with recurrent information and to provide a rich history of relevant cluster changes if analysis of past data is required. We demonstrate our work with both synthetic and real world data sets.

#index 1411091
#* Learning user purchase intent from user-centric data
#@ Rajan Lukose;Jiye Li;Jing Zhou;Satyanarayana Raju Penmetsa
#t 2008
#c 3
#% 136350
#% 342606
#% 727859
#% 729967
#% 770059
#% 818259
#% 888427
#% 926881
#% 959277
#! Most existing personalization systems rely on site-centric user data, in which the inputs available to the system are the user's behaviors on a specific site. We use a dataset supplied by a major audience measurement company that represents a complete user-centric view of clickstream behavior. Using the supplied product purchase metadata to set up a prediction problem, we learn models of the user's probability of purchase within a time window for multiple product categories by using features that represent the user's browsing and search behavior on all websites. As a baseline, we compare our results to the best such models that can be learned from site-centric data at a major search engine site. We demonstrate substantial improvements in accuracy with comparable and often better recall. A novel behaviorally (as opposed to syntactically) based search term suggestion algorithm is also proposed for feature selection of clickstream data. Finally, our models are not privacy invasive. If deployed client-side, our models amount to a dynamic "smart cookie" that is expressive of a user's individual intentions with a precise probabilistic interpretation.

#index 1411092
#* Query expansion for the language modelling framework using the naïve Bayes assumption
#@ Laurence A. F. Park;Kotagiri Ramamohanarao
#t 2008
#c 3
#% 262096
#% 280819
#% 818240
#% 838530
#% 1393154
#! Language modelling is new form of information retrieval that is rapidly becoming the preferred choice over probabilistic and vector space models, due to the intuitiveness of the model formulation and its effectiveness. The language model assumes that all terms are independent, therefore the majority of the documents returned to the ser will be those that contain the query terms. By making this assumption, related documents that do not contain the query terms will never be found, unless the related terms are introduced into the query using a query expansion technique. Unfortunately, recent attempts at performing a query expansion using a language model have not been in-line with the language model, being complex and not intuitive to the user. In this article, we introduce a simple method of query expansion using the naïve Bayes assumption, that is in-line with the language model since it is derived from the language model. We show how to derive the query expansion term relationships using probabilistic latent semantic analysis (PLSA). Through experimentation, we show that using PLSA query expansion within the language model framework, we can provide a significant increase in precision

#index 1411093
#* Fast online estimation of the joint probability distribution
#@ J. P. Patist
#t 2008
#c 3
#% 129987
#% 246832
#% 350336
#% 587754
#% 810543
#% 810711
#% 840901
#% 857390
#% 918001
#! In this paper we propose an algorithm for the on-line maintenance of the joint probability distribution of a data stream. The joint probability distribution is modeled by a mixture of low dependence Bayesian networks, and maintained by an on-line EM-algorithm. Modeling the joint probability function by a mixture of low dependence Bayesian networks is motivated by two key observations. First, the probability distribution can be maintained with time cost linear in the number of data points and constant time per data point. Whereas other methods like Bayesian networks have polynomial time complexity. Secondly, looking at the literature there is empirical indication [1] that mixtures of Naive-Bayes structures can model the data as accurate as Bayesian networks. In this paper we relax the constraints of the mixture model of Naive-Bayes structures to that of the mixture models of arbitrary low dependence structures. Furthermore we propose an on-line algorithm for the maintenance of a mixture model of arbitrary Bayesian networks. We empirically show that speed-up is achieved with no decrease in performance.

#index 1411094
#* Fast k most similar neighbor classifier for mixed data based on approximating and eliminating
#@ Selene Hernández-Rodríguez;J. Ariel Carrasco-Ochoa;J. Fco. Martínez-Trinidad
#t 2008
#c 3
#% 9649
#% 158959
#% 207795
#% 478111
#% 751625
#% 882440
#% 940215
#% 940367
#% 1011871
#% 1667834
#! The k nearest neighbor (k-NN) classifier has been a widely used nonparametric technique in Pattern Recognition. In order to decide the class of a new prototype, the k-NN classifier performs an exhaustive comparison between the prototype to classify (query) and the prototypes in the training set T. However, when T is large, the exhaustive comparison is expensive. To avoid this problem, many fast k-NN algorithms have been developed. Some of these algorithms are based on Approximating-Eliminating search. In this case, the Approximating and Eliminating steps rely on the triangle inequality. However, in soft sciences, the prototypes are usually described by qualitative and quantitative features (mixed data), and sometimes the comparison function does not satisfy the triangle inequality. Therefore, in this work, a fast k most similar neighbour classifier for mixed data (AEMD) is presented. This classifier consists of two phases. In the first phase, a binary similarity matrix among the prototypes in T is stored. In the second phase, new Approximating and Eliminating steps, which are not based on the triangle inequality, are presented. The proposed classifier is compared against other fast k-NN algorithms, which are adapted to work with mixed data. Some experiments with real datasets are presented

#index 1411095
#* Entity network prediction using multitype topic models
#@ Hitohiro Shiozaki;Koji Eguchi;Takenao Ohkawa
#t 2008
#c 3
#% 278107
#% 280819
#% 387427
#% 575570
#% 722904
#% 881534
#% 907493
#! Conveying information about who, what, when and where is a primary purpose of some genres of documents, typically news articles. To handle such information, statistical models that capture dependencies between named entities and topics can serve an important role. Although some relationships between who and where should be mentioned in such a document, no statistical topic models explicitly addressed the textual interactions between a who-entity and a where-entity. This paper presents a statistical model that directly captures dependencies between an arbitrary number of word types, such as who-entities, where-entities and topics, mentioned in each document. We show how this multitype topic model performs better at making predictions on entity networks, in which each vertex represents an entity and each edge weight represents how a pair of entities at the incident vertices is closely related, through our experiments on predictions of who-entities and links between them.

#index 1411096
#* Using supervised and unsupervised techniques to determine groups of patients with different doctor-patient stability
#@ Eu-Gene Siew;Leonid Churilov;Kate A. Smith-Miles;Joachim P. Sturmberg
#t 2008
#c 3
#% 386001
#% 630973
#! Decision trees and self organising feature maps (SOFM) are frequently used to identify groups. This research aims to compare the similarities between any groupings found between supervised (Classification and Regression Trees - CART) and unsupervised classification (SOFM), and to identify insights into factors associated with doctor-patient stability. Although CART and SOFM uses different learning paradigms to produce groupings, both methods came up with many similar groupings. Both techniques showed that self perceived health and age are important indicators of stability. In addition, this study has indicated profiles of patients that are at risk which might be interesting to general practitioners

#index 1411097
#* Local projection in jumping emerging patterns discovery in transaction databases
#@ Pawel Terlecki;Krzysztof Walczak
#t 2008
#c 3
#% 320536
#% 379331
#% 481290
#% 814195
#% 989614
#% 998464
#% 1670453
#% 1696106
#! This paper considers a rough set approach for the problem of finding minimal jumping emerging patterns (JEPs) in classified transactional datasets. The discovery is transformed into a series of transactionwise local reduct computations. In order to decrease average subproblem dimensionality, we introduce local projection of a database. The novel algorithm is compared to the table condensation method and JEP-Producer for sparse and dense, originally relational data. For a more complete picture, in our experiments, different implementations of basic structures are considered.

#index 1411098
#* Applying latent semantic indexing in frequent itemset mining for document relation discovery
#@ Thanaruk Theeramunkong;Kritsada Sriphaew;Manabu Okumura
#t 2008
#c 3
#% 282956
#% 300120
#% 783644
#% 808786
#% 1186486
#! Word-based relations among technical documents are immensely useful information but often hidden in a large amount of scientific publications. This work presents a method to apply latent semantic indexing in frequent itemset mining to discover potential relations among scientific publications. In this work, two weighting schemes, tf and tfidf are investigated with the exploitation of latent semantic indexing. The proposed method is evaluated using a set of technical documents in a publication database by comparing the extracted document relations with their references (citations). To this end, the paper uses order accumulative citation matrices to evaluate the validity (quality) of discovered patterns. The results also show that the proposed method successfully discovers a set of document relations, comparing to the original method that uses no latent semantic indexing.

#index 1411099
#* G-TREACLE: a new grid-based and tree-alike pattern clustering technique for large databases
#@ Cheng-Fa Tsai;Chia-Chen Yen
#t 2008
#c 3
#% 248792
#% 776575
#% 1393220
#! As data mining having attracted a significant amount of research attention, many clustering methods have been proposed in past decades. However, most of those techniques have annoying obstacles in precise pattern recognition. This paper presents a new clustering algorithm termed G-TREACLE, which can fulfill numerous clustering requirements in data mining applications. As a hybrid approach that adopts grid-based concept, the proposed algorithm recognizes the solid framework of clusters and, then, identifies the arbitrary edge of clusters by utilization of a new density-based expansion process, which named "tree-alike pattern". Experimental results illustrate that the new algorithm precisely recognizes the whole cluster, and efficiently reduces the problem of high computational time. It also indicates that the proposed new clustering algorithm performs better than several existing well-known approaches such as the K-means, DBSCAN, CLIQUE and GDH algorithms, while produces much smaller errors than the K-means, DBSCAN, CLIQUE and GDH approaches in most the cases examined herein

#index 1411100
#* A clustering-oriented star coordinate translation method for reliable clustering parameterization
#@ Chieh-Yuan Tsai;Chuang-Cheng Chiu
#t 2008
#c 3
#% 342601
#% 972390
#% 1788944
#! When conducting a clustering process, users are generally concerned whether the clustering result is reliable enough to reflect the actual clustering phenomenon. The number of clusters and initial cluster centers are two critical parameters that influence the reliability of clustering results highly. We propose a Clustering-Oriented Star Coordinate Translation (COSCT) method to help users determining the two parameters more confidently. Through COSCT all objects from a multi-dimensional space are adaptively translated to a 2D starcoordinate plane, so that the clustering parameterization can be easily conducted by observing the clustering phenomenon in the plane. To enhance the cluster-displaying quality of the star-coordinate plane, the feature weighting and coordinate arrangement procedures are developed. The effectiveness of the COSCT method is demonstrated using a set of experiments.

#index 1411101
#* Constrained clustering for gene expression data mining
#@ Vincent S. Tseng;Lien-Chin Chen;Ching-Pin Kao
#t 2008
#c 3
#% 341704
#% 451052
#% 464291
#% 464608
#% 464631
#% 466890
#% 839670
#! Constrained clustering algorithms have the advantage that domaindependent constraints can be incorporated in clustering so as to achieve better clustering results. However, the existing constrained clustering algorithms are mostly k-means like methods, which may only deal with distance-based similarity measures. In this paper, we propose a constrained hierarchical clustering method, called Correlational-Constrained Complete Link (C-CCL), for gene expression analysis with the consideration of gene-pair constraints, while using correlation coefficients as the similarity measure. C-CCL was evaluated for the performance with the correlational version of COP-k-Means (C-CKM) method on a real yeast dataset. We evaluate both clustering methods with two validation measures and the results show that C-CCL outperforms C-CKM substantially in clustering quality

#index 1411102
#* Concept lattice-based mutation control for reactive motifs discovery
#@ Kitsana Waiyamai;Peera Liewlom;Thanapat Kangkachit;Thanawin Rakthanmanon
#t 2008
#c 3
#% 471417
#% 535537
#% 832870
#% 1389053
#% 1671162
#! We propose a method for automatically discovering reactive motifs, which are motifs discovered from binding and catalytic sites, which incorporate information at binding and catalytic sites with bio-chemical knowledge. We introduce the concept of mutation control that uses amino acid substitution groups and conserved regions to generate complete amino acid substitution groups. Mutation control operations are described and formalized using a concept lattice representation. We show that a concept lattice is efficient for both representations of bio-chemical knowledge and computational support for mutation control operations. Experiments using a C4.5 learning algorithm with reactive motifs as features predict enzyme function with 72% accuracy compared with 67% accuracy using expert-constructed motifs. This suggests that automatically generating reactive motifs are a viable alternative to the time-consuming process of expert-based motifs for enzyme function prediction.

#index 1411103
#* Mining a complete set of both positive and negative association rules from large databases
#@ Hao Wang;Xing Zhang;Guoqing Chen
#t 2008
#c 3
#% 152934
#% 227919
#% 248012
#% 464822
#% 481290
#% 628207
#% 767654
#% 799740
#! Association rule mining is one of the key issues in knowledge discovery. In recent years, negative association rule mining has attracted remarkable attention. This paper presents a notion of validity for both positive and negative association rules, which is considered intuitive and necessary. Then, a mining algorithm to find all rules in light of completeness is proposed. In doing so, several pruning strategies based on the upward closure property are developed and incorporated into the algorithm so as to guarantee the computational efficiency.

#index 1411104
#* Designing a system for a process parameter determined through modified PSO and fuzzy neural network
#@ Jui-Tsung Wong;Kuei-Hsien Chen;Chwen-Tzeng Su
#t 2008
#c 3
#% 571704
#% 1788453
#! In the manufacturing industry, the key to retaining a competitive advantage lies in increased yield and reduced a number of reworks. Determining the optimal parameters for the process so that the quality characteristics can meet the target is an important strategy. Traditional statistical techniques such as response surface methodology and analysis of variance, whose basic assumptions must be met, are generally used in this regard. In recent years, artificial intelligence has reached a sufficient level of maturity and is extensively being used in various domains. This paper proposes a system based on the modified particle swarm optimizer (PSO) and the adaptive network-based fuzzy inference system (ANFIS) to determine the process parameters. A perturbed strategy is incorporated into the modified PSO. The application of this system is then demonstrated with the determining of parameters in the wire bonding process in the IC packaging industry. Moreover, the performance of the modified PSO is evaluated with testing functions. The results show that the modified PSO yielded a superior performance to traditional PSO. In the optimization of the process parameter, the modified PSO is able to find the optimal solution in the ANFIS model.

#index 1411105
#* Data-aware clustering hierarchy for wireless sensor networks
#@ Xiaochen Wu;Peng Wang;Wei Wang;Baile Shi
#t 2008
#c 3
#% 236912
#% 366513
#% 414174
#% 444568
#% 608160
#% 1675422
#% 1772138
#% 1832810
#! In recent years, the wireless sensor network (WSN) is employed a wide range of applications. But existing communication protocols for WSN ignore the characteristics of collected data and set routes only according to the mutual distance and residual energy of sensors. In this paper we propose a Data-Aware Clustering Hierarchy (DACH), which organizes the sensors based on both distance information and data distribution in the network Furthermore, we also present a multi-granularity query processing method based on DACH, which can estimate the query result more efficiently. Our empirical study shows that DACH has higher energy efficiency than Low-Energy Adaptive Clustering Hierarchy (LEACH), and the multi-granularity query processing method based on DACH brings more accurate results than a random access system using same cost of energy.

#index 1411106
#* A more topologically stable locally linear embedding algorithm based on R*-tree
#@ Tian Xia;Jintao Li;Yongdong Zhang;Sheng Tang
#t 2008
#c 3
#% 86950
#% 593047
#% 879415
#! Locally linear embedding is a popular manifold learning algorithm for nonlinear dimensionality reduction. However, the success of LLE depends greatly on an input parameter - neighborhood size, and it is still an open problem how to find the optimal value for it. This paper focuses on this parameter, proposes that it should be self-tuning according to local density not a uniform value for all the data as LLE does, and presents a new variant algorithm of LLE, which can effectively prune "short circuit" edges by performing spatial search on the R*-Tree built on the dataset. This pruning leads the original fixed neighborhood size to be a self-tuning value, thus makes our algorithm have more topologically stableness than LLE does. The experiments prove that our idea and method are correct.

#index 1411107
#* Sparse kernel-based feature weighting
#@ Shuang-Hong Yang;Yu-Jiu Yang;Bao-Gang Hu
#t 2008
#c 3
#% 126894
#% 266426
#% 722929
#% 722942
#% 857439
#% 913838
#% 975162
#% 983819
#% 1759704
#! The success of many learning algorithms hinges on the reliable selection or construction of a set of highly predictive features. Kernel-based feature weighting bridges the gap between feature extraction and subset selection. This paper presents a rigorous derivation of the Kernel-Relief algorithm and assesses its effectiveness in comparison with other state-of-art techniques. For practical considerations, an online sparsification procedure is incorporated into the basis construction process by assuming that the kernel bases form a causal series. The proposed sparse Kernel-Relief algorithm not only produces nonlinear features with extremely sparse kernel expressions but also reduces the computational complexity significantly.

#index 1411108
#* Term committee based event identification within news topics
#@ Kuo Zhang;JuanZi Li;Gang Wu;KeHong Wang
#t 2008
#c 3
#% 144034
#% 262042
#% 350859
#% 397148
#% 445316
#% 577297
#% 783535
#% 818215
#% 824666
#! Most previous research focus on organizing news set into flat collections of stories. However, a topic in news is more than a mere collection of stories: it is characterized by a definite structure of inter-related events. Stories within a topic usually share some terms which are related to the topic other than a specific event, so stories of different events are usually very similar to each other within a topic. To deal with this problem, we propose a new event identification method based on the term committee. We first capture some tight term clusters as term committees of potential events, and then use them to reweight the key terms in a story. The experimental results on two Linguistic Data Consortium (LDC) datasets show that the proposed method for event identification outperforms previous methods significantly.

#index 1411109
#* Locally linear online mapping for mining low-dimensional data manifolds
#@ Huicheng Zheng;Wei Shen;Qionghai Dai;Sanqing Hu
#t 2008
#c 3
#% 236651
#% 391311
#% 1075274
#% 1393163
#% 1860128
#! This paper proposes an online-learning neural model which maps nonlinear data structures onto mixtures of low-dimensional linear manifolds. Thanks to a new distortion measure, our model avoids confusion between local sub-models common in other similar networks. There is no local extremum for learning at each neuron. Mixtures of local models are achieved by competitive and cooperative learning under a self-organizing framework. Experiments show that the proposed model is better adapted to various nonlinear data distributions than other models in comparison. We further show a successful application of this model to discovering low-dimensional manifolds of handwritten digit images for recognition.

#index 1411110
#* A creditable subspace labeling method based on D-S evidence theory
#@ Yu Zong;Xian-Chao Zhang;He Jiang;Ming-Chu Li
#t 2008
#c 3
#% 77847
#% 248790
#% 248792
#% 280417
#% 420057
#% 443531
#% 481281
#! Due to inherent sparse, noise and nearly zero difference characteristics of high dimensional data sets, traditional clustering methods fails to detect meaningful clusters in them. Subspace clustering attempts to find the true distribution inherent to the subsets with original attributes. However, which subspace contains the true clustering result is usually uncertain. From this point of view, subspace clustering can be regarded as an uncertain discursion problem. In this paper, we firstly develop the criterion to evaluate creditable subspaces which contain the meaningful clustering results, and then propose a creditable subspace labeling method (CSL) based on D-S evidence theory. The creditable subspaces of the original data space can be found by iteratively executing the algorithm CSL. Once the creditable subspaces are got, the true clustering results can be found using a traditional clustering algorithm on each creditable subspace. Experiments show that CSL can detect the actual creditable subspace with the original attribute. In this way, a novel approach of clustering problems using traditional clustering algorithms to deal with high dimension data sets is proposed.

#index 1411111
#* Discovering new orders of the chemical elements through genetic algorithms
#@ Alexandre Blansché;Shuichi Iwata
#t 2008
#c 3
#% 428427
#% 798814
#% 1022816
#! The design of new materials is a major issue in many domains (electronics, environment and so on). A large number of databases have been developed in order to help scientists to design new materials. Databases of experimental results can be used to learn prediction models of each property. Data mining methods, can be applied on such databases to discover empirical rules and predict properties. In this paper we propose a method for discovering new orders of the chemical elements. This reorganization of the chemical elements can be used to improved prediction accuracy of classification methods and to enhance similarities between elements. A genetic algorithm is used to find a satisfying solution according to several evaluation criteria through a Pareto-based multi-objective approach. We carried out several experiments of prediction of compound formation (ternary chalcopyrite compounds ABX2, where X is either S, Se or Te). The first results showed that distance-based evaluation seems promising, as it has been possible to discover groups of similar elements regarding the task.

#index 1411112
#* What is frequent in a single graph?
#@ Björn Bringmann;Siegfried Nijssen
#t 2008
#c 3
#% 232136
#% 629708
#% 841960
#% 917768
#% 1117041
#% 1692830
#! The standard, transactional setting of pattern mining assumes that data is subdivided in transactions; the aim is to find patterns that can be mapped onto at least a minimum number of transactions. However, this setting can be hard to apply when the aim is to find graph patterns in databases consisting of large graphs. For instance, the web, or any social network, is a single large graph that one may not wish to split into small parts. The focus in network analysis is on finding structural regularities or anomalies in one network, rather than finding structural regularities common to a set of them. This requires us to revise the definition of key concepts in pattern mining, such as support, in the single-graph setting. Our contribution is a support measure that we prove to be computationally less expensive and often closer to intuition than other measures proposed. Further we prove several properties between these measures and experimentally validate the efficiency of our measure.

#index 1411113
#* A cluster-based genetic-fuzzy mining approach for items with multiple minimum supports: `
#@ Chun-Hao Chen;Tzung-Pei Hong;Vincent S. Tseng
#t 2008
#c 3
#% 240200
#% 246002
#% 251420
#% 481290
#% 893944
#! In the past, we proposed an algorithm for extracting appropriate multiple minimum support values, membership functions and fuzzy association rules form quantitative transactions. The evaluation process might take a lot of time, especially when the database to be scanned could not totally fed into main memory. In this paper, an enhanced approach, called the Cluster-based Genetic-Fuzzy mining approach for items with Multiple Minimum Supports (CGFMMS), is thus proposed to speed up the evaluation process and keep nearly the same quality of solutions as the previous one. Experimental results also show the effectiveness and the efficiency of the proposed approach.

#index 1411114
#* A selective classifier for incomplete data
#@ Jingnian Chen;Houkuan Huang;Fengzhan Tian;Shengfeng Tian
#t 2008
#c 3
#% 17144
#% 136350
#% 169659
#% 322915
#% 926881
#% 975104
#% 1290046
#! Classifiers based on feature selection (selective classifiers) are a kind of algorithms that can effectively improve the accuracy and efficiency of classification by deleting irrelevant or redundant attributes of a data set. Due to the complexity of processing incomplete data, however, most of them deal with complete data. Yet actual data are often incomplete and have many redundant or irrelevant attributes. So constructing selective classifiers for incomplete data is an important problem. With the analysis of main methods of processing incomplete data for classification, a selective classifier for incomplete data named RBSR (ReliefF algorithm-Based Selective Robust Bayes Classifier), which is based on the Robust Bayes Classifiers (RBC) and ReliefF algorithm, is presented. The proposed algorithm needs no assumptions about data sets that are necessary for previous methods of processing incomplete data in classification. This algorithm can deal with incomplete data sets with many attributes and instances. Experiments were performed on twelve benchmark incomplete data sets. We compared RBSR with the very effective RBC and several other classifiers for incomplete data. The experimental results show that RBSR can not only enormously reduce the number of redundant or irrelevant attributes, but greatly improve the accuracy and stability of classification as well.

#index 1411115
#* Detecting near-duplicates in large-scale short text databases
#@ Caichun Gong;Yulan Huang;Xueqi Cheng;Shuo Bai
#t 2008
#c 3
#% 46803
#% 201889
#% 201935
#% 347225
#% 504572
#% 879600
#% 956507
#! Near-duplicates are abundant in short text databases. Detecting and eliminating them is of great importance. SimFinder proposed in this paper is a fast algorithm to identify all near-duplicates in large-scale short text databases. An ad hoc term weighting scheme is employed to measure each term's discriminative ability. A certain number of terms with higher weights are seletect as features for each short text. SimFinder generates several fingerprints for each text, and only texts with at least one fingerprint in common are compared with each other. An optimization procedure is employed in SimFinder to make it more efficient. Experiments indicate that SimFinder is an effective solution for short text duplicate detection with almost linear time and storage complexity. Both precision and recall of SimFinder are promising.

#index 1411116
#* Customer churn time prediction in mobile telecommunication industry using ordinal regression
#@ Rupesh K. Gopal;Saroj K. Meher
#t 2008
#c 3
#% 290482
#% 572780
#% 959870
#% 1088723
#! Customer churn in considered to be a core issue in telecommunication customer relationship management (CRM). Accurate prediction of churn time or customer tenure is important for developing appropriate retention strategies. In this paper, we discuss a method based on ordinal regression to predict churn time or tenure of mobile telecommunication customers. Customer tenure is treated as an ordinal outcome variable and ordinal regression is used for tenure modeling. We compare ordinal regression with the state-of-the-art methods for tenure prediction - survival analysis. We notice from our results that ordinal regression could be an alternative technique for survival analysis for churn time prediction of mobile customers. To the best knowledge of authors, the use of ordinal regression as a potential technique for modeling customer tenure has been attempted for the first time.

#index 1411117
#* Rule extraction with rough-fuzzy hybridization method
#@ Nan-Chen Hsieh
#t 2008
#c 3
#% 271689
#% 428036
#% 784508
#% 1345629
#% 1346946
#% 1786932
#% 1788596
#! This study presents a rough-fuzzy hybridization method to generate fuzzy if-then rules automatically from a medical diagnosis dataset with quantitative data values, based on fuzzy set and rough set theory. The proposed method consists of four stages: preprocessing inputs with fuzzy linguistic representation; rough set theory in finding notable reducts; candidate fuzzy if-then rules generation by data summarization, and truth evaluation the effectiveness of fuzzy if-then rules. The main contributions of the proposed method are the capability of fuzzy linguistic representation of the fuzzy if-then rules, finding concise fuzzy if-then rules from medical diagnosis dataset, and tolerance of imprecise data.

#index 1411118
#* I/O scalable Bregman co-clustering
#@ Kuo-Wei Hsu;Arindam Banerjee;Jaideep Srivastava
#t 2008
#c 3
#% 300213
#% 420053
#% 443082
#% 734592
#% 766665
#% 769928
#% 771926
#% 845220
#% 989573
#% 1014670
#% 1669944
#! Consider an MxN matrix, where the (i,j)th entry represents the affinity between the i_th entity of the first type and the j_th entity of the second type. Co-clustering is an approach to simultaneously cluster both types of entities, using the affinities as the information guiding the clustering. Co-clustering has been found to achieve clustering and dimensionality reduction at the same time, and therefore it is finding application in various problems. Bregman co-clustering algorithm, which has been recently proposed, converts the co-clustering task to the search for an optimal approximation matrix. It is much more scalable but memory-based implementations have a severe computational bottleneck. In this paper we show that a significant fraction of computations performed by the Bregman co-clustering algorithm naturally map to those performed by an on-line analytical processing (OLAP) engine, making the latter a well suited data management engine for the algorithm. Based on this observation, we have developed a version of Bregman co-clustering algorithm that works on top of OLAP. Our experiments show that this version is much more scalable, achieving an order of magnitude performance improvement over the memory-based implementation. We believe this unlocks the power of this novel technique for application to much larger datasets.

#index 1411119
#* Jumping emerging patterns with occurrence count in image classification
#@ Łukasz Kobyliński;Krzysztof Walczak
#t 2008
#c 3
#% 345848
#% 379331
#! In this paper we propose an application of jumping emerging patterns (JEPs) to the classification of images. We define of a new type of patterns, namely the jumping emerging patterns with occurrence count (occJEPs), which allow reasoning in transaction databases with recurrent items. Such data is a frequently used representation of images, for which classification is one of the most important data mining problems that needs to be solved accurately and efficiently. We provide a formal definition of the new type of patterns, an outline of an algorithm for finding occJEPs and a comparison with other rule- and pattern-based classifiers for a selection of sample images.

#index 1411120
#* Mining non-coincidental rules without a user defined support threshold
#@ Yun Sing Koh
#t 2008
#c 3
#% 227919
#% 280487
#% 323981
#% 420073
#% 481290
#% 578394
#% 717219
#% 729988
#% 767654
#% 1707789
#! Traditional association rulemining techniques employ the support and confidence framework. However, specifying minimum support of the mined rules in advance often leads to either too many or too few rules, which negatively impacts the performance of the overall system. Here we propose replacing Apriori's user-defined minimum support threshold with the more meaningful MinAbsSup function. This calculates a custom minimum support for each itemset based on the probability of chance collision of its items, as derived from the inverse of Fisher's exact test. We will introduce the notion of coincidental itemsets; given a transaction dataset there is a chance that two independent items are appearing together by random coincidence. Rules generated from these itemsets do not denote a meaningful association, and are not useful.

#index 1411121
#* Transaction clustering using a seeds based approach
#@ Yun Sing Koh;Russel Pears
#t 2008
#c 3
#% 118771
#% 152934
#% 203462
#% 280419
#% 287285
#% 296738
#% 314054
#% 479659
#% 483675
#% 1390196
#! Transaction clustering has received a great deal of attention in the past few years. Its functionality extends well beyond traditional clustering algorithms which basically perform a near-neighbourhood search for locating groups of similar instances. The basic concept underlying transaction clustering stems from the concept of large items as defined by association rule mining algorithms. Clusters formed on the basis of large items that are shared between instances offer an attractive alternative to association rule mining systems. Currently, none of the techniques proposed offer a good solution to scenarios where large items overlap across clusters. In this paper we overcome the aforementioned limitations by using cluster seeds that represent initial centroids. Seeds are generated from sets of transaction items that occur together above a certain threshold and such seeds may overlap in their itemsets across clusters.

#index 1411122
#* Using ontology-based user preferences to aggregate rank lists in web search
#@ Lin Li;Zhenglu Yang;Masaru Kitsuregawa
#t 2008
#c 3
#% 309095
#% 330769
#% 641963
#% 728360
#% 818224
#% 832349
#% 838547
#% 1250380
#% 1397425
#! This paper studies rank aggregation by using ontology-based user preferences in the context of Web search. We introduce a set of techniques to combine the respective rank lists produced by different attributes of user preferences. Furthermore, the learned user preferences are structured as a taxonomic hierarchy (a simple ontology). We use the learned ontology to store the attributes such as, the topics that a user is interested in and the degrees of user interests in these topics. The primary goal of our work is to form a broadly acceptable rank list among these attributes by making use of rank-based aggregation. Experiment results on a real click-through data set show that our user-centered rank aggregation techniques are effective in improving the quality of the Web search in terms of user satisfaction.

#index 1411123
#* The application of echo state network in stock data mining
#@ Xiaowei Lin;Zehong Yang;Yixu Song
#t 2008
#c 3
#% 931317
#% 943557
#% 977260
#% 977265
#! Stock data, which is among the most complicated time series, is difficult to analyze and mine. Neural network has been a popular method for data mining in financial area since last decade. In this paper, we explore the use of Echo State Networks (ESNs) to perform time-series mining on stock markets. The Hurst exponent is applied to adaptively determine initial transient and choose sub-series with greatest predictability before training. With the capability of short-term memory provided by ESN, a stock prediction system is built to forecast the close price of the next trading day based on history prices and technical indicators. The experiment results on S&P 500 data set suggest that ESN outperforms other conventional neural networks in most cases and is a suitable and effective way for stock price mining.

#index 1411124
#* Text categorization of multilingual web pages in specific domain
#@ Jicheng Liu;Chunyan Liang
#t 2008
#c 3
#% 200694
#% 318412
#% 325001
#% 430761
#% 458379
#! Compared to the traditional text categorization, automated categorization for domain- specific web pages poses new research challenges because of the noisy and diverse nature of the pages and the fine and complex category structure. For multilingual web pages, it also needs to be considered that how to extract the terms of different languages exactly. Using a dataset of hybrid Chinese-English chemical web pages, a new dictionary-based multilingual text categorization approach is proposed in this paper to try to classify the pages into a hierarchical topic structure more accurately. By using an automatic encoding detection and integration method, the approach can properly recognize and integrate the web page encodings. This makes the feature extraction more precise for the multilingual pages. The approach can also intensify the domain concepts in the web pages based on a chemistry dictionary. The experimental results show that the proposed approach has the better performance than the traditional categorization method when classifying the multilingual web pages in specific domain.

#index 1411125
#* Efficient joint clustering algorithms in optimization and geography domains
#@ Chia-Hao Lo;Wen-Chih Peng
#t 2008
#c 3
#% 466890
#% 576214
#% 800179
#% 989622
#% 1393158
#! Prior works have elaborated on the problem of joint clustering in the optimization and geography domains. However, prior works neither clearly specify the connected constraint in the geography domain nor propose efficient algorithms. In this paper, we formulate the joint clustering problem in which a connected constraint and the number of clusters should be specified. We propose an algorithm K-means with Local Search (abbreviated as KLS) to solve the joint clustering problem with the connected constraint. Experimental results show that KLS can find correct clusters efficiently.

#index 1411126
#* Active learning with misclassification sampling using diverse ensembles enhanced by unlabeled instances
#@ Jun Long;Jianping Yin;En Zhu;Wentao Zhao
#t 2008
#c 3
#% 116165
#% 169717
#% 236729
#% 443616
#% 464268
#% 466095
#% 466576
#% 770807
#% 1272126
#% 1279286
#! Active learners can significantly reduce the number of labeled training instances to learn a classification function by actively selecting only the most informative instances for labeling. Most existing methods try to select the instances which could halve the version space size after each sampling. In contrast to them, we try to reduce the volume of the version space more than half. Therefore, a sampling criterion of misclassification is presented. Furthermore, in each iteration of active learning, a strong classifier was introduced to estimate the target function for evaluation of the misclassification degree of an instance. We use a modified popular ensemble learning method DECORATE as the strong classifier which was enhanced by the unlabeled instances with high certainty by the current base classifier. The experiments show that the proposed method outperforms the traditional sampling methods on most selected datasets.

#index 1411127
#* A new model for image annotation
#@ Sanparith Marukatat
#t 2008
#c 3
#% 457912
#% 642989
#% 780862
#% 1502531
#! An approach to automatic image annotation is proposed. Generally, the relation between visual characteristics and the annotation label is estimated from the annotated corpus and is used to predict label for new test image. Unfortunately, when limited number of images are annotated, with possible multiple labels per image, this relation cannot be reliably estimated. To cope with this problem, we propose taking into account information derived directly from other images in the dataset. This method extends naturally to semi-supervised setting where un-annotated images are also used select annotation labels. Experiment shows that the proposed method yields promising results.

#index 1411128
#* Unmixed spectrum clustering for template composition in lung sound classification
#@ Tomonari Masada;Senya Kiyasu;Sueharu Miyahara
#t 2008
#c 3
#% 899702
#% 1860500
#! In this paper, we propose a method for composing templates of lung sound classification. First, we obtain a sequence of power spectra by FFT for each given lung sound and compute a small number of component spectra by ICA for each of the overlapping sets of tens of consecutive power spectra. Second, we put component spectra obtained from various lung sounds into a single set and conduct clustering a large number of times. When component spectra belong to the same cluster in all clustering results, these spectra show robust similarity. Therefore, we can use such spectra to compose a template of lung sound classification.

#index 1411129
#* Forward semi-supervised feature selection
#@ Jiangtao Ren;Zhengyuan Qiu;Wei Fan;Hong Cheng;Philip S. Yu
#t 2008
#c 3
#% 252011
#% 722929
#% 796212
#% 983948
#! Traditionally, feature selection methods work directly on labeled examples. However, the availability of labeled examples cannot be taken for granted for many real world applications, such as medical diagnosis, forensic science, fraud detection, etc, where labeled examples are hard to find. This practical problem calls the need for "semi-supervised feature selection" to choose the optimal set of features given both labeled and unlabeled examples that return the most accurate classifier for a learning algorithm. In this paper, we introduce a "wrapper-type" forward semi-supervised feature selection framework. In essence, it uses unlabeled examples to extend the initial labeled training set. Extensive experiments on publicly available datasets shows that our proposed framework, generally, outperforms both traditional supervised and state of-the-art "filter-type" semi-supervised feature selection algorithms [5] by 1% to 10% in accuracy.

#index 1411130
#* Automatic extraction of basis expressions that indicate economic trends
#@ Hiroki Sakaji;Hiroyuki Sakai;Shigeru Masuyama
#t 2008
#c 3
#% 939719
#% 939897
#! This paper proposes a method to automatically extract basis expressions that indicate economic trends from newspaper articles by using a statistical method. We also propose a method to classify them into positive expressions that indicate upbeat, and negative expressions that indicate downturn in economy, respectively. It is important for companies, governments and investors to predict economic trends in order to forecast revenue, sales of products, prices of commodities and stock prices. We considered that basis expressions are useful for the companies, governments and investors to forecast economic trends. We extracted basis expressions, and classified them into positive expressions or negative expressions as information to forecast economic trends. Our method used a bootstrap method that was minimally a supervised algorithm for extracting basis expressions. Moreover, our method classified basis expressions into positive expressions or negative ones without dictionaries.

#index 1411131
#* A new framework for taxonomy discovery from text
#@ Ahmad El Sayed;Hakim Hacid;Djamel Zighed
#t 2008
#c 3
#% 363038
#% 445448
#% 742666
#% 786523
#% 1272078
#% 1917617
#! Ontology learning from text is considered as an appealing and a challenging approach to address the shortcomings of the handcrafted ontologies. In this paper, we present OLEA, a new framework for ontology learning from text. The proposal is a hybrid approach combining the pattern-based and the distributional approaches. It addresses key issues in the area of ontology learning: low recall of the pattern-based approach, low precision of the distributional approach, and finally ontology evolution. Preliminary experiments performed at each stage of the learning process show the pros and cons of the proposal.

#index 1411132
#* R-map: mapping categorical data for clustering and visualization based on reference sets
#@ Zhi-Yong Shen;Jun Sun;Yi-Dong Shen;Ming Li
#t 2008
#c 3
#% 314054
#! In this paper, we propose a framework that maps categorical data into a numerical data space via a reference set, aiming to make the existing numerical clustering algorithms directly applicable on the generated image data set as well as to visualize the data. Using statistics theories, we analyze our framework and give the conditions under which the data mapping is efficient and yet preserves a flexible property of the original data, i.e. the data points within the same cluster are more similar. The algorithm is simple and has good effectiveness under some conditions. The experimental evaluation on numerous categorical data sets shows that it not only outperforms the related data mapping approaches but also beats some categorical clustering algorithms in terms of effectiveness and efficiency.

#index 1411133
#* Mining changes in patent trends for competitive intelligence
#@ Meng-Jung Shih;Duen-Ren Liu;Ming-Li Hsu
#t 2008
#c 3
#% 1345699
#! Obtaining sufficient competitive intelligence is a critical factor in helping business managers gain and maintain competitive advantages. Patent data is an important source of competitive intelligence that enterprises can use to gain a strategic advantage. Under existing approaches, to detect changes in patent trends, business managers must rely on comparing two patent analysis charts of different time periods, it requires human effort and time. In this paper, we propose a patent trend change mining (PTCM) technique that can identify changes in patent trends without the need for specialist knowledge. We apply the PTCM approach to Taiwan's semiconductor industry to discover changes in four types of patent trends: the R&D activities of a company, the R&D activities of the industry, company activities in the industry and industry activities generally. The change mining approach generates competitive intelligence to help managers develop appropriate business strategies based on their findings.

#index 1411134
#* Seeing several stars: a rating inference task for a document containing several evaluation criteria
#@ Kazutaka Shimada;Tsutomu Endo
#t 2008
#c 3
#% 211044
#% 466263
#% 815915
#% 854646
#% 907489
#% 939346
#% 1250238
#% 1299754
#% 1712143
#! In this paper we address a novel sentiment analysis task of rating inference. Previous rating inference tasks, which are sometimes referred to as "seeing stars", estimate only one rating in a document. However reviewers judge not only the overall polarity for a product but also details for it. A document in this new task contains several ratings for a product. Furthermore the range of the ratings is zero to six points (i.e., stars). In other words this task denotes "seeing several stars in a document". If significant words or phrases for evaluation criteria and their strength as positive or negative opinions are extracted, a system with the knowledge can recommend products for users appropriately. For example, the system can output a detailed summary from review documents. In this paper we compare several methods to infer the ratings in a document and discuss a feature selection approach for the methods. The experimental results are useful for new researchers who try this new task.

#index 1411135
#* Structure-based hierarchical transformations for interactive visual exploration of social networks
#@ Lisa Singh;Mitchell Beard;Brian Gopalan;Gregory Nelson
#t 2008
#c 3
#% 283833
#% 641202
#% 982260
#! In this paper, we propose hierarchical transformations of traditional social networks based on structural expansion values of nodes in the network. The hierarchical visualization clusters or groups nodes with similar structural expansion values in the network. It is a complement to traditional network visualization and gives users the ability to quickly understand how structure is distributed throughout the network. After describing our approach, we analyze a real world social network, highlighting the benefit of a network structure-based hierarchical transformation for visual exploration of this network.

#index 1411136
#* CP-tree: a tree structure for single-pass frequent pattern mining
#@ Syed Khairuzzaman Tanbeer;Chowdhury Farhan Ahmed;Byeong-Soo Jeong;Young-Koo Lee
#t 2008
#c 3
#% 152934
#% 300120
#% 481290
#% 951835
#% 985041
#! FP-growth algorithm using FP-tree has been widely studied for frequent pattern mining because it can give a great performance improvement compared to the candidate generation-and-test paradigm of Apriori. However, it still requires two database scans which are not applicable to processing data streams. In this paper, we present a novel tree structure, called CP-tree (Compact Pattern tree), that captures database information with one scan (Insertion phase) and provides the same mining performance as the FP-growth method (Restructuring phase) by dynamic tree restructuring process. Moreover, CP-tree can give full functionalities for interactive and incremental mining. Extensive experimental results show that the CP-tree is efficient for frequent pattern mining, interactive, and incremental mining with single database scan.

#index 1411137
#* Combining context and existing knowledge when recognizing biological entities: early results
#@ Mika Timonen;Antti Pesonen
#t 2008
#c 3
#% 830618
#! Entity recognition has been studied for several years with good results. However, as the focus of information extraction (IE) and entity recognition (ER) has been set on biology and bioinformatics, the existing methods do not produce as good results as before. This is mainly due to the complex naming conventions of biological entities. In our information extraction system for biomedical documents called OAT (Ontology Aided Text mining system) we developed our own method for recognizing the biological entities. The difference to the existing methods, which use lexicons, rules and statistics, is that we combine the context of the entity with the existing knowledge about the relationships of the entities. This has produced encouraging preliminary results. This paper describes the approach we are using in our information extraction system for entity recognition.

#index 1411138
#* Semantic video annotation by mining association patterns from visual and speech features
#@ Vincent S. Tseng;Ja-Hwung Su;Jhih-Hong Huang;Chih-Jen Chen
#t 2008
#c 3
#% 800182
#% 899439
#% 1032195
#% 1279436
#% 1502531
#! In this paper, we propose a novel approach for semantic video annotation through integrating visual features and speech features. By employing statistics and association patterns, the relations between video shots and human concept can be discovered effectively to conceptualize videos. In other words, the utilization of high-level rules can effectively complement the insufficiency of statistics-based methods in dealing with broad and complex keyword identification in video annotation. Empirical evaluations on NIST TRECVID video datasets reveal that our proposed approach can enhance the annotation accuracy substantially.

#index 1411139
#* Cell-based outlier detection algorithm: a fast outlier detection algorithm for large datasets
#@ You Wan;Fuling Bian
#t 2008
#c 3
#% 300136
#% 300183
#% 342625
#% 478624
#% 479791
#% 501988
#% 574604
#% 729912
#! Finding outliers is an important task for many KDD applications. We developed a cell-based outlier detection algorithm (short for CEBOD) to detect outliers in large dataset. The algorithm is based on LOF; major difference is CEBOD can avoid large computations on the majority part of dataset by filter the initial dataset. Our experiment shows that CEBOD is more efferent than LOF, and can find outliers in large datasets fast and accurately. A large dataset is loaded into memory by blocks, and the data are placed into appropriate cells based on their values. Each cell holds a certain number of data, which represents the cell's density. Data locate in high density cells and have no nearness relationship with local outlier factor calculation are filtered. And we record these cells' density for the next block of data fill in. The final calculation will be done on those data in low density cells. In this way, we can handle a large dataset which can't be loaded into memory once, improving the algorithm's efficiency by reducing many useless computations. The time complexity of CEBOD is O(N).

#index 1411140
#* Fighting webspam: detecting spam on the graph via content and link features
#@ Yu-Jiu Yang;Shuang-Hong Yang;Bao-Gang Hu
#t 2008
#c 3
#% 983949
#% 987245
#% 1016177
#% 1279294
#! We address a novel semi-supervised learning strategy for Web Spam issue. The proposed approach explores graph construction which is the key of representing data semantical relationship, and emphasizes on label propagation from multi views under consistency criterion. Furthermore, we infer labels for the rest of the unlabeled nodes in fusing spectral space. Experiments on the Webspam Challenging dataset validate the efficiency and effectiveness of the proposed method.

#index 1411141
#* A framework for discovering spatio-temporal cohesive networks
#@ Jin Soung Yoo;Joengmin Hwang
#t 2008
#c 3
#% 466644
#% 844416
#! A spatio-temporal cohesive network represents a social network in which people often interact closely in both space and time. Spatially and temporally close people tend to share information and show homogeneous behavior.We discuss modeling social networks from spatiotemporal human activity data, and alternative interest measures for estimating the strength of subgroup cohesion in spatial and temporal space. We present an algorithm for mining spatio-temporal cohesive networks.

#index 1411142
#* Efficient mining of minimal distinguishing subgraph patterns from graph databases
#@ Zhiping Zeng;Jianyong Wang;Lizhu Zhou
#t 2008
#c 3
#% 629708
#% 844306
#% 864460
#% 956459
#% 1037035
#! Distinguishing patterns represent strong distinguishing knowledge and are very useful for constructing powerful, accurate and robust classifiers. The distinguishing graph patterns(DGPs) are able to capture structure differences between any two categories of graph datasets. Whereas, few previous studies worked on the discovery of DGPs. In this paper, as the first, we study the problem of mining the complete set of minimal DGPs with any number of positive graphs, arbitrary positive support and negative support. We proposed a novel algorithm, MDGP-Mine, to discover the complete set of minimal DGPs. The empirical results show that MDGP-Mine is efficient and scalable.

#index 1411143
#* Combined association rule mining
#@ Huaifeng Zhang;Yanchang Zhao;Longbing Cao;Chengqi Zhang
#t 2008
#c 3
#% 342631
#% 481290
#% 566862
#% 831299
#% 881508
#% 913787
#% 994925
#% 1406961
#! This paper proposes an algorithm to discover novel association rules, combined association rules. Compared with conventional association rule, this combined association rule allows users to perform actions directly. Combined association rules are always organized as rule sets, each of which is composed of a number of single combined association rules. These single rules consist of non-actionable attributes, actionable attributes, and class attribute, with the rules in one set sharing the same non-actionable attributes. Thus, for a group of objects having the same non-actionable attributes, the actions corresponding to a preferred class can be performed directly. However, standard association rule mining algorithms encounter many difficulties when applied to combined association rule mining, and hence new algorithms have to be developed for combined association rule mining. In this paper, we will focus on rule generation and interestingness measures in combined association rule mining. In rule generation, the frequent itemsets are discovered among itemset groups to improve efficiency. New interestingness measures are defined to discover more actionable knowledge. In the case study, the proposed algorithm is applied into the field of social security. The combined association rule provides much greater actionable knowledge to business owners and users.

#index 1411144
#* Enriching wordnet with Folksonomies
#@ Hao Zheng;Xian Wu;Yong Yu
#t 2008
#c 3
#% 280849
#% 756964
#% 838540
#% 956589
#% 1272078
#% 1655418
#% 1696335
#! Manually constructed thesauri are not updated regularly, so they are hard to catch the fast emergence of new words. Moreover, the vocabularies of the professionals who construct the thesauri may not completely match the vocabularies of normal users. Recently, Folksonomy services are very popular and highly sensitive to information drift and the change of users' vocabularies. In this paper, we explore a method for enriching formal thesauri with informal Folksonomies. We demonstrate our method by semi-automatically enriching WordNet with new words emerging from a social bookmark service. Tags are related to each other by the subsumption relationships extracted from Folksonomies. New words are recommended to be placed in appropriate synsets of the WordNet hierarchy. An initial evaluation on our experimental result shows the effectiveness of our method.

#index 1411145
#* A new credit scoring method based on rough sets and decision tree
#@ XiYue Zhou;DeFu Zhang;Yi Jiang
#t 2008
#c 3
#% 124073
#% 136350
#% 411406
#% 449588
#% 950502
#% 1393142
#! Credit scoring is a very typical classification problem in Data Mining. Many classification methods have been presented in the literatures to tackle this problem. The decision tree method is a particularly effective method to build a classifier from the sample data. Decision tree classification method has higher prediction accuracy for the problems of classification, and can automatically generate classification rules. However, the original sample data sets used to generate the decision tree classification model often contain many noise or redundant data. These data will have a great impact on the prediction accuracy of the classifier. Therefore, it is necessary and very important to preprocess the original sample data. On this issue, a very effective approach is the rough sets. In rough sets theory, a basic problem that can be tackled using rough sets approach is reduction of redundant attributes. This paper presents a new credit scoring approach based on combination of rough sets theory and decision tree theory. The results of this study indicate that the process of reduction of attribute is very effective and our approach has good performance in terms of prediction accuracy.

#index 1411146
#* Analyzing the propagation of influence and concept evolution in enterprise social networks through centrality and latent semantic analysis
#@ Weizhong Zhu;Chaomei Chen;Robert B. Allen
#t 2008
#c 3
#% 268079
#% 290830
#% 378980
#% 729936
#% 729983
#% 769887
#% 958237
#! Understanding the propagation of influence and the concept flow over a network in general has profound theoretical and practical implications. In this paper, we propose a novel approach to ranking individual members of a real-world communication network in terms of their roles in such propagation processes. We first improve the accuracy of the centrality measures by incorporating temporal attributes. Then, we integrate weighted PageRank and centrality scores to further improve the quality of these measures. We valid these ranking measures through a study of an email archive of a W3C working group against an independent list of experts. The results show that time-sensitive Degree, time-sensitive Betweenness and the integration of the weighted PageRank and these centrality measures yield the best ranking results. Our approach partially solves the rank sink problem of PageRank by adjusting flexible jumping probabilities with Betweenness centrality scores. Finally the text analysis based on Latent Semantic Indexing extracts key concepts distributed in different time frames and explores the evolution of the discussion topics in the social network. The overall study depicts an overview of the roles of the actors and conceptual evolution in the social network. These findings are important to understand the dynamics of the social networks.

#index 1483010
#* A framework for modeling positive class expansion with single snapshot
#@ Yang Yu;Zhi-Hua Zhou
#t 2010
#c 3
#! In many real-world data mining tasks, the connotation of the target concept may change as time goes by. For example, the connotation of “learned knowledge” of a student today may be different from his/her “learned knowledge” tomorrow, since the “learned knowledge” of the student is expanding everyday. In order to learn a model capable of making accurate predictions, the evolution of the concept must be considered, and thus, a series of data sets collected at different time is needed. In many tasks, however, there is only a single data set instead of a series of data sets. In other words, only a single snapshot of the data along the time axis is available. In this paper, we formulate the Positive Class Expansion with single Snapshot (PCES) problem and discuss its difference with existing problem settings. To show that this new problem is addressable, we propose a framework which involves the incorporation of desirable biases based on user preferences. The resulting optimization problem is solved by the Stochastic Gradient Boosting with Double Target approach, which achieves encouraging performance on PCES problems in experiments.

#index 1483011
#* Large-scale k-means clustering with user-centric privacy-preservation
#@ Jun Sakuma;Shigenobu Kobayashi
#t 2010
#c 3
#! A k-means clustering with a new privacy-preserving concept, user-centric privacy preservation, is presented. In this framework, users can conduct data mining using their private information by storing them in their local storage. After the computation, they obtain only the mining result without disclosing private information to others. In most cases, the number of parties that can join conventional privacy-preserving data mining has been assumed to be only two. In our framework, we assume large numbers of parties join the protocol; therefore, not only scalability but also asynchronism and fault-tolerance is important. Considering this, we propose a k-mean algorithm combined with a decentralized cryptographic protocol and a gossip-based protocol. The computational complexity is O(log n) with respect to the number of parties n, and experimental results show that our protocol is scalable even with one million parties.

#index 1483012
#* Evolving trees for the retrieval of mass spectrometry-based bacteria fingerprints
#@ Stephan Simmuteit;Frank-Michael Schleif;Thomas Villmann;Barbara Hammer
#t 2010
#c 3
#! In this paper, we investigate the application of Evolving Trees (ET) for the analysis of mass spectrometric data of bacteria. Evolving Trees are extensions of self-organizing maps (SOMs) developed for hierarchical classification systems. Therefore, they are well suited for taxonomic problems such as the identification of bacteria. Here, we focus on three topics, an appropriate pre-processing and encoding of the spectra, an adequate data model by means of a hierarchical Evolving Tree and an interpretable visualization. First, the high dimensionality of the data is reduced by a compact representation. Here, we employ sparse coding, specifically tailored for the processing of mass spectra. In the second step, the topographic information which is expected in the fingerprints is used for advanced tree evaluation and analysis. We adapted the original topographic product for SOMs for ET to achieve a judgment of topography. Additionally we transferred the concept of U-matrix for evaluation of the separability of SOMs to their analog in ET. We demonstrate these extensions for two mass spectrometric data sets of bacteria fingerprints and show their classification and evaluation capabilities in comparison to state of the art techniques.

#index 1483013
#* Partitioning large networks without breaking communities
#@ Anand Narasimhamurthy;Derek Greene;Neil Hurley;Pádraig Cunningham
#t 2010
#c 3
#! The identification of cohesive communities is a key process in social network analysis. However, the algorithms that are effective for finding communities do not scale well to very large problems, as their time complexity is worse than linear in the number of edges in the graph. This is an important issue for those interested in applying social network analysis techniques to very large networks, such as networks of mobile phone subscribers. In this respect, the contributions of this paper are twofold. First, we demonstrate these scaling issues using a prominent community-finding algorithm as a case study. Then, we show that a two-stage process, whereby the network is first decomposed into manageable subnetworks using a multilevel graph partitioning procedure, is effective in finding communities in networks with more than 106 nodes.

#index 1483014
#* Detecting duplicate biological entities using Markov random field-based edit distance
#@ Min Song;Alex Rudniy
#t 2010
#c 3
#! Detecting duplicate entities in biological data is an important research task. In this paper, we propose a novel and context-sensitive Markov random field-based edit distance (MRFED) for this task. We apply the Markov random field theory to the Needleman–Wunsch distance and combine MRFED with TFIDF, a token-based distance algorithm, resulting in SoftMRFED. We compare SoftMRFED with other distance algorithms such as Levenshtein, SoftTFIDF, and Monge–Elkan for two matching tasks: biological entity matching and synonym matching. The experimental results show that SoftMRFED significantly outperforms the other edit distance algorithms on several test data collections. In addition, the performance of SoftMRFED is superior to token-based distance algorithms in two matching tasks.

#index 1483015
#* Query processing issues in region-based image databases
#@ Ilaria Bartolini;Paolo Ciaccia;Marco Patella
#t 2010
#c 3
#! Many modern image database systems adopt a region-based paradigm, in which images are segmented into homogeneous regions in order to improve the retrieval accuracy. With respect to the case where images are dealt with as a whole, this leads to some peculiar query processing issues that have not been investigated so far in an integrated way. Thus, it is currently hard to understand how the different alternatives for implementing the region-based image retrieval model might impact on performance. In this paper, we analyze in detail such issues, in particular the type of matching between regions (either one-to-one or many-to-many). Then, we propose a novel ranking model, based on the concept of Skyline, as an alternative to the usual one based on aggregation functions and k-Nearest Neighbors queries. We also discuss how different query types can be efficiently supported. For all the considered scenarios we detail efficient index-based algorithms that are provably correct. Extensive experimental analysis shows, among other things, that: (1) the 1–1 matching type has to be preferred to the N–M one in terms of efficiency, whereas the two have comparable effectiveness, (2) indexing regions rather than images performs much better, and (3) the novel Skyline ranking model is consistently the most efficient one, even if this sometimes comes at the price of a reduced effectiveness.

#index 1483016
#* Visualizing temporal cluster changes using Relative Density Self-Organizing Maps
#@  Denny;Graham J. Williams;Peter Christen
#t 2010
#c 3
#! We introduce a Self-Organizing Map (SOM)-based visualization method that compares cluster structures in temporal datasets using Relative Density SOM (ReDSOM) visualization. ReDSOM visualizations combined with distance matrix-based visualizations and cluster color linking, is capable of visually identifying emerging clusters, disappearing clusters, split clusters, merged clusters, enlarging clusters, contracting clusters, the shifting of cluster centroids, and changes in cluster density. As an example, when a region in a SOM becomes significantly more dense compared to an earlier SOM, and is well separated from other regions, then the new region can be said to represent a new cluster. The capabilities of ReDSOM are demonstrated using synthetic datasets, as well as real-life datasets from the World Bank and the Australian Taxation Office. The results on the real-life datasets demonstrate that changes identified interactively can be related to actual changes. The identification of such cluster changes is important in many contexts, including the exploration of changes in population behavior in the context of compliance and fraud in taxation.

#index 1483017
#* xCrawl: a high-recall crawling method for Web mining
#@ Kostyantyn Shchekotykhin;Dietmar Jannach;Gerhard Friedrich
#t 2010
#c 3
#! Web mining systems exploit the redundancy of data published on the Web to automatically extract information from existing Web documents. The first step in the Information Extraction process is thus to locate as many Web pages as possible that contain relevant information within a limited period of time, a task which is commonly accomplished by applying focused crawling techniques. The performance of such a crawler can be measured by its “recall”, i.e., the percentage of documents found and identified as relevant compared to the total number of existing documents. A higher recall value implies that more redundant data are available, which in turn leads to better results in the subsequent fact extraction phase of the Web mining process. In this paper, we propose xCrawl, a new focused crawling method which outperforms state-of-the-art approaches with respect to the recall values achievable within a given period of time. This method is based on a new combination of ideas and techniques used to identify and exploit the navigational structures of Web sites, such as hierarchies, lists, or maps. In addition, automatic query generation is applied to rapidly collect Web sources containing target documents. The proposed crawling technique was inspired by the requirements of a Web mining system developed to extract product and service descriptions given in tabular form and was evaluated in different application scenarios. Comparisons with existing focused crawling techniques reveal that the new crawling method leads to a significant increase in recall while maintaining precision.

#index 1483018
#* Multi-sorting algorithm for finding pairs of similar short substrings from large-scale string data
#@ Takeaki Uno
#t 2010
#c 3
#! Finding similar substrings/substructures is a central task in analyzing huge string data such as genome sequences, Web documents, log data, feature vectors of pictures, photos, videos, etc. Although the existence of polynomial time algorithms for such problems is trivial since the number of substrings is bounded by the square of their lengths, straightforward algorithms do not work for huge databases because of their high degree order of the computation time. This paper addresses the problem of finding pairs of strings with small Hamming distances from huge databases composed of short strings of a fixed length. Comparison of long strings can be solved by inputting all their substrings of fixed length so that we can find candidates of similar non-short substrings. We focus on the practical efficiency of algorithms, and propose an algorithm that runs in time almost linear in the input/output size. We prove that the computation time of its variant is linear in the database size when the length of the short strings is constant, and computational experiments for genome sequences and Web texts show its practical efficiency. Slight modifications adapt to the edit distance and mismatch tolerance computation. An implementation is available at the author’s homepage.

#index 1483019
#* Best papers from the 12th Pacific-Asia conference on knowledge discovery and data mining (PAKDD2008)
#@ Takashi Washio;Einoshin Suzuki;Kai Ming Ting
#t 2010
#c 3

#index 1491565
#* Proceedings of the 13th Pacific-Asia international conference on Knowledge discovery and data mining: new frontiers in applied data mining
#@ Thanaruk Theeramunkong;Cholwich Nattee;Paulo J. L. Adeodato;Nitesh V. Chawla;Peter Christen;Philippe Lenca;Josiah Poon;Graham Williams
#t 2009
#c 3

#index 1491566
#* The iZi project: easy prototyping of interesting pattern mining algorithms
#@ Frédéric Flouvat;Fabien De Marchi;Jean-Marc Petit
#t 2009
#c 3
#% 16
#% 152934
#% 300120
#% 384978
#% 420062
#% 450951
#% 451056
#% 481290
#% 487528
#% 579314
#% 823219
#% 853552
#% 864559
#% 881575
#% 893145
#% 926881
#% 936820
#% 979298
#% 1083743
#% 1229096
#% 1698990
#% 1710150
#! In the last decade, many data mining tools have been developed. They address most of the classical data mining problems such as classification, clustering or pattern mining. However, providing classical solutions for classical problems is not always sufficient. This is especially true for pattern mining problems known to be "representable as set", an important class of problems which have many applications such as in data mining, in databases, in artificial intelligence, or in software engineering. A common idea is to say that solutions devised so far for classical pattern mining problems, such as frequent itemset mining, should be useful to answer these tasks. Unfortunately, it seems rather optimistic to envision the application of most of publicly available tools even for closely related problems. In this context, the main contribution of this paper is to propose a modular and efficient tool in which users can easily adapt and control several pattern mining algorithms. From a theoretical point of view, this work takes advantage of the common theoretical background of pattern mining problems isomorphic to boolean lattices. This tool, a C++ library called iZi, has been devised and applied to several problems such as itemset mining, constraint mining in relational databases, and query rewriting in data integration systems. According to our first results, the programs obtained using the library have very interesting performance characteristics regarding simplicity of their development. The library is open source and freely available on the Web.

#index 1491567
#* CODE: a data complexity framework for imbalanced datasets
#@ Cheng G. Weng;Josiah Poon
#t 2009
#c 3
#% 345823
#% 534295
#% 765520
#% 765523
#% 813970
#% 961628
#% 1271973
#% 1272304
#% 1708340
#% 1959949
#! Imbalanced datasets occur in many domains, such as fraud detection, cancer detection and web; and in such domains, the class of interest often concerns the rare occurring events. Thus it is important to have a good performance on these classes while maintaining a reasonable overall accuracy. Although imbalanced datasets can be difficult to learn, but in the previous researches, the skewed class distribution has been suggested to not necessarily being the one that poses problems for learning. Therefore, when the learning of the rare class becomes problematic, it does not imply that the skewed class distribution is the cause to blame, but rather that the imbalanced distribution may just be a byproduct of some other hidden intrinsic difficulties. This paper tries to shade some light on this issue of learning from imbalanced dataset. We propose to use data complexity models to profile datasets in order to make connections with imbalanced datasets; this can potentially lead to better learning approaches. We have extended from our previous work with an improved implementation of the CODE framework in order to tackle a more difficult learning challenge. Despite the increased difficulty, CODE still enables a reasonable performance on profiling the data complexity of imbalanced datasets.

#index 1491568
#* An empirical study of applying ensembles of heterogeneous classifiers on imperfect data
#@ Kuo-Wei Hsu;Jaideep Srivastava
#t 2009
#c 3
#% 92533
#% 136350
#% 391311
#% 451221
#% 765519
#% 765520
#% 913833
#% 915253
#% 926881
#% 1176879
#% 1196041
#% 1390379
#% 1393009
#% 1650665
#! Two factors that slow down the deployment of classification or supervised learning in real-world situations. One is the reality that data are not perfect in practice, while the other is the fact that every technique has its own limits. Although there have been techniques developed to resolve issues about imperfectness of real-world data, there is no single one that outperforms all others and each such technique focuses on some types of imperfectness. Furthermore, quite a few works apply ensembles of heterogeneous classifiers to such situations. In this paper, we report a work on progress that studies the impact of heterogeneity on ensemble, especially focusing on the following aspects: diversity and classification quality for imbalanced data. Our goal is to evaluate how introducing heterogeneity into ensemble influences its behavior and performance.

#index 1491569
#* Undersampling approach for imbalanced training sets and induction from multi-label text-categorization domains
#@ Sareewan Dendamrongvit;Miroslav Kubat
#t 2009
#c 3
#% 73372
#% 136350
#% 246832
#% 302391
#% 311034
#% 318412
#% 375017
#% 458379
#% 465754
#% 478470
#% 763708
#% 789853
#% 1013605
#! Text categorization is an important application domain of multilabel classification where each document can simultaneously belong to more than one class. The most common approach is to address the problem of multi-label examples by inducing a separate binary classifier for each class, and then use these classifiers in parallel. What the information-retrieval community has all but ignored, however, is that such classifiers are almost always induced from highly imbalanced training sets. The study reported in this paper shows how taking this aspect into consideration with a majority-class undersampling we used here can indeed improve classification performance as measured by criteria common in text categorization: macro/micro precision, recall, and F1. We also show how a slight modification of an older undersampling technique helps further improve the results.

#index 1491570
#* Adaptive methods for classification in arbitrarily imbalanced and drifting data streams
#@ Ryan N. Lichtenwalter;Nitesh V. Chawla
#t 2009
#c 3
#% 204531
#% 226674
#% 234990
#% 280498
#% 342600
#% 342639
#% 451036
#% 729932
#% 731721
#% 874985
#% 875974
#% 879596
#% 926881
#% 961134
#% 989579
#% 1019070
#% 1064748
#% 1074047
#% 1108850
#% 1117007
#% 1271973
#% 1702630
#% 1708211
#! Streaming data is pervasive in a multitude of data mining applications. One fundamental problem in the task of mining streaming data is distributional drift over time. Streams may also exhibit high and varying degrees of class imbalance, which can further complicate the task. In scenarios like these, class imbalance is particularly difficult to overcome and has not been as thoroughly studied. In this paper, we comprehensively consider the issues of changing distributions in conjunction with high degrees of class imbalance in streaming data. We propose new approaches based on distributional divergence and meta-classification that improve several performance metrics often applied in the study of imbalanced classification. We also propose a new distance measure for detecting distributional drift and examine its utility in weighting ensemble base classifiers. We employ a sequential validation framework, which we believe is the most meaningful option in the context of streaming imbalanced data.

#index 1491571
#* Two measures of objective novelty in association rule mining
#@ José L. Balcázar
#t 2009
#c 3
#% 152934
#% 181339
#% 216972
#% 232136
#% 280433
#% 431033
#% 443427
#% 452846
#% 466666
#% 477786
#% 500546
#% 501193
#% 549576
#% 570151
#% 608320
#% 631970
#% 727897
#% 737332
#% 751575
#% 772329
#% 794935
#% 867053
#% 867057
#% 1030110
#% 1099013
#% 1656269
#% 1707806
#% 1710149
#% 1849703
#! Association rule mining is well-known to depend heavily on a support threshold parameter, and on one or more thresholds for intensity of implication; among these measures, confidence is most often used and, sometimes, related alternatives such as lift, leverage, improvement, or all-confidence are employed, either separately or jointly with confidence. We remain within the support-and-confidence framework in an attempt at studying complementary notions, which have the goal of measuring relative forms of objective novelty or surprisingness of each individual rule with respect to other rules that hold in the same dataset. We measure novelty through the extent to which the confidence value is robust, taken relative to the confidences of related (for instance, logically stronger) rules, as opposed to the absolute consideration of the single rule at hand. We consider two variants of this idea and analyze their logical and algorithmic properties. Since this approach has the drawback of requiring further parameters, we also propose a framework in which the user sets a single parameter, of quite clear intuitive semantics, from which the corresponding thresholds for confidence and novelty are computed.

#index 1491572
#* PAKDD data mining competition 2009: new ways of using known methods
#@ Chaim Linhart;Guy Harari;Sharon Abramovich;Altina Buchris
#t 2009
#c 3
#! The PAKDD 2009 competition focuses on the problem of credit risk assessment. As required, we had to confront the problem of the robustness of the credit-scoring model against performance degradation caused by gradual market changes along a few years of business operation. We utilized the following standard models: logistic regression, KNN, SVM, GBM and decision tree. The novelty of our approach is two-fold: the integration of existing models, namely feeding the results of KNN as an input variable to the logistic regression, and re-coding categorical variables as numerical values that represent each category's statistical impact on the target label. The best solution we obtained reached 3rd place in the competition, with an AUC score of 0.655.

#index 1491573
#* Feature selection for brain-computer interfaces
#@ Irena Koprinska
#t 2009
#c 3
#% 126894
#% 156186
#% 169659
#% 296375
#% 465754
#% 466410
#% 585045
#% 727663
#% 926881
#% 1491573
#% 1959960
#! In this paper we empirically evaluate feature selection methods for classification of Brain-Computer Interface (BCI) data. We selected five state-of the-art methods, suitable for the noisy, correlated and highly dimensional BCI data, namely: information gain ranking, correlation-based feature selection, ReliefF, consistency-based feature selection and 1R ranking. We tested them with ten classification algorithms, representing different learning paradigms, on a benchmark BCI competition dataset. The results show that all feature selectors significantly reduced the number of features and also improved accuracy when used with suitable classification algorithms. The top three feature selectors in terms of classification accuracy were correlation-based feature selection, information gain and 1R ranking, with correlation based feature selection choosing the smallest number of features.

#index 1491574
#* Mining protein interactions from text using convolution kernels
#@ Ramanathan Narayanan;Sanchit Misra;Simon Lin;Alok Choudhary
#t 2009
#c 3
#% 190581
#% 269217
#% 458379
#% 469402
#% 748722
#% 799689
#% 833738
#% 843734
#% 938706
#% 939945
#! As the sizes of biomedical literature databases increase, there is an urgent need to develop intelligent systems that automatically discover Protein-Protein interactions from text. Despite resource-intensive efforts to create manually curated interaction databases, the sheer volume of biological literature databases makes it impossible to achieve significant coverage. In this paper, we describe a scalable hierarchical Support Vector Machine(SVM) based framework to efficiently mine protein interactions with high precision. In addition, we describe a convolution tree-vector kernel based on syntactic similarity of natural language text to further enhance the mining process. By using the inherent syntactic similarity of interaction phrases as a kernel method, we are able to significantly improve the classification quality. Our hierarchical framework allows us to reduce the search space dramatically with each stage, while sustaining a high level of accuracy. We test our framework on a corpus of over 10000 manually annotated phrases gathered from various sources. The convolution kernel technique identifies sentences describing interactions with a precision of 95% and a recall of 92%, yielding significant improvements over previous machine learning techniques.

#index 1491575
#* Missing phrase recovering by combining forward and backward phrase translation tables
#@ Peerachet Porkaew;Thepchai Supnithi
#t 2009
#c 3
#% 740915
#% 816170
#% 995522
#% 1215368
#! We propose a method to recover missing phrases dropped in the phrase extraction algorithm. Those phrases, therefore, are not translated even though we tested the system with the training data. On the other hand, in nativeto-foreign, or backward training, some missing phrases can be recovered. In this paper, we combined two phrase translation tables extracted by the source-to-target and target-to-source training for the sake of more complete phrase translation table. We re-estimated the lexical weights and phrase translation probabilities for each phrase pair. Additional combining weights were applied to both tables. We assessed our method on different combining weights by counting the missing phrases and calculating the BLEU scores and NIST scores. Approximately 7% of missing phrases are recovered and 1.3% of BLEU score is increased.

#index 1491576
#* Automatic extraction of Thai-English term translations and synonyms from medical web using iterative candidate generation with association measures
#@ Kobkrit Viriyayudhakorn;Thanaruk Theeramunkong;Cholwich Nattee;Thepchai Supnithi;Manabu Okumura
#t 2009
#c 3
#% 458630
#% 760835
#% 766427
#% 854927
#% 859461
#% 910579
#% 1712136
#! Electronic technical documents available on the Internet are a powerful source for automatic extraction of term translations and synonyms. This paper presents an association-based approach to extract possible translations and synonyms by iterative candidate generation using a search engine. The plausible candidate pairs can be chosen by calculating their co-occurring statistics. In our experiment to extract Thai-English medical term pairs, four possible alternative associations; namely confidence, support, lift and conviction, are investigated and their performances are compared by ten-fold cross validation. The experimental results show that lift achieves the best performance with 73.1% f-measure with 67% precision and 84.2% recall on translation pair extraction, 68.7% f-measure with 71.5% precision and 67.7% recall on Thai synonym term extraction and 72.8% f-measure with 72.0% precision and 75.1% recall on English synonym term extraction. The precision of our approach in Thai-English translation, Thai synonym and English synonym extraction are 4 times, 3.5 times and 5.5 times higher than baseline precision respectively.

#index 1491577
#* Accurate subsequence matching on data stream under time warping distance
#@ Vit Niennattrakul;Dechawut Wanichsan;Chotirat Ann Ratanamahatana
#t 2009
#c 3
#% 462231
#% 564263
#% 654456
#% 795273
#% 809264
#% 844343
#% 993961
#% 1063497
#% 1127609
#% 1206627
#! Dynamic Time Warping (DTW) distance has been proven to work exceptionally well, but with higher time and space complexities. Particularly for time series data, subsequence matching under DTW distance poses a much challenging problem to work on streaming data. Recent work, SPRING, has introduced a solution to this problem with only linear time and space which makes subsequence matching on data stream become more and more practical. However, we will demonstrate that it may still give inaccurate results, and then propose a novel Accurate Subsequence Matching (ASM) algorithm that eliminates this discrepancy by using a global constraint and a scaling factor. We further demonstrate utilities of our work on a comprehensive set of experiments that guarantees an improvement in accuracy while maintaining the same time and space complexities.

#index 1603721
#* Proceedings of the 15th Pacific-Asia conference on Advances in knowledge discovery and data mining - Volume Part I
#@ Joshua Zhexue Huang;Longbing Cao;Jaideep Srivastava
#t 2011
#c 3

#index 1603722
#* An instance selection algorithm based on reverse nearest neighbor
#@ Bi-Ru Dai;Shu-Ming Hsu
#t 2011
#c 3
#% 92533
#% 248797
#% 300163
#% 309141
#% 420077
#% 420138
#% 449588
#% 465760
#% 466263
#% 477947
#% 577224
#% 729437
#% 818916
#% 835018
#% 899917
#% 1013615
#% 1074372
#% 1252994
#% 1275276
#% 1777284
#! Data reduction is to extract a subset from a dataset. The advantages of data reduction are decreasing the requirement of storage and increasing the efficiency of classification. Using the subset as training data is possible to maintain classification accuracy; sometimes, it can be further improved because of eliminating noises. The key is how to choose representative samples while ignoring noises at the same time. Many instance selection algorithms are based on nearest neighbor decision rule (NN). Some of these algorithms select samples based on two strategies, incremental and decremental. The first type of algorithms select some instances as samples and iteratively add instances which do not have the same class label with their nearest sample to the sample set. The second type of algorithms remove instances which do not have the same class label with their majority of kNN. However, we propose an algorithm based on Reverse Nearest Neighbor (RNN), called the Reverse Nearest Neighbor Reduction (RNNR). RNNR selects samples which can represent other instances in the same class. In addition, RNNR does not need to iteratively scan a dataset which takes much processing time. Experimental results show that RNNR achieves comparable accuracy and selects fewer samples than comparators.

#index 1603723
#* A game theoretic approach for feature clustering and its application to feature selection
#@ Dinesh Garg;Sellamanickam Sundararajan;Shirish Shevade
#t 2011
#c 3
#% 150232
#% 237380
#% 243728
#% 341672
#% 722753
#% 722929
#% 722937
#% 814023
#% 902583
#% 979758
#% 995140
#% 1098053
#! In this paper, we develop a game theoretic approach for clustering features in a learning problem. Feature clustering can serve as an important preprocessing step in many problems such as feature selection, dimensionality reduction, etc. In this approach, we view features as rational players of a coalitional game where they form coalitions (or clusters) among themselves in order to maximize their individual payoffs. We show how Nash Stable Partition (NSP), a well known concept in the coalitional game theory, provides a natural way of clustering features. Through this approach, one can obtain some desirable properties of the clusters by choosing appropriate payoff functions. For a small number of features, the NSP based clustering can be found by solving an integer linear program (ILP). However, for large number of features, the ILP based approach does not scale well and hence we propose a hierarchical approach. Interestingly, a key result that we prove on the equivalence between a k-size NSP of a coalitional game and minimum k-cut of an appropriately constructed graph comes in handy for large scale problems. In this paper, we use feature selection problem (in a classification setting) as a running example to illustrate our approach. We conduct experiments to illustrate the efficacy of our approach.

#index 1603724
#* Feature selection strategy in text classification
#@ Pui Cheong Gabriel Fung;Fred Morstatter;Huan Liu
#t 2011
#c 3
#% 118731
#% 194283
#% 219051
#% 232653
#% 260001
#% 280817
#% 280866
#% 316508
#% 332658
#% 340940
#% 344447
#% 458379
#% 465754
#% 507844
#% 1387562
#! Traditionally, the best number of features is determined by the socalled "rule of thumb", or by using a separate validation dataset. We can neither find any explanation why these lead to the best number nor do we have any formal feature selection model to obtain this number. In this paper, we conduct an in-depth empirical analysis and argue that simply selecting the features with the highest scores may not be the best strategy. A highest scores approach will turn many documents into zero length, so that they cannot contribute to the training process. Accordingly, we formulate the feature selection process as a dual objective optimization problem, and identify the best number of features for each document automatically. Extensive experiments are conducted to verify our claims. The encouraging results indicate our proposed framework is effective.

#index 1603725
#* Unsupervised feature weighting based on local feature relatedness
#@ Jiali Yun;Liping Jing;Jian Yu;Houkuan Huang
#t 2011
#c 3
#% 46803
#% 309128
#% 818500
#% 1019082
#% 1083703
#% 1117027
#% 1176863
#% 1177819
#% 1196006
#% 1214660
#! Feature weighting plays an important role in text clustering. Traditional feature weighting is determined by the syntactic relationship between feature and document (e.g. TF-IDF). In this paper, a semantically enriched feature weighting approach is proposed by introducing the semantic relationship between feature and document, which is implemented by taking account of the local feature relatedness -- the relatedness between feature and its contextual features within each individual document. Feature relatedness is measured by two methods, document collection-based implicit relatedness measure and Wikipedia link-based explicit relatedness measure. Experimental results on benchmark data sets show that the new feature weighting approach surpasses traditional syntactic feature weighting. Moreover, clustering quality can be further improved by linearly combining the syntactic and semantic factors. The new feature weighting approach is also compared with two existing feature relatedness-based approaches which consider the global feature relatedness (feature relatedness in the entire feature space) and the interdocument feature relatedness (feature relatedness between different documents) respectively. In the experiments, the new feature weighting approach outperforms these two related work in clustering quality and costs much less computational complexity.

#index 1603726
#* An effective feature selection method for text categorization
#@ Xipeng Qiu;Jinlong Zhou;Xuanjing Huang
#t 2011
#c 3
#% 266215
#% 280817
#% 321635
#% 340904
#% 344447
#% 387427
#% 458379
#% 465754
#% 507844
#% 729437
#% 740900
#% 794857
#% 818217
#% 1083637
#% 1264944
#% 1828410
#% 1860547
#! Feature selection is an efficient strategy to reduce the dimensionality of data and removing the noise in text categorization. However, most feature selection methods aim to remove non-informative features based on corpus statistics, which do not relate to the classification accuracy directly. In this paper, we propose an effective feature selection method, which aims at the classification accuracy of KNN. Our experiments show that our method is better than the traditional methods, and it is also beneficial to other classifiers, such as Support Vector Machines (SVM).

#index 1603727
#* A subpath kernel for rooted unordered trees
#@ Daisuke Kimura;Tetsuji Kuboyama;Tetsuo Shibuya;Hisashi Kashima
#t 2011
#c 3
#% 190581
#% 279755
#% 282232
#% 464640
#% 722803
#% 731608
#% 743284
#% 850429
#% 876061
#% 1211692
#! Kernel method is one of the promising approaches to learning with tree-structured data, and various efficient tree kernels have been proposed to capture informative structures in trees. In this paper, we propose a new tree kernel function based on "subpath sets" to capture vertical structures in rooted unordered trees, since such tree-structures are often used to code hierarchical information in data. We also propose a simple and efficient algorithm for computing the kernel by extending the multikey quicksort algorithm used for sorting strings. The time complexity of the algorithm is O((|T1|+|T2|)log(|T1|+|T2|)) time on average, and the space complexity is O(|T1| + |T2|), where |T1| and |T2| are the numbers of nodes in two trees T1 and T2. We apply the proposed kernel to two supervised classification tasks, XML classification in web mining and glycan classification in bioinformatics. The experimental results show that the predictive performance of the proposed kernel is competitive with that of the existing efficient tree kernel for unordered trees proposed by Vishwanathan et al. [1], and is also empirically faster than the existing kernel.

#index 1603728
#* Classification probabilistic PCA with application in domain adaptation
#@ Victor Cheng;Chun-Hung Li
#t 2011
#c 3
#% 309208
#% 770847
#% 794857
#% 881502
#% 1261539
#% 1270196
#% 1650298
#! Conventional dimensionality reduction algorithms such as principle component analysis (PCA) and non-negative matrix factorization (NMF) are unsupervised. Supervised probabilistic PCA (SPPCA) can utilize label information. However, this information is usually treated as regression targets rather than discrete nominal labels. We propose a classification probabilistic PCA (CPPCA) which is an extension of probabilistic PCA. Unlike SPPCA, the label class information is turned into a class probabilistic function by using a sigmoidal function. As the posterior distribution of latent variables are non-Gaussian, we use Laplace approximation with Expectation Maximization (EM) to obtain the solution. The formulation is applied to a domain adaptation classification problem where the labeled training data and unlabeled test data come from different but related domains. Experimental results show that the proposed model has accuracy over conventional probabilistic PCA, SPPCA and its semi-supervised version. It has similar performance when compared with popular dedicated algorithms for domain adaptation, the structural correspondence learning (SCL) and its variants.

#index 1603729
#* Probabilistic matrix factorization leveraging contexts for unsupervised relation extraction
#@ Shingo Takamatsu;Issei Sato;Hiroshi Nakagawa
#t 2011
#c 3
#% 132648
#% 741083
#% 938705
#% 983606
#% 987253
#% 1073982
#% 1130901
#% 1272263
#% 1275182
#% 1289532
#! The clustering of the semantic relations between entities extracted from a corpus is one of the main issues in unsupervised relation extraction (URE). Previous methods assume a huge corpus because they have utilized frequently appearing entity pairs in the corpus. In this paper, we present a URE that works well for a small corpus by using word sequences extracted as relations. The feature vectors of the word sequences are extremely sparse. To deal with the sparseness problem, we take the two approaches: dimension reduction and leveraging context in the whole corpus including sentences from which no relations are extracted. The context in this case is captured with feature co-occurrences, which indicate appearances of two features in a single sentence. The approaches are implemented by a probabilistic matrix factorization that jointly factorizes the matrix of the feature vectors and the matrix of the feature co-occurrences. Experimental results show that our method outperforms previously proposed methods.

#index 1603730
#* The unsymmetrical-style co-training
#@ Bin Wang;Harry Zhang;Bruce Spencer;Yuanyuan Guo
#t 2011
#c 3
#% 252011
#% 290482
#% 311027
#% 316509
#% 464466
#% 466888
#% 748550
#% 811376
#% 815908
#% 855280
#% 1100081
#% 1289496
#% 1412745
#! Semi-supervised learning has attracted much attention over the past decade because it provides the advantage of combining unlabeled data with labeled data to improve the learning capability of models. Cotraining is a representative paradigm of semi-supervised learning methods. Typically, some co-training style algorithms, such as co-training and co-EM, learn two classifiers based on two views of the instance space. But they have to satisfy the assumptions that these two views are sufficient and conditionally independent given the class labels. Other co-training style algorithms, such as multiple-learner, use two different underlying classifiers based on only a single view of the instance space. However, they could not utilize the labeled data effectively, and suffer from the early convergence. After analyzing various co-training style algorithms, we have found that all of these algorithms have symmetrical framework structures that are related to their constraints. In this paper, we propose a novel unsymmetrical-style method, which we call the unsymmetrical cotraining algorithm. The unsymmetrical co-training algorithm combines the advantages of other co-training style algorithms and overcomes their disadvantages. Within our unsymmetrical structure, we apply two unsymmetrical classifiers, namely, the self-training classifier and the EM classifier, and then train these two classifiers in an unsymmetrical way. The unsymmetrical co-training algorithm not only avoids the constraint of the conditional independence assumption, but also overcomes the flaws of the early convergence and the ineffective utilization of labeled data. We conduct experiments to compare the performances of these cotraining style algorithms. From the experimental results, we can see that the unsymmetrical co-training algorithm outperforms other co-training algorithms.

#index 1603731
#* Balance support vector machines locally using the structural similarity kernel
#@ Jianxin Wu
#t 2011
#c 3
#% 120270
#% 197394
#% 290830
#% 787098
#% 840938
#% 875974
#% 1073923
#% 1131829
#% 1301383
#% 1495359
#! A structural similarity kernel is presented in this paper for SVM learning, especially for learning with imbalanced datasets. Kernels in SVM are usually pairwise, comparing the similarity of two examples only using their feature vectors. By building a neighborhood graph (kNN graph) using the training examples, we propose to utilize the similarity of linking structures of two nodes as an additional similarity measure. The structural similarity measure is proven to form a positive definite kernel and is shown to be equivalent to a regularization term that encourages balanced weights in all local neighborhoods. Analogous to the unsupervised HITS algorithm, the structural similarity kernel turns hub scores into signed authority scores, and is particularly effective in dealing with imbalanced learning problems. Experimental results on several benchmark datasets show that structural similarity can help the linear and the histogram intersection kernel to match or surpass the performance of the RBF kernel in SVM learning, and can significantly improve imbalanced learning results.

#index 1603732
#* Using classifier-based nominal imputation to improve machine learning
#@ Xiaoyuan Su;Russell Greiner;Taghi M. Khoshgoftaar;Amri Napolitano
#t 2011
#c 3
#% 92533
#% 136350
#% 269218
#% 356892
#% 1145184
#% 1301004
#% 1650665
#! Many learning algorithms perform poorly when the training data are incomplete. One standard approach involves first imputing the missing values, then giving the completed data to the learning algorithm. However, this is especially problematic when the features are nominal. This work presents "classifier-based nominal imputation" (CNI), an easy-to-implement and effective nominal imputation technique that views nominal imputation as classification: it learns a classifier for each feature (that maps the other features of an instance to the predicted value of that feature), then uses that classifier to predict themissing values of that feature. Our empirical results show that learners that preprocess their incomplete training data using CNI using support vector machine or decision tree learners have significantly higher predictive accuracy than learners that (1) do not use preprocessing, (2) use baseline imputation techniques, or (3) use this CNI preprocessor with other classification algorithms. This improvement is especially apparent when the base learner is instance-based. CNI is also found helpful for other base learners, such as naïve Bayes and decision tree, on incomplete nominal data.

#index 1603733
#* A bayesian framework for learning shared and individual subspaces from multiple data sources
#@ Sunil Kumar Gupta;Dinh Phung;Brett Adams;Svetha Venkatesh
#t 2011
#c 3
#% 387427
#% 989655
#% 1040539
#% 1055704
#% 1073982
#% 1083666
#% 1279785
#% 1318623
#% 1356643
#% 1446818
#% 1451257
#% 1775731
#! This paper presents a novel Bayesian formulation to exploit shared structures across multiple data sources, constructing foundations for effective mining and retrieval across disparate domains. We jointly analyze diverse data sources using a unifying piece of metadata (textual tags). We propose a method based on Bayesian Probabilistic Matrix Factorization (BPMF) which is able to explicitly model the partial knowledge common to the datasets using shared subspaces and the knowledge specific to each dataset using individual subspaces. For the proposed model, we derive an efficient algorithm for learning the joint factorization based on Gibbs sampling. The effectiveness of the model is demonstrated by social media retrieval tasks across single and multiple media. The proposed solution is applicable to a wider context, providing a formal framework suitable for exploiting individual as well as mutual knowledge present across heterogeneous data sources of many kinds.

#index 1603734
#* Are tensor decomposition solutions unique? on the Global convergence HOSVD and parafac algorithms
#@ Dijun Luo;Chris Ding;Heng Huang
#t 2011
#c 3
#% 316143
#% 345848
#% 415697
#% 415767
#% 457831
#% 570887
#% 727684
#% 770769
#% 813966
#% 881493
#% 883843
#% 1083660
#% 1092546
#% 1214694
#! Matrix factorizations and tensor decompositions are now widely used in machine learning and data mining. They decompose input matrix and tensor data into matrix factors by optimizing a least square objective function using iterative updating algorithms, e.g. HOSVD (High Order Singular Value Decomposition) and ParaFac (Parallel Factors). One fundamental problem of these algorithms remains unsolved: are the solutions found by these algorithms global optimal? Surprisingly, we provide a positive answer for HSOVD and negative answer for ParaFac by combining theoretical analysis and experimental evidence. Our discoveries of this intrinsic property of HOSVD assure us that in real world applications HOSVD provides repeatable and reliable results.

#index 1603735
#* Improved Spectral Hashing
#@ Sanparith Marukatat;Wasin Sinthupinyo
#t 2011
#c 3
#% 249321
#% 266426
#% 317313
#% 345849
#% 392851
#% 479973
#% 592073
#% 724290
#% 760805
#% 875957
#% 1061636
#% 1148464
#% 1711516
#! Nearest neighbor search is one of the most fundamental problem in machine learning, machine vision, clustering, information retrieval, etc. To handle a dataset of million or more records, efficient storing and retrieval techniques are needed. Binary code is an efficient method to address these two problems. Recently, the problem of finding good binary code has been formulated and solved, resulting in a technique called spectral hashing [21]. In this work we analyze the spectral hashing, its possible shortcomings and solutions. Experimental results are promising.

#index 1603736
#* High-order co-clustering text data on semantics-based representation model
#@ Liping Jing;Jiali Yun;Jian Yu;Joshua Huang
#t 2011
#c 3
#% 280819
#% 387427
#% 551737
#% 722904
#% 727861
#% 729918
#% 823328
#% 915227
#% 987328
#% 1036692
#% 1073897
#% 1074073
#% 1083703
#% 1176940
#% 1183237
#% 1196006
#% 1214660
#% 1482130
#! The language modeling approach is widely used to improve the performance of text mining in recent years because of its solid theoretical foundation and empirical effectiveness. In essence, this approach centers on the issue of estimating an accurate model by choosing appropriate language models as well as smooth techniques. Semantic smoothing, which incorporates semantic and contextual information into the language models, is effective and potentially significant to improve the performance of text mining. In this paper, we proposed a high-order structure to represent text data by incorporating background knowledge, Wikipedia. The proposed structure consists of three types of objects, term, document and concept. Moreover, we firstly combined the high-order co-clustering algorithm with the proposed model to simultaneously cluster documents, terms and concepts. Experimental results on benchmark data sets (20Newsgroups and Reuters-21578) have shown that our proposed high-order co-clustering on high-order structure outperforms the general co-clustering algorithm on bipartite text data, such as document-term, document-concept and document-(term+concept).

#index 1603737
#* The role of hubness in clustering high-dimensional data
#@ Nenad Tomašev;Miloš Radovanovič;Dunja Mladenič;Mirjana Ivanovič
#t 2011
#c 3
#% 294730
#% 300131
#% 465031
#% 737337
#% 818916
#% 835018
#% 844313
#% 940497
#% 982755
#% 991230
#% 1096306
#% 1215932
#% 1261593
#% 1385976
#% 1470140
#% 1551185
#! High-dimensional data arise naturally in many domains, and have regularly presented a great challenge for traditional data-mining techniques, both in terms of effectiveness and efficiency. Clustering becomes difficult due to the increasing sparsity of such data, as well as the increasing difficulty in distinguishing distances between data points. In this paper we take a novel perspective on the problem of clustering high-dimensional data. Instead of attempting to avoid the curse of dimensionality by observing a lower-dimensional feature subspace, we embrace dimensionality by taking advantage of some inherently high-dimensional phenomena. More specifically, we show that hubness, i.e., the tendency of high-dimensional data to contain points (hubs) that frequently occur in k-nearest neighbor lists of other points, can be successfully exploited in clustering. We validate our hypothesis by proposing several hubness-based clustering algorithms and testing them on high-dimensional data. Experimental results demonstrate good performance of our algorithms in multiple settings, particularly in the presence of large quantities of noise.

#index 1603738
#* Spatial entropy-based clustering for mining data with spatial correlation
#@ Baijie Wang;Xin Wang
#t 2011
#c 3
#% 420078
#% 443531
#% 1390197
#% 1721065
#! Due to the inherent characteristics of spatial datasets, spatial clustering methods need to consider spatial attributes, nonspatial attributes and spatial correlation among non-spatial attributes across space. However, most existing spatial clustering methods ignore spatial correlation, considering spatial and non-spatial attributes independently. In this paper, we first prove that spatial entropy is a monotonic decreasing function for non-spatial attribute similarity and spatial correlation. Then we propose a novel density-based spatial clustering method called SEClu, which applies spatial entropy in measuring non-spatial attribute similarity and spatial correlation during the clustering process. The experimental results from both the synthetic data and the real application demonstrate that SEClu can effectively identify spatial clusters with spatial correlated patterns.

#index 1603739
#* Self-adjust local connectivity analysis for spectral clustering
#@ Hui Wu;Guangzhi Qu;Xingquan Zhu
#t 2011
#c 3
#% 296738
#% 313959
#% 724227
#% 769935
#% 883900
#% 953366
#% 992320
#% 995140
#% 1002473
#% 1108819
#% 1192924
#% 1269492
#% 1279294
#% 1421792
#% 1435379
#% 1470149
#% 1824968
#! Spectral clustering has been applied in various applications. But there still exist some important issues to be resolved, among which the two major ones are to (1) specify the scale parameter in calculating the similarity between data objects, and (2) select propoer eigenvectors to reduce data dimensionality. Though these topics have been studied extensively, the existing methods cannot work well in some complicated scenarios, which limits the wide deployment of the spectral clustering method. In this work, we revisit the above two problems and propose three contributions to the field: 1) a unified framework is designed to study the impact of the scale parameter on similarity between data objects. This framework can easily accommodate various state of art spectral clustering methods in determining the scale parameter; 2) a novel approach based on local connectivity analysis is proposed to specify the scale parameter; 3) propose a new method for eigenvector selection. Compared with existing techniques, the proposed approach has a rigorous theoretical basis and is efficient from practical perspective. Experimental results show the efficacy of our approach to clustering data of different scenarios.

#index 1603740
#* An effective density-based hierarchical clustering technique to identify coherent patterns from gene expression data
#@ Sauravjyoti Sarmah;Rosy Das Sarmah;Dhruba Kumar Bhattacharyya
#t 2011
#c 3
#% 374537
#% 469425
#% 589434
#% 778728
#% 818916
#% 832901
#% 1013086
#% 1041358
#% 1065563
#% 1212696
#! We present an effective tree-based clustering technique (Gene ClusTree) for finding clusters over gene expression data. GeneClusTree attempts to find all the clusters over subspaces using a tree-based density approach by scanning the whole database in minimum possible scans and is free from the restrictions of using a normal proximity measure [1]. Effectiveness of GeneClusTree is established in terms of well known z-score measure and p-value over several real-life datasets. The p-value analysis shows that our technique is capable in detecting biologically relevant clusters from gene expression data.

#index 1603741
#* Nonlinear discriminative embedding for clustering via spectral regularization
#@ Yubin Zhan;Jianping Yin
#t 2011
#c 3
#% 313959
#% 424085
#% 593047
#% 724227
#% 729437
#% 765552
#% 913838
#% 995140
#% 1305478
#! In this paper, we propose a novel nonlinear discriminative dimensionality reduction method for clustering high dimensional data. The proposed method first represents the desired low dimensional nonlinear embedding as linear combinations of predefined smooth vectors with respect to data manifold, which are characterized by a weighted graph. Then the optimal combination coefficients and optimal cluster assignment matrix are computed by maximizing between-cluster scatter and minimizing within-cluster scatter simultaneously as well as preserving smoothness of the cluster assignment matrix with respect to the data manifold. We solve the optimization problem in an iterative algorithm, which is proved to be convergent. The contributions of the proposed method are two folds: 1) obtained nonlinear embedding can recover intrinsic manifold structure as well as enhance the cluster structure of the original data; 2) the cluster results can also be obtained in dimensionality reduction procedure. Extensive experiments conducted on UCI data sets and real world data sets have shown the effectiveness of the proposed method for both clustering and visualization high dimensional data set.

#index 1603742
#* An adaptive fuzzy k-nearest neighbor method based on parallel particle swarm optimization for bankruptcy prediction
#@ Hui-Ling Chen;Da-You Liu;Bo Yang;Jie Liu;Gang Wang;Su-Jing Wang
#t 2011
#c 3
#% 420065
#% 889273
#% 1058637
#% 1421762
#% 1777303
#! This study proposes an efficient non-parametric classifier for bankruptcy prediction using an adaptive fuzzy k-nearest neighbor (FKNN) method, where the nearest neighbor k and the fuzzy strength parameter m are adaptively specified by the particle swarm optimization (PSO) approach. In addition to performing the parameter optimization for FKNN, PSO is utilized to choose the most discriminative subset of features for prediction as well. Time varying acceleration coefficients (TVAC) and inertia weight (TVIW) are employed to efficiently control the local and global search ability of PSO. Moreover, both the continuous and binary PSO are implemented in parallel on a multi-core platform. The resultant bankruptcy prediction model, named PTVPSO-FKNN, is compared with three classification methods on a real-world case. The obtained results clearly confirm the superiority of the developed model as compared to the other three methods in terms of Classification accuracy, Type I error, Type II error and AUC (area under the receiver operating characteristic (ROC) curve) criterion. It is also observed that the PTVPSO-FKNN is a powerful feature selection tool which has indentified a subset of best discriminative features. Additionally, the proposed model has gained a great deal of efficiency in terms of CPU time owing to the parallel implementation.

#index 1603743
#* Semi-supervised parameter-free divisive hierarchical clustering of categorical data
#@ Tengke Xiong;Shengrui Wang;André Mayers;Ernest Monga
#t 2011
#c 3
#% 296738
#% 329562
#% 420081
#% 464291
#% 464608
#% 769881
#% 769896
#% 794518
#% 835018
#% 989642
#% 1013613
#% 1156095
#% 1183429
#% 1183591
#% 1318615
#% 1318681
#! Semi-supervised clustering can yield considerable improvement over unsupervised clustering. Most existing semi-supervised clustering algorithms are non-hierarchical, derived from the k-means algorithm and designed for analyzing numeric data. Clustering categorical data is a challenging issue due to the lack of inherently meaningful similarity measure, and semi-supervised clustering in the categorical domain remains untouched. In this paper, we propose a novel semi-supervised divisive hierarchical algorithm for categorical data. Our algorithm is parameter-free, fully automatic and effective in taking advantage of instance-level constraint background knowledge to improve the quality of the resultant dendrogram. Experiments on real-life data demonstrate the promising performance of our algorithm.

#index 1603744
#* Identifying hidden contexts in classification
#@ Indre Žliobaite
#t 2011
#c 3
#% 204531
#% 266787
#% 464888
#% 729437
#% 743489
#% 1378110
#% 1380964
#! In this study we investigate how to identify hidden contexts from the data in classification tasks. Contexts are artifacts in the data, which do not predict the class label directly. For instance, in speech recognition task speakers might have different accents, which do not directly discriminate between the spoken words. Identifying hidden contexts is considered as data preprocessing task, which can help to build more accurate classifiers, tailored for particular contexts and give an insight into the data structure. We present three techniques to identify hidden contexts, which hide class label information from the input data and partition it using clustering techniques. We form a collection of performance measures to ensure that the resulting contexts are valid. We evaluate the performance of the proposed techniques on thirty real datasets. We present a case study illustrating how the identified contexts can be used to build specialized more accurate classifiers.

#index 1603745
#* Cross-lingual sentiment classification via bi-view non-negative matrix tri-factorization
#@ Junfeng Pan;Gui-Rong Xue;Yong Yu;Yang Wang
#t 2011
#c 3
#% 280819
#% 815915
#% 818313
#% 854646
#% 881468
#% 939848
#% 1055769
#% 1166512
#% 1264731
#% 1264775
#% 1328329
#% 1328330
#% 1338619
#% 1400008
#! Recently the sentiment classification problem interests the researchers over the world, but most sentiment corpora are in English, which limits the research progress on sentiment classification in other languages. Cross-lingual sentiment classification aims to use annotated sentiment corpora in one language (e.g. English) as training data, to predict the sentiment polarity of the data in another language (e.g. Chinese). In this paper, we design a bi-view non-negative matrix tri-factorization (BNMTF) model for the cross-lingual sentiment classification problem. We employ machine translation service so that both training and test data is able to have two representation, one in source language and the other in target language. Our BNMTF model is derived from the non-negative matrix tri-factorization models in both languages in order to make more accurate prediction. Our BNMTF model has three main advantages: (1) combining the information from two views (2) incorporating the lexical knowledge and training document label knowledge (3) adding information from test documents. Experimental results show the effectiveness of our BNMTF model, which can outperform other baseline approaches to cross-lingual sentiment classification.

#index 1603746
#* A sequential dynamic multi-class model and recursive filtering by variational bayesian methods
#@ Xiangyun Qing;Xingyu Wang
#t 2011
#c 3
#% 342600
#% 889295
#% 1154723
#% 1189216
#% 1292093
#% 1304741
#% 1860941
#! Adaptive classification evolving over time is an important learning task that arises in many applications. In this paper, a sequential dynamic multi-class model (SDMM) is proposed for representing the multi-class adaptive learning task, which is based on the polychotomous response model and dynamic logistic regression. Multiple state chains in the SDMM are coupled by the observable labels and feature vectors. Each state chain is modeled as a first-order Markov process with timevarying covariance parameters for characterizing the non-stationary generating process of sequential labels. Augmented auxiliary variables are introduced for developing efficient inference procedures according to the popular data augmentation strategy. Variational Bayesian methods are applied to estimate the dynamic state variables and augmented auxiliary variables recursively. According to the results of recursive filtering procedures using mean-field approximation forms, one-step-ahead predicted probabilities are calculated by marginalizing the state variables. Experiment results based on both synthetic and real data show that the proposed model significantly outperforms the non-sequential static methods for the multi-class adaptive learning problems with missing labels. Encouraging results have been obtained by comprising well-known multi-class data stream algorithms.

#index 1603747
#* Random ensemble decision trees for learning concept-drifting data streams
#@ Peipei Li;Xindong Wu;Qianhui Liang;Xuegang Hu;Yuhong Zhang
#t 2011
#c 3
#% 136350
#% 209021
#% 256615
#% 312727
#% 342600
#% 342639
#% 400847
#% 451036
#% 481945
#% 727888
#% 729932
#% 823408
#% 1008315
#% 1016245
#% 1055665
#% 1105837
#% 1107590
#% 1195979
#% 1214635
#% 1214654
#% 1250172
#! Few online classification algorithms based on traditional inductive ensembling focus on handling concept drifting data streams while performing well on noisy data. Motivated by this, an incremental algorithm based on random Ensemble Decision Trees for Concept-drifting data streams (EDTC) is proposed in this paper. Three variants of random feature selection are developed to implement split-tests. To better track concept drifts in data streams with noisy data, an improved twothreshold-based drifting detection mechanism is introduced. Extensive studies demonstrate that our algorithm performs very well compared to several known online algorithms based on single models and ensemble models. A conclusion is hence drawn that multiple solutions are provided for learning from concept drifting data streams with noise.

#index 1603748
#* Collaborative data cleaning for sentiment classification with noisy training corpus
#@ Xiaojun Wan
#t 2011
#c 3
#% 252011
#% 316709
#% 402289
#% 466263
#% 742220
#% 809938
#% 811348
#% 815254
#% 815915
#% 854646
#% 938687
#% 939719
#% 939773
#% 939848
#% 939897
#% 1263573
#% 1264731
#% 1264775
#% 1277969
#% 1328329
#% 1328330
#% 1328331
#% 1330516
#! Labeled review corpus is considered as a very valuable resource for the task of sentiment classification of product reviews. Fortunately, there are a large amount of product reviews on the Web, and each review is associated with a tag assigned by users to indicate its polarity orientation. We can download such reviews with tags and use them as training corpus for sentiment classification. However, users may assign the polarity tag arbitrarily and inaccurately, and some tags are not appropriate, which results in that the automatically constructed corpus contains many noises and the noisy instances will deteriorate the classification performance. In this paper, we propose the co-cleaning and tri-cleaning algorithms to collaboratively clean the corpus and thus improve the sentiment classification performance. The proposed algorithms use multiple classifiers to iteratively select and remove the most confidently noisy instances from the corpus. Experimental results verify the effectiveness of our proposed algorithms, and the tri-cleaning algorithm is most effective and promising.

#index 1603749
#* Using constraints to generate and explore higher order discriminative patterns
#@ Michael Steinbach;Haoyu Yu;Gang Fang;Vipin Kumar
#t 2011
#c 3
#% 71597
#% 280409
#% 299985
#% 379331
#% 420126
#% 481290
#% 729935
#% 835018
#% 881486
#% 989614
#% 1083649
#% 1692331
#! Discriminative pattern mining looks for association patterns that occur more frequently in one class than another and has important applications in many areas including finding biomarkers in biomedical data. However, finding such patterns is challenging because higher order combinations of variables may show high discrimination even when single variables or lower-order combinations show little or no discrimination. Thus, generating such patterns is important for evaluating discriminative pattern mining algorithms and better understanding the nature of discriminative patterns. To that end, we describe how such patterns can be defined using mathematical constraints which are then solved with widely available software that generates solutions for the resulting optimization problem. We present a basic formulation of the problem obtained from a straightforward translation of the desired pattern characteristics into mathematical constraints, and then show how the pattern generation problem can be reformulated in terms of the selection of rows from a truth table. This formulation is more efficient and provides deeper insight into the process of creating higher order patterns. It also makes it easy to define patterns other than just those based on the conjunctive logic used by traditional association and discriminant pattern analysis.

#index 1603750
#* Mining maximal co-located event sets
#@ Jin Soung Yoo;Mark Bow
#t 2011
#c 3
#% 248791
#% 300120
#% 342635
#% 410276
#% 459020
#% 527021
#% 769914
#% 784296
#% 784509
#% 832571
#% 844416
#% 889100
#% 937814
#% 1135161
#% 1135162
#% 1204356
#% 1411038
#! A spatial co-location is a set of spatial events being frequently observed together in nearby geographic space. A common framework for mining spatial association patterns employs a level-wised search method (like Apriori). However, the Apriori-based algorithms do not scale well for discovering long co-location patterns in large or dense spatial neighborhoods and can be restricted for only short pattern discovery. To address this problem, we propose an algorithm for finding maximal co-located event sets which concisely represent all co-location patterns. The proposed algorithm generates only most promising candidates, traverses the pattern search space in depth-first manner with an effective pruning scheme, and reduces expensive co-location instance search operations. Our experiment result shows that the proposed algorithm is computationally effective when mining maximal co-locations

#index 1603751
#* Pattern mining for a two-stage information filtering system
#@ Xujuan Zhou;Yuefeng Li;Peter Bruza;Yue Xu;Raymond Y. K. Lau
#t 2011
#c 3
#% 124004
#% 248791
#% 387427
#% 584888
#% 779877
#% 863392
#% 879595
#% 915323
#% 987227
#% 1026882
#% 1130911
#! As information available over computer networks is growing exponentially, searching for useful information becomes increasingly more difficult. Accordingly, developing an effective information filtering mechanism is becoming very important to alleviate the problem of information overload. Information filtering systems often employ user profiles to represent users' information needs so as to determine the relevance of documents from an incoming data stream. This paper presents a novel two-stage information filtering model which combines the merits of termbased and pattern-based approaches to effectively filter sheer volume of information. In particular, the first filtering stage is supported by a novel rough analysis model which efficiently removes a large number of irrelevant documents, thereby addressing the overload problem. The second filtering stage is empowered by a semantically rich pattern taxonomy mining model which effectively fetches incoming documents according to the specific information needs of a user, thereby addressing the mismatch problem. The experimental results based on the RCV1 corpus show that the proposed two-stage filtering model significantly outperforms both the term-based and pattern-based information filtering models.

#index 1603752
#* Efficiently retrieving longest common route patterns of moving objects by summarizing turning regions
#@ Guangyan Huang;Yanchun Zhang;Jing He;Zhiming Ding
#t 2011
#c 3
#% 235941
#% 289010
#% 421124
#% 844292
#% 960283
#% 976716
#% 989604
#% 1030849
#% 1127436
#% 1156046
#! The popularity of online location services provides opportunities to discover useful knowledge from trajectories of moving objects. This paper addresses the problem of mining longest common route (LCR) patterns. As a trajectory of a moving object is generally represented by a sequence of discrete locations sampled with an interval, the different trajectory instances along the same route may be denoted by different sequences of points (location, timestamp). Thus, the most challenging task in the mining process is to abstract trajectories by the right points. We propose a novel mining algorithm for LCR patterns based on turning regions (LCRTurning), which discovers a sequence of turning regions to abstract a trajectory and then maps the problem into the traditional problem of mining longest common subsequences (LCS). Effectiveness of LCRTurning algorithm is validated by an experimental study based on various sizes of simulated moving objects datasets.

#index 1603753
#* Automatic assignment of item weights for pattern mining on data streams
#@ Yun Sing Koh;Russel Pears;Gillian Dobbie
#t 2011
#c 3
#% 729959
#% 785339
#% 915241
#% 1236684
#% 1737786
#! Research inWeighted Association Rule Mining (WARM) has largely concentrated on mining traditional static transactional datasets. Whilst there have been a few attempts at researching WARM in a data stream environment, none have addressed the problem of assigning and adapting weights in the presence of concept drift, which often occurs in a data stream environment. In this research we experiment with two methods of adapting weights; firstly, a simplistic method that recomputes the entire set of weights at fixed intervals, and secondly a method that relies on a distance function that assesses the extent of change in the stream and only updates those items that have had significant change in their patterns of interaction. We show that the latter method is able to maintain good accuracy whilst being several times faster than the former.

#index 1603754
#* Predicting private company exits using qualitative data
#@ Harish S. Bhat;Daniel Zaelit
#t 2011
#c 3
#% 400847
#% 889273
#% 1000358
#% 1038334
#% 1301004
#! Private companies backed by venture capitalists or private equity funds receive their funding in a series of rounds. Information about when each round occurred and which investors participated in each round has been compiled into different databases. Here we mine one such database to model how the private company will exit the VC/PE space. More specifically, we apply a random forest algorithm to each of nine sectors of private companies. Resampling is used to correct imbalanced class distributions. Our results show that a late-stage investor may be able to leverage purely qualitative knowledge of a company's first three rounds of funding to assess the probability that (1) the company will not go bankrupt and (2) the company will eventually make an exit of some kind (and no longer remain private). For both of these two-class classification problems, our models' out-of-sample success rate is 75% and the area under the ROC curve is 0.83, averaged across all sectors. Finally, we use the random forest classifier to rank the covariates based on how predictive they are. The results indicate that the models could provide both predictive and explanatory power for business decisions.

#index 1603755
#* A rule-based method for customer churn prediction in telecommunication services
#@ Ying Huang;Bingquan Huang;M.-T. Kechadi
#t 2011
#c 3
#% 136350
#% 420077
#% 449566
#% 477799
#% 478279
#% 840957
#% 1267852
#% 1272280
#% 1280020
#% 1290056
#% 1337755
#% 1378224
#% 1777282
#! Rule-based classification methods, which provide the interpretation of a classification, are very useful in churn prediction. However, most of the rule-based methods are not able to provide the prediction probability which is helpful for evaluating customers. This paper proposes a rule induction based classification algorithm, called CRL. CRL applies several heuristic methods to learn a set of rules, and then uses them to predict the customer potential behaviours. The experiments were carried out to evaluate the proposed method, based on 4 datasets of University of California, Irvine(UCI) and one dataset of telecoms. The experimental results show that CRL can achieve high classification accuracy and outperforms the existing rule-based methods in churn prediction.

#index 1603756
#* Adaptive and effective keyword search for XML
#@ Weidong Yang;Hao Zhu;Nan Li;Guansheng Zhu
#t 2011
#c 3
#% 654442
#% 810052
#% 863389
#% 956599
#% 960261
#% 1015258
#% 1016135
#% 1019060
#% 1022318
#% 1044480
#% 1055787
#% 1181282
#% 1372728
#% 1710592
#! Most of the existing methods for XML keyword search are based on the notion of Lowest Common Ancestor (LCA). However, as we explore the most important fundamental flaw inside those result models is that the search results are eternally determined and nonadjustable. In order to serve better results, we propose a novel and flexible result model which can avoid all these defects. Within our model, a scoring function is presented to judge the quality of each result. The considered metrics of evaluating results are weighted, and can be updated as needed. Based on the result model, three heuristic algorithms are proposed. Moreover, a mechanism is employed to select the most suitable one out of these algorithms to generate better results. Extensive experiments show that our approach outperforms any LCA-based ones with higher recall and precision.

#index 1603757
#* Steering time-dependent estimation of posteriors with hyperparameter indexing in bayesian topic models
#@ Atsuhiro Takasu;Yuichiro Shibata;Kiyoshi Oguri
#t 2011
#c 3
#% 280819
#% 722904
#% 875959
#% 881498
#% 989623
#% 1073975
#% 1417055
#% 1424114
#% 1451206
#! This paper provides a new approach to topical trend analysis. Our aim is to improve the generalization power of latent Dirichlet allocation (LDA) by using document timestamps. Many previous works model topical trends by making latent topic distributions timedependent. We propose a straightforward approach by preparing a different word multinomial distribution for each time point. Since this approach increases the number of parameters, overfitting becomes a critical issue. Our contribution to this issue is two-fold. First, we propose an effective way of defining Dirichlet priors over the word multinomials. Second, we propose a special scheduling of variational Bayesian (VB) inference. Comprehensive experiments with six datasets prove that our approach can improve LDA and also Topics over Time, a well-known variant of LDA, in terms of test data perplexity in the framework of VB inference.

#index 1603758
#* Constrained LDA for grouping product features in opinion mining
#@ Zhongwu Zhai;Bing Liu;Hua Xu;Peifa Jia
#t 2011
#c 3
#% 464291
#% 722904
#% 769892
#% 805873
#% 828958
#% 1085668
#% 1211693
#% 1271481
#% 1292576
#% 1338553
#% 1484383
#! In opinion mining of product reviews, one often wants to produce a summary of opinions based on product features. However, for the same feature, people can express it with different words and phrases. To produce an effective summary, these words and phrases, which are domain synonyms, need to be grouped under the same feature. Topic modeling is a suitable method for the task. However, instead of simply letting topic modeling find groupings freely, we believe it is possible to do better by giving it some pre-existing knowledge in the form of automatically extracted constraints. In this paper, we first extend a popular topic modeling method, called Latent Dirichlet Allocation (LDA), with the ability to process large scale constraints. Then, two novel methods are proposed to extract two types of constraints automatically. Finally, the resulting constrained-LDA and the extracted constraints are applied to group product features. Experiments show that constrained-LDA outperforms the original LDA and the latest mLSA by a large margin.

#index 1603759
#* Semantic dependent word pairs generative model for fine-grained product feature mining
#@ Tian-Jie Zhan;Chun-Hung Li
#t 2011
#c 3
#% 722904
#% 769892
#% 1035591
#% 1292576
#% 1310463
#% 1470684
#% 1517895
#! In the field of opinion mining, extraction of fine-grained product feature is a challenging problem. Noun is the most important features to represent product features. Generative model such as the latent Dirichlet allocation (LDA) has been used for detecting keyword clusters in document corpus. As adjectives often dominate review corpus, they are often excluded from the vocabulary in such generative model for opinion sentiment analysis. On the other hand, adjectives provide useful context for noun features as they are often semantically related to the nouns. To take advantage of such semantic relations, dependency tree is constructed to extract pairs of noun and adjective with semantic dependency relation. We propose a semantic dependent word pairs generative model for pairs of noun and adjective for each sentence. Product features and their corresponding adjectives are simultaneously clustered into distinct groups which enable improved accuracy of product features as well as providing clustered adjectives. Experimental results demonstrated the advantage of our models with lower perplexity, average cluster entropies, compared to baseline models based on LDA. Highly semantic cohesive, descriptive and discriminative fine-grained product features are obtained automatically.

#index 1603760
#* Grammatical dependency-based relations for term weighting in text classification
#@ Dat Huynh;Dat Tran;Wanli Ma;Dharmendra Sharma
#t 2011
#c 3
#% 190581
#% 280817
#% 458379
#% 465754
#% 741900
#% 878916
#% 1008096
#% 1074073
#% 1117027
#% 1250381
#% 1275012
#% 1289516
#% 1299755
#% 1705406
#! Term frequency and term co-occurrence are currently used to estimate term weightings in a document. However these methods do not employ relations based on grammatical dependency among terms to measure dependency between word features. In this paper, we propose a new approach that employs grammatical relations to estimate weightings of terms in a text document and present how to apply the term weighting scheme to text classification. A graph model is used to encode the extracted relations. A graph centrality algorithm is then applied to calculate scores that represent significance values of the terms in the document context. Experiments performed on many corpora with SVM classifier show that the proposed term weighting approach outperforms those based on term frequency and term co-occurrence.

#index 1603761
#* XML documents clustering using a tensor space model
#@ Sangeetha Kutty;Richi Nayak;Yuefeng Li
#t 2011
#c 3
#% 342617
#% 938793
#% 983661
#% 989575
#% 1083660
#% 1089780
#% 1147645
#% 1176933
#% 1252653
#% 1431737
#% 1489461
#% 1674750
#! The traditional Vector Space Model (VSM) is not able to represent both the structure and the content of XML documents. This paper introduces a novel method of representing XML documents in a Tensor Space Model (TSM) and then utilizing it for clustering. Empirical analysis shows that the proposed method is scalable for large-sized datasets; as well, the factorized matrices produced from the proposed method help to improve the quality of clusters through the enriched document representation of both structure and content information.

#index 1603762
#* An efficient pre-processing method to identify logical components from PDF documents
#@ Ying Liu;Kun Bai;Liangcai Gao
#t 2011
#c 3
#% 348147
#% 420077
#% 458372
#% 464434
#% 493837
#% 544484
#% 625351
#% 643004
#% 658628
#% 658655
#% 658656
#% 755816
#% 781729
#% 786564
#% 807369
#% 816181
#% 855119
#% 967256
#% 1130940
#% 1283377
#% 1401079
#% 1673026
#! As the rapid growth of the scientific documents in digital libraries, the search demands for the documents as well as specific components increase dramatically. Accurately detecting the component boundary is of vital importance to all the further information extraction and applications. However, document component boundary detection (especially the table, figure, and equation) is a challenging problem because there is no standardized formats and layouts across diverse documents. This paper presents an efficient document preprocessing technique to improve the document component boundary detection performance by taking advantage of the nature of document lines. Our method easily simplifies the component boundary detection problem into the sparse line analysis problem with much less noise. We define eight document line label types and apply machine learning techniques as well as the heuristic rule-based method on identifying multiple document components. Combining with different heuristic rules, we extract the multiple components in a batch way by filtering out massive noises as early as possible. Our method focus on an important un-tagged document format - PDF documents. The experimental results prove the effectiveness of the sparse line analysis.

#index 1603763
#* Combining proper name-coreference with conditional random fields for semi-supervised named entity recognition in Vietnamese text
#@ Rathany Chan Sam;Huong Thanh Le;Thuy Thanh Nguyen;Thien Huu Nguyen
#t 2011
#c 3
#% 252011
#% 278107
#% 464434
#% 709765
#% 748550
#% 817461
#% 854813
#% 855119
#% 874511
#% 943828
#% 1016021
#% 1264970
#% 1271483
#% 1275038
#! Named entity recognition (NER) is the process of seeking to locate atomic elements in text into predefined categories such as the names of persons, organizations and locations.Most existingNERsystems are based on supervised learning. This method often requires a large amount of labelled training data, which is very time-consuming to build. To solve this problem, we introduce a semi-supervised learning method for recognizing named entities in Vietnamese text by combining proper name coreference, named-ambiguityheuristicswithapowerful sequential learningmodel,Conditional RandomFields. Our approach inherits the idea of Liao and Veeramachaneni [6] and expands it by using proper name coreference. Starting by training the model using a small data set that is annotated manually, the learning model extracts high confident named entities and finds low confident ones by using proper name coreference rules. The low confident named entities are put in the training set to learn new context features. The F-scores of the systemfor extracting "Person", "Location" and "Organization" entities are 83.36%, 69.53% and 65.71%when applying heuristics proposed by Liao andVeeramachaneni.Those valueswhen using our proposed heuristics are 93.13%, 88.15% and 79.35%, respectively. It shows that our method is good in increasing the system accuracy.

#index 1603764
#* Topic analysis of web user behavior using LDA model on proxy logs
#@ Hiroshi Fujimoto;Minoru Etoh;Akira Kinno;Yoshikazu Akinaga
#t 2011
#c 3
#% 255177
#% 266283
#% 275360
#% 280819
#% 420134
#% 586843
#% 722760
#% 722904
#% 769895
#% 825476
#% 956521
#% 1155906
#% 1229386
#% 1246495
#% 1275346
#% 1355042
#% 1587267
#% 1656345
#% 1683871
#! We propose a web user profiling and clustering framework based on LDA-based topic modeling with an analogy to document analysis in which documents and words represent users and their actions. The main technical challenge addressed here is how to symbolize web access actions, by words, that are monitored through a web proxy. We develop a hierarchical URL dictionary generated from Yahoo! Directory and a cross-hierarchical matching method that provides the function of automatic abstraction. We apply the proposed framework to 7500 students in Osaka University. The results include, for example, 24 topics such as "Technology Oriented", "Job Hunting", and "SNS-addict." The results reflect the typical interest profiles of University students, while perplexity analysis is employed to confirm the optimality of the framework.

#index 1603765
#* SizeSpotSigs: an effective deduplicate algorithm considering the size of page content
#@ Xianling Mao;Xiaobing Liu;Nan Di;Xiaoming Li;Hongfei Yan
#t 2011
#c 3
#% 201935
#% 249321
#% 255137
#% 345087
#% 347225
#% 387427
#% 443393
#% 479973
#% 544011
#% 571725
#% 769944
#% 805905
#% 879600
#% 879617
#% 907504
#% 978157
#% 1074121
#% 1083644
#% 1292753
#% 1355054
#! Detecting if two Web pages are near replicas, in terms of their contents rather than files, is of great importance in many web information based applications. As a result, many deduplicating algorithms have been proposed. Nevertheless, analysis and experiments show that existing algorithms usually don't work well for short Web pages1, due to relatively large portion of noisy information, such as ads and templates for websites, existing in the corresponding files. In this paper, we analyze the critical issues in deduplicating short Web pages and present an algorithm (AF SpotSigs) that incorporates them, which could work 15% better than the state-of-the-art method. Then we propose an algorithm (SizeSpotSigs), taking the size of page contents into account, which could handle both short and long Web pages. The contributions of SizeSpotSigs are three-fold: 1) Provide an analysis about the relation between noise-content ratio and similarity, and propose two rules of making the methods work better; 2) Based on the analysis, for Chinese, we propose 3 new features to improve the effectiveness for short Web pages; 3) We present an algorithm named SizeSpotSigs for near duplicate detection considering the size of the core content in Web page. Experiments confirm that SizeSpotSigs works better than state-of-the-art approaches such as SpotSigs, over a demonstrative Mixer of manually assessed nearduplicate news articles, which include both short and long Web pages.

#index 1603766
#* Knowledge transfer across multilingual corpora via latent topics
#@ Wim De Smet;Jie Tang;Marie-Francine Moens
#t 2011
#c 3
#% 262870
#% 280826
#% 384972
#% 722904
#% 732847
#% 770848
#% 818313
#% 939570
#% 983644
#% 983828
#% 983865
#% 983899
#% 989585
#% 1074129
#% 1083655
#% 1190212
#% 1261539
#% 1297066
#% 1328329
#% 1338620
#% 1377376
#% 1650298
#! This paper explores bridging the content of two different languages via latent topics. Specifically, we propose a unified probabilistic model to simultaneously model latent topics from bilingual corpora that discuss comparable content and use the topics as features in a cross-lingual, dictionary-less text categorization task. Experimental results on multilingual Wikipedia data show that the proposed topic model effectively discovers the topic information from the bilingual corpora, and the learned topics successfully transfer classification knowledge to other languages, for which no labeled training data are available.

#index 1607934
#* Proceedings of the 15th Pacific-Asia conference on Advances in knowledge discovery and data mining - Volume Part II
#@ Joshua Zhexue Huang;Longbing Cao;Jaideep Srivastava
#t 2011
#c 3

#index 1607935
#* Spectral analysis of k-balanced signed graphs
#@ Leting Wu;Xiaowei Ying;Xintao Wu;Aidong Lu;Zhi-Hua Zhou
#t 2011
#c 3
#% 447644
#% 1190129
#% 1384246
#% 1710595
#! Previous studies on social networks are often focused on networks with only positive relations between individual nodes. As a significant extension, we conduct the spectral analysis on graphs with both positive and negative edges. Specifically, we investigate the impacts of introducing negative edges and examine patterns in the spectral space of the graph's adjacency matrix. Our theoretical results show that communities in a k-balanced signed graph are distinguishable in the spectral space of its signed adjacency matrix even if connections between communities are dense. This is quite different from recent findings on unsigned graphs, where communities tend to mix together in the spectral space when connections between communities increase. We further conduct theoretical studies based on graph perturbation to examine spectral patterns of general unbalanced signed graphs. We illustrate our theoretical findings with various empirical evaluations.

#index 1607936
#* Spectral analysis for billion-scale graphs: discoveries and implementation
#@ U. Kang;Brendan Meeder;Christos Faloutsos
#t 2011
#c 3
#% 238376
#% 347020
#% 1021533
#% 1063553
#% 1108904
#% 1176933
#% 1176970
#% 1214705
#% 1318636
#% 1396903
#% 1594624
#% 1673564
#% 1710595
#! Given a graph with billions of nodes and edges, how can we find patterns and anomalies? Are there nodes that participate in too many or too few triangles? Are there close-knit near-cliques? These questions are expensive to answer unless we have the first several eigenvalues and eigenvectors of the graph adjacency matrix. However, eigensolvers suffer from subtle problems (e.g., convergence) for large sparse matrices, let alone for billion-scale ones. We address this problem with the proposed HEIGEN algorithm, which we carefully design to be accurate, efficient, and able to run on the highly scalable MAPREDUCE (HADOOP) environment. This enables HEIGEN to handle matrices more than 1000× larger than those which can be analyzed by existing algorithms. We implement HEIGEN and run it on the M45 cluster, one of the top 50 supercomputers in the world. We report important discoveries about near-cliques and triangles on several real-world graphs, including a snapshot of the Twitter social network (38Gb, 2 billion edges) and the "YahooWeb" dataset, one of the largest publicly available graphs (120Gb, 1.4 billion nodes, 6.6 billion edges).

#index 1607937
#* LGM: mining frequent subgraphs from linear graphs
#@ Yasuo Tabei;Daisuke Okanohara;Shuichi Hirose;Koji Tsuda
#t 2011
#c 3
#% 207408
#% 466644
#% 478274
#% 478622
#% 629708
#% 729938
#% 778732
#% 867881
#% 915350
#% 940556
#% 1041266
#% 1063502
#% 1108856
#% 1176903
#% 1183448
#% 1185052
#% 1916411
#! A linear graph is a graph whose vertices are totally ordered. Biological and linguistic sequences with interactions among symbols are naturally represented as linear graphs. Examples include protein contact maps, RNA secondary structures and predicate-argument structures. Our algorithm, linear graph miner (LGM), leverages the vertex order for efficient enumeration of frequent subgraphs. Based on the reverse search principle, the pattern space is systematically traversed without expensive duplication checking. Disconnected subgraph patterns are particularly important in linear graphs due to their sequential nature. Unlike conventional graph mining algorithms detecting connected patterns only, LGM can detect disconnected patterns as well. The utility and efficiency of LGM are demonstrated in experiments on protein contact maps.

#index 1607938
#* Efficient centrality monitoring for time-evolving graphs
#@ Yasuhiro Fujiwara;Makoto Onizuka;Masaru Kitsuregawa
#t 2011
#c 3
#% 255137
#% 723439
#% 813718
#% 824797
#% 881491
#% 937549
#% 1292553
#! The goal of this work is to identify the nodes that have the smallest sum of distances to other nodes (the lowest closeness centrality nodes) in graphs that evolve over time. Previous approaches to this problem find the lowest centrality nodes efficiently at the expense of exactness. The main motivation of this paper is to answer, in the affirmative, the question, 'Is it possible to improve the search time without sacrificing the exactness?'. Our solution is Sniper, a fast search method for time-evolving graphs. Sniper is based on two ideas: (1) It computes approximate centrality by reducing the original graph size while guaranteeing the answer exactness, and (2) It terminates unnecessary distance computations early when pruning unlikely nodes. The experimental results show that Sniper can find the lowest centrality nodes significantly faster than the previous approaches while it guarantees answer exactness.

#index 1607939
#* Graph-based clustering with constraints
#@ Rajul Anand;Chandan K. Reddy
#t 2011
#c 3
#% 438137
#% 464291
#% 464608
#% 464631
#% 769881
#% 770782
#% 835018
#% 840892
#% 844372
#% 1085668
#% 1318615
#% 1465169
#% 1663626
#% 1673558
#! A common way to add background knowledge to the clustering algorithms is by adding constraints. Though there had been some algorithms that incorporate constraints into the clustering process, not much focus was given to the topic of graph-based clustering with constraints. In this paper, we propose a constrained graph-based clustering method and argue that adding constraints in distance function before graph partitioning will lead to better results. We also specify a novel approach for adding constraints by introducing the distance limit criteria. We will also examine how our new distance limit approach performs in comparison to earlier approaches of using fixed distance measure for constraints. The proposed approach and its variants are evaluated on UCI datasets and compared with the other constrained-clustering algorithms which embed constraints in a similar fashion.

#index 1607940
#* A partial correlation-based Bayesian network structure learning algorithm under SEM
#@ Jing Yang;Lian Li
#t 2011
#c 3
#% 129987
#% 893460
#% 1117673
#% 1269873
#% 1650289
#! A new algorithm, PCB (Partial Correlation-Based) algorithm, is presented for Bayesian network structure learning. The algorithm combines ideas from local learning with partial correlation techniques in an effective way. It reconstructs the skeleton of a Bayesian network based on partial correlation and then performs greedy hill-climbing search to orient the edges. Specifically, we make three contributions. Firstly, we give the proof that in a SEM (simultaneous equation model) with uncorrelated errors, when datasets are generated by SEM no matter what distribution disturbances subject to, we can use partial correlation as the criterion of CI test. Second, we have done a series of experiments to find the best threshold value of partial correlation. Finally, we show how partial relation can be used in Bayesian network structure learning under SEM. The effectiveness of the method is compared with current state of the art methods on 8 networks. Simulation shows that PCB algorithm outperforms existing algorithms in both accuracy and run time.

#index 1607941
#* Predicting friendship links in social networks using a topic modeling approach
#@ Rohit Parimi;Doina Caragea
#t 2011
#c 3
#% 722904
#% 987245
#% 1190123
#% 1227610
#% 1287227
#% 1303240
#% 1333631
#! In the recent years, the number of social network users has increased dramatically. The resulting amount of data associated with users of social networks has created great opportunities for data mining problems. One data mining problem of interest for social networks is the friendship link prediction problem. Intuitively, a friendship link between two users can be predicted based on their common friends and interests. However, using user interests directly can be challenging, given the large number of possible interests. In the past, approaches that make use of an explicit user interest ontology have been proposed to tackle this problem, but the construction of the ontology proved to be computationally expensive and the resulting ontology was not very useful. As an alternative, we propose a topic modeling approach to the problem of predicting new friendships based on interests and existing friendships. Specifically, we use Latent Dirichlet Allocation (LDA) to model user interests and, thus, we create an implicit interest ontology. We construct features for the link prediction problem based on the resulting topic distributions. Experimental results on several LiveJournal data sets of varying sizes show the usefulness of the LDA features for predicting friendships.

#index 1607942
#* Info-cluster based regional influence analysis in social networks
#@ Chao Li;Zhongying Zhao;Jun Luo;Jianping Fan
#t 2011
#c 3
#% 342596
#% 729923
#% 949164
#% 1190127
#% 1214641
#! Influence analysis and expert finding have received a great deal of attention in social networks. Most of existing works, however, aim to maximize influence based on communities structure in social networks. They ignored the location information, which often imply abundant information about individuals or communities. In this paper, we propose Info-Cluster, an innovative concept to describe how the information originated from a location cluster propagates in or between communities. According to this concept, we propose a framework for identifying the Info-Cluster in social networks, which uses both location information and communities structure. Taking the location information into consideration, we first adopt the K-Means algorithm to find location clusters. Next, we identify the communities for the whole network data set. Given the location clusters and communities, we present the information propagation based Info-Cluster detection algorithm. Experiments on Renren networks show that our method can reveal many meaningful results about regional influence analysis.

#index 1607943
#* Utilizing past relations and user similarities in a social matching system
#@ Richi Nayak
#t 2011
#c 3
#% 338577
#% 452563
#% 1379672
#! Due to the higher expectation more and more online matching companies adopt recommender systems with content-based, collaborative filtering or hybrid techniques. However, these techniques focus on users explicit contact behaviors but ignore the implicit relationship among users in the network. This paper proposes a personalized social matching system for generating potential partners' recommendations that not only exploits users' explicit information but also utilizes implicit relationships among users. The proposed system is evaluated on the dataset collected from an online dating network. Empirical analysis shows the recommendation success rate has increased to 31% as compared to the baseline success rate of 19%.

#index 1607944
#* On sampling type distribution from heterogeneous social networks
#@ Jhao-Yin Li;Mi-Yen Yeh
#t 2011
#c 3
#% 479969
#% 824711
#% 881526
#% 1063501
#% 1063512
#% 1176911
#% 1254841
#% 1282000
#% 1717175
#! Social network analysis has drawn the attention of many researchers recently. As the advance of communication technologies, the scale of social networks grows rapidly. To capture the characteristics of very large social networks, graph sampling is an important approach that does not require visiting the entire network. Prior studies on graph sampling focused on preserving the properties such as degree distribution and clustering coefficient of a homogeneous graph, where each node and edge is treated equally. However, a node in a social network usually has its own attribute indicating a specific group membership or type. For example, people are of different races or nationalities. The link between individuals from the same or different types can thus be classified to intra- and inter-connections. Therefore, it is important whether a sampling method can preserve the node and link type distribution of the heterogeneous social networks. In this paper, we formally address this issue. Moreover, we apply five algorithms to the real Twitter data sets to evaluate their performance. The results show that respondent-driven sampling works well even if the sample sizes are small while random node sampling works best only under large sample sizes.

#index 1607945
#* Ant colony optimization with Markov random walk for community detection in graphs
#@ Di Jin;Dayou Liu;Bo Yang;Carlos Baquero;Dongxiao He
#t 2011
#c 3
#% 722902
#% 1013626
#% 1214721
#% 1520706
#! Network clustering problem (NCP) is the problem associated to the detection of network community structures. Building on Markov random walks we address this problem with a new ant colony optimization strategy, named as ACOMRW, which improves prior results on the NCP problem and does not require knowledge of the number of communities present on a given network. The framework of ant colony optimization is taken as the basic framework in the ACOMRWalgorithm. At each iteration, a Markov random walk model is taken as heuristic rule; all of the ants' local solutions are aggregated to a global one through clustering ensemble, which then will be used to update a pheromone matrix. The strategy relies on the progressive strengthening of within-community links and the weakening of between-community links. Gradually this converges to a solution where the underlying community structure of the complex network will become clearly visible. The performance of algorithm ACOMRW was tested on a set of benchmark computer-generated networks, and as well on real-world network data sets. Experimental results confirm the validity and improvements met by this approach.

#index 1607946
#* Faster and parameter-free discord search in quasi-periodic time series
#@ Wei Luo;Marcus Gallagher
#t 2011
#c 3
#% 757943
#% 844310
#% 1143811
#% 1501049
#% 1693294
#! Time series discord has proven to be a useful concept for time-series anomaly identification. To search for discords, various algorithms have been developed. Most of these algorithms rely on pre-building an index (such as a trie) for subsequences. Users of these algorithms are typically required to choose optimal values for word-length and/or alphabet-size parameters of the index, which are not intuitive. In this paper, we propose an algorithm to directly search for the top-K discords, without the requirement of building an index or tuning external parameters. The algorithm exploits quasi-periodicity present in many time series. For quasi-periodic time series, the algorithm gains significant speedup by reducing the number of calls to the distance function.

#index 1607947
#* INSIGHT: efficient and effective instance selection for time-series classification
#@ Krisztian Buza;Alexandros Nanopoulos;Lars Schmidt-Thieme
#t 2011
#c 3
#% 92533
#% 334059
#% 399763
#% 410276
#% 420136
#% 420138
#% 577221
#% 662750
#% 876074
#% 993965
#% 1127609
#% 1211798
#% 1406025
#% 1533886
#! Time-series classification is a widely examined data mining task with various scientific and industrial applications. Recent research in this domain has shown that the simple nearest-neighbor classifier using Dynamic Time Warping (DTW) as distance measure performs exceptionally well, in most cases outperforming more advanced classification algorithms. Instance selection is a commonly applied approach for improving efficiency of nearest-neighbor classifier with respect to classification time. This approach reduces the size of the training set by selecting the best representative instances and use only them during classification of new instances. In this paper, we introduce a novel instance selection method that exploits the hubness phenomenon in time-series data, which states that some few instances tend to be much more frequently nearest neighbors compared to the remaining instances. Based on hubness, we propose a framework for score-based instance selection, which is combined with a principled approach of selecting instances that optimize the coverage of training data. We discuss the theoretical considerations of casting the instance selection problem as a graph-coverage problem and analyze the resulting complexity. We experimentally compare the proposed method, denoted as INSIGHT, against FastAWARD, a state-of-the-art instance selection method for time series. Our results indicate substantial improvements in terms of classification accuracy and drastic reduction (orders of magnitude) in execution times.

#index 1607948
#* Multiple time-series prediction through multiple time-series relationships profiling and clustered recurring trends
#@ Harya Widiputra;Russel Pears;Nikola Kasabov
#t 2011
#c 3
#% 405645
#% 642772
#% 659939
#% 943440
#% 1081545
#% 1336657
#! Time-series prediction has been very well researched by both the Statistical and Data Mining communities. However the multiple time-series problem of predicting simultaneous movement of a collection of time sensitive variables which are related to each other has received much less attention. Strong relationships between variables suggests that trajectories of given variables that are involved in the relationships can be improved by including the nature and strength of these relationships into a prediction model. The key challenge is to capture the dynamics of the relationships to reflect changes that take place continuously over time. In this research we propose a novel algorithm for extracting profiles of relationships through an evolving clustering method. We use a form of non-parametric regression analysis to generate predictions based on the profiles extracted and historical information from the past. Experimental results on a real-world climatic data reveal that the proposed algorithm outperforms well established methods of time-series prediction.

#index 1607949
#* Probabilistic feature extraction from multivariate time series using spatio-temporal constraints
#@ Michał Lewandowski;Dimitrios Makris;Jean-Christophe Nebel
#t 2011
#c 3
#% 138308
#% 493731
#% 770779
#% 876009
#% 883872
#% 983920
#% 1074007
#% 1149135
#% 1411729
#% 1495533
#% 1511125
#! A novel nonlinear probabilistic feature extraction method, called Spatio-Temporal Gaussian Process Latent Variable Model, is introduced to discover generalised and continuous low dimensional representation of multivariate time series data in the presence of stylistic variations. This is achieved by incorporating a new spatio-temporal constraining prior over latent spaces within the likelihood optimisation of Gaussian Process Latent Variable Models (GPLVM). As a result, the core pattern of multivariate time series is extracted, whereas a style variability is marginalised. We validate the method by qualitative comparison of different GPLVM variants with their proposed spatio-temporal versions. In addition we provide quantitative results on a classification application, i.e. view-invariant action recognition, where imposing spatio-temporal constraints is essential. Performance analysis reveals that our spatio-temporal framework outperforms the state of the art.

#index 1607950
#* Real-time change-point detection using sequentially discounting normalized maximum likelihood coding
#@ Yasuhiro Urabe;Kenji Yamanishi;Ryota Tomioka;Hiroki Iwai
#t 2011
#c 3
#% 280408
#% 280413
#% 577295
#% 863386
#% 989638
#% 1078626
#% 1214760
#% 1347878
#! We are concerned with the issue of real-time change-point detection in time series. This technology has recently received vast attentions in the area of data mining since it can be applied to a wide variety of important risk management issues such as the detection of failures of computer devices from computer performance data, the detection of masqueraders/ malicious executables from computer access logs, etc. In this paper we propose a new method of real-time change point detection employing the sequentially discounting normalized maximum likelihood coding (SDNML). Here the SDNML is a method for sequential data compression of a sequence, which we newly develop in this paper. It attains the least code length for the sequence and the effect of past data is gradually discounted as time goes on, hence the data compression can be done adaptively to non-stationary data sources. In our method, the SDNML is used to learn the mechanism of a time series, then a change-point score at each time is measured in terms of the SDNML code-length. We empirically demonstrate the significant superiority of our method over existing methods, such as the predictive-coding method and the hypothesis testingmethod, in terms of detection accuracy and computational efficiency for artificial data sets. We further apply our method into real security issues called malware detection. We empirically demonstrate that our method is able to detect unseen security incidents at significantly early stages.

#index 1607951
#* Compression for anti-adversarial learning
#@ Yan Zhou;Meador Inge;Murat Kantarcioglu
#t 2011
#c 3
#% 38374
#% 193743
#% 393450
#% 646517
#% 860996
#% 961230
#% 1074376
#% 1129341
#! We investigate the susceptibility of compression-based learning algorithms to adversarial attacks. We demonstrate that compression-based algorithms are surprisingly resilient to carefully plotted attacks that can easily devastate standard learning algorithms. In the worst case where we assume the adversary has a full knowledge of training data, compression-based algorithms failed as expected. We tackle the worst case with a proposal of a new technique that analyzes subsequences strategically extracted from given data. We achieved near-zero performance loss in the worst case in the domain of spam filtering.

#index 1607952
#* Mining sequential patterns from probabilistic databases
#@ Muhammad Muzammal;Rajeev Raman
#t 2011
#c 3
#% 329537
#% 338609
#% 397383
#% 459006
#% 463903
#% 577256
#% 579314
#% 727919
#% 778732
#% 810120
#% 1063520
#% 1063531
#% 1179162
#% 1206706
#% 1206893
#% 1214616
#% 1214624
#% 1214633
#% 1291119
#% 1393138
#% 1411036
#% 1546619
#! We consider sequential pattern mining in situations where there is uncertainty about which source an event is associated with. We model this in the probabilistic database framework and consider the problem of enumerating all sequences whose expected support is sufficiently large. Unlike frequent itemset mining in probabilistic databases [C. Aggarwal et al. KDD'09; Chui et al., PAKDD'07; Chui and Kao, PAKDD'08], we use dynamic programming (DP) to compute the probability that a source supports a sequence, and show that this suffices to compute the expected support of a sequential pattern. Next, we embed this DP algorithm into candidate generate-and-test approaches, and explore the pattern lattice both in a breadth-first (similar to GSP) and a depth-first (similar to SPAM) manner. We propose optimizations for efficiently computing the frequent 1-sequences, for re-using previously-computed results through incremental support computation, and for elmiminating candidate sequences without computing their support via probabilistic pruning. Preliminary experiments show that our optimizations are effective in improving the CPU cost.

#index 1607953
#* Large scale real-life action recognition using conditional random fields with stochastic training
#@ Xu Sun;Hisashi Kashima;Ryota Tomioka;Naonori Ueda
#t 2011
#c 3
#% 274189
#% 464434
#% 576218
#% 854636
#% 983808
#% 1089790
#% 1117688
#% 1226766
#% 1270128
#% 1535467
#% 1778807
#! Action recognition is usually studied with limited lab settings and a small data set. Traditional lab settings assume that the start and the end of each action are known. However, this is not true for the real-life activity recognition, where different actions are present in a continuous temporal sequence, with their boundaries unknown to the recognizer. Also, unlike previous attempts, our study is based on a large-scale data set collected from real world activities. The novelty of this paper is twofold: (1) Large-scale non-boundary action recognition; (2) The first application of the averaged stochastic gradient training with feedback (ASF) to conditional random fields. We find the ASF training method outperforms a variety of traditional training methods in this task.

#index 1607954
#* Packing alignment: alignment for sequences of various length events
#@ Atsuyoshi Nakamura;Mineichi Kudo
#t 2011
#c 3
#% 321332
#! We study an alignment called a packing alignment that is an alignment for sequences of various length events like musical notes. One event in a packing alignment can have a number of consecutive opposing events unless the total length of them exceeds the length of that one event. Instead of using a score function that depends on event length, which was studied by Mongeau and Sankoff [5], packing alignment deals with event lengths explicitly using a simple score function. This makes the problem clearer as an optimization problem. Packing alignment can be calculated efficiently using dynamic programming. As an application of packing alignment, we conducted experiments on frequent approximate pattern extraction from MIDI files of famous musical variations. The patterns and occurrences extracted from the variations using packing alignment have more appropriate boundaries than those using conventional string alignments from the viewpoints of the repetition structure of the variations.

#index 1607955
#* Multiple distribution data description learning algorithm for novelty detection
#@ Trung Le;Dat Tran;Wanli Ma;Dharmendra Sharma
#t 2011
#c 3
#% 169368
#% 190581
#% 425031
#% 466595
#% 732387
#% 961162
#% 1051463
#% 1286826
#% 1301459
#% 1318804
#% 1397673
#! Current data description learning methods for novelty detection such as support vector data description and small sphere with large margin construct a spherically shaped boundary around a normal data set to separate this set from abnormal data. The volume of this sphere is minimized to reduce the chance of accepting abnormal data. However those learning methods do not guarantee that the single spherically shaped boundary can best describe the normal data set if there exist some distinctive data distributions in this set. We propose in this paper a new data description learning method that constructs a set of spherically shaped boundaries to provide a better data description to the normal data set. An optimisation problem is proposed and solving this problem results in an iterative learning algorithm to determine the set of spherically shaped boundaries. We prove that the classification error will be reduced after each iteration in our learning method. Experimental results on 28 well-known data sets show that the proposed method provides lower classification error rates.

#index 1607956
#* RADAR: rare category detection via computation of boundary degree
#@ Hao Huang;Qinming He;Jiangfeng He;Lianhang Ma
#t 2011
#c 3
#% 849810
#% 915233
#% 1176862
#% 1214706
#! Rare category detection is an open challenge for active learning. It can help select anomalies and then query their class labels with human experts. Compared with traditional anomaly detection, this task does not focus on finding individual and isolated instances. Instead, it selects interesting and useful anomalies from small compact clusters. Furthermore, the goal of rare category detection is to request as few queries as possible to find at least one representative data point from each rare class. Previous research works can be divided into three major groups, model-based, density-based and clustering-based methods. Performance of these approaches is affected by the local densities of the rare classes. In this paper, we develop a density insensitive method for rare category detection called RADAR. It makes use of reverse k-nearest neighbors to measure the boundary degree of each data point, and then selects examples with high boundary degree for the class-label querying. Experimental results on both synthetic and real-world data sets demonstrate the effectiveness of our algorithm.

#index 1607957
#* RKOF: robust kernel-based local outlier detection
#@ Jun Gao;Weiming Hu;Zhongfei Zhang;Xiaoqin Zhang;Ou Wu
#t 2011
#c 3
#% 34077
#% 209021
#% 235377
#% 300136
#% 321455
#% 342625
#% 501988
#% 785358
#% 823340
#% 881506
#% 1083710
#% 1098979
#% 1511054
#! Outlier detection is an important and attractive problem in knowledge discovery in large data sets. The majority of the recent work in outlier detection follow the framework of Local Outlier Factor (LOF), which is based on the density estimate theory. However, LOF has two disadvantages that restrict its performance in outlier detection. First, the local density estimate of LOF is not accurate enough to detect outliers in the complex and large databases. Second, the performance of LOF depends on the parameter k that determines the scale of the local neighborhood. Our approach adopts the variable kernel density estimate to address the first disadvantage and the weighted neighborhood density estimate to improve the robustness to the variations of the parameter k, while keeping the same framework with LOF. Besides, we propose a novel kernel function named the Volcano kernel, which is more suitable for outlier detection. Experiments on several synthetic and real data sets demonstrate that our approach not only substantially increases the detection performance, but also is relatively scalable in large data sets in comparison to the state-of-the-art outlier detection methods.

#index 1607958
#* Chinese categorization and novelty mining
#@ Flora S. Tsai;Yi Zhang
#t 2011
#c 3
#% 643014
#% 848153
#% 855172
#% 879584
#% 1172631
#% 1195951
#% 1385553
#% 1385826
#% 1392388
#% 1436340
#% 1436411
#% 1488002
#% 1521739
#% 1526149
#% 1532150
#% 1702202
#! The categorization and novelty mining of chronologically ordered documents is an important data mining problem. This paper focuses on the entire process of Chinese novelty mining, from preprocessing and categorization to the actual detection of novel information, which has rarely been studied. First, preprocessing techniques for detecting novel Chinese text are discussed and compared. Next, we investigate the categorization and novelty mining performance between English and Chinese sentences and also discuss the novelty mining performance based on the retrieval results. Moreover, we propose new novelty mining evaluation measures, Novelty-Precision, Novelty-Recall, Novelty-F Score, and Sensitivity, which measures the sensitivity of the novelty mining system to the incorrectly classified sentences. The results indicate that Chinese novelty mining at the sentence level is similar to English if the sentences are perfectly categorized. Using our new evaluation measures of Novelty-Precision, Novelty-Recall, Novelty-F Score, and Sensitivity, we can more fairly assess how the performance of novelty mining is influenced by the retrieval results.

#index 1607959
#* Finding rare classes: adapting generative and discriminative models in active learning
#@ Timothy M. Hospedales;Shaogang Gong;Tao Xiang
#t 2011
#c 3
#% 251145
#% 464268
#% 466887
#% 763705
#% 771846
#% 900512
#% 1019070
#% 1081614
#% 1100053
#% 1183431
#% 1246173
#% 1403297
#! Discovering rare categories and classifying new instances of them is an important data mining issue in many fields, but fully supervised learning of a rare class classifier is prohibitively costly. There has therefore been increasing interest both in active discovery: to identify new classes quickly, and active learning: to train classifiers with minimal supervision. Very few studies have attempted to jointly solve these two inter-related tasks which occur together in practice. Optimizing both rare class discovery and classification simultaneously with active learning is challenging because discovery and classification have conflicting requirements in query criteria. In this paper we address these issues with two contributions: a unified active learning model to jointly discover new categories and learn to classify them; and a classifier combination algorithm that switches generative and discriminative classifiers as learning progresses. Extensive evaluation on several standard datasets demonstrates the superiority of our approach over existing methods.

#index 1607960
#* Margin-based over-sampling method for learning from imbalanced datasets
#@ Xiannian Fan;Ke Tang;Thomas Weise
#t 2011
#c 3
#% 235377
#% 260149
#% 345754
#% 375017
#% 551723
#% 765520
#% 765522
#% 765525
#% 770774
#% 843876
#% 1246173
#% 1271973
#% 1301405
#% 1378224
#% 1708211
#! Learning from imbalanced datasets has drawn more and more attentions from both theoretical and practical aspects. Oversampling is a popular and simple method for imbalanced learning. In this paper, we show that there is an inherently potential risk associated with the over-sampling algorithms in terms of the large margin principle. Then we propose a new synthetic over sampling method, named Margin-guided Synthetic Over-sampling (MSYN), to reduce this risk. The MSYN improves learning with respect to the data distributions guided by the margin-based rule. Empirical study verities the efficacy of MSYN.

#index 1607961
#* Improving k nearest neighbor with exemplar generalization for imbalanced classification
#@ Yuxuan Li;Xiuzhen Zhang
#t 2011
#c 3
#% 92533
#% 136350
#% 246243
#% 260149
#% 280437
#% 307100
#% 331909
#% 420064
#% 466086
#% 765520
#% 926881
#% 961291
#% 1271973
#% 1273395
#% 1289281
#% 1378224
#! A k nearest neighbor (kNN) classifier classifies a query instance to the most frequent class of its k nearest neighbors in the training instance space. For imbalanced class distribution, a query instance is often overwhelmed by majority class instances in its neighborhood and likely to be classified to the majority class. We propose to identify exemplar minority class training instances and generalize them to Gaussian balls as concepts for the minority class. Our k Exemplar-based Nearest Neighbor (kENN) classifier is therefore more sensitive to the minority class. Extensive experiments show that kENN significantly improves the performance of kNN and also outperforms popular re-sampling and costsensitive learning strategies for imbalanced classification.

#index 1607962
#* Sample subset optimization for classifying imbalanced biological data
#@ Pengyi Yang;Zili Zhang;Bing B. Zhou;Albert Y. Zomaya
#t 2011
#c 3
#% 209021
#% 471428
#% 765519
#% 765520
#% 889273
#% 950260
#% 998622
#% 1073923
#% 1190817
#% 1271973
#% 1314745
#% 1362546
#% 1669884
#% 1784199
#! Data in many biological problems are often compounded by imbalanced class distribution. That is, the positive examples may largely outnumbered by the negative examples. Many classification algorithms such as support vector machine (SVM) are sensitive to data with imbalanced class distribution, and result in a suboptimal classification. It is desirable to compensate the imbalance effect in model training for more accurate classification. In this study, we propose a sample subset optimization technique for classifying biological data with moderate and extremely high imbalanced class distributions. By using this optimization technique with an ensemble of SVMs, we build multiple roughly balanced SVM base classifiers, each trained on an optimized sample subset. The experimental results demonstrate that the ensemble of SVMs created by our sample subset optimization technique can achieve higher area under the ROC curve (AUC) value than popular sampling approaches such as random over-/under-sampling; SMOTE sampling, and those in widely used ensemble approaches such as bagging and boosting.

#index 1607963
#* Class confidence weighted kNN algorithms for imbalanced data sets
#@ Wei Liu;Sanjay Chawla
#t 2011
#c 3
#% 129987
#% 345754
#% 478128
#% 871053
#% 875974
#% 940368
#% 940500
#% 961134
#% 1023380
#% 1108850
#% 1195987
#% 1215917
#% 1232015
#% 1271973
#% 1318666
#% 1710563
#! In this paper, a novel k-nearest neighbors (kNN) weighting strategy is proposed for handling the problem of class imbalance. When dealing with highly imbalanced data, a salient drawback of existing kNN algorithms is that the class with more frequent samples tends to dominate the neighborhood of a test instance in spite of distance measurements, which leads to suboptimal classification performance on the minority class. To solve this problem, we propose CCW (class confidence weights) that uses the probability of attribute values given class labels to weight prototypes in kNN. The main advantage of CCW is that it is able to correct the inherent bias to majority class in existing kNN algorithms on any distance measurement. Theoretical analysis and comprehensive experiments confirm our claims.

#index 1607964
#* Multi-agent based classification using argumentation from experience
#@ Maya Wardeh;Frans Coenen;Trevor Bench-Capon;Adam Wyner
#t 2011
#c 3
#% 209021
#% 300120
#% 312728
#% 424997
#% 458623
#% 551723
#% 844362
#% 998622
#% 1113098
#% 1144401
#% 1217696
#% 1222460
#% 1245907
#% 1279286
#% 1289281
#% 1301004
#% 1396284
#% 1411087
#% 1486487
#% 1729251
#! An approach to multi-agent classification, using an Argumentation from Experience paradigm is describe, whereby individual agents argue for a given example to be classified with a particular label according to their local data. Arguments are expressed in the form of classification rules which are generated dynamically. The advocated argumentation process has been implemented in the PISA multi-agent framework, which is also described. Experiments indicate that the operation of PISA is comparable with other classification approaches and that it can be utilised for Ordinal Classification and Imbalanced Class problems.

#index 1607965
#* Agent-based subspace clustering
#@ Chao Luo;Yanchang Zhao;Dan Luo;Chengqi Zhang;Wei Cao
#t 2011
#c 3
#% 248792
#% 273891
#% 280417
#% 397384
#% 643178
#% 1064330
#% 1245907
#% 1328215
#% 1442149
#! This paper presents an agent-based algorithm for discovering subspace clusters in high dimensional data. Each data object is represented by an agent, and the agents move from one local environment to another to find optimal clusters in subspaces. Heuristic rules and objective functions are defined to guide the movements of agents, so that similar agents(data objects) go to one group. The experimental results show that our proposed agent-based subspace clustering algorithm performs better than existing subspace clustering methods on both F1 measure and Entropy. The running time of our algorithm is scalable with the size and dimensionality of data. Furthermore, an application in stock market surveillance demonstrates its effectiveness in real world applications.

#index 1607966
#* Evaluating pattern set mining strategies in a constraint programming framework
#@ Tias Guns;Siegfried Nijssen;Luc De Raedt
#t 2011
#c 3
#% 180945
#% 449508
#% 449566
#% 1015933
#% 1083646
#% 1214686
#% 1493607
#% 1663669
#% 1673557
#! The pattern mining community has shifted its attention from local pattern mining to pattern set mining. The task of pattern set mining is concerned with finding a set of patterns that satisfies a set of constraints and often also scores best w.r.t. an optimisation criteria. Furthermore, while in local pattern mining the constraints are imposed at the level of individual patterns, in pattern set mining they are also concerned with the overall set of patterns. A wide variety of different pattern set mining techniques is available in literature. The key contribution of this paper is that it studies, compares and evaluates such search strategies for pattern set mining. The investigation employs concept-learning as a benchmark for pattern set mining and employs a constraint programming framework in which key components of pattern set mining are formulated and implemented. The study leads to novel insights into the strong and weak points of different pattern set mining strategies.

#index 1607967
#* Asking generalized queries with minimum cost
#@ Jun Du;Charles X. Ling
#t 2011
#c 3
#% 116165
#% 464268
#% 722797
#% 763705
#% 1272282
#% 1274894
#% 1289639
#% 1301004
#% 1318613
#! Previous works of active learning usually only ask specific queries. A more natural way is to ask generalized queries with don'tcare features. As each of such generalized queries can often represent a set of specific ones, the answers are usually more helpful in speeding up the learning process. However, despite of such advantages of the generalized queries, more expertise (or effort) is usually required for the oracle to provide accurate answers in real-world situations. Therefore, in this paper, we make a more realistic assumption that, the more general a query is, the higher querying cost it causes. This consequently yields a trade-off that, asking generalized queries can speed up the leaning, but usually with high cost; whereas, asking specific queries is much cheaper (with low cost), but the learning process might be slowed down. To resolve this issue, we propose two novel active learning algorithms for two scenarios: one to balance the predictive accuracy and the querying cost; and the other to minimize the total cost of misclassification and querying. We demonstrate that our new methods can significantly outperform the existing active learning algorithms in both of these two scenarios.

#index 1607968
#* Ranking individuals and groups by influence propagation
#@ Pei Li;Jeffrey Xu Yu;Hongyan Liu;Jun He;Xiaoyong Du
#t 2011
#c 3
#% 190611
#% 348173
#% 729923
#% 754098
#% 869641
#% 879603
#% 1016177
#% 1133030
#% 1190058
#% 1200878
#! Ranking the centrality of a node within a graph is a fundamental problem in network analysis. Traditional centrality measures based on degree, betweenness, or closeness miss to capture the structural context of a node, which is caught by eigenvector centrality (EVC) measures. As a variant of EVC, PageRank is effective to model and measure the importance of web pages in the web graph, but it is problematic to apply it to other link-based ranking problems. In this paper, we propose a new influence propagation model to describe the propagation of pre-defined importance over individual nodes and groups accompanied with random walk paths, and we propose new IPRank algorithm for ranking both individuals and groups. We also allow users to define specific decay functions that provide flexibility to measure link-based centrality on different kinds of networks. We conducted testing using synthetic and real datasets, and experimental results show the effectiveness of our method.

#index 1607969
#* Dynamic ordering-based search algorithm for markov blanket discovery
#@ Yifeng Zeng;Xian He;Yanping Xiang;Hua Mao
#t 2011
#c 3
#% 44876
#% 729990
#% 800408
#% 844415
#% 878207
#% 893460
#% 977231
#% 1318683
#% 1411067
#% 1412723
#! Markov blanket discovery plays an important role in both Bayesian network induction and feature selection for classification tasks. In this paper, we propose the Dynamic Ordering-based Search algorithm (DOS) for learning a Markov blanket of a domain variable from statistical conditional independence tests on data. The new algorithm orders conditional independence tests and updates the ordering immediately after a test is completed. Meanwhile, the algorithm exploits the known independence to avoid unnecessary tests by reducing the set of candidate variables. This results in both efficiency and reliability advantages over the existing algorithms. We theoretically analyze the algorithm on its correctness and empirically compare it with the state-of-the-art algorithm. Experiments show that the new algorithm achieves computational savings of around 40% on multiple benchmarks while securing similar or even better accuracy.

#index 1607970
#* Mining association rules for label ranking
#@ Cláudio Rebelo De Sá;Carlos Soares;Alípio Mário Jorge;Paulo Azevedo;Joaquim Costa
#t 2011
#c 3
#% 199538
#% 201894
#% 227917
#% 420112
#% 431102
#% 458687
#% 481290
#% 543918
#% 1093383
#% 1211710
#% 1447583
#% 1529063
#! Recently, a number of learning algorithms have been adapted for label ranking, including instance-based and tree-based methods. In this paper, we propose an adaptation of association rules for label ranking. The adaptation, which is illustrated in this work with APRIORI Algorithm, essentially consists of using variations of the support and confidence measures based on ranking similarity functions that are suitable for label ranking. We also adapt the method to make a prediction from the possibly conflicting consequents of the rules that apply to an example. Despite having made our adaptation from a very simple variant of association rules for classification, the results clearly show that the method is making valid predictions. Additionally, they show that it competes well with state-of-the-art label ranking algorithms.

#index 1607971
#* Tracing evolving clusters by subspace and value similarity
#@ Stephan Günnemann;Hardy Kremer;Charlotte Laufkötter;Thomas Seidl
#t 2011
#c 3
#% 248792
#% 280416
#% 397384
#% 659971
#% 727868
#% 769946
#% 800176
#% 881538
#% 1015261
#% 1016200
#% 1159172
#% 1165480
#% 1200861
#% 1328215
#% 1720762
#! Cluster tracing algorithms are used to mine temporal evolutions of clusters. Generally, clusters represent groups of objects with similar values. In a temporal context like tracing, similar values correspond to similar behavior in one snapshot in time. Each cluster can be interpreted as a behavior type and cluster tracing corresponds to tracking similar behaviors over time. Existing tracing approaches are designed for datasets satisfying two specific conditions: The clusters appear in all attributes, i.e. fullspace clusters, and the data objects have unique identifiers. These identifiers are used for tracking clusters by measuring the number of objects two clusters have in common, i.e. clusters are traced based on similar object sets. These conditions, however, are strict: First, in complex data, clusters are often hidden in individual subsets of the dimensions. Second, mapping clusters based on similar objects sets does not reflect the idea of tracing similar behavior types over time, because similar behavior can even be represented by clusters having no objects in common. A tracing method based on similar object values is needed. In this paper, we introduce a novel approach that traces subspace clusters based on object value similarity. Neither subspace tracing nor tracing by object value similarity has been done before.

#index 1607972
#* An IFS-based similarity measure to index electroencephalograms
#@ Ghita Berrada;Ander De Keijzer
#t 2011
#c 3
#% 52018
#% 310537
#% 466507
#% 832636
#% 1005452
#% 1161984
#% 1248752
#% 1786928
#! EEG is a very useful neurological diagnosis tool, inasmuch as the EEG exam is easy to perform and relatively cheap. However, it generates large amounts of data, not easily interpreted by a clinician. Several methods have been tried to automate the interpretation of EEG recordings. However, their results are hard to compare since they are tested on different datasets. This means a benchmark database of EEG data is required. However, for such a database to be useful, we have to solve the problem of retrieving information from the stored EEGs without having to tag each and every EEG sequence stored in the database (which can be a very time-consuming and error-prone process). In this paper, we present a similarity measure, based on iterated function systems, to index EEGs.

#index 1607973
#* DISC: data-intensive similarity measure for categorical data
#@ Aditya Desai;Himanshu Singh;Vikram Pudi
#t 2011
#c 3
#% 29587
#% 36672
#% 129980
#% 138168
#% 169651
#% 186084
#% 280419
#% 375388
#% 420081
#% 448726
#% 478120
#% 570885
#% 631985
#% 926881
#% 1272304
#% 1390190
#! The concept of similarity is fundamentally important in almost every scientific field. Clustering, distance-based outlier detection, classification, regression and search are major data mining techniques which compute the similarities between instances and hence the choice of a particular similarity measure can turn out to be a major cause of success or failure of the algorithm. The notion of similarity or distance for categorical data is not as straightforward as for continuous data and hence, is a major challenge. This is due to the fact that different values taken by a categorical attribute are not inherently ordered and hence a notion of direct comparison between two categorical values is not possible. In addition, the notion of similarity can differ depending on the particular domain, dataset, or task at hand. In this paper we present a new similarity measure for categorical data DISC - Data-Intensive Similarity Measure for Categorical Data. DISC captures the semantics of the data without any help from domain expert for defining the similarity. In addition to these, it is generic and simple to implement. These desirable features make it a very attractive alternative to existing approaches. Our experimental study compares it with 14 other similarity measures on 24 standard real datasets, out of which 12 are used for classification and 12 for regression, and shows that it is more accurate than all its competitors.

#index 1607974
#* ListOPT: learning to optimize for XML ranking
#@ Ning Gao;Zhi-Hong Deng;Hang Yu;Jia-Jian Jiang
#t 2011
#c 3
#% 290830
#% 309095
#% 375017
#% 387427
#% 642993
#% 734915
#% 766414
#% 824703
#% 840846
#% 879588
#% 907546
#% 983820
#% 1039843
#% 1074021
#% 1263233
#% 1489429
#! Many machine learning classification technologies such as boosting, support vector machine or neural networks have been applied to the ranking problem in information retrieval. However, since the purpose of these learning-torank methods is to directly acquire the sorted results based on the features of documents, they are unable to combine and utilize the existing ranking methods proven to be effective such as BM25 and PageRank. To solve this defect, we conducted a study on learning-to-optimize, which is to construct a learning model or method for optimizing the free parameters in ranking functions. This paper proposes a listwise learning-to-optimize process ListOPT and introduces three alternative differentiable query-level loss functions. The experimental results on the XML dataset of Wikipedia English show that these approaches can be successfully applied to tuning the parameters used in an existing highly cited ranking function BM25. Furthermore, we found that the formulas with optimized parameters indeed improve the effectiveness compared with the original ones.

#index 1607975
#* Item set mining based on cover similarity
#@ Marc Segond;Christian Borgelt
#t 2011
#c 3
#% 300120
#% 338609
#% 481290
#% 729942
#! While in standard frequent item set mining one tries to find item sets the support of which exceeds a user-specified threshold (minimum support) in a database of transactions, we strive to find item sets for which the similarity of their covers (that is, the sets of transactions containing them) exceeds a user-specified threshold. Starting from the generalized Jaccard index we extend our approach to a total of twelve specific similarity measures and a generalized form. We present an efficient mining algorithm that is inspired by the well-known Eclat algorithm and its improvements. By reporting experiments on several benchmark data sets we demonstrate that the runtime penalty incurred by the more complex (but also more informative) item set assessment is bearable and that the approach yields high quality and more useful item sets.

#index 1607976
#* Learning to advertise: how many ads are enough?
#@ Bo Wang;Zhaonan Li;Jie Tang;Kuo Zhang;Songcan Chen;Liyun Ru
#t 2011
#c 3
#% 730041
#% 956546
#% 956552
#% 1035578
#% 1055694
#% 1074092
#% 1074101
#% 1130909
#% 1190055
#% 1190056
#% 1190057
#% 1190161
#% 1214642
#% 1214702
#% 1227620
#% 1227642
#% 1227651
#% 1292566
#% 1355048
#% 1399955
#! Sponsored advertisement(ad) has already become the major source of revenue for most popular search engines. One fundamental challenge facing all search engines is how to achieve a balance between the number of displayed ads and the potential annoyance to the users. Displaying more ads would improve the chance for the user clicking an ad. However, when the ads are not really relevant to the users' interests, displaying more may annoy them and even "train" them to ignore ads. In this paper, we study an interesting problem that how many ads should be displayed for a given query. We use statistics on real ads click-through data to show the existence of the problem and the possibility to predict the ideal number. There are two main observations: 1) when the click entropy of a query exceeds a threshold, the CTR of that query will be very near zero; 2) the threshold of click entropy can be automatically determined when the number of removed ads is given. Further, we propose a learning approach to rank the ads and to predict the number of displayed ads for a given query. The experimental results on a commercial search engine dataset validate the effectiveness of the proposed approach.

#index 1607977
#* TeamSkill: modeling team chemistry in online multi-player games
#@ Colin DeLong;Nishith Pathak;Kendrick Erickson;Eric Perrino;Kyong Shim;Jaideep Srivastava
#t 2011
#c 3
#% 1100158
#% 1105563
#! In this paper, we introduce a framework for modeling elements of "team chemistry" in the skill assessment process using the performances of subsets of teams and four approaches which make use of this framework to estimate the collective skill of a team. A new dataset based on the Xbox 360 video game, Halo 3, is used for evaluation. The dataset is comprised of online scrimmage and tournament games played between professional Halo 3 teams competing in the Major League Gaming (MLG) Pro Circuit during the 2008 and 2009 seasons. Using the Elo, Glicko, and TrueSkill rating systems as "base learners" for our approaches, we predict the outcomes of games based on subsets of the overall dataset in order to investigate their performance given differing game histories and playing environments. We find that Glicko and TrueSkill benefit greatly from our approaches (TeamSkill-AllK-EV in particular), significantly boosting prediction accuracy in close games and improving performance overall, while Elo performs better without them. We also find that the ways in which each rating system handles skill variance largely determines whether or not it will benefit from our techniques.

#index 1607978
#* Learning the funding momentum of research projects
#@ Dan He;D. S. Parker
#t 2011
#c 3
#% 331608
#% 515363
#% 643520
#% 729943
#% 958156
#% 1214671
#% 1451184
#% 1860421
#! In developing grant proposals for funding agencies like NIH or NSF, it is often important to determine whether a research topic is gaining momentum -- where by 'momentum' we mean the rate of change of a certain measure such as popularity, impact or significance -- to evaluate whether the topic is more likely to receive grants. Analysis of data about past grant awards reveals interesting patterns about successful grant topics, suggesting it is sometimes possible to measure the degree to which a given research topic has 'increasing momentum'. In this paper, we develop a framework for quantitative modeling of the funding momentum of a project, based on the momentum of the individual topics in the project. This momentum follows certain patterns that rise and fall in a predictable fashion. To our knowledge, this is the first attempt to quantify the momentum of research topics or projects.

#index 1607979
#* Local feature based tensor kernel for image manifold learning
#@ Yi Guo;Junbin Gao
#t 2011
#c 3
#% 186346
#% 188519
#% 266426
#% 393059
#% 443975
#% 560968
#% 635689
#% 829014
#% 829033
#% 1030865
#% 1038791
#% 1069012
#% 1117687
#% 1377375
#% 1377380
#% 1393856
#% 1734523
#! In this paper, we propose a tensor kernel on images which are described as set of local features and then apply a novel dimensionality reduction algorithm called Twin Kernel Embedding (TKE) [1] on it for images manifold learning. The local features of the images extracted by some feature extraction methods like SIFT [2] are represented as tuples in the form of coordinates and feature descriptor which are regarded as highly structured data. In [3], different kernels were used for intra and inter images similarity. This is problematic because different kernels refer to different feature spaces and hence they are representing different measures. This heterogeneity embedded in the kernel Gram matrix which was input to a dimensionality reduction algorithm has been transformed to the image embedding space and therefore led to unclear understanding of the embedding. We address this problem by introducing a tensor kernel which treats different sources of information in a uniform kernel framework. The kernel Gram matrix generated by tensor kernel is homogeneous, that is all elements are from the same measurement. Image manifold learned from this kernel is more meaningful. Experiments on image visualization are used to show the effectiveness of this method.

#index 1669870
#* Proceedings of the 10th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining
#@ Wee-Keong Ng;Masaru Kitsuregawa;Jianzhong Li;Kuiyu Chang
#t 2006
#c 3

#index 1669871
#* Protection or privacy? data mining and personal data
#@ David J. Hand
#t 2006
#c 3
#! In order to run countries and economies effectively, governments and governmental institutions need to collect and analyse vast amounts of personal data. Similarly, health service providers, security services, transport planners, and education authorities need to know a great deal about their clients. And, of course, commercial operations run more efficiently and can meet the needs of their customers more effectively the more they know about them. In general then, the more data these organisation have, the better. On the other hand, the more private data which is collated and disseminated, the more individuals are at risk of crimes such as identity theft and financial fraud, not to mention the simple invasion of privacy that such data collection represents. Most work in data mining has concentrated on the positive aspects of extracting useful information from large data sets. But as the technology and its use advances so more awareness of the potential downside is needed. In this paper I look at some of these issues. I examine how data mining tools and techniques are being used by governments and commercial operations to gain insight into individual behaviour. And I look at the concerns that such advances are bringing.

#index 1669872
#* Data mining for surveillance applications
#@ Bhavani M. Thuraisingham
#t 2006
#c 3
#! Dr. Bhavani M. Thuraisingham is an invited speaker for PAKDD 2006. She is a Professor at the Eric Jonsson School of Engineering and Computer Science, University of Texas at Dallas. She is also director of the Cyber Security Research Center and President of Bhavani Security Consulting.

#index 1669873
#* A multiclass classification method based on output design
#@ Qi Qiang;Qinming He
#t 2006
#c 3
#% 190581
#% 562950
#% 722901
#! Output coding is a general framework for solving multiclass categorization problems. Some researchers have presented the notion of continuous codes and methods for designing output codes. However these methods are time-consuming and expensive. This paper describes a new framework, which we call Strong-to-Weak-to-Strong (SWS). We transform a “strong” learning algorithm to a “weak” algorithm by decreasing its iterative numbers of optimization while preserving its other characteristics like geometric properties and then make use of the kernel trick for “weak” algorithms to work in high dimensional spaces, finally improve the performances. An inspiring experimental results show that this approach is competitive with the other methods.

#index 1669874
#* Regularized semi-supervised classification on manifold
#@ Lianwei Zhao;Siwei Luo;Yanchang Zhao;Lingzhi Liao;Zhihai Wang
#t 2006
#c 3
#% 252011
#% 565545
#% 593047
#% 829023
#% 961218
#! Semi-supervised learning gets estimated marginal distribution PX with a large number of unlabeled examples and then constrains the conditional probability p(y | x) with a few labeled examples. In this paper, we focus on a regularization approach for semi-supervised classification. The label information graph is first defined to keep the pairwise label relationship and can be incorporated with neighborhood graph which reflects the intrinsic geometry structure of PX. Then we propose a novel regularized semi-supervised classification algorithm, in which the regularization term is based on the modified Graph Laplacian. By redefining the Graph Laplacian, we can adjust and optimize the decision boundary using the labeled examples. The new algorithm combines the benefits of both unsupervised and supervised learning and can use unlabeled and labeled examples effectively. Encouraging experimental results are presented on both synthetic and real world datasets.

#index 1669875
#* Similarity-Based sparse feature extraction using local manifold learning
#@ Cheong Hee Park
#t 2006
#c 3
#% 92546
#% 317525
#% 729437
#! Feature extraction is an important preprocessing step which is encountered in many areas such as data mining, pattern recognition and scientific visualization. In this paper, a new method for sparse feature extraction using local manifold learning is proposed. Similarities in a neighborhood are first computed to explore local geometric structures, producing sparse feature representation. Based on the constructed similarity matrix, linear dimension reduction is applied to enhance similarities among the elements in the same class and extract optimal features for classification performances. Since it only computes similarities in a neighborhood, sparsity in the similarity matrix can give computational efficiency and memory savings. Experimental results demonstrate superior performances of the proposed method.

#index 1669876
#* Generalized conditional entropy and a metric splitting criterion for decision trees
#@ Dan A. Simovici;Szymon Jaroszewicz
#t 2006
#c 3
#% 92537
#% 785423
#% 835018
#% 926881
#% 1810871
#! We examine a new approach to building decision tree by introducing a geometric splitting criterion, based on the properties of a family of metrics on the space of partitions of a finite set. This criterion can be adapted to the characteristics of the data sets and the needs of the users and yields decision trees that have smaller sizes and fewer leaves than the trees built with standard methods and have comparable or better accuracy.

#index 1669877
#* RNBL-MN: a recursive naive bayes learner for sequence classification
#@ Dae-Ki Kang;Adrian Silvescu;Vasant Honavar
#t 2006
#c 3
#% 136350
#% 169719
#% 246832
#% 260001
#% 269218
#% 328946
#% 458259
#% 1705338
#! Naive Bayes (NB) classifier relies on the assumption that the instances in each class can be described by a single generative model. This assumption can be restrictive in many real world classification tasks. We describe RNBL-MN, which relaxes this assumption by constructing a tree of Naive Bayes classifiers for sequence classification, where each individual NB classifier in the tree is based on a multinomial event model (one for each class at each node in the tree). In our experiments on protein sequence and text classification tasks, we observe that RNBL-MN substantially outperforms NB classifier. Furthermore, our experiments show that RNBL-MN outperforms C4.5 decision tree learner (using tests on sequence composition statistics as the splitting criterion) and yields accuracies that are comparable to those of support vector machines (SVM) using similar information.

#index 1669878
#* TRIPPER: rule learning using taxonomies
#@ Flavian Vasile;Adrian Silvescu;Dae-Ki Kang;Vasant Honavar
#t 2006
#c 3
#% 169719
#% 785348
#% 785368
#! In many application domains, there is a need for learning algorithms that generate accurate as well as comprehensible classifiers. In this paper, we present TRIPPER – a rule induction algorithm that extends RIPPER, a widely used rule-learning algorithm. TRIPPER exploits knowledge in the form of taxonomies over the values of features used to describe data. We compare the performance of TRIPPER with that of RIPPER on benchmark datasets from the Reuters 21578 corpus using WordNet (a human-generated taxonomy) to guide rule induction by TRIPPER. Our experiments show that the rules generated by TRIPPER are generally more comprehensible and compact and in the large majority of cases at least as accurate as those generated by RIPPER.

#index 1669879
#* Using weighted nearest neighbor to benefit from unlabeled data
#@ Kurt Driessens;Peter Reutemann;Bernhard Pfahringer;Claire Leschi
#t 2006
#c 3
#% 252011
#% 311027
#% 317313
#% 466263
#% 565545
#% 792603
#% 842682
#% 1113093
#! The development of data-mining applications such as textclassification and molecular profiling has shown the need for machine learning algorithms that can benefit from both labeled and unlabeled data, where often the unlabeled examples greatly outnumber the labeled examples. In this paper we present a two-stage classifier that improves its predictive accuracy by making use of the available unlabeled data. It uses a weighted nearest neighbor classification algorithm using the combined example-sets as a knowledge base. The examples from the unlabeled set are “pre-labeled” by an initial classifier that is build using the limited available training data. By choosing appropriate weights for this pre-labeled data, the nearest neighbor classifier consistently improves on the original classifier.

#index 1669880
#* Constructive meta-level feature selection method based on method repositories
#@ Hidenao Abe;Takahira Yamaguchi
#t 2006
#c 3
#% 126894
#% 132938
#% 136350
#% 167633
#% 169659
#% 209021
#% 240233
#% 243728
#% 290482
#% 328946
#% 385564
#% 520224
#% 629619
#% 858692
#! Feature selection is one of key issues related with data pre-processing of classification task in a data mining process. Although many efforts have been done to improve typical feature selection algorithms (FSAs), such as filter methods and wrapper methods, it is hard for just one FSA to manage its performances to various datasets. To above problems, we propose another way to support feature selection procedure, constructing proper FSAs to each given dataset. Here is discussed constructive meta-level feature selection that re-constructs proper FSAs with a method repository every given datasets, de-composing representative FSAs into methods. After implementing the constructive meta-level feature selection system, we show how constructive meta-level feature selection goes well with 32 UCI common data sets, comparing with typical FSAs on their accuracies. As the result, our system shows the highest performance on accuracies and the availability to construct a proper FSA to each given data set automatically.

#index 1669881
#* Variable randomness in decision tree ensembles
#@ Fei Tony Liu;Kai Ming Ting
#t 2006
#c 3
#% 136350
#% 209021
#% 236656
#% 256615
#% 312727
#% 400847
#% 451221
#% 727888
#% 1273395
#% 1707849
#% 1860125
#! In this paper, we propose Max-diverse.α, which has a mechanism to control the degrees of randomness in decision tree ensembles. This control gives an ensemble the means to balance the two conflicting functions of a random random ensemble, i.e., the abilities to model non-axis-parallel boundary and eliminate irrelevant features. We find that this control is more sensitive to the one provided by Random Forests. Using progressive training errors, we are able to estimate an appropriate randomness for any given data prior to any predictive tasks. Experiment results show that Max-diverse.α is significantly better than Random Forests and Max-diverse Ensemble, and it is comparable to the state-of-the-art C5 boosting.

#index 1669882
#* Further improving emerging pattern based classifiers via bagging
#@ Hongjian Fan;Ming Fan;Kotagiri Ramamohanarao;Mengxu Liu
#t 2006
#c 3
#% 209021
#% 280409
#% 290482
#% 312728
#% 379331
#% 400847
#% 424997
#% 546047
#% 766670
#! Emerging Patterns (EPs) are those itemsets whose supports in one class are significantly higher than their supports in the other class. In this paper we investigate how to “bag” EP-based classifiers to build effective ensembles. We design a new scoring function based on growth rates to increase the diversity of individual classifiers and an effective scheme to combine the power of ensemble members. The experimental results confirm that our method of “bagging” EP-based classifiers can produce a more accurate and noise tolerant classifier ensemble.

#index 1669883
#* Improving on bagging with input smearing
#@ Eibe Frank;Bernhard Pfahringer
#t 2006
#c 3
#% 209021
#% 256615
#% 312727
#% 314785
#% 333881
#% 400847
#% 465755
#% 465764
#% 580511
#% 1271973
#! Bagging is an ensemble learning method that has proved to be a useful tool in the arsenal of machine learning practitioners. Commonly applied in conjunction with decision tree learners to build an ensemble of decision trees, it often leads to reduced errors in the predictions when compared to using a single tree. A single tree is built from a training set of size N. Bagging is based on the idea that, ideally, we would like to eliminate the variance due to a particular training set by combining trees built from all training sets of size N. However, in practice, only one training set is available, and bagging simulates this platonic method by sampling with replacement from the original training data to form new training sets. In this paper we pursue the idea of sampling from a kernel density estimator of the underlying distribution to form new training sets, in addition to sampling from the data itself. This can be viewed as “smearing out” the resampled training data to generate new datasets, and the amount of “smear” is controlled by a parameter. We show that the resulting method, called “input smearing”, can lead to improved results when compared to bagging. We present results for both classification and regression problems.

#index 1669884
#* Boosting prediction accuracy on imbalanced datasets with SVM ensembles
#@ Yang Liu;Aijun An;Xiangji Huang
#t 2006
#c 3
#% 260149
#% 307100
#% 420064
#% 420077
#% 765522
#% 785364
#% 998622
#% 1271973
#% 1272000
#! Learning from imbalanced datasets is inherently difficult due to lack of information about the minority class. In this paper, we study the performance of SVMs, which have gained great success in many real applications, in the imbalanced data context. Through empirical analysis, we show that SVMs suffer from biased decision boundaries, and that their prediction performance drops dramatically when the data is highly skewed. We propose to combine an integrated sampling technique with an ensemble of SVMs to improve the prediction performance. The integrated sampling technique combines both over-sampling and under-sampling techniques. Through empirical study, we show that our method outperforms individual SVMs as well as several other state-of-the-art classifiers.

#index 1669885
#* DeLi-Clu: boosting robustness, completeness, usability, and efficiency of hierarchical clustering by a closest pair ranking
#@ Elke Achtert;Christian Böhm;Peer Kröger
#t 2006
#c 3
#% 2115
#% 36672
#% 86950
#% 248804
#% 273890
#% 427199
#% 465000
#% 783643
#% 1016192
#! Hierarchical clustering algorithms, e.g. Single-Link or OPTICS compute the hierarchical clustering structure of data sets and visualize those structures by means of dendrograms and reachability plots. Both types of algorithms have their own drawbacks. Single-Link suffers from the well-known single-link effect and is not robust against noise objects. Furthermore, the interpretability of the resulting dendrogram deteriorates heavily with increasing database size. OPTICS overcomes these limitations by using a density estimator for data grouping and computing a reachability diagram which provides a clear presentation of the hierarchical clustering structure even for large data sets. However, it requires a non-intuitive parameter ε that has significant impact on the performance of the algorithm and the accuracy of the results. In this paper, we propose a novel and efficient k-nearest neighbor join closest-pair ranking algorithm to overcome the problems of both worlds. Our density-link clustering algorithm uses a similar density estimator for data grouping, but does not require the ε parameter of OPTICS and thus produces the optimal result w.r.t. accuracy. In addition, it provides a significant performance boosting over Single-Link and OPTICS. Our experiments show both, the improvement of accuracy as well as the efficiency acceleration of our method compared to Single-Link and OPTICS.

#index 1669886
#* Iterative clustering analysis for grouping missing data in gene expression profiles
#@ Dae-Won Kim;Bo-Yeong Kang
#t 2006
#c 3
#% 306424
#% 830857
#% 833718
#% 1781086
#! Clustering has been used as a popular technique for finding groups of genes that show similar expression patterns under multiple experimental conditions. Because a clustering method requires a complete data matrix as an input, we must estimate the missing values using an imputation method in the preprocessing step of clustering. However, a common limitation of these conventional approach is that once the estimates of missing values are fixed in the preprocessing step, they are not changed during subsequent process of clustering. Badly estimated missing values obtained in data preprocessing are likely to deteriorate the quality and reliability of clustering results. Thus, a new clustering method is required for improving missing values during iterative clustering process.

#index 1669887
#* An EM-Approach for clustering multi-instance objects
#@ Hans-Peter Kriegel;Alexey Pryakhin;Matthias Schubert
#t 2006
#c 3
#% 224755
#% 316709
#% 347711
#% 464633
#% 481281
#% 565537
#% 772128
#! In many data mining applications the data objects are modeled as sets of feature vectors or multi-instance objects. In this paper, we present an expectation maximization approach for clustering multi-instance objects. We therefore present a statistical process that models multi-instance objects. Furthermore, we present M-steps and E-steps for EM clustering and a method for finding a good initial model. In our experimental evaluation, we demonstrate that the new EM algorithm is capable to increase the cluster quality for three real world data sets compared to a k-medoid clustering.

#index 1669888
#* Mining maximal correlated member clusters in high dimensional database
#@ Lizheng Jiang;Dongqing Yang;Shiwei Tang;Xiuli Ma;Dehui Zhang
#t 2006
#c 3
#% 152934
#% 248791
#% 300120
#% 310494
#% 397382
#% 413550
#% 481290
#% 727882
#% 769909
#% 769919
#% 826265
#! Mining high dimensional data is an urgent problem of great practical importance. Although some data mining models such as frequent patterns and clusters have been proven to be very successful for analyzing very large data sets, they have some limitations. Frequent patterns are inadequate to describe the quantitative correlations among nominal members. Traditional cluster models ignore distances of some pairs of members, so a pair of members in one big cluster may be far away. As a combination and complementary of both techniques, we propose the Maximal-Correlated-Member-Cluster (MCMC) model in this paper. The MCMC model is based on a statistical measure reflecting the relationship of nominal variables, and every pair of members in one cluster satisfy unified constraints. Moreover, in order to improve algorithm's efficiency, we introduce pruning techniques to reduce the search space. In the first phase, a Tri-correlation inequation is used to eliminate unrelated member pairs, and in the second phase, an Inverse-Order-Enumeration-Tree (IOET) method is designed to share common computations. Experiments over both synthetic datasets and real life datasets are performed to examine our algorithm's performance. The results show that our algorithm has much higher efficiency than the naïve algorithm, and this model can discover meaningful correlated patterns in high dimensional database.

#index 1669889
#* Hierarchical clustering based on mathematical optimization
#@ Le Hoai Minh;Le Thi Hoai An;Pham Dinh Tao
#t 2006
#c 3
#% 296738
#% 416553
#% 422103
#% 555251
#% 720742
#% 1272283
#% 1827949
#! In this paper a novel optimization model for bilevel hierarchical clustering has been proposed. This is a hard nonconvex, nonsmooth optimization problem for which we investigate an efficient technique based on DC (Difference of Convex functions) programming and DCA (DC optimization Algorithm). Preliminary numerical results on some artificial and real-world databases show the efficiency and the superiority of this approach with respect to related existing methods.

#index 1669890
#* Clustering multi-represented objects using combination trees
#@ Elke Achtert;Hans-Peter Kriegel;Alexey Pryakhin;Matthias Schubert
#t 2006
#c 3
#% 273890
#% 643009
#% 785334
#! When clustering complex objects, there often exist various feature transformations and thus multiple object representations. To cluster multi-represented objects, dedicated data mining algorithms have been shown to achieve improved results. In this paper, we will introduce combination trees for describing arbitrary semantic relationships which can be used to extend the hierarchical clustering algorithm OPTICS to handle multi-represented data objects. To back up the usability of our proposed method, we present encouraging results on real world data sets.

#index 1669891
#* Parallel density-based clustering of complex objects
#@ Stefan Brecheisen;Hans-Peter Kriegel;Martin Pfeifle
#t 2006
#c 3
#% 273890
#% 296738
#% 587733
#% 587749
#% 654490
#% 785337
#! In many scientific, engineering or multimedia applications, complex distance functions are used to measure similarity accurately. Furthermore, there often exist simpler lower-bounding distance functions, which can be computed much more efficiently. In this paper, we will show how these simple distance functions can be used to parallelize the density-based clustering algorithm DBSCAN. First, the data is partitioned based on an enumeration calculated by the hierarchical clustering algorithm OPTICS, so that similar objects have adjacent enumeration values. We use the fact that clustering based on lower-bounding distance values conservatively approximates the exact clustering. By integrating the multi-step query processing paradigm directly into the clustering algorithms, the clustering on the slaves can be carried out very efficiently. Finally, we show that the different result sets computed by the various slaves can effectively and efficiently be merged to a global result by means of cluster connectivity graphs. In an experimental evaluation based on real-world test data sets, we demonstrate the benefits of our approach.

#index 1669892
#* Neighborhood density method for selecting initial cluster centers in k-means clustering
#@ Yunming Ye;Joshua Zhexue Huang;Xiaojun Chen;Shuigeng Zhou;Graham Williams;Xiaofei Xu
#t 2006
#c 3
#% 296738
#% 299535
#% 466083
#% 1650609
#% 1707822
#! This paper presents a new method for effectively selecting initial cluster centers in k-means clustering. This method identifies the high density neighborhoods from the data first and then selects the central points of the neighborhoods as initial centers. The recently published Neighborhood-Based Clustering (NBC) algorithm is used to search for high density neighborhoods. The new clustering algorithm NK-means integrates NBC into the k-means clustering process to improve the performance of the k-means algorithm while preserving the k-means efficiency. NBC is enhanced with a new cell-based neighborhood search method to accelerate the search for initial cluster centers. A merging method is employed to filter out insignificant initial centers to avoid too many clusters being generated. Experimental results on synthetic data sets have shown significant improvements in clustering accuracy in comparison with the random k-means and the refinement k-means algorithms.

#index 1669893
#* Uncertain data mining: an example in clustering location data
#@ Michael Chau;Reynold Cheng;Ben Kao;Jackey Ng
#t 2006
#c 3
#% 295512
#% 374537
#% 772835
#% 1016202
#! Data uncertainty is an inherent property in various applications due to reasons such as outdated sources or imprecise measurement. When data mining techniques are applied to these data, their uncertainty has to be considered to obtain high quality results. We present UK-means clustering, an algorithm that enhances the K-means algorithm to handle data uncertainty. We apply UK-means to the particular pattern of moving-object uncertainty. Experimental results show that by considering uncertainty, a clustering algorithm can produce more accurate results.

#index 1669894
#* Parallel randomized support vector machine
#@ Yumao Lu;Vwani Roychowdhury
#t 2006
#c 3
#% 146885
#% 190581
#% 269217
#% 450263
#% 466677
#% 708179
#% 1080840
#! A parallel support vector machine based on randomized sampling technique is proposed in this paper. We modeled a new LP-type problem so that it works for general linear-nonseparable SVM training problems unlike the previous work [2]. A unique priority based sampling mechanism is used so that we can prove an average convergence rate that is so far the fastest bounded convergence rate to the best of our knowledge. The numerical results on synthesized data and a real geometric database show that our algorithm has good scalability.

#index 1669895
#* ϵ-Tube based pattern selection for support vector machines
#@ Dongil Kim;Sungzoon Cho
#t 2006
#c 3
#% 190581
#% 269218
#% 309208
#% 494972
#% 741673
#% 741674
#% 1390178
#! The training time complexity of Support Vector Regression (SVR) is O(N3). Hence, it takes long time to train a large dataset. In this paper, we propose a pattern selection method to reduce the training time of SVR. With multiple bootstrap samples, we estimate ε-tube. Probabilities are computed for each pattern to fall inside ε-tube. Those patterns with higher probabilities are selected stochastically. To evaluate the new method, the experiments for 4 datasets have been done. The proposed method resulted in the best performance among all methods, and even its performance was found stable.

#index 1669896
#* Self-adaptive two-phase support vector clustering for multi-relational data mining
#@ Ping Ling;Yan Wang;Chun-Guang Zhou
#t 2006
#c 3
#% 224755
#% 309208
#% 445215
#% 464633
#% 731604
#% 1860974
#! This paper proposes a novel Self-Adaptive Two-Phase Support Vector Clustering algorithm (STPSVC) to cluster multi-relational data. The algorithm produces an appreciate description of cluster contours and then extracts cluster centers information by iteratively performing classification procedure. An adaptive Kernel function is designed to find a desired width parameter for diverse dispersions. Experimental results indicate that the designed Kernel can capture multi-relational features well and STPSVC is of fine performance.

#index 1669897
#* One-Class support vector machines for recommendation tasks
#@ Yasutoshi Yajima
#t 2006
#c 3
#% 173879
#% 202011
#% 314933
#% 743284
#% 765552
#% 823388
#% 855602
#! The present paper proposes new approaches for recommendation tasks based on one-class support vector machines (1-SVMs) with graph kernels generated from a Laplacian matrix. We introduce new formulations for the 1-SVM that can manipulate graph kernels quite efficiently. We demonstrate that the proposed formulations fully utilize the sparse structure of the Laplacian matrix, which enables the proposed approaches to be applied to recommendation tasks having a large number of customers and products in practical computational times. Results of various numerical experiments demonstrating the high performance of the proposed approaches are presented.

#index 1669898
#* Heterogeneous information integration in hierarchical text classification
#@ Huai-Yuan Yang;Tie-Yan Liu;Li Gao;Wei-Ying Ma
#t 2006
#c 3
#% 190581
#% 309141
#% 318412
#% 416695
#% 458369
#% 466501
#% 757953
#% 770787
#% 770796
#% 829975
#! Previous work has shown that considering the category distance in the taxonomy tree can improve the performance of text classifiers. In this paper, we propose a new approach to further integrate more categorical information in the text corpus using the principle of multi-objective programming (MOP). That is, we not only consider the distance between categories defined by the branching of the taxonomy tree, but also consider the similarity between categories defined by the document/term distributions in the feature space. Consequently, we get a refined category distance by using MOP to leverage these two kinds of information. Experiments on both synthetic and real-world datasets demonstrated the effectiveness of the proposed algorithm in hierarchical text classification.

#index 1669899
#* FISA: feature-based instance selection for imbalanced text classification
#@ Aixin Sun;Ee-Peng Lim;Boualem Benatallah;Mahbub Hassan
#t 2006
#c 3
#% 420136
#% 577267
#% 722811
#% 722935
#% 765525
#% 813970
#% 1271973
#! Support Vector Machines (SVM) classifiers are widely used in text classification tasks and these tasks often involve imbalanced training. In this paper, we specifically address the cases where negative training documents significantly outnumber the positive ones. A generic algorithm known as FISA (Feature-based Instance Selection Algorithm), is proposed to select only a subset of negative training documents for training a SVM classifier. With a smaller carefully selected training set, a SVM classifier can be more efficiently trained while delivering comparable or better classification accuracy. In our experiments on the 20-Newsgroups dataset, using only 35% negative training examples and 60% learning time, methods based on FISA delivered much better classification accuracy than those methods using all negative training documents.

#index 1669900
#* Dynamic category profiling for text filtering and classification
#@ Rey-Long Liu
#t 2006
#c 3
#% 219053
#% 232646
#% 262085
#% 309088
#% 310503
#% 340904
#% 340941
#% 465754
#% 577232
#% 766436
#% 819772
#% 1349269
#! Information is often represented in text form and classified into categories for efficient browsing, retrieval, and dissemination. Unfortunately, automatic classifiers may conduct many misclassifications. One of the reasons is that the documents for training the classifiers are mainly from the categories, leading the classifiers to derive category profiles for distinguishing each category from others, rather than measuring the extent to which a document's content overlaps that of a category. To tackle the problem, we present a technique DP4FC to help various classifiers to improve the mining of category profiles. Upon receiving a document, DP4FC helps to create dynamic category profiles with respect to the document, and accordingly helps to make proper filtering and classification decisions. Theoretical analysis and empirical results show that DP4FC may make a classifier's performance both better and more stable.

#index 1669901
#* Detecting citation types using finite-state machines
#@ Minh-Hoang Le;Tu-Bao Ho;Yoshiteru Nakamori
#t 2006
#c 3
#% 309096
#% 345120
#% 438103
#% 466892
#% 569792
#% 1273862
#! This paper presents a method to extract citation types from scientific articles, viewed as an intrinsic part of emerging trend detection (ETD) in scientific literature. There are two main contributions in this work: (1) Definition of six categories (types) of citations in the literature that are extractable, human-understandable, and appropriate for building the interest and utility functions in emerging trend detection models, and (2) A method to classify citation types using finite-state machines which does not require user-interactions or explicit knowledge. The experimental comparative evaluations show the high performance of the method and the proposed ETD model shows the crucial role of classified citation types in the detection of emerging trends in scientific literature.

#index 1669902
#* A systematic study of parameter correlations in large scale duplicate document detection
#@ Shaozhi Ye;Ji-Rong Wen;Wei-Ying Ma
#t 2006
#c 3
#% 201935
#% 255137
#% 281245
#% 300176
#% 319876
#% 345087
#% 413577
#% 504572
#% 577370
#% 590525
#% 728115
#% 730067
#! Although much work has been done on duplicate document detection (DDD) and its applications, we observe the absence of a systematic study of the performance and scalability of large-scale DDD. It is still unclear how various parameters of DDD, such as similarity threshold, precision/recall requirement, sampling ratio, document size, correlate mutually. In this paper, correlations among several most important parameters of DDD are studied and the impact of sampling ratio is of most interest since it heavily affects the accuracy and scalability of DDD algorithms. An empirical analysis is conducted on a million documents from the TREC .GOV collection. Experimental results show that even using the same sampling ratio, the precision of DDD varies greatly on documents with different size. Based on this observation, an adaptive sampling strategy for DDD is proposed, which minimizes the sampling ratio within the constraint of a given precision threshold. We believe the insights from our analysis are helpful for guiding the future large scale DDD work.

#index 1669903
#* Comparison of documents classification techniques to classify medical reports
#@ F. H. Saad;B. de la Iglesia;G. D. Bell
#t 2006
#c 3
#% 99690
#% 127850
#% 266292
#% 269217
#% 280817
#% 311027
#% 406493
#% 464641
#% 564957
#% 727883
#% 1279298
#! This paper addresses a real world problem: the classification of text documents in the medical domain. There are a number of approaches to classifying text documents. Here, we use a partially supervised classification approach and argue that it is effective and computationally efficient for real-world problems. The approach uses a two-step strategy to cut down on the effort required to label each document for classification. Only a small set of positive documents are labeled initially, with others being labeled automatically as a result of the first step. The second step builds the actual text classifier. There are a number of methods that have been proposed for each step. A comprehensive evaluation of various combinations of methods is conducted to compare their performances using real world medical documents. The results show that using EM based methods to build the classifier yields better results than SVM. We also experimentally show that careful selection of a subset of features to represent the documents can improve the performance of the classifiers.

#index 1669904
#* XCLS: a fast and effective clustering algorithm for heterogenous XML documents
#@ Richi Nayak;Sumei Xu
#t 2006
#c 3
#% 66654
#% 287285
#% 296738
#% 413610
#% 495278
#% 577296
#% 734653
#% 789009
#% 805091
#% 1684783
#! We present a novel clustering algorithm to group the XML documents by similar structures. We introduce a Level structure format to represent the XML documents for efficient processing. We develop a global criterion function that do not require the pair-wise similarity to be computed between two individual documents, rather measures the similarity at clustering level utilising structural information of the XML documents. The experimental analysis shows the method to be fast and accurate.

#index 1669905
#* Clustering large collection of biomedical literature based on ontology-enriched bipartite graph representation and mutual refinement strategy
#@ Illhoi Yoo;Xiaohua Hu
#t 2006
#c 3
#% 46809
#% 118771
#% 218992
#% 228097
#% 262045
#% 280404
#% 375017
#% 397148
#% 464888
#% 465747
#% 465914
#% 577257
#% 591613
#% 769947
#! In this paper we introduce a novel document clustering approach that solves some major problems of traditional document clustering approaches. Instead of depending on traditional vector space model, this approach represents a set of documents as bipartite graphs using domain knowledge in ontology. In this representation, the concepts of the documents are classified according to their relationships with documents that are reflected on the bipartite graph. Using the concept groups, documents are clustered based on the concepts' contribution to each document. Through the mutual-refinement relationship with concept groups and document groups, the two groups are recursively refined. Our experimental results on MEDLINE articles show that our approach outperforms two leading document clustering algorithms: BiSecting K-means and CLUTO. In addition to its decent performance, our approach provides a meaningful explanation for each document cluster by identifying its most contributing concepts, thus helps users to understand and interpret documents and clustering results.

#index 1669906
#* Level-Biased statistics in the hierarchical structure of the web
#@ Guang Feng;Tie-Yan Liu;Xu-Dong Zhang;Wei-Ying Ma
#t 2006
#c 3
#% 290830
#% 309749
#% 1656296
#! In the literature of web search and mining, researchers used to consider the World Wide Web as a flat network, in which each page as well as each hyperlink is treated identically. However, it is the common knowledge that the Web is organized with a natural hierarchical structure according to the URLs of pages. Exploring the hierarchical structure, we found several level-biased characteristics of the Web. First, the distribution of pages over levels has a spindle shape. Second, the average indegree in each level decreases sharply when the level goes down. Third, although the indegree distributions in deeper levels obey the same power law with the global indegree distribution, the top levels show a quite different statistical characteristic. We believe that these new discoveries might be essential to the Web, and by taking use of them, the current web search and mining technologies could be improved and thus better services to the web users could be provided.

#index 1669907
#* Cleopatra: evolutionary pattern-based clustering of web usage data
#@ Qiankun Zhao;Sourav S. Bhowmick;Le Gruenwald
#t 2006
#c 3
#% 443194
#% 469425
#% 501656
#% 630984
#% 729967
#% 769895
#% 838496
#! Existing web usage mining techniques focus only on discovering knowledge based on the statistical measures obtained from the static characteristics of web usage data. They do not consider the dynamic nature of web usage data. In this paper, we present an algorithm called Cleopatra (CLustering of EvOlutionary PAtTeRn-based web Access sequences) to cluster web access sequences $\mathcal{(WAS)}s$ based on their evolutionary patterns. In this approach, Web access sequences that have similar change patterns in their support counts in the history are grouped into the same cluster. The intuition is that often $\mathcal{WAS}s$ are event/task-driven. As a result, $\mathcal{WAS}s$ related to the same event/task are expected to be accessed in similar ways over time. Such clusters are useful for several applications such as intelligent web site maintenance and personalized web services.

#index 1669908
#* Extracting and summarizing hot item features across different auction web sites
#@ Tak-Lam Wong;Wai Lam;Shing-Kit Chan
#t 2006
#c 3
#% 312860
#% 330784
#% 387791
#% 431536
#% 464434
#% 480824
#% 531459
#% 729978
#% 769877
#% 769892
#% 772300
#% 785365
#% 788107
#% 800608
#% 815924
#% 823366
#% 938708
#% 939896
#% 1291356
#% 1428371
#% 1810385
#! Online auction Web sites are fast changing and highly dynamic. It is difficult to digest the poorly organized and vast amount of information contained in the auction sites. We develop a unified framework aiming at automatically extracting the product features and summarizing the hot item features across different auction Web sites. One challenge of this problem is to extract useful information from the product descriptions provided by the sellers, which vary largely in the layout format. We formulate the problem as a single graph labeling problem using conditional random fields which can model the relationship among the neighbouring tokens in a Web page, the tokens from different pages, as well as various information such as the hot item features across different auction sites. We have conducted extensive experiments from several real-world auction Web sites to demonstrate the effectiveness of our framework.

#index 1669909
#* Clustering web sessions by levels of page similarity
#@ Caren Moraes Nichele;Karin Becker
#t 2006
#c 3
#% 447948
#% 487869
#% 552180
#% 729967
#% 775841
#! Session similarity is a key issue in web session clustering. Existing approaches vary on session representation and similarity computation. However, they do not consider the similarity between pages, which is crucial due to the semantic gap between URLs and corresponding application events. This paper presents a domain taxonomy-based clustering approach, which extends the WLCS technique by integrating page similarity to compute session similarity. The approach can be applied to both usage and navigation clustering purposes.

#index 1669910
#* iWed: an integrated multigraph cut-based approach for detecting events from a website
#@ Qiankun Zhao;Sourav S. Bhowmick;Aixin Sun
#t 2006
#c 3
#% 313959
#% 330678
#% 577273
#% 577297
#% 642981
#% 643014
#% 729967
#% 730021
#% 818215
#% 838496
#% 1719413
#! The web is a sensor of the real world. Often, content of web pages correspond to real world objects or events whereas the web usage data reflect users' opinions and actions to the corresponding events. Moreover, the evolution patterns of the web usage data may reflect the evolution of the corresponding events over time. In this paper, we present two variants of iWed(Integrated Web Event Detector) algorithm to extract events from website data by integrating author-centric data and visitor-centric data. We model the website related data as a multigraph, where each vertex represents a web page and each edge represents the relationship between the connected web pages in terms of structure, semantic, and/or usage pattern. Then, the problem of event detection is to extract strongly connected subgraphs from the multigraph to represent real world events. We solve this problem by adopting the normalized graph cut algorithm. Experiments show that the usage patterns play an important role in iWed algorithms and can produce high quality results.

#index 1669911
#* Enhancing duplicate collection detection through replica boundary discovery
#@ Zhigang Zhang;Weijia Jia;Xiaoming Li
#t 2006
#c 3
#% 201935
#% 204673
#% 255137
#% 281245
#% 300176
#% 319876
#% 345087
#% 503216
#% 504572
#% 544011
#% 616528
#% 769944
#% 1279489
#% 1599283
#! Web documents are widely replicated on the Internet. These replicated documents bring potential problems to Web based information systems. So replica detection on the Web is an indispensable task. The challenge is to find these duplicated collections from a very large data set with limited hardware resources in acceptable time. In this paper, we first introduce the notion of replica boundary to roughly reflect the situation of the replicas; then we propose an effective and efficient approach to discover the boundary of the replicas. The advantages of the proposed approach include: first, it dramatically reduces pair-wise document similarity computation, making it much faster than traditional replicated document detection approaches; second, it can identify the boundary of the replicated collections accurately, demonstrating to what extent two collections are replicated. On two web page sets containing 24 million and 30 million Web pages respectively, we evaluated the accuracy of the approach.

#index 1669912
#* Summarization and visualization of communication patterns in a large-scale social network
#@ Preetha Appan;Hari Sundaram;Belle Tseng
#t 2006
#c 3
#% 259754
#% 434557
#% 736155
#% 754107
#% 755055
#! This paper deals with the problem of summarization and visualization of communication patterns in a large scale corporate social network. The solution to the problem can have significant impact in understanding large scale social network dynamics. There are three key aspects to our approach. First we propose a ring based network representation scheme – the insight is that visual displays of temporal dynamics of large scale social networks can be accomplished without using graph based layout mechanisms. Second, we detect three specific network activity patterns – periodicity, isolated and widespread patterns at multiple time scales. For each pattern we develop specific visualizations within the overall ring based framework. Finally we develop an activity pattern ranking scheme and a visualization that enables us to summarize key social network activities in a single snapshot. We have validated our approach by using the large Enron corpus – we have excellent activity detection results, and very good preliminary user study results for the visualization.

#index 1669913
#* Patterns of influence in a recommendation network
#@ Jure Leskovec;Ajit Singh;Jon Kleinberg
#t 2006
#c 3
#% 478274
#% 577217
#% 577360
#% 629708
#% 729923
#% 772830
#% 794513
#! Information cascades are phenomena in which individuals adopt a new action or idea due to influence by others. As such a process spreads through an underlying social network, it can result in widespread adoption overall. We consider information cascades in the context of recommendations, and in particular study the patterns of cascading recommendations that arise in large social networks. We investigate a large person-to-person recommendation network, consisting of four million people who made sixteen million recommendations on half a million products. Such a dataset allows us to pose a number of fundamental questions: What kinds of cascades arise frequently in real life? What features distinguish them? We enumerate and count cascade subgraphs on large directed graphs; as one component of this, we develop a novel efficient heuristic based on graph isomorphism testing that scales to large datasets. We discover novel patterns: the distribution of cascade sizes is approximately heavy-tailed; cascades tend to be shallow, but occasional large bursts of propagation can occur. The relative abundance of different cascade subgraphs suggests subtle properties of the underlying social network and recommendation process.

#index 1669914
#* Constructing decision trees for graph-structured data by chunkingless graph-based induction
#@ Phu Chien Nguyen;Kouzou Ohara;Akira Mogi;Hiroshi Motoda;Takashi Washio
#t 2006
#c 3
#% 136350
#% 184048
#% 449566
#% 449588
#% 543941
#% 944955
#% 1707853
#! Chunkingless Graph-Based Induction (Cl-GBI) is a machine learning technique proposed for the purpose of extracting typical patterns from graph-structured data. This method is regarded as an improved version of Graph-Based Induction (GBI) which employs stepwise pair expansion (pairwise chunking) to extract typical patterns from graph-structured data, and can find overlapping patterns that cannot not be found by GBI. In this paper, we propose an algorithm for constructing decision trees for graph-structured data using Cl-GBI. This decision tree construction algorithm, called Decision Tree Chunkingless Graph-Based Induction (DT-ClGBI), can construct decision trees from graph-structured datasets while simultaneously constructing attributes useful for classification using Cl-GBI internally. Since patterns extracted by Cl-GBI are considered as attributes of a graph, and their existence/non-existence are used as attribute values, DT-ClGBI can be conceived as a tree generator equipped with feature construction capability. Experiments were conducted on synthetic and real-world graph-structured datasets showing the effectiveness of the algorithm.

#index 1669915
#* Combining smooth graphs with semi-supervised classification
#@ Xueyuan Zhou;Chunping Li
#t 2006
#c 3
#% 765552
#% 842682
#! In semi-supervised classification, many methods use the graph representation of data. Based on the graph, different methods, e.g. random walk model, spectral cluster, Markov chain, and regularization theory etc., are employed to design classification algorithms. However, all these methods use the form of graphs constructed directly from data, e.g. kNN graph. In reality, data is only the observation with noise of hidden variables. Classification results using data directly from the observation may be biased by noise. Therefore, filtering the noise before using any classification methods can give a better classification. We propose a novel method to filter the noise in high dimension data by smoothing the graph. The analysis is given from the aspects of spectral theory, Markov chain, and regularization. We show that our method can reduce the high frequency components of the graph, and also has an explanation from regularization view. A graph volume based parameter learning method can be efficiently applied to classification. Experiments on artificial and real world data set indicate that our method has a superior classification accuracy.

#index 1669916
#* Network data mining: discovering patterns of interaction between attributes
#@ John Galloway;Simeon J. Simoff
#t 2006
#c 3
#% 352757
#% 717527
#! Network Data Mining identifies emergent networks between myriads of individual data items and utilises special statistical algorithms that aid visualisation of ‘emergent' patterns and trends in the linkage. It complements predictive data mining methods and methods for outlier detection, which assume the independence between the attributes and the independence between the values of these attributes. Many problems, however, especially phenomena of a more complex nature, are not well suited for these methods. For example, in the analysis of transaction data there are no known suspicious transactions. This paper presents a human-centred methodology and supporting techniques that address the issues of depicting implicit relationships between data attributes and/or specific values of these attributes. The methodology and corresponding techniques are illustrated on a case study from the area of security.

#index 1669917
#* SGPM: static group pattern mining using apriori-like sliding window
#@ John Goh;David Taniar;Ee-Peng Lim
#t 2006
#c 3
#% 214664
#% 300120
#% 300173
#% 438312
#% 443515
#% 463903
#% 479785
#% 481290
#% 527021
#% 631926
#% 719768
#! Mobile user data mining is a field that focuses on extracting interesting pattern and knowledge out from data generated by mobile users. Group pattern is a type of mobile user data mining method. In group pattern mining, group patterns from a given user movement database is found based on spatio-temporal distances. In this paper, we propose an improvement of efficiency using area method for locating mobile users and using sliding window for static group pattern mining. This reduces the complexity of valid group pattern mining problem. We support the use of static method, which uses areas and sliding windows instead to find group patterns thus reducing the complexity of the mining problem.

#index 1669918
#* Mining temporal indirect associations
#@ Ling Chen;Sourav S. Bhowmick;Jinyan Li
#t 2006
#c 3
#% 152934
#% 478298
#% 552189
#% 641967
#% 1389686
#! This paper presents a novel pattern called temporal indirect association. An indirect association pattern refers to a pair of items that rarely occur together but highly depend on the presence of a mediator itemset. The existing model of indirect association does not consider the lifespan of items. Consequently, some discovered patterns may be invalid while some useful patterns may not be covered. To overcome this drawback, in this paper, we take into account the lifespan of items to extend the current model to be temporal. An algorithm, MG-Growth, that finds the set of mediators in pattern-growth manner is developed. Then, we extend the framework of the algorithm to discover temporal indirect associations. Our experimental results demonstrated the efficiency and effectiveness of the proposed algorithms.

#index 1669919
#* Mining top-k frequent closed itemsets is not in APX
#@ Chienwen Wu
#t 2006
#c 3
#% 388196
#% 579314
#% 729418
#% 751710
#% 789955
#% 800181
#! Mining top-k frequent closed itemsets was initially proposed and exactly solved by Wang et al. [IEEE Transactions on Knowledge and Data Engineering 17 (2005) 652-664]. However, in the literature, no research has ever considered the complexity of this problem. In this paper, we present a set of proofs showing that, in the general case, the problem of mining top-k frequent closed itemsets is not in APX. This indicates that heuristic algorithms rather than exact algorithms are preferred to solve the problem.

#index 1669920
#* Quality-Aware association rule mining
#@ Laure Berti-Équille
#t 2006
#c 3
#% 269634
#% 442973
#% 535837
#% 550575
#% 577214
#% 644182
#% 819448
#% 821865
#% 1015300
#! The quality of discovered association rules is commonly evaluated by interestingness measures (commonly support and confidence) with the purpose of supplying subsidies to the user in the understanding and use of the new discovered knowledge. Low-quality datasets have a very bad impact over the quality of the discovered association rules, and one might legitimately wonder whether a so-called “interesting” rule noted LHS - RHS is meaningful when 30 % of LHS data are not up-to-date anymore, 20% of RHS data are not accurate, and 15% of LHS data come from a data source that is well-known for its bad credibility. In this paper we propose to integrate data quality measures for effective and quality-aware association rule mining and we propose a cost-based probabilistic model for selecting legitimately interesting rules. Experiments on the challenging KDD-CUP-98 datasets show for different variations of data quality indicators the corresponding cost and quality of discovered association rules that can be legitimately (or not) selected.

#index 1669921
#* IMB3-Miner: mining induced/embedded subtrees by constraining the level of embedding
#@ Henry Tan;Tharam S. Dillon;Fedja Hadzic;Elizabeth Chang;Ling Feng
#t 2006
#c 3
#% 262071
#% 478622
#% 481290
#% 629656
#% 729942
#% 772830
#% 813989
#% 820921
#% 944956
#% 1015260
#! Tree mining has recently attracted a lot of interest in areas such as Bioinformatics, XML mining, Web mining, etc. We are mainly concerned with mining frequent induced and embedded subtrees. While more interesting patterns can be obtained when mining embedded subtrees, unfortunately mining such embedding relationships can be very costly. In this paper, we propose an efficient approach to tackle the complexity of mining embedded subtrees by utilizing a novel Embedding List representation, Tree Model Guided enumeration, and introducing the Level of Embedding constraint. Thus, when it is too costly to mine all frequent embedded subtrees, one can decrease the level of embedding constraint gradually up to 1, from which all the obtained frequent subtrees are induced subtrees. Our experiments with both synthetic and real datasets against two known algorithms for mining induced and embedded subtrees, FREQT and TreeMiner, demonstrate the effectiveness and the efficiency of the technique.

#index 1669922
#* Maintaining frequent itemsets over high-speed data streams
#@ James Cheng;Yiping Ke;Wilfred Ng
#t 2006
#c 3
#% 730084
#% 993960
#% 1016146
#! We propose a false-negative approach to approximate the set of frequent itemsets (FIs) over a sliding window. Existing approximate algorithms use an error parameter, ε, to control the accuracy of the mining result. However, the use of ε leads to a dilemma. A smaller ε gives a more accurate mining result but higher computational complexity, while increasing ε degrades the mining accuracy. We address this dilemma by introducing a progressively increasing minimum support function. When an itemset is retained in the window longer, we require its minimum support to approach the minimum support of an FI. Thus, the number of potential FIs to be maintained is greatly reduced. Our experiments show that our algorithm not only attains highly accurate mining results, but also runs significantly faster and consumes less memory than do existing algorithms for mining FIs over a sliding window.

#index 1669923
#* Generalized disjunction-free representation of frequents patterns with at most k negations
#@ Marzena Kryszkiewicz
#t 2006
#c 3
#% 152934
#% 502141
#% 1707856
#! The discovery of frequent patterns and their representations has attracted a lot of attention in the data mining community. An extensive research has been carried out mainly in discovering positive patterns. Recently, the generalized disjunction–free representation GDFLR of all frequent patterns both with and without negation has been proposed. There are cases, however, when a user is interested in patterns with a restricted number of negated items. In this paper, we offer the k-GDFLR representation as an adaptation of GDFLR, which represents all frequent patterns with at most k negated items. Algorithms discovering this representation are discussed as well. The experimental results show that k-GDFLR is more concise than GDFLR.

#index 1669924
#* Mining interesting imperfectly sporadic rules
#@ Yun Sing Koh;Nathan Rountree;Richard O'Keefe
#t 2006
#c 3
#% 152934
#% 248785
#% 420112
#% 477957
#% 481290
#% 481758
#% 785474
#% 1707792
#! Detecting association rules with low support but high confidence is a difficult data mining problem. To find such rules using approaches like the Apriori algorithm, minimum support must be set very low, which results in a large amount of redundant rules. We are interested in sporadic rules; i.e. those that fall below a maximum support level but above the level of support expected from random coincidence. In this paper we introduce an algorithm called MIISR to find a particular type of sporadic rule efficiently: where the support of the antecedent as a whole falls below maximum support, but where items may have quite high support individually. Our proposed method uses item constraints and coincidence pruning to discover these rules in reasonable time.

#index 1669925
#* Improved negative-border online mining approaches
#@ Ching-Yao Wang;Shian-Shyong Tseng;Tzung-Pei Hong
#t 2006
#c 3
#% 14513
#% 199537
#% 207552
#% 443164
#% 443427
#% 464204
#% 481290
#% 737975
#% 998750
#% 1731166
#! In the past, we proposed an extended multidimensional pattern relation (EMPR) to structurally and systematically store previously mining information for each inserted block of data, and designed a negative-border online mining (NOM) approach to provide ad-hoc, query-driven and online mining supports. In this paper, we try to use appropriate data structures and design efficient algorithms to improve the performance of the NOM approach. The lattice data structure is utilized to organize and maintain all candidate itemsets such that the candidate itemsets with the same proper subsets can be considered at the same time. The derived lattice-based NOM (LNOM) approach will require only one scan of the itemsets stored in EMPR, thus saving much computation time. In addition, a hashing technique is used to further improve the performance of the NOM approach since many itemsets stored in EMPR may be useless for calculating the counts of candidates. At last, experimental results show the effect of the improved NOM approaches.

#index 1669926
#* Association-Based dissimilarity measures for categorical data: limitation and improvement
#@ Si Quang Le;Tu Bao Ho;Le Sy Vinh
#t 2006
#c 3
#% 860824
#! Measuring the similarity for categorical data is a challenging task in data mining due to the poor structure of categorical data. This paper presents a dissimilarity measure for categorical data based on the relations among attributes. This measure not only has the advantage of value variance but also overcomes the limitations of condition the probability-based measure when applied to databases whose attributes are independent. Experiments with 30 databases also showed that the proposed measure boosted the accuracy of Nearest Neighbor classification in comparison with other tested measures.

#index 1669927
#* Is frequency enough for decision makers to make decisions?
#@ Shichao Zhang;Jeffrey Xu Yu;Jingli Lu;Chengqi Zhang
#t 2006
#c 3
#% 342667
#% 345870
#! There are many advanced techniques that can efficiently mine frequent itemsets using a minimum support. However, the question that remains unanswered is whether the minimum support can really help decision makers to make decisions. In this paper, we study four summary queries for frequent itemsets mining, namely, 1) finding a support-average of itemsets, 2) finding a support-quantile of itemsets, 3) finding the number of itemsets that greater/less than the support-average, i.e., an approximated distribution of itemsets, and 4) finding the relative frequency of an itemset. With these queries, a decision maker will know whether an itemset in question is greater/less than the support-quantile; the distribution of itemsets; and the frequentness of an itemset. Processing these summary queries is challenging, because the minimum-support constraint cannot be used to prune infrequent itemsets.

#index 1669928
#* Ramp: high performance frequent itemset mining with efficient bit-vector projection technique
#@ Shariq Bashir;Abdul Rauf Baig
#t 2006
#c 3
#% 465003
#% 466490
#% 481290
#! Mining frequent itemset using bit-vector representation approach is very efficient for small dense datasets, but highly inefficient for sparse datasets due to lack of any efficient bit-vector projection technique. In this paper we present a novel efficient bit-vector projection technique, for sparse and dense datasets. We also present a new frequent itemset mining algorithm Ramp (Real Algorithm for Mining Patterns) using bit-vector representation approach and our bit-vector projection technique. The performance of the Ramp is compared with the current best frequent itemset mining algorithms. Different experimental results on sparse datasets show that mining frequent itemset using Ramp is faster than the current best algorithms.

#index 1669929
#* Evaluating a rule evaluation support method based on objective rule evaluation indices
#@ Hidenao Abe;Shusaku Tsumoto;Miho Ohsaki;Takahira Yamaguchi
#t 2006
#c 3
#% 136350
#% 156186
#% 227917
#% 232126
#% 269218
#% 290482
#% 292240
#% 392618
#% 465922
#% 474183
#% 477792
#% 486152
#% 501346
#% 501381
#% 577214
#% 641961
#% 799768
#! In this paper, we present an evaluation of novel rule evaluation support method for post-processing of mined results with rule evaluation models based on objective indices. Post-processing of mined results is one of the key issues in a data mining process. However, it is difficult for human experts to evaluate many thousands of rules from a large dataset with noises completely. To reduce the costs of rule evaluation task, we have developed the rule evaluation support method with rule evaluation models, which are obtained with objective indices of mined classification rules and evaluations of a human expert for each rule. To evaluate performances of learning algorithms for constructing rule evaluation models, we have done a case study on the meningitis data mining as an actual problem. Furthermore, we have also evaluated our method on four rulesets from the four kinds of UCI datasets.

#index 1669930
#* Scoring method for tumor prediction from microarray data using an evolutionary fuzzy classifier
#@ Shinn-Ying Ho;Chih-Hung Hsieh;Kuan-Wei Chen;Hui-Ling Huang;Hung-Ming Chen;Shinn-Jang Ho
#t 2006
#c 3
#% 832712
#% 833529
#% 833751
#% 1777322
#% 1781390
#! In this paper, we propose a novel scoring method for tumor prediction using an evolutionary fuzzy classifier which can provide accurate and interpretable information. The merits of the proposed method are threefold. 1) The score ranged in [0, 100] can further illustrate the degree of tumor status in contrast to the conventional tumor classifier. 2) The derived score system can be used as a tumor classifier using a system-suggested or human-specified threshold value. 3) The derived classifier with a compact fuzzy rule base can generate an interpretable and accurate prediction result. The effectiveness of the proposed method is evaluated and compared using two well-known datasets from microarray data and an existing tumor classifier. It is shown by computer simulation that the proposed scoring method is effective using ROC curves of classification.

#index 1669931
#* Efficient discovery of structural motifs from protein sequences with combination of flexible intra- and inter-block gap constraints
#@ Chen-Ming Hsu;Chien-Yu Chen;Ching-Chi Hsu;Baw-Jhiune Liu
#t 2006
#c 3
#% 399793
#% 469565
#% 469571
#% 737330
#% 778732
#! Discovering protein structural signatures directly from their primary information is a challenging task, because the residues associated with a functional motif are not necessarily clustered in one region of the sequence. This work proposes an algorithm that aims to discover conserved sequential blocks interleaved by large irregular gaps from a set of unaligned biological sequences. Different from the previous works that employ only one type of constraint on gap flexibility, we propose using combination of intra- and inter-block gap constraints to discover longer patterns with larger irregular gaps. The smaller flexible intra-block gap constraint is used to relax the restriction in local motif blocks but still keep them compact, and the larger flexible inter-block gap constraint is proposed to allow longer irregular gaps between compact motif blocks. Using two types of gap constraints for different purposes improves the efficiency of mining process while keeping high accuracy of mining results. The efficiency of the algorithm also helps to identify functional motifs that are conserved in only a small subset of the input sequences.

#index 1669932
#* Finding consensus patterns in very scarce biosequence samples from their minimal multiple generalizations
#@ Yen Kaow Ng;Takeshi Shinohara
#t 2006
#c 3
#% 479338
#% 503275
#% 1718526
#! In this paper we examine the issues involved in finding consensus patterns from biosequence data of very small sample sizes, by searching for so-called minimal multiple generalization (mmg), that is, a set of syntactically minimal patterns that accounts for all the samples. The data we use are the sigma regulons with more conserved consensus patterns for the bacteria B. subtilis. By comparing between the mmgs found over different search spaces, we found that it is possible to derive patterns close to the known consensus patterns by simply making some reasonable requirements on the kinds of patterns to obtain. We also propose some simple measures to evaluate the patterns in an mmg.

#index 1669933
#* Kernels on lists and sets over relational algebra: an application to classification of protein fingerprints
#@ Adam Woźnica;Alexandros Kalousis;Melanie Hilario
#t 2006
#c 3
#% 393059
#% 722926
#% 771944
#% 799754
#% 1707847
#! In this paper we propose a new class of kernels defined over extended relational algebra structures. The “extension” was recently proposed in [1] and it overcomes one of the main limitation of the standard relational algebra, i.e. difficulties in modeling lists. These new kernels belong to the class of $\mathcal{R}$-Convolution kernels in the sense that the computation of the similarity between two complex objects is based on the similarities of objects' parts computed by means of subkernels. The complex objects (relational instances in our case) are tuples and sets and/or lists of relational instances for which elementary kernels and kernels on sets and lists are applied. The performance of this class of kernels together with the Support Vector Machines (SVM) algorithm is evaluated on the problem of classification of protein fingerprints and by combining different data representations we were able to improve the best accuracy reported so far in the literature.

#index 1669934
#* Mining quantitative maximal hyperclique patterns: a summary of results
#@ Yaochun Huang;Hui Xiong;Weili Wu;Sam Y. Sung
#t 2006
#c 3
#% 152934
#% 300120
#% 465003
#% 727897
#% 729942
#% 785518
#! Hyperclique patterns are groups of objects which are strongly related to each other. Indeed, the objects in a hyperclique pattern have a guaranteed level of global pairwise similarity to one another as measured by uncentered Pearson's correlation coefficient. Recent literature has provided the approach to discovering hyperclique patterns over data sets with binary attributes. In this paper, we introduce algorithms for mining maximal hyperclique patterns in large data sets containing quantitative attributes. An intuitive and simple solution is to partition quantitative attributes into binary attributes. However, there is potential information loss due to partitioning. Instead, our approach is based on a normalization scheme and can directly work on quantitative attributes. In addition, we adopt the algorithm structures of three popular association pattern mining algorithms and add a critical clique pruning technique. Finally, we compare the performance of these algorithms for finding quantitative maximal hyperclique patterns using some real-world data sets.

#index 1669935
#* A nonparametric outlier detection for effectively discovering top-n outliers from engineering data
#@ Hongqin Fan;Osmar R. Zaïane;Andrew Foss;Junfeng Wu
#t 2006
#c 3
#% 249322
#% 300136
#% 300183
#% 479791
#% 480304
#% 501988
#% 629657
#! We present a novel resolution-based outlier notion and a nonparametric outlier-mining algorithm, which can efficiently identify top listed outliers from a wide variety of datasets. The algorithm generates reasonable outlier results by taking both local and global features of a dataset into consideration. Experiments are conducted using both synthetic datasets and a real life construction equipment dataset from a large building contractor. Comparison with the current outlier mining algorithms indicates that the proposed algorithm is more effective.

#index 1669936
#* A fast greedy algorithm for outlier mining
#@ Zengyou He;Shengchun Deng;Xiaofei Xu;Joshua Zhexue Huang
#t 2006
#c 3
#% 300136
#% 300183
#% 302406
#% 333929
#% 334990
#% 449400
#% 482620
#% 487854
#% 570886
#% 574604
#% 629685
#% 729912
#% 823340
#% 855602
#% 1676127
#% 1708162
#! The task of outlier detection is to find small groups of data objects that are exceptional when compared with rest large amount of data. Recently, the problem of outlier detection in categorical data is defined as an optimization problem and a local-search heuristic based algorithm (LSA) is presented. However, as is the case with most iterative type algorithms, the LSA algorithm is still very time-consuming on very large datasets. In this paper, we present a very fast greedy algorithm for mining outliers under the same optimization model. Experimental results on real datasets and large synthetic datasets show that: (1) Our new algorithm has comparable performance with respect to those state-of-the-art outlier detection algorithms on identifying true outliers and (2) Our algorithm can be an order of magnitude faster than LSA algorithm.

#index 1669937
#* Ranking outliers using symmetric neighborhood relationship
#@ Wen Jin;Anthony K. H. Tung;Jiawei Han;Wei Wang
#t 2006
#c 3
#% 201876
#% 210173
#% 248790
#% 300136
#% 300163
#% 300183
#% 333929
#% 342625
#% 342638
#% 479791
#% 479986
#% 481281
#% 501988
#% 566132
#% 578689
#% 765134
#% 765438
#% 775363
#% 799747
#% 813973
#% 818916
#! Mining outliers in database is to find exceptional objects that deviate from the rest of the data set. Besides classical outlier analysis algorithms, recent studies have focused on mining local outliers, i.e., the outliers that have density distribution significantly different from their neighborhood. The estimation of density distribution at the location of an object has so far been based on the density distribution of its k-nearest neighbors [2,11]. However, when outliers are in the location where the density distributions in the neighborhood are significantly different, for example, in the case of objects from a sparse cluster close to a denser cluster, this may result in wrong estimation. To avoid this problem, here we propose a simple but effective measure on local outliers based on a symmetric neighborhood relationship. The proposed measure considers both neighbors and reverse neighbors of an object when estimating its density distribution. As a result, outliers so discovered are more meaningful. To compute such local outliers efficiently, several mining algorithms are developed that detects top-n outliers based on our definition. A comprehensive performance evaluation and analysis shows that our methods are not only efficient in the computation but also more effective in ranking outliers.

#index 1669938
#* Construction of finite automata for intrusion detection from system call sequences by genetic algorithms
#@ Kyubum Wee;Sinjae Kim
#t 2006
#c 3
#% 441363
#% 664466
#% 664711
#% 664712
#% 1001828
#% 1546406
#! Intrusion detection systems protect normal users and system resources from information security threats. Anomaly detection is an approach of intrusion detection that constructs models of normal behavior of users or systems and detects the behaviors that deviate from the model. Monitoring the sequences of system calls generated during the execution of privileged programs has been known to be an effective means of anomaly detection. Finite automata have been recognized as an appropriate device to model normal behaviors of system call sequences. However, there have been several technical difficulties in constructing finite automata from sequences of system calls. We present our study on how to construct finite automata from system call sequences using genetic algorithms. The resulting system is shown to be very effective in detecting intrusions through various experiments.

#index 1669939
#* An adaptive intrusion detection algorithm based on clustering and kernel-method
#@ Hansung Lee;Yongwha Chung;Daihee Park
#t 2006
#c 3
#% 1860974
#! An adaptive intrusion detection algorithm which combines the Adaptive Resonance Theory(ART) with the Concept Vector and the Mecer-Kernel is presented. Compared to the supervised- and the clustering-based Intrusion Detection Systems(IDSs), our algorithm can detect unknown types of intrusions in on-line by generating clusters incrementally.

#index 1669940
#* Weighted intra-transactional rule mining for database intrusion detection
#@ Abhinav Srivastava;Shamik Sural;A. K. Majumdar
#t 2006
#c 3
#% 216500
#% 306097
#% 310840
#% 316709
#% 428401
#% 463903
#% 507694
#% 577249
#% 615098
#% 737361
#% 978636
#! Data mining is the non-trivial process of identifying novel, potentially useful and understandable patterns in data. With most of the organizations starting on-line operations, the threat of security breaches is increasing. Since a database stores a lot of valuable information, its security has become paramount. One mechanism to safeguard the information in these databases is to use an intrusion detection system(IDS). In every database, there are a few attributes or columns that are more important to be tracked or sensed for malicious modifications as compared to the other attributes. In this paper, we propose an intrusion detection algorithm named weighted data dependency rule miner (WDDRM) for finding dependencies among the data items. The transactions that do not follow the extracted data dependency rules are marked as malicious. We show that WDDRM handles the modification of sensitive attributes quite accurately.

#index 1669941
#* On robust and effective k-anonymity in large databases
#@ Wen Jin;Rong Ge;Weining Qian
#t 2006
#c 3
#% 190611
#% 210173
#% 286825
#% 300183
#% 300184
#% 333876
#% 479791
#% 575967
#% 576761
#% 576762
#% 577239
#% 727929
#% 729930
#% 800513
#% 800514
#% 800515
#% 810011
#% 1068712
#% 1279283
#! The challenge of privacy-preserving data mining lies in respecting privacy requirements while discovering the original interesting patterns or structures. Existing methods loose the correlations among attributes by transforming the different attributes independently, or cannot guarantee the minimum abstraction level required by legal policies. In this paper, we propose a novel privacy-preserving transformation framework for distance-based mining operations based on the concept of privacy-preserving MicroClusters that satisfy a privacy constraint as well as a significance constraint. Our framework well extends the robustness of the state-of-the-art k-anonymity model by introducing a privacy constraint (minimum radius) while keeping its effectiveness by a significance constraint (minimum number of corresponding data records). The privacy-preserving MicroClusters are made public for data mining purposes, but the original data records are kept private. We present efficient methods for generating and maintaining privacy-preserving MicroClusters and show that data mining operations such as clustering can easily be adapted to the public data represented by MicroClusters instead of the private data records. The experiment demonstrates that the proposed methods achieve accurate clusterings results while preserving the privacy.

#index 1669942
#* Achieving private recommendations using randomized response techniques
#@ Huseyin Polat;Wenliang Du
#t 2006
#c 3
#% 280852
#% 280883
#% 330687
#% 397153
#% 542366
#% 616944
#% 729962
#% 763590
#% 832368
#% 993988
#! Collaborative filtering (CF) systems are receiving increasing attention. Data collected from users is needed for CF; however, many users do not feel comfortable to disclose data due to privacy risks. They sometimes refuse to provide information or might decide to give false data. By introducing privacy measures, it is more likely to increase users' confidence to contribute their data and to provide more truthful data. In this paper, we investigate achieving referrals using item-based algorithms on binary ratings without greatly exposing users' privacy. We propose to use randomized response techniques (RRT) to perturb users' data. We conduct experiments to evaluate the accuracy of our scheme and to show how different parameters affect our results using real data sets.

#index 1669943
#* Privacy-Preserving SVM classification on vertically partitioned data
#@ Hwanjo Yu;Jaideep Vaidya;Xiaoqian Jiang
#t 2006
#c 3
#% 23638
#% 190581
#% 300184
#% 342598
#% 727904
#% 729930
#% 742048
#% 769956
#% 809530
#% 810010
#% 874166
#% 954159
#% 1068712
#! Classical data mining algorithms implicitly assume complete access to all data, either in centralized or federated form. However, privacy and security concerns often prevent sharing of data, thus derailing data mining projects. Recently, there has been growing focus on finding solutions to this problem. Several algorithms have been proposed that do distributed knowledge discovery, while providing guarantees on the non-disclosure of data. Classification is an important data mining problem applicable in many diverse domains. The goal of classification is to build a model which can predict an attribute (binary attribute in this work) based on the rest of attributes. We propose an efficient and secure privacy-preserving algorithm for support vector machine (SVM) classification over vertically partitioned data.

#index 1669944
#* Data mining using relational database management systems
#@ Beibei Zou;Xuesong Ma;Bettina Kemme;Glen Newton;Doina Precup
#t 2006
#c 3
#% 248813
#% 269634
#% 280402
#% 452821
#% 479787
#% 481945
#% 490958
#% 771926
#% 1272326
#! Software packages providing a whole set of data mining and machine learning algorithms are attractive because they allow experimentation with many kinds of algorithms in an easy setup. However, these packages are often based on main-memory data structures, limiting the amount of data they can handle. In this paper we use a relational database as secondary storage in order to eliminate this limitation. Unlike existing approaches, which often focus on optimizing a single algorithm to work with a database backend, we propose a general approach, which provides a database interface for several algorithms at once. We have taken a popular machine learning software package, Weka, and added a relational storage manager as back-tier to the system. The extension is transparent to the algorithms implemented in Weka, since it is hidden behind Weka's standard main-memory data structure interface. Furthermore, some general mining tasks are transfered into the database system to speed up execution. We tested the extended system, refered to as WekaDB, and our results show that it achieves a much higher scalability than Weka, while providing the same output and maintaining good computation time.

#index 1669945
#* Bias-Free hypothesis evaluation in multirelational domains
#@ Christine Körner;Stefan Wrobel
#t 2006
#c 3
#% 477126
#% 1393858
#% 1650403
#! In propositional domains using a separate test set via random sampling or cross validation is generally considered to be an unbiased estimator of true error. In multirelational domains previous work has already noted that linkage of objects may cause these procedures to be biased and has proposed corrected sampling procedures. However, as we show in this paper, the existing procedures only address one particular case of bias introduced by linkage. In this paper we therefore introduce generalized subgraph sampling, a sampling procedure based on bin packing, which ensures that test sets are properly chosen to match the probability of reencountering previously seen objects and which includes previous approaches as a special case. Experiments with data from the Internet Movie Database illustrate the performance of our algorithm.

#index 1669946
#* Enhanced DB-Subdue: supporting subtle aspects of graph mining using a relational approach
#@ Ramanathan Balachandran;Srihari Padmanabhan;Sharma Chakravarthy
#t 2006
#c 3
#% 61792
#% 248813
#% 431105
#% 445369
#% 466644
#% 481290
#% 629708
#% 1388505
#! This paper addresses subtle aspects of graph mining using an SQL-based approach. The enhancements addressed in this paper include detection of cycles, effect of overlapping substructures on compression, and development of a minimum description length for the relational approach. Extensive performance evaluation has been conducted to evaluate the extensions.

#index 1669947
#* Multimedia semantics integration using linguistic model
#@ Bo Yang;Ali R. Hurson
#t 2006
#c 3
#% 422982
#% 427301
#% 451642
#% 729342
#% 730229
#% 884822
#! The integration of multimedia semantics is challenging due to the feature-based representation of multimedia data and the heterogeneity among data sources. From human viewpoint, multimedia data objects are often considered as perceptions of the real world, and therefore can be represented at a semantic-entity level in the linguistic domain. This paper proposes a paradigm that facilitates the integration of multimedia semantics in heterogeneous distributed database environments with the help of linguistic analysis. Specifically, we derive a closed set of logic-based form expressions for the efficient computation of multimedia semantic contents, which include conceptual attributes and linguistic relationships into the consideration. In the expression set, the logic terms give a convenient way to describe semantic contents concisely and precisely, providing a representation of multimedia data that is closer to human perception. The space utilization is also improved through the collective representation of similar semantic contents and feature values. In addition, the optimization can be easily performed on logic expressions using mathematical analysis. By replacing long terms with equivalent terms of shorter lengths, the image representation can be automatically optimized. Using a heterogeneous database infrastructure, the proposed method has been simulated and analyzed.

#index 1669948
#* A novel indexing approach for efficient and fast similarity search of captured motions
#@ Chuanjun Li;B. Prabhakaran
#t 2006
#c 3
#% 227924
#% 504158
#% 632042
#% 729931
#% 784570
#% 867866
#! Indexing of motion data is important for quickly searching similar motions for sign language recognition and gait analysis and rehabilitation. This paper proposes a simple and efficient tree structure for indexing motion data with dozens of attributes. Feature vectors are extracted for indexing by using singular value decomposition (SVD) properties of motion data matrices. By having similar motions with large variations indexed together, searching for similar motions of a query needs only one node traversal at each tree level, and only one feature needs to be considered at one tree level. Experiments show that the majority of irrelevant motions can be pruned while retrieving all similar motions, and one traversal of the indexing tree takes only several microseconds with the existence of motion variations.

#index 1669949
#* Mining frequent spatial patterns in image databases
#@ Wei-Ta Chen;Yi-Ling Chen;Ming-Syan Chen
#t 2006
#c 3
#% 300120
#% 430763
#% 443082
#% 443164
#% 481290
#% 584926
#% 632037
#% 632342
#! Mining useful patterns in image databases can not only reveal useful information to users but also help the task of data management. In this paper, we propose an image mining framework, Frequent Spatial Pattern mining in images (FSP), to mine frequent patterns located in a pair of spatial locations of images. A pattern in the FSP is associated with a pair of spatial locations and refers to the occurrence of the same image content in a set of images. This framework is designed to be general so as to accept different levels of representations of image content and different layout forms of spatial representations.

#index 1669950
#* Image classification via LZ78 based string kernel: a comparative study
#@ Ming Li;Yanong Zhu
#t 2006
#c 3
#% 234979
#% 453575
#% 769896
#% 844035
#% 1705482
#% 1815525
#! Normalized Information Distance (NID) [1] is a general-purpose similarity metric based on the concept of Kolmogorov Complexity. We have developed this notion into a valid kernel distance, called LZ78-based string kernel [2] and have shown that it can be used effectively for a variety of 1D sequence classification tasks [3]. In this paper, we further demonstrate its applicability on 2D images. We report experiments with our technique on two real datasets: (i) a collection of real-life photographs and (ii) a collection of medical diagnostic images from Magnetic Resonance (MR) data. The classification results are compared with those of the original similarity metric (i.e. NID) and several conventional classification algorithms. In all cases, the proposed kernel approach demonstrates better or equivalent performance when compared with other candidate methods but with lower computational overhead.

#index 1669951
#* Distributed pattern discovery in multiple streams
#@ Jimeng Sun;Spiros Papadimitriou;Christos Faloutsos
#t 2006
#c 3
#% 443085
#% 654443
#% 1707797
#! Given m groups of streams which consist of n1,...,nm co-evolving streams in each group, we want to: (i) incrementally find local patterns within a single group, (ii) efficiently obtain global patterns across groups, and more importantly, (iii) efficiently do that in real time while limiting shared information across groups. In this paper, we present a distributed, hierarchical algorithm addressing these problems. Our experimental case study confirms that the proposed method can perform hierarchical correlation detection efficiently and effectively.

#index 1669952
#* COMET: event-driven clustering over multiple evolving streams
#@ Mi-Yen Yeh;Bi-Ru Dai;Ming-Syan Chen
#t 2006
#c 3
#% 310500
#% 342600
#% 378388
#% 443392
#% 466506
#% 594012
#% 632090
#% 659972
#% 744027
#% 765403
#% 785384
#% 800496
#% 993961
#! In this paper, we present a framework for event-driven Clustering Over Multiple Evolving sTreams, which, abbreviated as COMET, monitors the distribution of clusters on multiple data streams and online reports the results. This information is valuable to support corresponding online decisions. Note that as time advances, the data streams are evolving and the clusters they belong to will change. Instead of directly clustering the multiple data streams periodically, COMET applies an efficient cluster adjustment procedure only when it is required. The signal of requiring to do cluster adjustments is defined as an ”event.” We design a mechanism of event detection which employs piecewise linear approximation as the key technique. The piecewise linear approximation is advantageous in that it can not only be performed in real time as the data comes in, but also be able to capture the trend of data. When an event occurs, through split and merge operations we can report the latest clustering results effectively with high clustering quality.

#index 1669953
#* Variable support mining of frequent itemsets over data streams using synopsis vectors
#@ Ming-Yen Lin;Sue-Chen Hsueh;Sheng-Kun Hwang
#t 2006
#c 3
#% 300120
#% 378388
#% 481290
#% 785339
#% 790709
#% 796209
#% 993960
#! Mining frequent itemsets over data streams is an emergent research topic in recent years. Previous approaches generally use a fixed support threshold to discover the patterns in the stream. However, the threshold will be changed to cope with the needs of the users and the characteristics of the incoming data in reality. Changing the threshold implies a re-mining of the whole transactions in a non-streaming environment. Nevertheless, the "look-once" feature of the streaming data cannot provide the discarded transactions so that a re-mining on the stream is impossible. Therefore, we propose a method for variable support mining of frequent itemsets over the data stream. A synopsis vector is constructed for maintaining statistics of past transactions and is invoked only when necessary. The conducted experimental results show that our approach is efficient and scalable for variable support mining in data streams.

#index 1669954
#* Hardware enhanced mining for association rules
#@ Wei-Chuan Liu;Ken-Hao Liu;Ming-Syan Chen
#t 2006
#c 3
#% 199538
#% 227922
#% 232136
#% 316709
#% 434348
#% 438428
#% 443082
#% 443091
#% 481290
#% 569754
#% 844308
#% 1015262
#! In this paper, we propose a hardware-enhanced mining framework to cope with many challenging data mining tasks in a data stream environment. In this framework, hardware enhancements are implemented in commercial Field Programmable Gate Array (FPGA) devices, which have been growing rapidly in terms of density and speed. By exploiting the parallelism in hardware, many data mining primitive subtasks can be executed with high throughput, thus increasing the performance of the overall data mining tasks. Simple operations like counting, which take a major portion of conventional mining execution time, can in fact be executed on the hardware enhancements very efficiently. Subtask modules that are used repetitively can also be replaced with the equivalent hardware enhancements. Specifically, we realize an Apriori-like algorithm with our proposed hardware-enhanced mining framework to mine frequent temporal patterns from data streams. The frequent counts of 1-itemsets and 2-itemsets are obtained after one pass of scanning the datasets with our hardware implementation. It is empirically shown that the hardware enhancements provide the scalability by mapping the high complexity operations such as subset itemsets counting to the hardware. Our approach achieve considerably higher throughput than traditional database architectures with pure software implementation. With fast increase in applications of mobile devices where power consumption is a concern and complicated software executions are prohibited, it is envisioned that hardware enhanced mining is an important direction to explore.

#index 1669955
#* A single index approach for time-series subsequence matching that supports moving average transform of arbitrary order
#@ Yang-Sae Moon;Jinho Kim
#t 2006
#c 3
#% 86950
#% 172949
#% 379495
#% 397381
#% 443369
#% 460862
#% 464994
#% 754411
#% 765403
#! Moving average transform is known to reduce the effect of noise and has been used in many areas such as econometrics. Previous subsequence matching methods with moving average transform, however, would incur index overhead both in storage space and in update maintenance since the methods should build multiple indexes for supporting arbitrary orders. To solve this problem, we propose a single index approach for subsequence matching that supports moving average transform of arbitrary order. For a single index approach, we first provide the notion of poly-order moving average transform by generalizing the original definition of moving average transform. We then formally prove correctness of the poly-order transform-based subsequence matching. By using the poly-order transform, we also propose two different subsequence matching methods that support moving average transform of arbitrary order. Experimental results for real stock data show that our methods improve average performance significantly, by 22.4 ~ 33.8 times, over the sequential scan.

#index 1669956
#* Efficient mining of emerging events in a dynamic spatiotemporal environment
#@ Yu Meng;Margaret H. Dunham
#t 2006
#c 3
#% 204531
#% 310500
#% 420057
#% 449400
#% 577275
#% 730000
#% 785385
#% 1015261
#! This paper presents an efficient data mining technique for modeling multidimensional time variant data series and its suitability for mining emerging events in a spatiotemporal environment. The data is modeled using a data structure that interleaves a clustering method with a dynamic Markov chain. Novel operations are used for deleting obsolete states, and finding emerging events based on a scoring scheme. The model is incremental, scalable, adaptive, and suitable for online processing. Algorithm analysis and experiments demonstrate the efficiency and effectiveness of the proposed technique.

#index 1669957
#* A multi-hierarchical representation for similarity measurement of time series
#@ Xinqiang Zuo;Xiaoming Jin
#t 2006
#c 3
#% 227924
#% 310545
#% 310580
#% 333941
#% 460862
#% 480146
#% 631923
#% 662750
#% 769880
#% 800574
#% 823400
#% 1707869
#! In a large time series database, similarity searching is a frequent subroutine to find the similar time series of the given one. In the process, the performance of similarity measurement directly effects the usability of the searching results. The proposed methods mostly use the sum of the distances between the values on the time points, e.g. Euclidean Distance, dynamic time warping (DTW) etc. However, in measuring, they do not consider the hierarchy of each point in time series according to importance. This causes that they cannot accurately and efficiently measure similarity of time series. In the paper, we propose a Multi-Hierarchical Representation (MHR) to replace the original one based on the opinion that the points of one time series should be compared with the ones of another with the same importance in measuring. MHR gives the hierarchies of the points, and then the original one can be represented by the Multi-Hierarchical subseries, which consist of points in the same hierarchy. The distance between the representations can be computed as the measuring result. Finally, the synthetic and real data sets were used in the effectiveness experiments comparing ours with other major methods. And the comparison of their efficiencies was also performed on the real data set. All the results showed the superiority of ours in terms of effectiveness and efficiency.

#index 1669958
#* Multistep-Ahead time series prediction
#@ Haibin Cheng;Pang-Ning Tan;Jing Gao;Jerry Scripps
#t 2006
#c 3
#% 111449
#% 425030
#! Multistep-ahead prediction is the task of predicting a sequence of values in a time series. A typical approach, known as multi-stage prediction, is to apply a predictive model step-by-step and use the predicted value of the current time step to determine its value in the next time step. This paper examines two alternative approaches known as independent value prediction and parameter prediction. The first approach builds a separate model for each prediction step using the values observed in the past. The second approach fits a parametric function to the time series and builds models to predict the parameters of the function. We perform a comparative study on the three approaches using multiple linear regression, recurrent neural networks, and a hybrid of hidden Markov model with multiple linear regression. The advantages and disadvantages of each approach are analyzed in terms of their error accumulation, smoothness of prediction, and learning difficulty.

#index 1669959
#* Sequential pattern mining with time intervals
#@ Yu Hirate;Hayato Yamana
#t 2006
#c 3
#% 316552
#% 413550
#% 463903
#% 464996
#% 567606
#! Sequential pattern mining can be used to extract frequent sequences maintaining their transaction order. As conventional sequential pattern mining methods do not consider transaction occurrence time intervals, it is impossible to predict the time intervals of any two transactions extracted as frequent sequences. Thus, from extracted sequential patterns, although users are able to predict what events will occur, they are not able to predict when the events will occur. Here, we propose a new sequential pattern mining method that considers time intervals. Using Japanese earthquake data, we confirmed that our method is able to extract new types of frequent sequences that are not extracted by conventional sequential pattern mining methods.

#index 1669960
#* A wavelet analysis based data processing for time series of data mining predicting
#@ Weimin Tong;Yijun Li;Qiang Ye
#t 2006
#c 3
#% 58636
#% 333876
#% 420077
#% 501506
#% 1860422
#! This paper presents wavelet method for time series in business-field forecasting. An autoregressive moving average (ARMA) model is used, it can model the near-periodicity, nonstationarity and nonlinearity existed in business short-term time series. According to the wavelet denoising, wavelet decomposition and wavelet reconstruction, the hidden period and the nonstationarity existed in time series are extracted and separated by wavelet transformation. The characteristic of wavelet decomposition series is applied to BP networks and an autoregressive moving average (ARMA) model. It shows that the proposed method can provide more accurate results than the conventional techniques, like those only using BP networks or autoregressive moving average (ARMA) models.

#index 1669961
#* Intelligent particle swarm optimization in multi-objective problems
#@ Shinn-Jang Ho;Wen-Yuan Ku;Jun-Wun Jou;Ming-Hao Hung;Shinn-Ying Ho
#t 2006
#c 3
#% 220941
#% 784140
#% 846510
#% 964548
#% 964570
#% 1022808
#% 1022896
#% 1777083
#% 1777103
#% 1777146
#% 1777209
#% 1777304
#% 1777311
#% 1777322
#% 1781390
#% 1784753
#! In this paper, we proposes a novel intelligent multi-objective particle swarm optimization (IMOPSO) to solve multi-objective optimization problems. High performance of IMOPSO mainly arises from two parts: one is using generalized Pareto-based scale-independent fitness function (GPSISF) can efficiently given all candidate solutions a score, and then decided candidate solutions level. The other one is replacing the conventional particle move process of PSO with an intelligent move mechanism (IMM) based on orthogonal experimental design to enhance the search ability. IMM can evenly sample and analyze from the best experience of an individual particle and group particles by using a systematic reasoning method, and then efficiently generate a good candidate solution for the next move of the particle. Some benchmark functions are used to evaluate the performance of IMOPSO, and compared with some existing multi-objective evolution algorithms. According to experimental results and analysis, they show that IMOPSO performs well.

#index 1669962
#* Hidden space principal component analysis
#@ Weida Zhou;Li Zhang;Licheng Jiao
#t 2006
#c 3
#% 266426
#% 1861417
#! A new nonlinear principle component analysis (PCA) method, hidden space principal component analysis (HSPCA) is presented in this paper. Firstly, the data in the input space is mapped into a high hidden space by a nonlinear function whose role is similar to that of hidden neurons in Artificial Neural Networks. Then the goal of features extraction and data compression will be implemented by performing PCA on the mapped data in the hidden space. Compared with linear PCA method, our algorithm is a nonlinear PCA one essentially and can extract the data features more efficiently. While compared with kernel PCA method presented recently, the mapped samples are exactly known and the conditions satisfied by nonlinear mapping functions are more relaxed. The unique condition is symmetry for kernel function in HSPCA. Finally, experimental results on artificial and real-world data show the feasibility and validity of HSPCA.

#index 1669963
#* Neighbor line-based locally linear embedding
#@ De-Chuan Zhan;Zhi-Hua Zhou
#t 2006
#c 3
#% 446756
#% 642073
#% 729437
#% 775082
#% 1113093
#% 1271973
#% 1712814
#% 1778633
#% 1781626
#% 1860477
#! Locally linear embedding (Lle) is a powerful approach for mapping high-dimensional data nonlinearly to a lower-dimensional space. However, when the training examples are not densely sampled, Lle often returns invalid results. In this paper, the Nl3e (Neighbor Line-based Lle) approach is proposed, which generates some virtual examples with the help of neighbor line such that the Lle learning can be executed on an enriched training set. Experiments show that Nl3e outperforms Lle in visualization.

#index 1669964
#* Predicting rare extreme values
#@ Luis Torgo;Rita Ribeiro
#t 2006
#c 3
#% 1272000
#! Modelling extreme data is very important in several application domains, like for instance finance, meteorology, ecology, etc.. This paper addresses the problem of predicting extreme values of a continuous variable. The main distinguishing feature of our target applications resides on the fact that these values are rare. Any prediction model is obtained by some sort of search process guided by a pre-specified evaluation criterion. In this work we argue against the use of standard criteria for evaluating regression models in the context of our target applications. We propose a new predictive performance metric for this class of problems that our experiments show to perform better in distinguishing models that are more accurate at rare extreme values. This new evaluation metric could be used as the basis for developing better models in terms of rare extreme values prediction.

#index 1669965
#* Domain-Driven actionable knowledge discovery in the real world
#@ Longbing Cao;Chengqi Zhang
#t 2006
#c 3
#% 338592
#% 345858
#% 438134
#% 452846
#% 575985
#% 577214
#% 748028
#% 829253
#% 1720563
#! Actionable knowledgediscovery is one of Grand Challenges in KDD. To this end, many methodologies have been developed. However, they either view data mining as an autonomous data-driven trial-and-error process, or only analyze the issues in an isolated and case-by-case manner. As a result, the knowledge discovered is often not actionable to constrained business. This paper proposes a practical perspective, referred to as domain-driven in-depth pattern discovery (DDID-PD). It presents a domain-driven view of discovering knowledge satisfying real business needs. Its main ideas include constraint mining, in-depth mining, human-cooperated mining, and loop-closed mining. We demonstrate its deployment in mining actionable trading strategies in Australian Stock Exchange data.

#index 1669966
#* Evaluation of attribute-aware recommender system algorithms on data with varying characteristics
#@ Karen H. L. Tso;Lars Schmidt-Thieme
#t 2006
#c 3
#% 124010
#% 220711
#% 266281
#% 280447
#% 280852
#% 283169
#% 304425
#% 314933
#% 481290
#% 528182
#% 578684
#% 734594
#% 770816
#% 844329
#% 854878
#% 979690
#% 1674709
#! The growth of Internet commerce has provoked the use of Recommender Systems (RS). Adequate datasets of users and products have always been demanding to better evaluate RS algorithms. Yet, the amount of public data, especially data containing content information (attributes) is limited. In addition, the performance of RS is highly dependent on various characteristics of the datasets. Thus, few others have conducted studies on synthetically generated datasets to mimic the user-product relationship. Evaluating algorithms based on only one or two datasets is often not sufficient. A more thorough analysis can be conducted by applying systematic changes to data, which cannot be done with real data. However, synthetic datasets that include attributes are rarely investigated. In this paper, we review synthetic datasets applied in RS and present our synthetic data generation methodology that considers attributes. Furthermore, we conduct empirical evaluations on existing hybrid recommendation algorithms and other state-of-the-art algorithms using these variable synthetic data and observe their behavior as the characteristic of data varies. In addition, we also introduce the use of entropy to control the randomness of the generated data.

#index 1669967
#* An intelligent system based on kernel methods for crop yield prediction
#@ A. Majid Awan;Mohd. Noor Md. Sap
#t 2006
#c 3
#% 190581
#% 266426
#% 393059
#% 722810
#% 769935
#% 770830
#% 800199
#% 849007
#% 1860974
#% 1861034
#! This paper presents work on developing a software system for predicting crop yield from climate and plantation data. At the core of this system is a method for unsupervised partitioning of data for finding spatio-temporal patterns in climate data using kernel methods which offer strength to deal with complex data. For this purpose, a robust weighted kernel k-means algorithm incorporating spatial constraints is presented. The algorithm can effectively handle noise, outliers and auto-correlation in the spatial data, for effective and efficient data analysis, and thus can be used for predicting oil-palm yield by analyzing various factors affecting the yield.

#index 1669968
#* A machine learning application for human resource data mining problem
#@ Zhen Xu;Binheng Song
#t 2006
#c 3
#% 168059
#% 185240
#% 341700
#% 376266
#% 421198
#% 576571
#! Apply machine learning methods to data mining domain can be more helpful to extract useful knowledge for problems with changing conditions. Human resource allocation is a kind of problem in data mining domain. It presents machine learning techniques to dissolve it. First, we construct a new model which optimizes the multi-objectives allocation problem by using fuzzy logic strategy. One of the most important problems in the model is how to get the precise individual capability matrixes. Machine learning method by being told is well used to settle the problem in this paper. In the model, appraisal values about employees are saved in knowledge warehouse. Before tasks allocation, machine learning approach provides the capability matrixes based on the existing data sets. Then Task-Arrange or Hungarian Algorithm provides the final solution with our proposed matrixes. After present tasks are finished, machine learning method by being told can update the matrixes according to the suggestions on employees' performance provided by the specialists. Useful knowledge can be well mined in cycles by learning approach. As a numerical example demonstrated, it is helpful to make a realistic decision on human resource allocation under a dynamic environment for organizations.

#index 1669969
#* Towards automated design of large-scale circuits by combining evolutionary design with data mining
#@ Shuguang Zhao;Mingying Zhao;Jun Zhao;Licheng Jiao
#t 2006
#c 3
#% 124073
#% 369236
#% 421135
#% 421145
#% 586604
#% 1674262
#% 1776252
#! As an important branch of evolvable hardware, evolutionary design of circuit (EDC) is a promising way to realize automated design of complex electronic circuits. To improve EDC in efficiency, scalability and capability of optimization, a novel technique was developed. It features an adaptive multi-objective genetic algorithm and interactions between EDC and data mining. It was validated by the experiments on arithmetic circuits, showing some exciting results. Some circuits evolved are the best ones ever reported in terms of gate count and operating speed. Moreover, some novel knowledge, e.g., efficient and scalable design formulae and generalized transform rules have been discovered by mining the data and results of EDC, which are easy to verify but difficult to dig out by human experts with existing knowledge.

#index 1669970
#* Mining unexpected associations for signalling potential adverse drug reactions from administrative health databases
#@ Huidong Jin;Jie Chen;Chris Kelman;Hongxing He;Damien McAullay;Christine M. O'Keefe
#t 2006
#c 3
#% 310505
#% 729934
#% 823417
#! Adverse reactions to drugs are a leading cause of hospitalisation and death worldwide. Most post-marketing Adverse Drug Reaction (ADR) detection techniques analyse spontaneous ADR reports which underestimate ADRs significantly. This paper aims to signal ADRs from administrative health databases in which data are collected routinely and are readily available. We introduce a new knowledge representation, Unexpected Temporal Association Rules (UTARs), to describe patterns characteristic of ADRs. Due to their unexpectedness and infrequency, existing techniques cannot perform effectively. To handle this unexpectedness we introduce a new interestingness measure, unexpected-leverage, and give a user-based exclusion technique for its calculation. Combining it with an event-oriented data preparation technique to handle infrequency, we develop a new algorithm, MUTARA, for mining simple UTARs. MUTARA effectively short-lists some known ADRs such as the disease esophagitis unexpectedly associated with the drug alendronate. Similarly, MUTARA signals atorvastatin followed by nizatidine or dicloxacillin which may be prescribed to treat its side effects stomach ulcer or urinary tract infection, respectively. Compared with association mining techniques, MUTARA signals potential ADRs more effectively.

#index 1707779
#* Proceedings of the 9th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining
#@ Tu Bao Ho;David Cheung;Huan Liu
#t 2005
#c 3

#index 1707780
#* Machine learning for analyzing human brain function
#@ Tom Mitchell
#t 2005
#c 3
#! A major opportunity for knowledge discovery and data mining over the coming decade is to accelerate scientific discovery by providing new computer tools to analyze experimental data. Scientific fields from astronomy to cell biology to neuroscience now collect experimental data sets that are huge when compared to the data sets available just a decade ago. New data mining tools are needed to interpret these new data sets. This talk presents our own research in one such scientific subfield: studying the operation of the human brain using functional Magnetic Resonance Imaging (fMRI). A typical fMRI experiment captures three-dimensional images of human brain activity, once per second, at a spatial resolution of a few millimeters, providing a 3D movie of brain activity. We present our recent research exploring the question of how best to analyze fMRI data to study human cognitive processes. We will first describe our recent successes training machine learning classifiers to distinguish cognitive subprocesses based on observed fMRI images. For example, we have been able to train classifiers to discriminate whether a person is reading words about tools, or words about buildings, based on their observed fMRI brain activation. We will then introduce an algorithm for learning a new class of probabilistic time series models called Hidden Process Models, and discuss their use for tracking multiple hidden cognitive processes from observed fMRI brain image data.

#index 1707781
#* Subgroup discovery techniques and applications
#@ Nada Lavrač
#t 2005
#c 3
#% 232136
#% 331909
#% 449566
#% 477497
#% 478615
#% 763701
#% 793063
#% 1272357
#! This paper presents the advances in subgroup discovery and the ways to use subgroup discovery to generate actionable knowledge for decision support. Actionable knowledge is explicit symbolic knowledge, typically presented in the form of rules, that allow the decision maker to recognize some important relations and to perform an appropriate action, such as planning a population screening campaign aimed at detecting individuals with high disease risk. Two case studies from medicine and functional genomics are used to present the lessons learned in solving problems requiring actionable knowledge generation for decision support.

#index 1707782
#* IT development in the 21st century and its implications
#@ Unna Huh
#t 2005
#c 3
#! This talk discusses general IT development in the 21st century and its positive and negative effects. It also talks about Korea's IT development and makes suggestions for Korea's further advances in IT. The three keywords to describe the IT development in the 21st century are digitalization, convergence, and ubiquitous revolution. This IT development has presented new opportunities for our society, corporations and individuals while posing a threat to us. That is, IT revolution may dramatically improve the quality of human life and allow amazing degree of comfort in our lives, but like a double-edged sword, IT may also be misused and have disastrous impacts on our daily lives, such as invasion of privacy, leakage and abuse of personal information, and hacking. In dealing with these problems, technological advances alone may not be sufficient. There is a need for innovative education regionally and worldwide to cultivate wisdom in U-citizens so that they can use the modern convenience of IT with strong ethics. We also need to establish new laws and societal systems appropriate for the ubiquitous era.

#index 1707783
#* Data mining of gene expression microarray via weighted prefix trees
#@ Tran Trang;Nguyen Cam Chi;Hoang Ngoc Minh
#t 2005
#c 3
#% 205024
#% 1015488
#% 1786711
#% 1786712
#! We used discrete combinatoric methods and non numerical algorithms [9], based on weighted prefix trees, to examine the data mining of DNA microarray data, in order to capture biological or medical informations and extract new knowledge from these data. We describe hierarchical cluster analysis of DNA microarray data using structure of weighted trees in two manners : classifying the degree of overlap between different microarrays and classifying the degree of expression levels between different genes. These are most efficiently done by finding the characteristic genes and microarrays with the maximum degree of overlap and determining the group of candidate genes suggestive of a pathology.

#index 1707784
#* Automatic extraction of low frequency bilingual word pairs from parallel corpora with various languages
#@ Hiroshi Echizen-ya;Kenji Araki;Yoshio Momouchi
#t 2005
#c 3
#% 211043
#% 279755
#% 757787
#% 815311
#% 939797
#! In this paper, we propose a new learning method for extraction of low-frequency bilingual word pairs from parallel corpora with various languages. It is important to extract low-frequency bilingual word pairs because the frequencies of many bilingual word pairs are very low when large-scale parallel corpora are unobtainable. We use the following inference to extract low frequency bilingual word pairs: the word equivalents that adjoin the source language words of bilingual word pairs also adjoin the target language words of bilingual word pairs in local parts of bilingual sentence pairs. Evaluation experiments indicated that the extraction rate of our system was more than 8.0 percentage points higher than the extraction rate of the system based on the Dice coefficient. Moreover, the extraction rates of bilingual word pairs for which the frequencies are one and two respectively improved 11.0 and 6.6 percentage points using AIL.

#index 1707785
#* A kernel function method in clustering
#@ Ling Zhang;Tao Wu;Yanping Zhang
#t 2005
#c 3
#% 36672
#% 296738
#% 444006
#% 501525
#% 1860526
#% 1860543
#% 1860761
#% 1860974
#% 1861189
#! Cluster analysis is one of main methods used in data mining. So far there have existed many cluster analysis approaches such as partitioning method, density-based, k-means, k-nearest neighborhood, etc. Recently, some researchers have explored a few kernel-based clustering methods, e.g., kernel-based K-means clustering. The new algorithms have demonstrated some advantages. So it's needed to explore the basic principle underlain the algorithms such as whether the kernel function transformation can increase the separability of the input data in clustering and how to use the principle to construct new clustering methods. In this paper, we will discuss the problems.

#index 1707786
#* Performance measurements for privacy preserving data mining
#@ Nan Zhang;Wei Zhao;Jianer Chen
#t 2005
#c 3
#% 300184
#% 333876
#% 576111
#% 653942
#% 729962
#% 751578
#% 769970
#! This paper establishes the foundation for the performance measurements of privacy preserving data mining techniques. The performance is measured in terms of the accuracy of data mining results and the privacy protection of sensitive data. On the accuracy side, we address the problem of previous measures and propose a new measure, named “effective sample size”, to solve this problem. We show that our new measure can be bounded without any knowledge of the data being mined, and discuss when the bound can be met. On the privacy protection side, we identify a tacit assumption made by previous measures and show that the assumption is unrealistic in many situations. To solve the problem, we introduce a game theoretic framework for the measurement of privacy.

#index 1707787
#* Extraction of frequent few-overlapped monotone DNF formulas with depth-first pruning
#@ Yoshikazu Shima;Kouichi Hirata;Masateru Harao
#t 2005
#c 3
#% 232102
#% 232136
#% 333877
#% 464873
#% 465003
#% 466491
#% 481290
#% 498786
#% 502141
#% 733265
#! In this paper, first we introduce frequent few-overlapped monotone DNF formulas under the minimum supportσ, the minimum term supportτ and the maximum overlapλ. We say that a monotone DNF formula is frequent if the support of it is greater than σ and the support of each term (or itemset) in it is greater than τ, and few-overlapped if the overlap of it is less than λ and λ τ.Then, we design the algorithm ffo_dnf to extract them. The algorithm ffo_dnf first enumerates all of the maximal frequent itemsets under τ, and secondly connects the extracted itemsets by a disjunction ∨ until satisfying σ and λ. The first step of ffo_dnf, called a depth-first pruning, follows from the property that every pair of itemsets in a few-overlapped monotone DNF formula is incomparable under a subset relation. Furthermore, we show that the extracted formulas by ffo_dnf are representative.Finally, we apply the algorithm ffo_dnf to bacterial culture data.

#index 1707788
#* Rule extraction from trained support vector machines
#@ Ying Zhang;HongYe Su;Tao Jia;Jian Chu
#t 2005
#c 3
#% 92555
#% 182682
#% 190581
#% 191910
#% 393059
#% 420077
#% 1477339
#! Support vector machine (SVM) is applied to many research fields because of its good generalization ability and solid theoretical foundation. However, as the model generated by SVM is like a black box, it is difficult for user to interpret and understand how the model makes its decision. In this paper, a hyperrectangle rules extraction (HRE) algorithm is proposed to extract rules from trained SVM. Support vector clustering (SVC) algorithm is used to find the prototypes of each class, then hyperrectangles are constructed according to the prototypes and the support vectors (SVs) under some heuristic conditions. When the hyperrectangles are projected onto coordinate axes, the if-then rules are obtained. Experimental results indicate that HRE algorithm can extract rules efficiently from trained SVM and the number and support of obtained rules can be easily controlled according to a user-defined minimal support threshold.

#index 1707789
#* Pruning derivative partial rules during impact rule discovery
#@ Shiying Huang;Geoffrey I. Webb
#t 2005
#c 3
#% 152934
#% 227919
#% 280433
#% 280458
#% 310494
#% 342640
#% 420112
#% 420126
#% 536291
#% 1272179
#! Because exploratory rule discovery works with data that is only a sample of the phenomena to be investigated, some resulting rules may appear interesting only by chance. Techniques are developed for automatically discarding statistically insignificant exploratory rules that cannot survive a hypothesis with regard to its ancestors. We call such insignificant rules derivative extended rules. In this paper, we argue that there is another type of derivative exploratory rules, which is derivative with regard to their children. We also argue that considerable amount of such derivative partial rules can not be successfully removed using existing rule pruning techniques. We propose a new technique to address this problem. Experiments are done in impact rule discovery to evaluate the effect of this derivative partial rule filter. Results show that the inherent problem of too many resulting rules in exploratory rule discovery is alleviated.

#index 1707790
#* IGB: a new informative generic base of association rules
#@ Gh. Gasmi;S. Ben Yahia;E. Mephu Nguifo;Y. Slimani
#t 2005
#c 3
#% 501193
#% 536291
#% 546698
#% 577214
#% 785491
#! The problem of the relevance and the usefulness of extracted association rules is becoming paramount, since an overwhelming number of association rules may be derived from even reasonably sized real-life databases. A possible solution consists in using results of Formal Concept Analysis to generate a generic base of association rules. This set, of reduced size, makes it possible to derive all the association rules via an adequate axiomatic system. In this paper, we introduce a novel generic and informative base of association rules, conveying two types of knowledge: “factual” and “implicative”. We present also a valid and complete axiomatic system allowing to derive the set of all association rules. Results of the experiments carried out on real-life databases showed important profits in terms of compactness of the introduced generic base.

#index 1707791
#* A divide and conquer approach for deriving partially ordered sub-structures
#@ S. Ben Yahia;Y. Slimani;J. Rezgui
#t 2005
#c 3
#% 279120
#% 300120
#% 429873
#! The steady growth in the size of data has encouraged the emergence of advanced main memory trie-based data structures. Concurrently, more acute knowledge extraction techniques are devised for the discovery of compact and lossless knowledge formally expressed by generic bases. In this paper, we present an approach for deriving generic bases of association rules. Using this approach, we construct small partially ordered sub-structures. Then, these ordered sub-structures are parsed to derive, in a straightforward manner, local generic association bases. Finally, local bases are merged to generate the global one. Extensive experiments carried out essentially showed that the proposed data structure allows to generate a more compact representation of an extraction context comparatively to existing approaches in literature.

#index 1707792
#* Finding sporadic rules using apriori-inverse
#@ Yun Sing Koh;Nathan Rountree
#t 2005
#c 3
#% 152934
#% 280433
#% 280487
#% 443393
#% 481290
#% 717219
#! We define sporadic rules as those with low support but high confidence: for example, a rare association of two symptoms indicating a rare disease. To find such rules using the well-known Apriori algorithm, minimum support has to be set very low, producing a large number of trivial frequent itemsets. We propose “Apriori-Inverse”, a method of discovering sporadic rules by ignoring all candidate itemsets above a maximum support threshold. We define two classes of sporadic rule: perfectly sporadic rules (those that consist only of items falling below maximum support) and imperfectly sporadic rules (those that may contain items over the maximum support threshold). We show that Apriori-Inverse finds all perfectly sporadic rules much more quickly than Apriori. We also propose extensions to Apriori-Inverse to allow us to find some (but not necessarily all) imperfectly sporadic rules.

#index 1707793
#* Automatic view selection: an application to image mining
#@ Manoranjan Dash;Deepak Kolippakkam
#t 2005
#c 3
#% 243727
#% 300120
#% 464457
#! In this paper we discuss an image mining application of Egeria detection. Egeria is a type of weed found in various lands and water regions over San Joaquin and Sacramento deltas. The challenge is to find a view to accurately detect the weeds in new images. Our solution contributes two new aspects to image mining. (1) Application of view selection to image mining: View selection is appropriate when a specific learning task is to be learned. For example, to look for an object in a set of images, it is useful to select the appropriate views (a view is a set of features and their assigned values). (2) Automatic view selection for accurate detection: Usually classification problems rely on user-defined views. But in this work we use association rule mining to automatically select the best view. Results show that the selected view outperforms other views including the full view.

#index 1707794
#* Pushing tougher constraints in frequent pattern mining
#@ Francesco Bonchi;Claudio Lucchese
#t 2005
#c 3
#% 248785
#% 273899
#% 300120
#% 310558
#% 438134
#% 464989
#% 481290
#% 576117
#% 577215
#% 632028
#% 727876
#% 785336
#% 998627
#! In this paper we extend the state-of-art of the constraints that can be pushed in a frequent pattern computation. We introduce a new class of tough constraints, namely Loose Anti-monotone constraints, and we deeply characterize them by showing that they are a superclass of convertible anti-monotone constraints (e.g. constraints on average or median) and that they model tougher constraints (e.g. constraints on variance or standard deviation). Then we show how these constraints can be exploited in a level-wise Apriori-like computation by means of a new data-reduction technique: the resulting algorithm outperforms previous proposals for convertible constraints, and it is to treat much tougher constraints with the same effectiveness of easier ones.

#index 1707795
#* An efficient compression technique for frequent itemset generation in association rule mining
#@ Mafruz Zaman Ashrafi;David Taniar;Kate Smith
#t 2005
#c 3
#% 152934
#% 201894
#% 300120
#% 300124
#% 434348
#% 443350
#% 465003
#% 481290
#% 481754
#% 729920
#% 729942
#! Association Rule mining is one of the widely used data mining techniques. To achieve a better performance, many efficient algorithms have been proposed. Despite these efforts, we are often unable to complete a mining task because these algorithms require a large amount of main memory to enumerate all frequent itemsets, especially when dataset is large or the user-specified support is low. Thus, it becomes apparent that we need to have an efficient main memory handling technique, which allows association rule mining algorithms to handle larger datasets in main memory. To achieve this goal, in this paper we propose an algorithm for vertical association rule mining that compresses a vertical dataset in an efficient manner, using bit vectors. Our performance evaluations show that the compression ratio attained by our proposed technique is better than those of the other well known techniques.

#index 1707796
#* Mining time-profiled associations: an extended abstract
#@ Jin Soung Yoo;Pusheng Zhang;Shashi Shekhar
#t 2005
#c 3
#% 172949
#% 334059
#% 460862
#% 464839
#% 481290
#% 664910
#! A time-profiled association is an association pattern consistent with a query sequence over time, e.g., identifying the interacting relationship of droughts and wild fires in Australia with the El Nino phenomenon in the past 50 years. Traditional association rule mining approaches reveal the generic dependency among variables in association patterns but do not capture the evolution of these patterns over time. Incorporating the temporal evolution of association patterns and identifying the co-occurring patterns consistent over time can be done by time-profiled association mining. Mining time-profiled associations is computationally challenging due to the large size of the itemset space and the long time points in practice. In this paper, we propose a novel one-step algorithm to unify the generation of statistical parameter sequences and sequence retrieval. The proposed algorithm substantially reduces the itemset search space by pruning candidate itemsets based on the monotone property of the lower bounding measure of the sequence of statistical parameters. Experimental results show that our algorithm outperforms a naive approach.

#index 1707797
#* Online algorithms for mining inter-stream associations from large sensor networks
#@ K. K. Loo;Ivy Tong;Ben Kao
#t 2005
#c 3
#% 660004
#% 993949
#% 993960
#! We study the problem of mining frequent value sets from a large sensor network. We discuss how sensor stream data could be represented that facilitates efficient online mining and propose the interval-list representation. Based on Lossy Counting, we propose ILB, an interval-list-based online mining algorithm for discovering frequent sensor value sets. Through extensive experiments, we compare the performance of ILB against an application of Lossy Counting (LC) using a weighted transformation method. Results show that ILB outperforms LC significantly for large sensor networks.

#index 1707798
#* Mining frequent ordered patterns
#@ Zhi-Hong Deng;Cong-Rui Ji;Ming Zhang;Shi-Wei Tang
#t 2005
#c 3
#% 152934
#% 227919
#% 300120
#% 443350
#% 463903
#% 481290
#% 631926
#! Mining frequent patterns has been studied popularly in data mining research. All of previous studies assume that items in a pattern are unordered. However, the order existing between items must be considered in some applications. In this paper, we first give the formal model of ordered patterns and discuss the problem of mining frequent ordered patterns. Base on our analyses, we present two efficient algorithms for mining frequent ordered patterns. We also present results of applying these algorithms to a synthetic data set, which show the effectiveness of our algorithms.

#index 1707799
#* Conditional random fields for transmembrane helix prediction
#@ Lior Lukov;Sanjay Chawla;W. Bret Church
#t 2005
#c 3
#% 191603
#% 359093
#% 464434
#! It is estimated that 20% of genes in the human genome encode for integral membrane proteins (IMPs) and some estimates are much higher. IMPs control a broad range of events essential to the proper functioning of cells, tissues and organisms and are the most common target of clinically useful drugs [1]. However there is a dearth of high-resolution 3D structural information on the IMPs. Therefore good prediction methods of IMPs structures are to be highly valued. In this paper we apply Conditional Random Fields (CRFs) to build a probabilistic model to solve the membrane protein helix prediction problem. The advantage of CRFs is that it allows seamless and principled integration of biological domain knowledge into the model. Our results show that the CRF model outperforms other well known helix prediction approaches on several important measures.

#index 1707800
#* A DNA index structure using frequency and position information of genetic alphabet
#@ Woo-Cheol Kim;Sanghyun Park;Jung-Im Won;Sang-Wook Kim;Jee-Hee Yoon
#t 2005
#c 3
#% 174226
#% 235941
#% 320454
#% 321327
#% 427199
#% 480482
#% 481956
#! Exact match queries, wildcard match queries, and k-mismatch queries are widely used in lots of molecular biology applications including the searching of ESTs (Expressed Sequence Tag) and DNA transcription factors. In this paper, we suggest an efficient indexing and processing mechanism for such queries. Our indexing method places a sliding window at every possible location of a DNA sequence and extracts its signature by considering the occurrence frequency of each nucleotide. It then stores a set of signatures using a multi-dimensional index, such as the R*-tree. Also, by assigning a weight to each position of a window, it prevents signatures from being concentrated around a few spots in indexing space. Our query processing method converts a query sequence into a multi-dimensional rectangle and searches the index for the signatures overlapped with the rectangle.

#index 1707801
#* An automatic unsupervised querying algorithm for efficient information extraction in biomedical domain
#@ Min Song;Il-Yeol Song;Xiaohua Hu;Robert B. Allen
#t 2005
#c 3
#% 235288
#% 283138
#% 443052
#% 453324
#% 729880
#! In the domain of bioinformatics, extracting a relation such as protein-protein interations from a large database of text documents is a challenging task. One major issue with biomedical information extraction is how to efficiently digest the sheer size of unstructured biomedical data corpus. Often, among these huge biomedical data, only a small fraction of the documents contain information that is relevant to the extraction task. We propose a novel query expansion algorithm to automatically discover the characteristics of documents that are useful for extraction of a target relation. Our technique introduces a hybrid query re-weighting algorithm combining the modified Robertson Sparck-Jones query ranking algorithm with a keyphrase extraction algorithm. Our technique also adopts a novel query translation technique that incorporates POS categories to query translation. We conduct a series of experiments and report the experimental results. The results show that our technique is able to retrieve more documents that contain protein-protein pairs from MEDLINE as iteration increases. Our technique is also compared with SLIPPER, a supervised rule-based query expansion technique. The results show that our technique outperforms SLIPPER from 17.90% to 29.98 better in four iterations.

#index 1707802
#* Voting fuzzy k-NN to predict protein subcellular localization from normalized amino acid pair compositions
#@ Thai Quang Tung;Doheon Lee;Dae-Won Kim;Jong-Tae Lim
#t 2005
#c 3
#% 729437
#% 830380
#! There are a huge number of protein sequences in databanks whose functions are not known. Since the biological functions of these proteins are closely correlated with their subcellular localization, it is important to develop a system to automatically predict subcellular localization from sequences for large-scale genome analysis. In this paper, we first propose a new formula to estimate the composition of amino acid pairs for feature extraction, and then we present a voting scheme that combines a set of fuzzy k-nearest-neighbor (k-NN) classifiers to predict subcellular locations. In order to detect sequence-order features, individual classifier is constructed using different types of features, including amino acid and amino acid pair compositions. We apply our method to several datasets and significant improvements are achieved.

#index 1707803
#* Comparison of tree based methods on mammography data
#@ Richard De Veaux;Thu Hoàng
#t 2005
#c 3
#% 73372
#% 209021
#! X-ray film mammography and physical examination of the breast are the mainstays for early detection of breast cancer. Unfortunately, error rates for mammograms read by radiologists are high. We examine a particularly difficult to read series of 1618 mammograms where in order to achieve a false positive rate lower than 50%, the false negative rate of radiologists is nearly 25%. We examine a variety of automatic data mining tools in an attempt to improve the accuracy of the diagnosis. Our results suggest that roughly the same or higher accuracy rate than the radiologists can be attained at a much reduced cost. This potential cost savings could have a major financial impact for health care in developing nations.

#index 1707804
#* Bayesian sequence learning for predicting protein cleavage points
#@ Michael Mayo
#t 2005
#c 3
#% 290482
#% 471740
#% 481734
#! A challenging problem in data mining is the application of efficient techniques to automatically annotate the vast databases of biological sequence data. This paper describes one such application in this area, to the prediction of the position of signal peptide cleavage points along protein sequences. It is shown that the method, based on Bayesian statistics, is comparable in terms of accuracy to the existing state-of-the-art neural network techniques while providing explanatory information for its predictions.

#index 1707805
#* A novel indexing method for efficient sequence matching in large DNA database environment
#@ Jung-Im Won;Jee-Hee Yoon;Sanghyun Park;Sang-Wook Kim
#t 2005
#c 3
#% 86950
#% 174226
#% 443055
#% 443469
#% 451770
#% 546101
#% 607874
#% 1015330
#! In molecular biology, DNA sequence matching is one of the most crucial operations. Since DNA databases contain a huge volume of sequences, fast indexes are essential for efficient processing of DNA sequence matching. In this paper, we first point out the problems of the suffix tree, an index structure widely-used for DNA sequence matching, in the respects of the storage overhead, search performance, and difficulty in seamless integration with DBMS. Then, we propose a new index structure that resolves such problems. The proposed index structure consists of the two parts: the primary part realizes the trie as binary bit-string representation without any pointers, and the secondary part helps fast accesses of leaf nodes of the trie that need to be accessed for post-processing. We also suggest efficient algorithms based on that index for DNA sequence matching. To verify the superiority of the proposed approach, we conduct performance evaluation via a series of experiments. The results reveal that the proposed approach, which requires smaller storage space, can be a few orders of magnitude faster than the suffix tree.

#index 1707806
#* Threshold tuning for improved classification association rule mining
#@ Frans Coenen;Paul Leng;Lu Zhang
#t 2005
#c 3
#% 136350
#% 152934
#% 300120
#% 458257
#% 466483
#% 478448
#% 481290
#! One application of Association Rule Mining (ARM) is to identify Classification Association Rules (CARs) that can be used to classify future instances from the same population as the data being mined. Most CARM methods first mine the data for candidate rules, then prune these using coverage analysis of the training data. In this paper we describe a CARM algorithm that avoids the need for coverage analysis, and a technique for tuning its threshold parameters to obtain more accurate classification. We present results to show this approach can achieve better accuracy than comparable alternatives at lower cost.

#index 1707807
#* Using rough set in feature selection and reduction in face recognition problem
#@ Le Hoai Bac;Nguyen Anh Tuan
#t 2005
#c 3
#% 347878
#! Feature selection and reduction are fundamental steps in pattern recognition problems. The idea of reducts in rough set theory has encouraged many researchers in studying the effectiveness of rough set theory in the problem mentioned above. Through results of experiments in this article, we will show that rough set theory, accompanied by appropriate heuristics, can increase significantly the system's recognition accuracy.

#index 1707808
#* Analysis of company growth data using genetic algorithms on binary trees
#@ Gerrit K. Janssens;Kenneth Sösrensen;Arthur Limère;Koen Vanhoof
#t 2005
#c 3
#% 124074
#% 136350
#% 224592
#% 412460
#% 443082
#% 449588
#! This paper investigates why some companies grow faster than others, by data mining a survey of a large number of companies in Flanders (the northern part of Belgium). Faster or slower average growth over a time period is explained by building a classification tree containing several categorical variables (both quantitative and qualitative). The technique used – called genAID – splits the population at different levels. It is inspired by the Automatic Interaction Detector (AID) technique to find trees that explain the variability in average growth but uses a genetic algorithm to overcome some of the drawbacks of AID. Classical AID or other tree-growing techniques usually generate a single tree for interpretation. This approach has been criticized because, due to the artifacts of data, spurious interactions may occur. genAID offers the user-analyst a set of trees, which are the best ones found over a number of generations of the genetic algorithm. The user-analyst is then offered the choice of choosing a tree by trading off explanatory power against either the ease of understanding or the conformity with an existing theory.

#index 1707809
#* Considering re-occurring features in associative classifiers
#@ Rafal Rak;Wojciech Stach;Osmar R. Zaïane;Maria-Luiza Antonie
#t 2005
#c 3
#% 300120
#% 396747
#% 466483
#% 629642
#% 632037
#% 764481
#! There are numerous different classification methods; among the many we can cite associative classifiers. This newly suggested model uses association rule mining to generate classification rules associating observed features with class labels. Given the binary nature of association rules, these classification models do not take into account repetition of features when categorizing. In this paper, we enhance the idea of associative classifiers with associations with re-occurring items and show that this mixture produces a good model for classification when repetition of observed features is relevant in the data mining application at hand.

#index 1707810
#* A new evolutionary neural network classifier
#@ Arit Thammano;Asavin Meengen
#t 2005
#c 3
#% 292863
#% 316709
#% 733620
#! This paper proposes two new concepts: (1) the new evolutionary algorithm and (2) the new approach to deal with the classification problems by applying the concepts of the fuzzy c-means algorithm and the evolutionary algorithm to the artificial neural network. During training, the fuzzy c-means algorithm is initially used to form the clusters in the cluster layer; then the evolutionary algorithm is employed to optimize those clusters and their parameters. During testing, the class whose cluster node returns the maximum output value is the result of the prediction. This proposed model has been benchmarked against the standard backpropagation neural network, the fuzzy ARTMAP, C4.5, and CART. The results on six benchmark problems are very encouraging.

#index 1707811
#* A privacy-preserving classification mining algorithm
#@ Weiping Ge;Wei Wang;Xiaorong Li;Baile Shi
#t 2005
#c 3
#% 300184
#% 333876
#% 480940
#% 512307
#% 729962
#! Privacy-preserving classification mining is one of the fast-growing sub-areas of data mining. How to perturb original data and then build a decision tree based on perturbed data is the key research challenge. By applying transition probability matrix this paper proposes a novel privacy-preserving classification mining algorithm which suits all data types, arbitrary probability distribution of original data, and perturbing all attributes (including label attribute). Experimental results demonstrate that decision tree built using this algorithm on perturbed data has comparable classifying accuracy to decision tree built using un-privacy-preserving algorithm on original data.

#index 1707812
#* Combining classifiers with multi-representation of context in word sense disambiguation
#@ Cuong Anh Le;Van-Nam Huynh;Akira Shimazu
#t 2005
#c 3
#% 251145
#% 741080
#% 741085
#% 741837
#% 742209
#% 748601
#% 748703
#% 854628
#% 854639
#% 939778
#! In this paper, we first argue that various ways of using context in WSD can be considered as distinct representations of a polysemous word under consideration, then all these representations are used jointly to identify the meaning of the target word. Under such a consideration, we can then straightforwardly apply the general framework for combining classifiers developed in Kittler et al. [5] to WSD problem. This results in many commonly used decision rules for WSD. The experimental result shows that the multi-representation based combination strategy of classifiers outperform individual ones as well as known techniques of classifier combination in WSD.

#index 1707813
#* Automatic occupation coding with combination of machine learning and hand-crafted rules
#@ Kazuko Takahashi;Hiroya Takamura;Manabu Okumura
#t 2005
#c 3
#% 132938
#% 269221
#% 344447
#% 458379
#% 728353
#% 817481
#% 855289
#! We apply a machine learning method to the occupation coding, which is a task to categorize the answers to open-ended questions regarding the respondent's occupation. Specifically, we use Support Vector Machines (SVMs) and their combination with hand-crafted rules. Conducting the occupation coding manually is expensive and sometimes leads to inconsistent coding results when the coders are not experts of the occupation coding. For this reason, a rule-based automatic method has been developed and used. However, its categorization performance is not satisfiable. Therefore, we adopt SVMs, which show high performance in various fields, and compare it with the rule-based method. We also investigate effective combination methods of SVMs and the rule-based method. In our methods, the output of the rule-based method is used as features for SVMs. We empirically show that SVMs outperform the rule-based method in the occupation coding and that the combination of the two methods yields even better accuracy.

#index 1707814
#* Retrieval based on language model with relative entropy and feedback
#@ Hua Huo;Boqin Feng
#t 2005
#c 3
#% 115608
#% 262096
#% 280850
#% 280864
#% 340948
#% 342707
#% 642974
#% 766430
#! A new method for information retrieval which is on the basis of language model with relative entropy and feedback is presented in this paper. The method builds a query language model and document language models respectively for the query and the documents. We rank the documents according to the relative entropies of the estimated document language models with respect to the estimated query language model. The feedback documents are used to estimate a query model by the approach that we assume that the feedback documents are generated by a combined model in which one component is the feedback document language model and the other is the collection language model. Experimental results show that the method is effective for feedback documents and performs better than the basic language modeling approach. The results also indicate that the performance of the method is sensitive to both the smoothing parameters and the interpolation coefficients used to estimate the values of the language models.

#index 1707815
#* Text classification for DAG-Structured categories
#@ Cao D. Nguyen;Tran A. Dung;Tru H. Cao
#t 2005
#c 3
#% 190581
#% 269221
#% 290482
#% 309141
#% 309208
#% 318412
#% 375017
#% 402289
#% 458379
#% 465747
#% 466078
#% 466501
#% 1558464
#! Hierarchical text classification concerning the relationship among categories has become an interesting problem recently. Most research has focused on tree-structured categories, but in reality directed acyclic graph (DAG) – structured categories, where a child category may have more than one parent category, appear more often. In this paper, we introduce three approaches, namely, flat, tree-based, and DAG-based, for solving the multi-label text classification problem in which categories are organized as a DAG, and documents are classified into both leaf and internal categories. We also present experimental results of the methods using SVMs as classifiers on the Reuters-21578 collection and our data set of research papers in Artificial Intelligence.

#index 1707816
#* Sentiment classification using word sub-sequences and dependency sub-trees
#@ Shotaro Matsumoto;Hiroya Takamura;Manabu Okumura
#t 2005
#c 3
#% 260001
#% 464996
#% 478622
#% 577355
#% 742218
#% 746885
#% 815915
#% 854646
#% 938687
#! Document sentiment classification is a task to classify a document according to the positive or negative polarity of its opinion (favorable or unfavorable). We propose using syntactic relations between words in sentences for document sentiment classification. Specifically, we use text mining techniques to extract frequent word sub-sequences and dependency sub-trees from sentences in a document dataset and use them as features of support vector machines. In experiments on movie review datasets, our classifiers obtained the best results yet published using these data.

#index 1707817
#* Improving rough classifiers using concept ontology
#@ Nguyen Sinh Hoa;Nguyen Hung Son
#t 2005
#c 3
#% 236752
#% 353887
#% 366687
#% 409395
#% 500530
#% 501160
#% 579472
#% 1408565
#! We present a method of classifier synthesis based on rough set theory and hierarchical learning idea. The improvement of the generated classifiers is achieved by using concept ontology as a domain knowledge. We examine the effectiveness of the proposed approach by comparing it with standard learning approaches with respect to different criteria. Our experiments are performed on benchmark data set as well as on artificial data sets generated by a road traffic simulator.

#index 1707818
#* QED: an efficient framework for temporal region query processing
#@ Yi-Hong Chu;Kun-Ta Chuang;Ming-Syan Chen
#t 2005
#c 3
#% 115608
#% 147613
#% 484828
#% 566128
#! In this paper, we explore a new problem of ”temporal dense region query” to discover the dense regions in the constrainted time intervals which can be separated or not. A Querying tEmporal Dense Region framework (abbreviated as QED) proposed to deal with this problem consists of two phases: (1) an offline maintaining phase, to maintain the statistics of data by constructing a number of summarized structures, RF-trees; (2) an online query processing phase, to provide an efficient algorithm to execute queries on the RF-trees. The QED framework has the advantage that by using the summarized structures, RF-trees, the queries can be executed efficiently without accessing the raw data. In addition, a number of RF-trees can be merged with one another efficiently such that the queries will be executed efficiently on the combined RF-tree. As validated by our empirical studies, the QED framework performs very efficiently while producing the results of high quality.

#index 1707819
#* A MPAA-Based iterative clustering algorithm augmented by nearest neighbors search for time-series data streams
#@ Jessica Lin;Michai Vlachos;Eamonn Keogh;Dimitrios Gunopulos;Jianwei Liu;Shoujian Yu;Jiajin Le
#t 2005
#c 3
#% 310500
#% 477825
#% 480146
#% 494573
#% 993949
#! In streaming time series the Clustering problem is more complex, since the dynamic nature of streaming data makes previous clustering methods inappropriate. In this paper, we propose firstly a new method to evaluate Clustering in streaming time series databases. First, we introduce a novel multi-resolution PAA (MPAA) transform to achieve our iterative clustering algorithm. The method is based on the use of a multi-resolution piecewise aggregate approximation representation, which is used to extract features of time series. Then, we propose our iterative clustering approach for streaming time series. We take advantage of the multiresolution property of MPPA and equip a stopping criteria based on Hoeffding bound in order to achieve fast response time. Our streaming time-series clustering algorithm also works by leveraging off the nearest neighbors of the incoming streaming time series datasets and fulfill incremental clustering approach. The comprehensive experiments based on several publicly available real data sets shows that significant performance improvement is achieved and produce high-quality clusters in comparison to the previous methods.

#index 1707820
#* Locating motifs in time-series data
#@ Zheng Liu;Jeffrey Xu Yu;Xuemin Lin;Hongjun Lu;Wei Wang
#t 2005
#c 3
#% 316709
#% 322619
#% 479962
#% 548116
#% 629607
#% 727900
#% 729960
#! Finding motifs in time-series is proposed to make clustering of time-series subsequences meaningful, because most existing algorithms of clustering time-series subsequences are reported meaningless in recent studies. The existing motif finding algorithms emphasize the efficiency at the expense of quality, in terms of the number of time-series subsequences in a motif and the total number of motifs found. In this paper, we formalize the problem as a continuous top-k motif balls problem in an m-dimensional space, and propose heuristic approaches that can significantly improve the quality of motifs with reasonable overhead, as shown in our experimental studies.

#index 1707821
#* Stochastic local clustering for massive graphs
#@ Satu Elisa Schaeffer
#t 2005
#c 3
#% 594009
#% 594012
#% 659972
#% 728120
#% 1719555
#! Most graph-theoretical clustering algorithms require the complete adjacency relation of the graph representing the examined data. This is infeasible for very large graphs currently emerging in many application areas. We propose a local approach that computes clusters in graphs, one at a time, relying only on the neighborhoods of the vertices included in the current cluster candidate. This enables implementing a local and parameter-free algorithm. Approximate clusters may be identified quickly by heuristic methods. We report experimental results on clustering graphs using simulated annealing.

#index 1707822
#* A neighborhood-based clustering algorithm
#@ Shuigeng Zhou;Yue Zhao;Jihong Guan;Joshua Huang
#t 2005
#c 3
#% 152902
#% 316709
#% 479649
#! In this paper, we present a new clustering algorithm, NBC, i.e., Neighborhood Based Clustering, which discovers clusters based on the neighborhood characteristics of data. The NBC algorithm has the following advantages: (1) NBC is effective in discovering clusters of arbitrary shape and different densities; (2) NBC needs fewer input parameters than the existing clustering algorithms; (3) NBC can cluster both large and high-dimensional databases efficiently.

#index 1707823
#* Improved self-splitting competitive learning algorithm
#@ Jun Liu;Kotagiri Ramamohanarao
#t 2005
#c 3
#% 466425
#% 1042844
#% 1860937
#! The Self-Splitting Competitive Learning (SSCL) is a powerful algorithm that solves the difficult problems of determining the number of clusters and the sensitivity to prototype initialization in clustering. The SSCL algorithm iteratively partitions the data space into natural clusters without a prior information on the number of clusters. However, SSCL suffers from two major disadvantages: it does not have a proven convergence and the speed of learning process is slow. We propose solutions for these two problems. Firstly, we introduce a new update scheme and lead a proven convergence of Asymptotic Property Vector. Secondly, we modify the split-validity to accelerate the learning process. Experiments show these techniques make the algorithm faster than the original one.

#index 1707824
#* Speeding-Up hierarchical agglomerative clustering in presence of expensive metrics
#@ Mirco Nanni
#t 2005
#c 3
#% 282894
#% 296738
#% 333933
#% 432432
#% 497065
#% 765546
#! In several contexts and domains, hierarchical agglomerative clustering (HAC) offers best-quality results, but at the price of a high complexity which reduces the size of datasets which can be handled. In some contexts, in particular, computing distances between objects is the most expensive task. In this paper we propose a pruning heuristics aimed at improving performances in these cases, which is well integrated in all the phases of the HAC process and can be applied to two HAC variants: single-linkage and complete-linkage. After describing the method, we provide some theoretical evidence of its pruning power, followed by an empirical study of its effectiveness over different data domains, with a special focus on dimensionality issues.

#index 1707825
#* Dynamic cluster formation using level set methods
#@ Andy M. Yip;Chris Ding;Tony F. Chan
#t 2005
#c 3
#% 80995
#% 248792
#! Density-based clustering has the advantages for (i) allowing arbitrary shape of cluster and (ii) not requiring the number of clusters as input. However, when clusters touch each other, both the cluster centers and cluster boundaries (as the peaks and valleys of the density distribution) become fuzzy and difficult to determine. In higher dimension, the boundaries become wiggly and over-fitting often occurs. We introduce the notion of cluster intensity function (CIF) which captures the important characteristics of clusters. When clusters are well-separated, CIFs are similar to density functions. But as clusters touch each other, CIFs still clearly reveal cluster centers, cluster boundaries, and, degree of membership of each data point to the cluster that it belongs. Clustering through bump hunting and valley seeking based on these functions are more robust than that based on kernel density functions which are often oscillatory or over-smoothed. These problems of kernel density estimation are resolved using Level Set Methods and related techniques. Comparisons with two existing density-based methods, valley seeking and DBSCAN, are presented to illustrate the advantages of our approach.

#index 1707826
#* A vector field visualization technique for self-organizing maps
#@ Georg Pölzlbauer;Andreas Rauber;Michael Dittenbach
#t 2005
#c 3
#% 391311
#% 493275
#% 501357
#! The Self-Organizing Map is one of most prominent tools for the analysis and visualization of high-dimensional data. We propose a novel visualization technique for Self-Organizing Maps which can be displayed either as a vector field where arrows point to cluster centers, or as a plot that stresses cluster borders. A parameter is provided that allows for visualization of the cluster structure at different levels of detail. Furthermore, we present a number of experimental results using standard data mining benchmark data.

#index 1707827
#* Visualization of cluster changes by comparing self-organizing maps
#@  Denny;David McG. Squire
#t 2005
#c 3
#% 273693
#% 280408
#% 280409
#% 391311
#% 487680
#% 493568
#% 577295
#% 1633202
#% 1860652
#! In this paper we introduce Self-Organizing Map-based techniques that can reveal structural cluster changes in two related data sets from different time periods in a way that can explain the new result in relation to the previous one. These techniques are demonstrated using a real-world data set from the World Development Indicators database maintained by the World Bank. The results verify that the methods are capable of revealing changes in cluster strucure and membership, corresponding to known changes in economic fortunes of countries.

#index 1707828
#* An incremental data stream clustering algorithm based on dense units detection
#@ Jing Gao;Jianzhong Li;Zhaogong Zhang;Pang-Ning Tan
#t 2005
#c 3
#% 248792
#% 378388
#% 479658
#% 659972
#% 727930
#% 742045
#% 1015261
#! The data stream model of computation is often used for analyzing huge volumes of continuously arriving data. In this paper, we present a novel algorithm called DUCstream for clustering data streams. Our work is motivated by the needs to develop a single-pass algorithm that is capable of detecting evolving clusters, and yet requires little memory and computation time. To that end, we propose an incremental clustering method based on dense units detection. Evolving clusters are identified on the basis of the dense units, which contain relatively large number of points. For efficiency reasons, a bitwise dense unit representation is introduced. Our experimental results demonstrate DUCstream's efficiency and efficacy.

#index 1707829
#* Visual interactive evolutionary algorithm for high dimensional data clustering and outlier detection
#@ Lydia Boudjeloud;François Poulet
#t 2005
#c 3
#% 207252
#% 345858
#% 385564
#% 436508
#% 998618
#! Usual visualization techniques for multidimensional data sets, such as parallel coordinates and scatter-plot matrices, do not scale well to high numbers of dimensions. A common approach to solve this problem is dimensionality selection. Existing dimensionality selection techniques usually select pertinent dimension subsets that are significant to the user without loose of information. We present concrete cooperation between automatic algorithms, interactive algorithms and visualization tools: the evolutionary algorithm is used to obtain optimal dimension subsets which represent the original data set without loosing information for unsupervised mode (clustering or outlier detection). The last effective cooperation is a visualization tool used to present the user interactive evolutionary algorithm results and let him actively participate in evolutionary algorithm searching with more efficiency resulting in a faster evolutionary algorithm convergence. We have implemented our approach and applied it to real data set to confirm this approach is effective for supporting the user in the exploration of high dimensional data sets.

#index 1707830
#* Approximated clustering of distributed high-dimensional data
#@ Hans-Peter Kriegel;Peter Kunath;Martin Pfeifle;Matthias Renz
#t 2005
#c 3
#% 86950
#% 296738
#% 390532
#% 406493
#% 414607
#% 527186
#% 568869
#% 632035
#% 654490
#% 799757
#! In many modern application ranges high-dimensional feature vectors are used to model complex real-world objects. Often these objects reside on different local sites. In this paper, we p resent a general approach for extracting knowledge out of distributed data sets without transmitting all data from the local clients to a server site. In order to keep the transmission cost low, we first determine suitable local feature vector approximations which are sent to the server. Thereby, we approximate each feature vector as precisely as possible with a specified number of bytes. In order to extract knowledge out of these approximations, we introduce a suitable distance function between the feature vector approximations. In a detailed experimental evaluation, we demonstrate the benefits of our new feature vector approximation technique for the important area of distributed clustering. Thereby, we show that the combination of standard clustering algorithms and our feature vector approximation technique outperform specialized approaches for distributed clustering when using high-dimensional feature vectors.

#index 1707831
#* Improvements of incspan: incremental mining of sequential patterns in large database
#@ Son N. Nguyen;Xingzhi Sun;Maria E. Orlowska
#t 2005
#c 3
#% 287242
#% 329537
#% 459006
#% 463903
#% 502121
#% 577256
#% 646296
#% 769931
#% 778732
#! In reality, sequence databases are updated incrementally. The changes on the database may invalidate some existing sequential patterns and introduce new ones. Instead of recomputing the database each time, the incremental mining algorithms target efficiently maintaining the sequential patterns in the dynamically changing database. Recently, a new incremental mining algorithm, called IncSpan was proposed at the International Conference on Knowledge Discovery and Data Mining (KDD'04). However, we find that in general, IncSpan fails to mine the complete set of sequential patterns from an updated database. In this paper, we clarify this weakness by proving the incorrectness of the basic properties in the IncSpan algorithm. Also, we rectify the observed shortcomings by giving our solution.

#index 1707832
#* Efficient sampling: application to image data
#@ Surong Wang;Manoranjan Dash;Liang-Tien Chia
#t 2005
#c 3
#% 1331
#% 300120
#% 481290
#% 577261
#% 729915
#% 1860548
#! Sampling is an important preprocessing algorithm that is used to mine large data efficiently. Although a simple random sample often works fine for reasonable sample size, accuracy falls sharply with reduced sample size. In kdd'03 we proposed ease that outputs a sample based on its ‘closeness' to the original sample. Reported results show that ease outperforms simple random sampling (srs). In this paper we propose easier that extends ease in two ways. 1) ease is a halving algorithm, i.e., to achieve the required sample ratio it starts from a suitable initial large sample and iteratively halves. easier, on the other hand, does away with the repeated halving by directly obtaining the required sample ratio in one iteration. 2) ease was shown to work on ibm quest dataset which is a categorical count dataset. easier, in addition, is shown to work on continuous data such as Color Structure Descriptor of images. Two mining tasks, classification and association rule mining, are used to validate the efficacy of easier samples vis-a-visease and srs samples.

#index 1707833
#* Cluster-Based rough set construction
#@ Qiang Li;Bo Zhang
#t 2005
#c 3
#% 316709
#% 366687
#% 450930
#% 501964
#% 760809
#! In many data mining applications, cluster analysis is widely used and its results are expected to be interpretable, comprehensible, and usable. Rough set theory is one of the techniques to induce decision rules and manage inconsistent and incomplete information. This paper proposes a method to construct equivalence classes during the clustering process, isolate outlier points and finally deduce a rough set model from the clustering results. By the rough set model, attribute reduction and decision rule induction can be implemented efficiently and effectively. Experiments on real world data show that our method is useful and robust in handling data with noise.

#index 1707834
#* Learning bayesian networks structures from incomplete data: an efficient approach based on extended evolutionary programming
#@ Xiaolin Li;Xiangdong He;Senmiao Yuan
#t 2005
#c 3
#% 197387
#% 212700
#% 400980
#% 465762
#% 1650579
#% 1650962
#! This paper describes a new data mining algorithm to learn Bayesian networks structures from incomplete data based on extended Evolutionary programming (EP) method and the Minimum Description Length (MDL) metric. This problem is characterized by a huge solution space with a highly multimodal landscape. The algorithm presents fitness function based on expectation, which converts incomplete data to complete data utilizing current best structure of evolutionary process. Aiming at preventing and overcoming premature convergence, the algorithm combines the restart strategy into EP. The experimental results illustrate that our algorithm can learn a good structure from incomplete data.

#index 1707835
#* Dynamic fuzzy clustering for recommender systems
#@ Sung-Hwan Min;Ingoo Han
#t 2005
#c 3
#% 104472
#% 260778
#% 319705
#% 374537
#% 420121
#% 1650569
#! Collaborative filtering is the most successful recommendation technique. In this paper, we apply the concept of time to collaborative filtering algorithm. We propose dynamic fuzzy clustering algorithm and apply it to collaborative filtering algorithm for dynamic recommendations. We add a time dimension to the original input data of collaborative filtering for finding the fuzzy cluster at different timeframes. We propose the dynamic degree of membership and determine the neighborhood for a given user based on the dynamic fuzzy cluster. The results of the evaluation experiment show the proposed model's improvement in making recommendations.

#index 1707836
#* Improving mining quality by exploiting data dependency
#@ Fang Chu;Yizhou Wang;Carlo Zaniolo;D. Stott Parker
#t 2005
#c 3
#% 44876
#% 232118
#% 345862
#% 406493
#% 577240
#% 799777
#% 1016178
#% 1650318
#% 1848680
#! The usefulness of the results produced by data mining methods can be critically impaired by several factors such as (1) low quality of data, including errors due to contamination, or incompleteness due to limited bandwidth for data acquisition, and (2) inadequacy of the data model for capturing complex probabilistic relationships in data. Fortunately, a wide spectrum of applications exhibit strong dependencies between data samples. For example, the readings of nearby sensors are generally correlated, and proteins interact with each other when performing crucial functions. Therefore, dependencies among data can be successfully exploited to remedy the problems mentioned above. In this paper, we propose a unified approach to improving mining quality using Markov networks as the data model to exploit local dependencies. Belief propagation is used to efficiently compute the marginal or maximum posterior probabilities, so as to clean the data, to infer missing values, or to improve the mining results from a model that ignores these dependencies. To illustrate the benefits and great generality of the technique, we present its application to three challenging problems: (i) cost-efficient sensor probing, (ii) enhancing protein function predictions, and (iii) sequence data denoising.

#index 1707837
#* Feature selection for high dimensional face image using self-organizing maps
#@ Xiaoyang Tan;Songcan Chen;Zhi-Hua Zhou;Fuyan Zhang
#t 2005
#c 3
#% 234978
#% 399588
#% 446756
#% 465754
#% 627545
#% 729344
#% 772213
#% 1022958
#% 1861529
#! While feature selection is very difficult for high dimensional, unstructured data such as face image, it may be much easier to do if the data can be faithfully transformed into lower dimensional space. In this paper, a new method is proposed to transform the high dimensional face images into low-dimensional SOM topological space, and then identify important local features of face images for face recognition automatically using simple statistics computed from the class distribution of the face image data. The effectiveness of the proposed method are demonstrated by the experiments on AR face databases, which reveal that up to 80% local features can be pruned with only slightly loss of the classification accuracy.

#index 1707838
#* Progressive sampling for association rules based on sampling error estimation
#@ Kun-Ta Chuang;Ming-Syan Chen;Wen-Chieh Yang
#t 2005
#c 3
#% 280406
#% 387427
#% 481779
#% 614619
#% 629652
#! We explore in this paper a progressive sampling algorithm, called Sampling Error Estimation (SEE), which aims to identify an appropriate sample size for mining association rules. SEE has two advantages over previous works in the literature. First, SEE is highly efficient because an appropriate sample size can be determined without the need of executing association rules. Second, the identified sample size of SEE is very accurate, meaning that association rules can be highly efficiently executed on a sample of this size to obtain a sufficiently accurate result. This is attributed to the merit of SEE for being able to significantly reduce the influence of randomness by examining several samples with the same size in one database scan. As validated by experiments on various real data and synthetic data, SEE can achieve very prominent improvement in efficiency and also the resulting accuracy over previous works.

#index 1707839
#* CLeVer: a feature subset selection technique for multivariate time series
#@ Kiyoung Yang;Hyunjin Yoon;Cyrus Shahabi
#t 2005
#c 3
#% 722929
#% 1390189
#% 1558464
#% 1781033
#! Feature subset selection (FSS) is one of the data pre-processing techniques to identify a subset of the original features from a given dataset before performing any data mining tasks. We propose a novel FSS method for Multivariate Time Series (MTS) based on Common Principal Components, termed CLeVer. It utilizes the properties of the principal components to retain the correlation information among original features while traditional FSS techniques, such as Recursive Feature Elimination (RFE), may lose it. In order to evaluate the effectiveness of our selected subset of features, classification is employed as the target data mining task. Our experiments show that CLeVer outperforms RFE and Fisher Criterion by up to a factor of two in terms of classification accuracy, while requiring up to 2 orders of magnitude less processing time.

#index 1707840
#* Covariance and PCA for categorical variables
#@ Hirotaka Niitsuma;Takashi Okada
#t 2005
#c 3
#% 211942
#% 258951
#% 458673
#% 566688
#! Covariances from categorical variables are defined using a regular simplex expression for categories. The method follows the variance definition by Gini, and it gives the covariance as a solution of simultaneous equations using the Newton method. The calculated results give reasonable values for test data. A method of principal component analysis (RS-PCA) is also proposed using regular simplex expressions, which allows easy interpretation of the principal components.

#index 1707841
#* ADenTS: an adaptive density-based tree structure for approximating aggregate queries over real attributes
#@ Tianyi Wu;Jian Xu;Chen Wang;Wei Wang;Baile Shi
#t 2005
#c 3
#% 273902
#% 273903
#% 280448
#% 300193
#% 333977
#% 480306
#! In many fields and applications, it is critical for users to make decisions through OLAP queries. How to promote accuracy and efficiency while answering multiple aggregate queries, e.g. COUNT, SUM, AVG, MAX, MIN and MEDIAN? It has been the urgent problem in the fields of OLAP and data summarization recently. There have been a few solutions such as MRA-Tree and GENHIST for it. However, they could only answer a certain aggregate query which was defined in a particular data cube with some limited applications. In this paper, we develop a novel framework ADenTS, i.e. Adaptive Density-based Tree Structure, to answer various types of aggregate queries within a single data cube. We represent the whole cube by building a coherent tree structure. Several techniques for approximation are also proposed. The experimental results show that our method outperforms others in effectiveness.

#index 1707842
#* Frequent itemset mining with parallel RDBMS
#@ Xuequn Shang;Kai-Uwe Sattler
#t 2005
#c 3
#% 201894
#% 300120
#% 481290
#% 481954
#% 810643
#% 1390188
#! Data mining on large relational databases has gained popularity and its significance is well recognized. However, the performance of SQL based data mining is known to fall behind specialized implementation. We investigate approaches based on SQL for the problem of finding frequent patterns from a transaction table, including an algorithm that we recently proposed, called Ppropad (Parallel PROjection PAttern Discovery). Ppropad successively projects the transaction table into frequent itemsets to avoid making multiple passes over the large original transaction table and generating a huge sets of candidates. We have built a parallel database system with DB2 and made performance evaluation on it. We prove that data mining with SQL can achieve sufficient performance by the utilization of database tuning.

#index 1707843
#* Using consensus susceptibility and consistency measures for inconsistent knowledge management
#@ Ngoc Thanh Nguyen;Michal Malowiecki
#t 2005
#c 3
#% 69486
#% 183693
#% 304429
#% 444686
#% 450047
#% 639008
#% 939492
#% 1348855
#! Conflicts may appear during knowledge processing, where some knowledge pieces are different but they refer to the same subject. Consensus methods are useful in processing inconsistent knowledge. However, for almost conflict situations consensus may be determined but it is not always sensible. In this paper we investigate the aspect of reasonableness of consensus. For this aim we define two notions: consensus susceptibility and consistency measure. Owing to them one may get to know when it is worth to determine a consensus for a conflict. We show the dependencies between consistency and the consensus susceptibility for conflict situations. Some results of the analysis are presented.

#index 1707844
#* WLPMiner: weighted frequent pattern mining with length-decreasing support constraints
#@ Unil Yun;John J. Leggett
#t 2005
#c 3
#% 152934
#% 300120
#% 310541
#% 466653
#% 481290
#% 577234
#% 587748
#% 641014
#% 729933
#% 729988
#! Two main concerns exist for frequent pattern mining in the real world. First, each item has different importance so researchers have proposed weighted frequent pattern mining algorithms that reflect the importance of items. Second, patterns having only smaller items tend to be interesting if they have high support, while long patterns can still be interesting although their supports are relatively small. Weight and length decreasing support constraints are key factors, but no mining algorithms consider both the constraints. In this paper, we re-examine two basic but interesting constraints, a weight constraint and a length decreasing support constraint and propose weighted frequent pattern mining with length decreasing constraints. Our main approach is to push weight constraints and length decreasing support constraints into the pattern growth algorithm. For pruning techniques, we propose the notion of Weighted Smallest Valid Extension (WSVE) with applying length decreasing support constraints in weight-based mining. The WSVE property is applied to transaction and node pruning. WLPMiner generates more concise and important weighted frequent patterns with a length decreasing support constraint in large databases by applying the weighted smallest valid extension.

#index 1707845
#* A framework for incorporating class priors into discriminative classification
#@ Rong Jin;Yi Liu
#t 2005
#c 3
#% 211044
#% 304917
#% 342706
#% 466263
#% 492324
#% 592155
#% 647057
#% 1860548
#! Discriminative and generative methods provide two distinct approaches to machine learning classification. One advantage of generative approaches is that they naturally model the prior class distributions. In contrast, discriminative approaches directly model the conditional distribution of class given inputs, so the class priors are only implicitly obtained if the input density is known. In this paper, we propose a framework for incorporating class prior proportions into discriminative methods in order to improve their classification accuracy. The basic idea is to enforce that the distribution of class labels predicted on the test data by the discriminative model is consistent with the class priors. Therefore, the discriminative model has to not only fit the training data well but also predict class labels for the test data that are consistent with the class priors. Experiments on five different UCI datasets and one image database show that this framework is effective in improving the classification accuracy when the training data and the test data come from the same class proportions, even if the test data does not have exactly the same feature distribution as the training data.

#index 1707846
#* Increasing classification accuracy by combining adaptive sampling and convex pseudo-data
#@ Chia Huey Ooi;Madhu Chetty
#t 2005
#c 3
#% 832992
#% 832996
#! The availability of microarray data has enabled several studies on the application of aggregated classifiers for molecular classification. We present a combination of classifier aggregating and adaptive sampling techniques capable of increasing prediction accuracy of tumor samples for multiclass datasets. Our aggregated classifier method is capable of improving the classification accuracy of predictor sets obtained from our maximal-antiredundancy-based feature selection technique. On the Global Cancer Map (GCM) dataset, an improvement over the highest accuracy reported has been achieved by the joint application of our feature selection technique and the modified aggregated classifier method.

#index 1707847
#* Kernels over relational algebra structures
#@ Adam Woźnica;Alexandros Kalousis;Melanie Hilario
#t 2005
#c 3
#% 224755
#% 392781
#% 393059
#% 464633
#% 464640
#% 477497
#% 550387
#% 743284
#% 771944
#! In this paper we present a novel and general framework based on concepts of relational algebra for kernel-based learning over relational schema. We exploit the notion of foreign keys to define a new attribute that we call instance-set and we use this type of attribute to define a tree like structured representation of the learning instances. We define kernel functions over relational schemata which are instances of $\Re$-Convolution kernels and use them as a basis for a relational instance-based learning algorithm. These kernels can be considered as being defined over typed and unordered trees where elementary kernels are used to compute the graded similarity between nodes. We investigate their formal properties and evaluate the performance of the relational instance-based algorithm on a number of relational data sets.

#index 1707848
#* Adaptive nonlinear auto-associative modeling through manifold learning
#@ Junping Zhang;Stan Z. Li
#t 2005
#c 3
#% 92546
#% 1712814
#! We propose adaptive nonlinear auto-associative modeling (ANAM) based on Locally Linear Embedding algorithm (LLE) for learning intrinsic principal features of each concept separately and recognition thereby. Unlike traditional supervised manifold learning algorithm, the proposed ANAM algorithm has several advantages: 1) it implicitly embodies discriminant information because the suboptimal parameters of ANAM are determined based on error rate of the validation set. 2) it avoids the curse of dimensionality without loss accuracy because recognition is completed in the original space. Experiments on character and digit databases show that the advantages of the proposed ANAM algorithm.

#index 1707849
#* Maximizing tree diversity by building complete-random decision trees
#@ Fei Tony Liu;Kai Ming Ting;Wei Fan
#t 2005
#c 3
#% 136350
#% 209021
#% 236656
#% 256615
#% 312727
#% 314785
#% 400847
#% 466583
#% 727888
#! One of the ways to lower generalization error of decision tree ensemble is to maximize tree diversity. Building complete-random trees forgoes strength obtained from a test selection criterion. However, it achieves higher tree diversity. We provide a taxonomy of different randomization methods and find that complete-random test selection produces diverse trees and other randomization methods such as bootstrap sampling may impair tree growth and limit tree diversity. The well accepted practice in constructing decision trees is to apply bootstrap sampling and voting. To challenge this practice, we explore eight variants of complete-random trees using three parameters: ensemble methods, tree height restriction and sample randomization. Surprisingly, the most accurate variant is very simple and performs comparably to Bagging and Random Forests. It achieves good results by maximizing tree diversity and is called Max-diverse Ensemble.

#index 1707850
#* SETRED: self-training with editing
#@ Ming Li;Zhi-Hua Zhou
#t 2005
#c 3
#% 116165
#% 169717
#% 252011
#% 311027
#% 316509
#% 464466
#% 466263
#% 478765
#% 529191
#% 565531
#% 722495
#% 784540
#% 816079
#! Self-training is a semi-supervised learning algorithm in which a learner keeps on labeling unlabeled examples and retraining itself on an enlarged labeled training set. Since the self-training process may erroneously label some unlabeled examples, sometimes the learned hypothesis does not perform well. In this paper, a new algorithm named Setred is proposed, which utilizes a specific data editing method to identify and remove the mislabeled examples from the self-labeled data. In detail, in each iteration of the self-training process, the local cut edge weight statistic is used to help estimate whether a newly labeled example is reliable or not, and only the reliable self-labeled examples are used to enlarge the labeled training set. Experiments show that the introduction of data editing is beneficial, and the learned hypotheses of Setred outperform those learned by the standard self-training algorithm.

#index 1707851
#* Adjusting mixture weights of gaussian mixture model via regularized probabilistic latent semantic analysis
#@ Luo Si;Rong Jin
#t 2005
#c 3
#% 190541
#% 280819
#% 722904
#% 1113099
#% 1650298
#! Mixture models, such as Gaussian Mixture Model, have been widely used in many applications for modeling data. Gaussian mixture model (GMM) assumes that data points are generated from a set of Gaussian models with the same set of mixture weights. A natural extension of GMM is the probabilistic latent semantic analysis (PLSA) model, which assigns different mixture weights for each data point. Thus, PLSA is more flexible than the GMM method. However, as a tradeoff, PLSA usually suffers from the overfitting problem. In this paper, we propose a regularized probabilistic latent semantic analysis model (RPLSA), which can properly adjust the amount of model flexibility so that not only the training data can be fit well but also the model is robust to avoid the overfitting problem. We conduct empirical study for the application of speaker identification to show the effectiveness of the new model. The experiment results on the NIST speaker recognition dataset indicate that the RPLSA model outperforms both the GMM and PLSA models substantially. The principle of RPLSA of appropriately adjusting model flexibility can be naturally extended to other applications and other types of mixture models.

#index 1707852
#* Training support vector machines using greedy stagewise algorithm
#@ Liefeng Bo;Ling Wang;Licheng Jiao
#t 2005
#c 3
#% 116149
#% 197394
#% 266882
#% 269217
#% 269218
#% 722757
#% 722760
#% 856251
#! Hard margin support vector machines (HM-SVMs) have a risk of getting overfitting in the presence of the noise. Soft margin SVMs deal with this problem by the introduction of the capacity control term and obtain the state of the art performance. However, this disposal leads to a relatively high computational cost. In this paper, an alternative method, greedy stagewise algorithm, named GS-SVMs is presented to deal with the overfitting of HM-SVMs without the introduction of capacity control term. The most attractive property of GS-SVMs is that its computational complexity scales quadratically with the size of training samples in the worst case. Extensive empirical comparisons confirm the feasibility and validity GS-SVMs.

#index 1707853
#* Cl-GBI: a novel approach for extracting typical patterns from graph-structured data
#@ Phu Chien Nguyen;Kouzou Ohara;Hiroshi Motoda;Takashi Washio
#t 2005
#c 3
#% 136350
#% 184048
#% 431105
#% 449588
#% 543941
#% 629603
#% 629708
#% 727845
#% 772830
#% 785402
#% 1268739
#% 1390147
#! Graph-Based Induction (GBI) is a machine learning technique developed for the purpose of extracting typical patterns from graph-structured data by stepwise pair expansion (pair-wise chunking). GBI is very efficient because of its greedy search strategy, however, it suffers from the problem of overlapping subgraphs. As a result, some of typical patterns cannot be discovered by GBI though a beam search has been incorporated in an improved version of GBI called Beam-wise GBI (B-GBI). In this paper, improvement is made on the search capability by using a new search strategy, where frequent pairs are never chunked but used as pseudo nodes in the subsequent steps, thus allowing extraction of overlapping subgraphs. This new algorithm, called Cl-GBI (Chunkingless GBI), was tested against two datasets, the promoter dataset from UCI repository and the hepatitis dataset provided by Chiba University, and shown successful in extracting more typical patterns than B-GBI.

#index 1707854
#* Improved bayesian spam filtering based on co-weighted multi-area information
#@ Raju Shrestha;Yaping Lin
#t 2005
#c 3
#% 309119
#% 376266
#% 448801
#! Bayesian spam filters, in general, compute probability estimations for tokens either without considering the email areas of occurrences except the body or treating the same token occurred in different areas as different tokens. However, in reality the same token occurring in different areas are inter-related and the relation too could play role in the classification. In this paper we incorporated this novel idea, co-relating multi-area information by co-weighting them and obtaining more effective combined integrated probability estimations for tokens. The new approach is compared with individual area-wise estimations and traditional separate estimations in all areas, and the experimental results with three public corpora showed significant improvement, stability, robustness and consistency in the spam filtering with the proposed estimation.

#index 1707855
#* An efficient framework for mining flexible constraints
#@ Arnaud Soulet;Bruno Crémilleux
#t 2005
#c 3
#% 216508
#% 248785
#% 280409
#% 420062
#% 431033
#% 464989
#% 481290
#% 483808
#% 576117
#% 629643
#% 769889
#% 785336
#% 1656272
#! Constraint-based mining is an active field of research which is a key point to get interactive and successful KDD processes. Nevertheless, usual solvers are limited to particular kinds of constraints because they rely on properties to prune the search space which are incompatible together. In this paper, we provide a general framework dedicated to a large set of constraints described by SQL-like and syntactic primitives. This set of constraints covers the usual classes and introduces new tough and flexible constraints. We define a pruning operator which prunes the search space by automatically taking into account the characteristics of the constraint at hand. Finally, we propose an algorithm which efficiently makes use of this framework. Experimental results highlight that usual and new complex constraints can be mined in large datasets.

#index 1707856
#* Support oriented discovery of generalized disjunction-free representation of frequent patterns with negation
#@ Marzena Kryszkiewicz;Katarzyna Cichoń
#t 2005
#c 3
#% 152934
#% 232136
#% 502141
#! The discovery of frequent patterns has attracted a lot of attention in the data mining community. While an extensive research has been carried out for discovering positive patterns, little has been offered for discovering patterns with negation. An amount of frequent patterns with negation is usually huge and exceeds the number of frequent positive patterns by orders of magnitude. The problem can be significantly alleviated by applying the generalized disjunction-free literal sets representation, which is a concise lossless representation of all frequent patterns, both with and without negation. In this paper, we offer new efficient algorithm GDFLR-SO-Apriori for discovering this representation and evaluate it against the GDFLR-Apriori algorithm.

#index 1707857
#* Feature selection algorithm for data with both nominal and continuous features
#@ Wenyin Tang;Kezhi Mao
#t 2005
#c 3
#% 169659
#% 185018
#% 466410
#% 629619
#% 629706
#% 720010
#% 729437
#% 1272304
#! Wrapper and filter are two commonly used feature selection schemes. Because of its computational efficiency, the filter method is often the first choice when dealing with large dataset. However, most of filter methods reported in the literature are developed for continuous feature selection. In this paper, we proposed a filter method for mixed data with both continuous and nominal features. The new algorithm includes a novel criterion for mixed feature evaluation, and a novel search algorithm for mixed feature subset generation. The proposed method is tested using a few benchmark real-world problems.

#index 1707858
#* A two-phase algorithm for fast discovery of high utility itemsets
#@ Ying Liu;Wei-keng Liao;Alok Choudhary
#t 2005
#c 3
#% 310541
#% 447910
#% 481290
#% 641014
#% 729988
#% 998745
#! Traditional association rules mining cannot meet the demands arising from some real applications. By considering the different values of individual items as utilities, utility mining focuses on identifying the itemsets with high utilities. In this paper, we present a Two-Phase algorithm to efficiently prune down the number of candidates and precisely obtain the complete set of high utility itemsets. It performs very efficiently in terms of speed and memory cost both on synthetic and real databases, even on large databases that are difficult for existing algorithms to handle.

#index 1707859
#* On multiple query optimization in data mining
#@ Marek Wojciechowski;Maciej Zakrzewicz
#t 2005
#c 3
#% 36117
#% 152934
#% 216508
#% 280454
#% 464204
#% 478284
#% 481290
#% 487532
#% 1271968
#! Traditional multiple query optimization methods focus on identifying common subexpressions in sets of relational queries and on constructing their global execution plans. In this paper we consider the problem of optimizing sets of data mining queries submitted to a Knowledge Discovery Management System. We describe the problem of data mining query scheduling and we introduce a new algorithm called CCAgglomerative to schedule data mining queries for frequent itemset discovery.

#index 1707860
#* USAID: unifying signature-based and anomaly-based intrusion detection
#@ Zhuowei Li;Amitabha Das;Jianying Zhou
#t 2005
#c 3
#% 340031
#% 414388
#% 466674
#% 577250
#% 726510
#% 789054
#% 789057
#% 790040
#% 846500
#! Most intrusion detection techniques suffer from either an inability to detect unknown intrusions, or unacceptably high false alarm rates. However, there lacks a general basis to analyze and find solutions to these problems. In this paper, we propose such a theoretical basis for intrusion detection, which makes it possible to systematically express and analyze the detection performance metrics such as the detection rate and false alarm rate in a quantified manner. Most importantly, the insights gained from the basis lead to the proposal for a new intrusion detection technique – USAID. USAID attempts to exploit the advantages of both techniques, and overcome their respective shortcomings. The experimental results show that USAID can achieve uniform level of efficiency to detect both known (99.78%) and new intrusions (98.18%), with a significantly reduced false alarm rate (1.45%). Most significantly, the performance of USAID is superior to all the participants in KDD'99 if the anomalies detected by USAID can be categorized correctly.

#index 1707861
#* Mining mobile group patterns: a trajectory-based approach
#@ San-Yih Hwang;Ying-Han Liu;Jeng-Kuen Chiu;Ee-Peng Lim
#t 2005
#c 3
#% 280408
#% 295512
#% 300174
#% 378405
#% 527198
#% 554904
#! In this paper, we present a group pattern mining approach to derive the grouping information of mobile device users based on a trajectory model. Group patterns of users are determined by distance threshold and minimum time duration. A trajectory model of user movement is adopted to save storage space and to cope with untracked or disconnected location data. To discover group patterns, we propose ATGP algorithm and TVG-growth that are derived from the Apriori and VG-growth algorithms respectively.

#index 1707862
#* Can we apply projection based frequent pattern mining paradigm to spatial co-location mining?
#@ Yan Huang;Liqin Zhang;Ping Yu
#t 2005
#c 3
#% 210187
#% 300120
#% 342635
#% 342956
#% 481290
#% 501066
#% 527021
#% 769914
#! A co-location pattern is a set of spatial features whose objects are frequently located in spatial proximity. Spatial co-location patterns resemble frequent patterns in many aspects. Since its introduction, the paradigm of mining frequent patterns has undergone a shift from a generate-and-test based frequent pattern mining to a projection based frequent pattern mining. However for spatial datasets, the lack of a transaction concept, which is critical in frequent pattern definition and its mining algorithms, makes the similar shift of paradigm in spatial co-location mining very difficult. We investigate a projection based co-location mining paradigm. In particular, we propose a projection based co-location mining framework and an algorithm called FP-CM, for FP-growth Based Co-location Miner. This algorithm only requires a small constant number of database scans. It out-performs the generate-and-test algorithm by an order of magnitude as shown by our preliminary experiment results.

#index 1707863
#* PatZip: pattern-preserved spatial data compression
#@ Yu Qian;Kang Zhang;D. T. Huynh
#t 2005
#c 3
#% 61589
#% 210173
#% 280402
#% 300132
#% 333933
#% 438137
#% 721137
#% 737335
#% 765495
#% 1068601
#% 1854970
#! This paper presents a compression method, PatZip, to improve the efficiency of spatial pattern mining methods. PatZip can avoid overcompression and stop automatically before pattern is destroyed. Compared with existing compression methods, PatZip is deterministic and its result is reproducible, and original data can be easily recovered. The compression process is data-driven and parameter-free, and requires only O(nlogn) time for n data points.

#index 1707864
#* A likelihood ratio distance measure for the similarity between the fourier transform of time series
#@ G. J. Janacek;A. J. Bagnall;M. Powell
#t 2005
#c 3
#% 172949
#% 316560
#% 460862
#% 466507
#% 577221
#% 765412
#% 769880
#% 1113099
#! Fast Fourier Transforms (FFTs) have been a popular transformation and compression technique in time series data mining since first being proposed for use in this context in [1]. The Euclidean distance between coefficients has been the most commonly used distance metric with FFTs. However, on many problems it is not the best measure of similarity available. In this paper we describe an alternative distance measure based on the likelihood ratio statistic to test the hypothesis of difference between series. We compare the new distance measure to Euclidean distance on five types of data with varying levels of compression. We show that the likelihood ratio measure is better at discriminating between series from different models and grouping series from the same model.

#index 1707865
#* The TIMERS II algorithm for the discovery of causality
#@ Howard J. Hamilton;Kamran Karimi
#t 2005
#c 3
#% 290482
#% 637726
#% 1390164
#! We present the Temporal Investigation Method for Enregistered Record Sequences II (TIMERS II), which can be used to classify the relationship between a decision attribute and a number of condition attributes as instantaneous, causal, or acausal. In this paper we consider it possible to refer to both previous and next values of attributes in temporal rules, and thus enhance the definition of acausality. We also present a new algorithm for distinguishing between causality and acausality.

#index 1707866
#* A recent-biased dimension reduction technique for time series data
#@ Yanchang Zhao;Chengqi Zhang;Shichao Zhang
#t 2005
#c 3
#% 576112
#% 632089
#! There are many techniques developed for tackling time series and most of them consider every part of a sequence equally. In many applications, however, recent data can often be much more interesting and significant than old data. This paper defines new recent-biased measures for distance and energy, and proposes a recent-biased technique based on DWT for time series in which more recent data are considered more significant. With such a recent-biased technique, the dimension of time series can be reduced while effectively preserving the recent-biased energy. Our experiments have demonstrated the effectiveness of the proposed approach for handling time series.

#index 1707867
#* Graph partition model for robust temporal data segmentation
#@ Jinhui Yuan;Bo Zhang;Fuzong Lin
#t 2005
#c 3
#% 375017
#% 466675
#% 780818
#% 1857269
#! This paper proposes a novel temporal data segmentation approach based on a graph partition model. To find the optimal segmentation, which maintains maximal connectivity within the same segment while keeping minimum association between different ones, we adopt the min-max cut as an objective function. For temporal data, a linear time algorithm is designed by importing the temporal constraints. With multi-pair comparison strategy, the proposed method is more robust than the existing pair-wise comparison ones. The experiments on TRECVID benchmarking platform demonstrate the effectiveness of our approach.

#index 1707868
#* Accurate symbolization of time series
#@ Xinqiang Zuo;Xiaoming Jin
#t 2005
#c 3
#% 501995
#% 662750
#% 727900
#% 853027
#! Symbolization is a useful method for mining time series. As our experimental results demonstrated, the previous methods are not accurate enough due to their limitations in handling a prevalent kind of time series in which similar movements are often with different lengths. This paper considers the accuracy issue of symbolization of time series. We propose a novel approach that emphasizes the meaning of each movement in the time series, regardless of the length or shift of it. To make the proposed approach more practicable, we also provide a semiautomatic method for setting the parameters. The nature of the problem and the performance of our approach had been analyzed on both real data and synthetic data. Experimental results justified the superiority of our approach over the previous one and gave some useful empirical conclusions.

#index 1707869
#* A novel bit level time series representation with implication of similarity search and clustering
#@ Chotirat Ratanamahatana;Eamonn Keogh;Anthony J. Bagnall;Stefano Lonardi
#t 2005
#c 3
#% 480146
#% 577221
#% 761281
#% 769880
#% 769896
#! Because time series are a ubiquitous and increasingly prevalent type of data, there has been much research effort devoted to time series data mining recently. As with all data mining problems, the key to effective and scalable algorithms is choosing the right representation of the data. Many high level representations of time series have been proposed for data mining. In this work, we introduce a new technique based on a bit level approximation of the data. The representation has several important advantages over existing techniques. One unique advantage is that it allows raw data to be directly compared to the reduced representation, while still guaranteeing lower bounds to Euclidean distance. This fact can be exploited to produce faster exact algorithms for similarly search. In addition, we demonstrate that our new representation allows time series clustering to scale to much larger datasets.

#index 1707870
#* Finding temporal features of event-oriented patterns
#@ Xingzhi Sun;Maria E. Orlowska;Xue Li
#t 2005
#c 3
#% 420063
#% 1390144
#! A major task of traditional temporal event sequence mining is to predict the occurrences of a special type of event (called target event) in a long temporal sequence. Our previous work has defined a new type of pattern, called event-oriented pattern, which can potentially predict the target event within a certain period of time. However, in the event-oriented pattern discovery, because the size of interval for prediction is pre-defined, the mining results could be inaccurate and carry misleading information. In this paper, we introduce a new concept, called temporal feature, to rectify this shortcoming. Generally, for any event-oriented pattern discovered under the pre-given size of interval, the temporal feature is the minimal size of interval that makes the pattern interesting. Thus, by further investigating the temporal features of discovered event-oriented patterns, we can refine the knowledge for the target event prediction.

#index 1707871
#* An anomaly detection method for spacecraft using relevance vector learning
#@ Ryohei Fujimaki;Takehisa Yairi;Kazuo Machida
#t 2005
#c 3
#% 493884
#% 722760
#% 1650422
#! This paper proposes a novel anomaly detection system for spacecrafts based on data mining techniques. It constructs a nonlinear probabilistic model w.r.t. behavior of a spacecraft by applying the relevance vector regression and autoregression to massive telemetry data, and then monitors the on-line telemetry data using the model and detects anomalies. A major advantage over conventional anomaly detection methods is that this approach requires little a priori knowledge on the system.

#index 1707872
#* Cyclic pattern kernels revisited
#@ Tamás Horváth
#t 2005
#c 3
#% 197751
#% 263371
#% 269217
#% 383546
#% 415004
#% 577218
#% 727896
#% 731607
#% 743284
#% 756494
#% 769891
#% 1378224
#! The cyclic pattern kernel (CPK) is a powerful graph kernel based on patterns formed by simple cycles of labeled graphs. In a recent work, we proposed a method for computing CPK which is restricted to graphs containing polynomial number of simple cycles. In this work, we present two approaches relaxing this limitation. We first show that for graphs of bounded treewidth, CPK can be computed in time polynomial in the number of cyclic patterns, which in turn can be exponentially smaller than that of simple cycles. We then propose an alternative CPK based on the set of relevant cycles which is known to be enumerable with polynomial delay and its cardinality is typically only cubic in the number of vertices. Empirical results on the NCI-HIV dataset indicate that there is no significant difference in predictive performance between CPK based on simple cycles and that based on relevant cycles.

#index 1707873
#* Subspace clustering of text documents with feature weighting k-means algorithm
#@ Liping Jing;Michael K. Ng;Jun Xu;Joshua Zhexue Huang
#t 2005
#c 3
#% 329562
#% 376266
#% 729437
#% 765518
#! This paper presents a new method to solve the problem of clustering large and complex text data. The method is based on a new subspace clustering algorithm that automatically calculates the feature weights in the k-means clustering process. In clustering sparse text data the feature weights are used to discover clusters from subspaces of the document vector space and identify key words that represent the semantics of the clusters. We present a modification of the published algorithm to solve the sparsity problem that occurs in text clustering. Experimental results on real-world text data have shown that the new method outperformed the Standard KMeans and Bisection-KMeans algorithms, while still maintaining efficiency of the k-means clustering process.

#index 1707874
#* Using term clustering and supervised term affinity construction to boost text classification
#@ Chong Wang;Wenyuan Wang
#t 2005
#c 3
#% 313959
#% 375017
#% 406493
#% 464615
#! The similarity measure is a crucial step in many machine learning problems. The traditional cosine similarity suffers from its inability to represent the semantic relationship of terms. This paper explores the kernel-based similarity measure by using term clustering. An affinity matrix of terms is constructed via the co-occurrence of the terms in both unsupervised and supervised ways. Normalized cut is employed to do the clustering to cut off the noisy edges. Diffusion kernel is adopted to measure the kernel-like similarity of the terms in the same cluster. Experiments demonstrate our methods can give satisfactory results, even when the training set is small.

#index 1707875
#* Technology trends analysis from the internet resources
#@ Shin-ichi Kobayashi;Yasuyuki Shirai;Kazuo Hiyane;Fumihiro Kumeno;Hiroshi Inujima;Noriyoshi Yamauchi
#t 2005
#c 3
#% 580063
#% 580065
#% 580066
#% 580067
#! In business or technology planning, it is strongly required to grasp the overall technology trends and predict what will happen in the near future. In this paper, we propose the method where we can detect and analyze the technology trends from the Internet resources.

#index 1707876
#* Dynamic mining hierarchical topic from web news stream data using divisive-agglomerative clustering method
#@ Jian-Wei Liu;Shou-Jian Yu;Jia-Jin Le
#t 2005
#c 3
#% 115470
#% 310500
#% 993961
#! Given the popularity of Web news services, we focus our attention on mining hierarchical topic from Web news stream data. To address this problem, we present a Divisive-Agglomerative clustering method to find hierarchical topic from Web news stream. The novelty of the proposed algorithm is the ability to identify meaningful news topics while reducing the amount of computations by maintaining cluster structure incrementally. Our streaming news clustering algorithm also works by leveraging off the nearest neighbors of the incoming streaming news datasets and has ability of identifying the different shapes and different densities of clusters. Experimental results demonstrate that the proposed clustering algorithm produces high-quality topic discovery.

#index 1707877
#* Collecting topic-related web pages for link structure analysis by using a potential hub and authority first approach
#@ Leuo-Hong Wang;Tong-Wen Lee
#t 2005
#c 3
#% 248810
#% 262061
#% 268079
#% 290830
#% 330707
#% 340147
#% 578242
#% 751565
#% 773039
#! Constructing a base set consisting of topic-related web pages is a preliminary step for those web mining algorithms which use the link structure analysis technique based on HITS. However, except checking the anchor text of links and the content of pages, there has been few of research addressing other possibilities to improve topic relevance while collecting the base set. In this paper, we propose a potential hub and authority first (PHA-first) approach utilizing the concept of hub and authority to filter web pages. We investigate the satisfaction of dozens of users about the pages recommended by our method and HITS on different topics. The results indicate that our method is superior to HITS in most cases. In addition, we also evaluate the recall and precision measures of our method. The results show that our method is with relative high precision and low recall for all topics.

#index 1707878
#* A top down algorithm for mining web access patterns from web logs
#@ Guo Jian-Kui;Ruan Bei-jun;Cheng Zun-ping;Su Fang-zhong;Wang Ya-qin;Deng Xu-bin;Shang Ning;Zhu Yang-Yong
#t 2005
#c 3
#% 300120
#% 342643
#% 459006
#% 463903
#% 464996
#% 487526
#% 501656
#% 502147
#% 629612
#% 630984
#% 1390174
#! This paper proposes a new algorithm, called TAM WAP(the shorthand forTop down Algorithm for Mining Web AccessPatterns), to mine interesting WAP from Web logs. TAM WAP searches the P tree database in the top down manner to mine WAP. By selectively building intermediate data according to the features of current area to be mined, it can avoid stubbornly building intermediate data for each step of mining process. The experiments for both real data and artificial data show that our algorithm outperforms conventional methods.

#index 1707879
#* Kernel principal component analysis for content based image retrieval
#@ Guang-Ho Cha
#t 2005
#c 3
#% 86950
#% 169940
#% 211942
#% 248798
#% 266426
#% 375017
#% 406493
#% 422913
#% 480307
#% 1762960
#% 1775143
#! Kernel principal component analysis (PCA) has recently been proposed as a nonlinear extension of PCA. The basic idea is to first map the input space into a feature space via a nonlinear map and then compute the principal components in that feature space. This paper illustrates the potential of kernel PCA for dimensionality reduction and feature extraction in content-based image retrieval. By the use of Gaussian kernels, the principal components were computed in the feature space of an image data set and they are used as new dimensions to approximate images. Extensive experimental results show that kernel PCA performs better than linear PCA in content-based image retrievals.

#index 1707880
#* Mining frequent trees with node-inclusion constraints
#@ Atsuyoshi Nakamura;Mineichi Kudo
#t 2005
#c 3
#% 312860
#% 348146
#% 443502
#% 463903
#% 478274
#% 481290
#% 577218
#! In this paper, we propose an efficient algorithm enumerating all frequent subtrees containing all special nodes that are guaranteed to be included in all trees belonging to a given data. Our algorithm is a modification of TreeMiner algorithm [10] so as to efficiently generate only candidate subtrees satisfying our constraints. We report mining results obtained by applying our algorithm to the problem of finding frequent structures containing the name and reputation of given restaurants in Web pages collected by a search engine.

#index 1710553
#* Proceedings of the 14th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining - Volume Part II
#@ Mohammed J. Zaki;Jeffrey Xu Yu;B. Ravindran;Vikram Pudi
#t 2010
#c 3

#index 1710554
#* Subclass-Oriented dimension reduction with constraint transformation and manifold regularization
#@ Bin Tong;Einoshin Suzuki
#t 2010
#c 3
#% 80995
#% 765518
#% 791402
#% 961218
#% 961279
#% 975127
#% 989642
#% 1131009
#! We propose a new method, called Subclass-oriented Dimension Reduction with Pairwise Constraints (SODRPaC), for dimension reduction on high dimensional data Current linear semi-supervised dimension reduction methods using pairwise constraints, e.g., must-link constraints and cannot-link constraints, can not handle appropriately the data of multiple subclasses where the points of a class are separately distributed in different groups To illustrate this problem, we particularly classify the must-link constraint into two categories, which are the inter-subclass must-link constraint and the intra-subclass must-link constraint, respectively We argue that handling the inter-subclass must-link constraint is challenging for current discriminant criteria Inspired by the above observation and the cluster assumption that nearby points are possible in the same class, we carefully transform must-link constraints into cannot-link constraints, and then propose a new discriminant criterion by employing the cannot-link constraints and the compactness of shared nearest neighbors For the reason that the local data structure is one of the most significant features for the data of multiple subclasses, manifold regularization is also incorporated in our dimension reduction framework Extensive experiments on both synthetic and practical data sets illustrate the effectiveness of our method.

#index 1710555
#* Distributed knowledge discovery with non linear dimensionality reduction
#@ Panagis Magdalinos;Michalis Vazirgiannis;Dialecti Valsamou
#t 2010
#c 3
#% 215860
#% 340175
#% 340176
#% 402667
#% 451536
#% 478296
#% 480132
#% 837604
#% 1023422
#% 1147693
#% 1181276
#% 1663643
#! Data mining tasks results are usually improved by reducing the dimensionality of data This improvement however is achieved harder in the case that data lay on a non linear manifold and are distributed across network nodes Although numerous algorithms for distributed dimensionality reduction have been proposed, all assume that data reside in a linear space In order to address the non-linear case, we introduce D-Isomap, a novel distributed non linear dimensionality reduction algorithm, particularly applicable in large scale, structured peer-to-peer networks Apart from unfolding a non linear manifold, our algorithm is capable of approximate reconstruction of the global dataset at peer level a very attractive feature for distributed data mining problems We extensively evaluate its performance through experiments on both artificial and real world datasets The obtained results show the suitability and viability of our approach for knowledge discovery in distributed environments.

#index 1710556
#* DPSP: distributed progressive sequential pattern mining on the cloud
#@ Jen-Wei Huang;Su-Chen Lin;Ming-Syan Chen
#t 2010
#c 3
#% 463903
#% 769932
#% 915361
#% 963669
#% 989654
#% 989669
#% 1100176
#% 1117043
#% 1117743
#% 1177859
#% 1707831
#! The progressive sequential pattern mining problem has been discussed in previous research works With the increasing amount of data, single processors struggle to scale up Traditional algorithms running on a single machine may have scalability troubles Therefore, mining progressive sequential patterns intrinsically suffers from the scalability problem In view of this, we design a distributed mining algorithm to address the scalability problem of mining progressive sequential patterns The proposed algorithm DPSP, standing for Distributed Progressive Sequential Pattern mining algorithm, is implemented on top of Hadoop platform, which realizes the cloud computing environment We propose Map/Reduce jobs in DPSP to delete obsolete itemsets, update current candidate sequential patterns and report up-to-date frequent sequential patterns within each POI The experimental results show that DPSP possesses great scalability and consequently increases the performance and the practicability of mining algorithms.

#index 1710557
#* An approach for fast hierarchical agglomerative clustering using graphics processors with CUDA
#@ S. A Arul Shalom;Manoranjan Dash;Minh Tue
#t 2010
#c 3
#% 810059
#% 895650
#! Graphics Processing Units in today's desktops can well be thought of as a high performance parallel processor Each single processor within the GPU is able to execute different tasks independently but concurrently Such computational capabilities of the GPU are being exploited in the domain of Data mining Two types of Hierarchical clustering algorithms are realized on GPU using CUDA Speed gains from 15 times up to about 90 times have been realized The challenges involved in invoking Graphical hardware for such Data mining algorithms and effects of CUDA blocks are discussed It is interesting to note that block size of 8 is optimal for GPU with 128 internal processors.

#index 1710558
#* Ontology-Based mining of brainwaves: a sequence similarity technique for mapping alternative features in event-related potentials (ERP) data
#@ Haishan Liu;Gwen Frishkoff;Robert Frank;Dejing Dou
#t 2010
#c 3
#% 55294
#% 152937
#% 300160
#% 307632
#% 333990
#% 460862
#% 462017
#% 481280
#% 572314
#% 643518
#% 765433
#% 989598
#% 1061515
#% 1102998
#! In this paper, we present a method for identifying correspondences, or mappings, between alternative features of brainwave activity in event-related potentials (ERP) data The goal is to simulate mapping across results from heterogeneous methods that might be used in different neuroscience research labs The input to the mapping consists of two ERP datasets whose spatiotemporal characteristics are captured by alternative sets of features, that is, summary spatial and temporal measures capturing distinct neural patterns that are linked to concepts in a set of ERP ontologies, called NEMO (Neural ElectroMagnetic Ontologies) [3, 6] The feature value vector of each summary metric is transformed into a point-sequence curve, and clustering is performed to extract similar subsequences (clusters) representing the neural patterns that can then be aligned across datasets Finally, the similarity between measures is derived by calculating the similarity between corresponding point-sequence curves Experiment results showed that the proposed approach is robust and has achieved significant improvement on precision than previous algorithms.

#index 1710559
#* Combining support vector machines and the t-statistic for gene selection in DNA microarray data analysis
#@ Tao Yang;Vojislave Kecman;Longbing Cao;Chengqi Zhang
#t 2010
#c 3
#% 425048
#% 905737
#% 924717
#% 1291547
#! This paper proposes a new gene selection (or feature selection) method for DNA microarray data analysis In the method, the t-statistic and support vector machines are combined efficiently The resulting gene selection method uses both the data intrinsic information and learning algorithm performance to measure the relevance of a gene in a DNA microarray We explain why and how the proposed method works well The experimental results on two benchmarking microarray data sets show that the proposed method is competitive with previous methods The proposed method can also be used for other feature selection problems.

#index 1710560
#* Satrap: data and network heterogeneity aware P2P data-mining
#@ Hock Hee Ang;Vivekanand Gopalkrishnan;Anwitaman Datta;Wee Keong Ng;Steven C H. Hoi
#t 2010
#c 3
#% 424996
#% 816452
#% 915500
#% 989669
#% 1072520
#% 1108838
#% 1558464
#% 1742091
#% 1861262
#! Distributed classification aims to build an accurate classifier by learning from distributed data while reducing computation and communication cost A P2P network where numerous users come together to share resources like data content, bandwidth, storage space and CPU resources is an excellent platform for distributed classification However, two important aspects of the learning environment have often been overlooked by other works, viz., 1) location of the peers which results in variable communication cost and 2) heterogeneity of the peers' data which can help reduce redundant communication In this paper, we examine the properties of network and data heterogeneity and propose a simple yet efficient P2P classification approach that minimizes expensive inter-region communication while achieving good generalization performance Experimental results demonstrate the feasibility and effectiveness of the proposed solution.

#index 1710561
#* Player performance prediction in massively multiplayer online role-playing games (MMORPGs)
#@ Kyong Jin Shim;Richa Sharan;Jaideep Srivastava
#t 2010
#c 3
#% 1281934
#! In this study, we propose a comprehensive performance management tool for measuring and reporting operational activities of game players This study uses performance data of game players in EverQuest II, a popular MMORPG developed by Sony Online Entertainment, to build performance prediction models for game players The prediction models provide a projection of player's future performance based on his past performance, which is expected to be a useful addition to existing player performance monitoring tools First, we show that variations of PECOTA [2] and MARCEL [3], two most popular baseball home run prediction methods, can be used for game player performance prediction Second, we evaluate the effects of varying lengths of past performance and show that past performance can be a good predictor of future performance up to a certain degree Third, we show that game players do not regress towards the mean and that prediction models built on buckets using discretization based on binning and histograms lead to higher prediction coverage.

#index 1710562
#* Relevant gene selection using normalized cut clustering with maximal compression similarity measure
#@ Rajni Bala;R. K. Agrawal;Manju Sardana
#t 2010
#c 3
#% 313959
#% 345824
#% 361966
#% 722929
#% 778728
#% 883887
#% 940380
#% 1090577
#! Microarray cancer classification has drawn attention of research community for better clinical diagnosis in last few years Microarray datasets are characterized by high dimension and small sample size To avoid curse of dimensionality good feature selection methods are needed Here, we propose a two stage algorithm for finding a small subset of relevant genes responsible for classification in high dimensional microarray datasets In first stage of algorithm, the entire feature space is divided into k clusters using normalized cut Similarity measure used for clustering is maximal information compression index The informative gene is selected from each cluster using t-statistics and a pool of non redundant genes is created In second stage a wrapper based forward feature selection method is used to obtain a set of optimal genes for a given classifier The proposed algorithm is tested on three well known datasets from Kent Ridge Biomedical Data Repository Comparison with other state of art methods shows that our proposed algorithm is able to achieve better classification accuracy with less number of features.

#index 1710563
#* A novel prototype reduction method for the K-nearest neighbor algorithm with K≥1
#@ Tao Yang;Longbing Cao;Chengqi Zhang
#t 2010
#c 3
#% 60576
#% 307100
#% 744805
#% 753300
#% 775082
#% 871053
#% 940368
#% 940500
#% 1083123
#% 1215917
#! In this paper, a novel prototype reduction algorithm is proposed, which aims at reducing the storage requirement and enhancing the online speed while retaining the same level of accuracy for a K-nearest neighbor (KNN) classifier To achieve this goal, our proposed algorithm learns the weighted similarity function for a KNN classifier by maximizing the leave-one-out cross-validation accuracy Unlike the classical methods PW, LPD and WDNN which can only work with K=1, our developed algorithm can work with K≥1 This flexibility allows our learning algorithm to have superior classification accuracy and noise robustness The proposed approach is assessed through experiments with twenty real world benchmark data sets In all these experiments, the proposed approach shows it can dramatically reduce the storage requirement and online time for KNN while having equal or better accuracy than KNN, and it also shows comparable results to several prototype reduction methods proposed in literature.

#index 1710564
#* Generalized two-dimensional FLD method for feature extraction: an application to face recognition
#@ Shiladitya Chowdhury;Jamuna Kanta Sing;Dipak Kumar Basu;Mita Nasipuri
#t 2010
#c 3
#% 80995
#% 235342
#% 727684
#% 1378328
#% 1860965
#! This paper presents a novel scheme for face feature extraction, namely, the generalized two-dimensional Fisher's linear discriminant (G-2DFLD) method The G-2DFLD method is an extension of the 2DFLD method for feature extraction Like 2DFLD method, G-2DFLD method is also based on the original 2D image matrix However, unlike 2DFLD method, which maximizes class separability either from row or column direction, the G-2DFLD method maximizes class separability from both the row and column directions simultaneously In G-2DFLD method, two alternative Fisher's criteria have been defined corresponding to row and column-wise projection directions The principal components extracted from an image matrix in 2DFLD method are vectors; whereas, in G-2DFLD method these are scalars Therefore, the size of the resultant image feature matrix is much smaller using G-2DFLD method than that of using 2DFLD method The proposed G-2DFLD method was evaluated on two popular face recognition databases, the AT&T (formerly ORL) and the UMIST face databases The experimental results show that the new G-2DFLD scheme outperforms the PCA, 2DPCA, FLD and 2DFLD schemes, not only in terms of computation times, but also for the task of face recognition using a multi-class support vector machine.

#index 1710565
#* Learning gradients with gaussian processes
#@ Xinwei Jiang;Junbin Gao;Tianjiang Wang;Paul W. Kwan
#t 2010
#c 3
#% 393059
#% 891549
#% 961151
#% 961221
#% 983834
#! The problems of variable selection and inference of statistical dependence have been addressed by modeling in the gradients learning framework based on the representer theorem In this paper, we propose a new gradients learning algorithm in the Bayesian framework, called Gaussian Processes Gradient Learning (GPGL) model, which can achieve higher accuracy while returning the credible intervals of the estimated gradients that existing methods cannot provide The simulation examples are used to verify the proposed algorithm, and its advantages can be seen from the experimental results.

#index 1710566
#* Analyzing the role of dimension arrangement for data visualization in radviz
#@ Luigi Di Caro;Vanessa Frias-Martinez;Enrique Frias-Martinez
#t 2010
#c 3
#% 240414
#% 296984
#% 477817
#% 529288
#% 726032
#% 789228
#% 893370
#% 1053049
#% 1147622
#% 1546431
#% 1633202
#! The Radial Coordinate Visualization (Radviz) technique has been widely used to effectively evaluate the existence of patterns in highly dimensional data sets A crucial aspect of this technique lies in the arrangement of the dimensions, which determines the quality of the posterior visualization Dimension arrangement (DA) has been shown to be an NP-problem and different heuristics have been proposed to solve it using optimization techniques However, very little work has focused on understanding the relation between the arrangement of the dimensions and the quality of the visualization In this paper we first present two variations of the DA problem: (1) a Radviz independent approach and (2) a Radviz dependent approach We then describe the use of the Davies-Bouldin index to automatically evaluate the quality of a visualization i.e., its visual usefulness Our empirical evaluation is extensive and uses both real and synthetic data sets in order to evaluate our proposed methods and to fully understand the impact that parameters such as number of samples, dimensions, or cluster separability have in the relation between the optimization algorithm and the visualization tool.

#index 1710567
#* Subgraph mining on directed and weighted graphs
#@ Stephan Günnemann;Thomas Seidl
#t 2010
#c 3
#% 310514
#% 313959
#% 375017
#% 466675
#% 498852
#% 881487
#% 989618
#% 989654
#% 1100134
#% 1108861
#% 1108882
#% 1117074
#% 1328215
#! Subgraph mining algorithms aim at the detection of dense clusters in a graph In recent years many graph clustering methods have been presented Most of the algorithms focus on undirected or unweighted graphs In this work, we propose a novel model to determine the interesting subgraphs also for directed and weighted graphs We use the method of density computation based on influence functions to identify dense regions in the graph We present different types of interesting subgraphs In experiments we show the high clustering quality of our GDens algorithm GDens outperforms competing approaches in terms of quality and runtime.

#index 1710568
#* Finding itemset-sharing patterns in a large itemset-associated graph
#@ Mutsumi Fukuzaki;Mio Seki;Hisashi Kashima;Jun Sese
#t 2010
#c 3
#% 232136
#% 248791
#% 300120
#% 420063
#% 466644
#% 478274
#% 481290
#% 629708
#% 769881
#% 769940
#% 796210
#% 989636
#! Itemset mining and graph mining have attracted considerable attention in the field of data mining, since they have many important applications in various areas such as biology, marketing, and social network analysis However, most existing studies focus only on either itemset mining or graph mining, and only a few studies have addressed a combination of both In this paper, we introduce a new problem which we call itemset-sharing subgraph (ISS) set enumeration, where the task is to find sets of subgraphs with common itemsets in a large graph in which each vertex has an associated itemset The problem has various interesting potential applications such as in side-effect analysis in drug discovery and the analysis of the influence of word-of-mouth communication in marketing in social networks We propose an efficient algorithm ROBIN for finding ISS sets in such graph; this algorithm enumerates connected subgraphs having common itemsets and finds their combinations Experiments using a synthetic network verify that our method can efficiently process networks with more than one million edges Experiments using a real biological network show that our algorithm can find biologically interesting patterns We also apply ROBIN to a citation network and find successful collaborative research works.

#index 1710569
#* A framework for SQL-Based mining of large graphs on relational databases
#@ Sriganesh Srihari;Shruti Chandrashekar;Srinivasan Parthasarathy
#t 2010
#c 3
#% 248813
#% 769907
#% 1063514
#% 1107595
#% 1328181
#% 1388505
#! We design and develop an SQL-based approach for querying and mining large graphs within a relational database management system (RDBMS) We propose a simple lightweight framework to integrate graph applications with the RDBMS through a tightly-coupled network layer, thereby leveraging efficient features of modern databases Comparisons with straight-up main memory implementations of two kernels - breadth-first search and quasi clique detection - reveal that SQL implementations offer an attractive option in terms of productivity and performance.

#index 1710570
#* Fast discovery of reliable k-terminal subgraphs
#@ Melissa Kasari;Hannu Toivonen;Petteri Hintsanen
#t 2010
#c 3
#% 370988
#% 769887
#% 881480
#% 881496
#% 1026554
#% 1083509
#% 1100170
#% 1275150
#% 1692830
#! We present a novel and efficient algorithm for solving the most reliable subgraph problem with multiple query nodes on undirected random graphs Reliable subgraphs are useful for summarizing connectivity between given query nodes Formally, we are given a graph G=(V, E), a set of query (or terminal) nodes Q⊂V, and a positive integer B The objective is to find a subgraph H⊂G containing Q, such that H has at most B edges, and the probability that H is connected is maximized Previous algorithms for the problem are either computationally demanding, or restricted to only two query nodes Our algorithm extends a previous algorithm to handle k query nodes, where 2≤k≤|V| We demonstrate experimentally the usefulness of reliable k-terminal subgraphs, and the accuracy, efficiency and scalability of the proposed algorithm on real graphs derived from public biological databases.

#index 1710571
#* GTRACE2: improving performance using labeled union graphs
#@ Akihiro Inokuchi;Takashi Washio
#t 2010
#c 3
#% 408396
#% 459006
#% 464996
#% 478274
#% 629708
#% 769951
#% 915366
#% 1176913
#% 1268040
#! The mining of a complete set of frequent subgraphs from labeled graph data has been studied extensively Recently, much attention has been given to frequent pattern mining from graph sequences In this paper, we propose a method to improve GTRACE which mines frequent patterns called FTSs (Frequent Transformation Subsequences) from graph sequences Our performance study shows that the proposed method is efficient and scalable for mining both long and large graph sequence patterns, and is some orders of magnitude faster than the conventional method.

#index 1710572
#* Orthogonal nonnegative matrix tri-factorization for semi-supervised document co-clustering
#@ Huifang Ma;Weizhong Zhao;Qing Tan;Zhongzhi Shi
#t 2010
#c 3
#% 342621
#% 464291
#% 643008
#% 729918
#% 876018
#% 881468
#% 1074074
#% 1268046
#% 1328330
#! Semi-supervised clustering is often viewed as using labeled data to aid the clustering process However, existing algorithms fail to consider dual constraints between data points (e.g documents) and features (e.g words) To address this problem, in this paper, we propose a novel semi-supervised document co-clustering model OSS-NMF via orthogonal nonnegative matrix tri-factorization Our model incorporates prior knowledge both on document and word side to aid the new word-category and document-cluster matrices construction Besides, we prove the correctness and convergence of our model to demonstrate its mathematical rigorous Our experimental evaluations show that the proposed document clustering model presents remarkable performance improvements with certain constraints.

#index 1710573
#* Rule synthesizing from multiple related databases
#@ Dan He;Xindong Wu;Xingquan Zhu
#t 2010
#c 3
#% 152934
#% 322619
#% 379325
#% 379339
#% 429421
#% 443085
#% 452864
#% 481290
#% 577289
#% 727846
#% 738959
#% 758424
#% 769959
#% 789957
#% 800582
#% 948885
#% 1015913
#! In this paper, we study the problem of rule synthesizing from multiple related databases where items representing the databases may be different, and the databases may not be relevant, or similar to each other We argue that, for such multi-related databases, simple rule synthesizing without a detailed understanding of the databases is not able to reveal meaningful patterns inside the data collections Consequently, we propose a two-step clustering on the databases at both item and rule levels such that the databases in the final clusters contain both similar items and similar rules A weighted rule synthesizing method is then applied on each such cluster to generate final rules Experimental results demonstrate that the new rule synthesizing method is able to discover important rules which can not be synthesized by other methods.

#index 1710574
#* Fast orthogonal nonnegative matrix tri-factorization for simultaneous clustering
#@ Zhao Li;Xindong Wu;Zhenyu Lu
#t 2010
#c 3
#% 420083
#% 729918
#% 867067
#% 881468
#% 915294
#% 1117033
#% 1401781
#! Orthogonal Nonnegative Matrix Tri-Factorization (ONMTF), a dimension reduction method using three small matrices to approximate an input data matrix, clusters the rows and columns of an input data matrix simultaneously However, ONMTF is computationally expensive due to an intensive computation of the Lagrangian multipliers for the orthogonal constraints In this paper, we introduce Fast Orthogonal Nonnegative Matrix Tri-Factorization (FONT), which uses approximate constants instead of computing the Lagrangian multipliers As a result, FONT reduces the computational complexity significantly Experiments on document datasets show that FONT outperforms ONMTF in terms of clustering quality and running time Moreover, FONT is further accelerated by incorporating Alternating Least Squares, and can be much faster than ONMTF.

#index 1710575
#* Hierarchical web-page clustering via in-page and cross-page link structures
#@ Cindy Xide Lin;Yintao Yu;Jiawei Han;Bing Liu
#t 2010
#c 3
#% 262045
#% 279755
#% 282905
#% 413608
#% 481281
#% 607793
#% 827127
#% 907509
#% 989654
#% 1090774
#% 1100188
#% 1275120
#% 1410607
#! Despite of the wide diversity of web-pages, web-pages residing in a particular organization, in most cases, are organized with semantically hierarchic structures For example, the website of a computer science department contains pages about its people, courses and research, among which pages of people are categorized into faculty, staff and students, and pages of research diversify into different areas Uncovering such hierarchic structures could supply users a convenient way of comprehensive navigation and accelerate other web mining tasks In this study, we extract a similarity matrix among pages via in-page and crosspage link structures, based on which a density-based clustering algorithm is developed, which hierarchically groups densely linked webpages into semantic clusters Our experiments show that this method is efficient and effective, and sheds light on mining and exploring web structures.

#index 1710576
#* Mining numbers in text using suffix arrays and clustering based on dirichlet process mixture models
#@ Minoru Yoshida;Issei Sato;Hiroshi Nakagawa;Akira Terada
#t 2010
#c 3
#% 287434
#% 451536
#% 1410900
#! We propose a system that enables us to search with ranges of numbers Both queries and resulting strings can be both strings and numbers (e.g., “200–800 dollars”) The system is based on suffix-arrays augmented with treatment of number information to provide search for numbers by words, and vice versa Further, the system performs clustering based on a Dirichlet Process Mixture of Gaussians to treat extracted collection of numbers appropriately.

#index 1710577
#* Opinion-Based imprecise query answering
#@ Muhammad Abulaish;Tanvir Ahmad; Jahiruddin;Mohammad Najmud Doja
#t 2010
#c 3
#% 78171
#% 769892
#% 805873
#% 815915
#% 854646
#% 938687
#% 939848
#% 939896
#% 1035591
#! There is an exponential growth in user-generated contents in the form of customer reviews on the Web But, most of the contents are stored in either unstructured or semi-structured format due to which distillation of knowledge from this huge repository is a challenging task In addition, on analysis we found that most of the users use fuzzy terms instead of crisp terms to express opinions on product features Considering these facts, in this paper, we present an opinion-based query answering framework which mines product features and opinionated words to handle user queries over review documents The proposed framework uses BK-FIRM (Bandler-Kohout Fuzzy Information Retrieval Model) that facilitates the formulation of imprecise queries using linguistic qualifiers, retrieves relevant opinion documents, and presents them in the order of their degree of relevance The efficacy of the system is established through experiments over customer reviews on different models of digital camera, and mp3 player.

#index 1710578
#* Blog opinion retrieval based on topic-opinion mixture model
#@ Peng Jiang;Chunxia Zhang;Qing Yang;Zhendong Niu
#t 2010
#c 3
#% 342707
#% 722308
#% 750863
#% 766409
#% 881529
#% 939897
#% 956510
#% 1074094
#% 1074102
#% 1074171
#% 1127964
#% 1130914
#% 1131220
#% 1261565
#! Recently, as blog is becoming a popular medium to express opinions, blog opinion retrieval excites interest in the field of information retrieval It helps to find and rank blogs by both topic relevance and opinion relevance This paper presents our topic-opinion mixture model based approach to blog opinion retrieval in the TREC 2009 blog retrieval task In our approach, we assume each topic has its own opinion relevance model A topic-opinion mixture model is introduced to update original query model, and can be regarded as a mixture of topic relevance model and opinion relevance model By pseudo-relevance feedback method, we can estimate these two models from topic relevance feedback documents and opinion relevance feedback documents respectively Therefore our approach does not need any annotated data to train In addition, the global representation model is used to represent an entire blog that contains a number of blog posts Experimental results on TREC blogs08 collection show the effectiveness of our proposed approach.

#index 1710579
#* Feature subsumption for sentiment classification in multiple languages
#@ Zhongwu Zhai;Hua Xu;Jun Li;Peifa Jia
#t 2010
#c 3
#% 235941
#% 344447
#% 465754
#% 465895
#% 466263
#% 577355
#% 815915
#% 840938
#% 854646
#% 881503
#% 938687
#% 939848
#% 1030817
#% 1035591
#% 1036242
#% 1074166
#% 1127964
#% 1250237
#% 1261576
#% 1264775
#% 1440454
#! An open problem in machine learning-based sentiment classification is how to extract complex features that outperform simple features; figuring out which types of features are most valuable is another Most of the studies focus primarily on character or word Ngrams features, but substring-group features have never been considered in sentiment classification area before In this study, the substring-group features are extracted and selected for sentiment classification by means of transductive learning-based algorithm To demonstrate generality, experiments have been conducted on three open datasets in three different languages: Chinese, English and Spanish The experimental results show that the proposed algorithm's performance is usually superior to the best performance in related work, and the proposed feature subsumption algorithm for sentiment classification is multilingual Compared to the inductive learning-based algorithm, the experimental results also illustrate that the transductive learning-based algorithm can significantly improve the performance of sentiment classification As for term weighting, the experiments show that the “tfidf-c” outperforms all other term weighting approaches in the proposed algorithm.

#index 1710580
#* Decentralisation of scorefinder: a framework for credibility management on user-generated contents
#@ Yang Liao;Aaron Harwood;Kotagiri Ramamohanarao
#t 2010
#c 3
#% 340175
#% 340176
#% 505869
#% 768539
#% 823842
#% 999576
#% 1117742
#% 1118289
#% 1849768
#! User-generated content (UGC) from Internet users has significant value only when its credibility can be established A basic approach to establishing credibility is to take an average of scores from annotators, while more sophisticated approaches have been used to eliminate anomalous scoring behaviour by giving different weights to scores from different annotator profiles A number of applications such as file sharing and article reviewing use a decentralised architecture While computing a weighted average of static values in a decentralised application is well studied, sophisticated UGC algorithms are more complicated since source values to be aggregated and their weights may change in time In our work we consider a centralised credibility management algorithm, ScoreFinder, as an example, and show both structured and unstructured approaches for computing time-dependent weighted average values in peer-to-peer (P2P) networks Experimental results on two real data sets demonstrate that our approaches converge and deliver results comparable to those from the centralised version of ScoreFinder.

#index 1710581
#* Classification and pattern discovery of mood in weblogs
#@ Thin Nguyen;Dinh Phung;Brett Adams;Truyen Tran;Svetha Venkatesh
#t 2010
#c 3
#% 391311
#% 465754
#% 860659
#% 939912
#% 1127964
#! Automatic data-driven analysis of mood from text is an emerging problem with many potential applications Unlike generic text categorization, mood classification based on textual features is complicated by various factors, including its context- and user-sensitive nature We present a comprehensive study of different feature selection schemes in machine learning for the problem of mood classification in weblogs Notably, we introduce the novel use of a feature set based on the affective norms for English words (ANEW) lexicon studied in psychology This feature set has the advantage of being computationally efficient while maintaining accuracy comparable to other state-of-the-art feature sets experimented with In addition, we present results of data-driven clustering on a dataset of over 17 million blog posts with mood groundtruth Our analysis reveals an interesting, and readily interpreted, structure to the linguistic expression of emotion, one that comprises valuable empirical evidence in support of existing psychological models of emotion, and in particular the dipoles pleasure–displeasure and activation–deactivation.

#index 1710582
#* Capture of evidence for summarization: an application of enhanced subjective logic
#@ Sukanya Manna;B. Sumudu U. Mendis;Tom Gedeon
#t 2010
#c 3
#% 100002
#% 387791
#% 397991
#% 742437
#% 816173
#! In this paper, we present a method to generate an extractive summary from a single document using subjective logic The idea behind our approach is to consider words and their co-occurrences between sentences in a document as evidence of their relatedness to the contextual meaning of the document Our aim is to formulate a measure to find out ‘opinion' about a proposition (which is a sentence in this case) using subjective logic in a closed environment (as in a document) Stronger opinion about a sentence represents its importance and are hence considered to summarize a document Summaries generated by our method when evaluated with human generated summaries, show that they are more similar than baseline summaries.

#index 1710583
#* Fast perceptron decision tree learning from evolving data streams
#@ Albert Bifet;Geoff Holmes;Bernhard Pfahringer;Eibe Frank
#t 2010
#c 3
#% 292240
#% 310500
#% 328945
#% 342600
#% 342636
#% 342639
#% 420084
#% 729965
#% 810935
#% 1143748
#% 1214635
#% 1248312
#% 1332130
#% 1673597
#! Mining of data streams must balance three evaluation dimensions: accuracy, time and memory Excellent accuracy on data streams has been obtained with Naive Bayes Hoeffding Trees—Hoeffding Trees with naive Bayes models at the leaf nodes—albeit with increased runtime compared to standard Hoeffding Trees In this paper, we show that runtime can be reduced by replacing naive Bayes with perceptron classifiers, while maintaining highly competitive accuracy We also show that accuracy can be increased even further by combining majority vote, naive Bayes, and perceptrons We evaluate four perceptron-based learning strategies and compare them against appropriate baselines: simple perceptrons, Perceptron Hoeffding Trees, hybrid Naive Bayes Perceptron Trees, and bagged versions thereof We implement a perceptron that uses the sigmoid activation function instead of the threshold activation function and optimizes the squared error, with one perceptron per class value We test our methods by performing an evaluation study on synthetic and real-world datasets comprising up to ten million examples.

#index 1710584
#* Classification and novel class detection in data streams with active mining
#@ Mohammad M. Masud;Jing Gao;Latifur Khan;Jiawei Han;Bhavani Thuraisingham
#t 2010
#c 3
#% 342600
#% 729932
#% 823408
#% 840891
#% 1052684
#% 1116999
#% 1176894
#% 1206700
#% 1267760
#! We present ActMiner, which addresses four major challenges to data stream classification, namely, infinite length, concept-drift, concept-evolution, and limited labeled data Most of the existing data stream classification techniques address only the infinite length and concept-drift problems Our previous work, MineClass, addresses the concept-evolution problem in addition to addressing the infinite length and concept-drift problems Concept-evolution occurs in the stream when novel classes arrive However, most of the existing data stream classification techniques, including MineClass, require that all the instances in a data stream be labeled by human experts and become available for training This assumption is impractical, since data labeling is both time consuming and costly Therefore, it is impossible to label a majority of the data points in a high-speed data stream This scarcity of labeled data naturally leads to poorly trained classifiers ActMiner actively selects only those data points for labeling for which the expected classification error is high Therefore, ActMiner extends MineClass, and addresses the limited labeled data problem in addition to addressing the other three problems It outperforms the state-of-the-art data stream classification techniques that use ten times or more labeled data than ActMiner.

#index 1710585
#* Bulk loading hierarchical mixture models for efficient stream classification
#@ Philipp Kranen;Ralph Krieger;Stefan Denker;Thomas Seidl
#t 2010
#c 3
#% 304947
#% 427199
#% 462059
#% 464605
#% 510089
#% 915345
#% 1080140
#% 1181239
#% 1190668
#% 1263955
#% 1318644
#% 1650665
#% 1712966
#! The ever growing presence of data streams led to a large number of proposed algorithms for stream data analysis and especially stream classification over the last years Anytime algorithms can deliver a result after any point in time and are therefore the natural choice for data streams with varying time allowances between two items Recently it has been shown that anytime classifiers outperform traditional approaches also on constant streams Therefore, increasing the anytime classification accuracy yields better performance on both varying and constant data streams In this paper we propose three novel approaches that improve anytime Bayesian classification by bulk loading hierarchical mixture models In experimental evaluation against four existing techniques we show that our best approach outperforms all competitors and yields significant improvement over previous results in term of anytime classification accuracy.

#index 1710586
#* Summarizing multidimensional data streams: a hierarchy-graph-based approach
#@ Yoann Pitarch;Anne Laurent;Pascal Poncelet
#t 2010
#c 3
#% 481290
#% 846209
#% 918001
#% 1244759
#! When dealing with potentially infinite data streams, storing the whole data stream history is unfeasible and providing a high-quality summary is required In this paper, we propose a summarization method for multidimensional data streams based on a graph structure and taking advantage of the data hierarchies The summarization method considers the data distribution and thus overcomes a major drawback of the Tilted Time Window common framework We adapt this structure for synthesizing frequent itemsets extracted on temporal windows Thanks to our approach, as users do not analyze any more numerous extraction results, the result processing is improved.

#index 1710587
#* Efficient trade-off between speed processing and accuracy in summarizing data streams
#@ Nesrine Gabsi;Fabrice Clérot;Georges Hébrail
#t 2010
#c 3
#% 210173
#% 578560
#% 824788
#% 960257
#% 1015261
#% 1063498
#% 1154732
#% 1206633
#! Data streams constitute the core of many traditional (e.g financial) and emerging (e.g environmental) applications The sources of streams are ubiquitous in daily life (e.g web clicks) One feature of these data is the high speed of their arrival Thus, their processing entails a special constraint Despite the exponential growth in the capacity of storage devices, it is very expensive - even impossible - to store a data stream in its entirety Consequently, queries are evaluated only on the recent data of the stream, the old ones are expired However, some applications need to query the whole data stream Therefore, the inability to store a complete stream suggests the storage of a compact representation of its data, called summaries These structures allow users to query the past without an explosion of the required storage space, to provide historical aggregated information, to perform data mining tasks or to detect anomalous behavior in computer systems The side effect of using summaries is that queries over historical data may not return exact answers, but only approximate ones. This paper introduces a new approach which is a trade-off between the accuracy of query results and the time consumed in building summaries.

#index 1710588
#* Subsequence matching of stream synopses under the time warping distance
#@ Su-Chen Lin;Mi-Yen Yeh;Ming-Syan Chen
#t 2010
#c 3
#% 310545
#% 333941
#% 578400
#% 1022237
#! In this paper, we propose a method for online subsequence matching between histogram-based stream synopsis structures under the dynamic warping distance Given a query synopsis pattern, the work continuously identifies all the matching subsequences for a stream as the histograms are generated To effectively reduce the computation time, we design a Weighted Dynamic Time Warping (WDTW) algorithm which computes the warping distance directly between two histogram-based synopses Our experiments on real datasets show that the proposed method significantly speeds up the pattern matching by sacrificing a little accuracy.

#index 1710589
#* Normalized kernels as similarity indices
#@ Julien Ah-Pine
#t 2010
#c 3
#% 3084
#% 266426
#% 284557
#% 393059
#% 722902
#% 770830
#% 992320
#% 1378797
#! Measuring similarity between objects is a fundamental issue for numerous applications in data-mining and machine learning domains In this paper, we are interested in kernels We particularly focus on kernel normalization methods that aim at designing proximity measures that better fit the definition and the intuition of a similarity index To this end, we introduce a new family of normalization techniques which extends the cosine normalization Our approach aims at refining the cosine measure between vectors in the feature space by considering another geometrical based score which is the mapped vectors' norm ratio We show that the designed normalized kernels satisfy the basic axioms of a similarity index unlike most unnormalized kernels Furthermore, we prove that the proposed normalized kernels are also kernels Finally, we assess these different similarity measures in the context of clustering tasks by using a kernel PCA based clustering approach Our experiments employing several real-world datasets show the potential benefits of normalized kernels over the cosine normalization and the Gaussian RBF kernel.

#index 1710590
#* Adaptive matching based kernels for labelled graphs
#@ Adam Woźnica;Alexandros Kalousis;Melanie Hilario
#t 2010
#c 3
#% 347711
#% 722908
#% 731607
#% 743284
#% 763697
#% 769891
#% 771944
#% 833065
#% 840908
#% 844291
#% 857307
#% 915322
#% 918579
#! Several kernels over labelled graphs have been proposed in the literature so far Most of them are based on the Cross Product (CP) Kernel applied on decompositions of graphs into sub-graphs of specific types This approach has two main limitations: (i) it is difficult to choose a-priori the appropriate type of sub-graphs for a given problem and (ii) all the sub-graphs of a decomposition participate in the computation of the CP kernel even though many of them might be poorly correlated with the class variable To tackle these problems we propose a class of graph kernels constructed on the proximity space induced by the graph distances These graph distances address the aforementioned limitations by learning combinations of different types of graph decompositions and by flexible matching the elements of the decompositions Experiments performed on a number of graph classification problems demonstrate the effectiveness of the proposed approach.

#index 1710591
#* A new framework for dissimilarity and similarity learning
#@ Adam Woźnica;Alexandros Kalousis
#t 2010
#c 3
#% 333790
#% 770811
#% 891559
#% 915322
#% 961174
#% 977991
#% 983830
#% 1073912
#% 1074017
#% 1232015
#! In this work we propose a novel framework for learning a (dis)similarity function We cast the learning problem as a binary classification task or a regression task in which the new learning instances are the pairwise absolute differences of the original instances Under the classification approach the class label we assign to a specific pairwise difference indicates whether the two original instances associated with the difference are members of the same class or not Under the regression approach we assign positive target values to the pairwise differences of instances from different classes and negative target values to the differences of instances of the same class The computation of the (dis)similarity of two examples amounts to the computation of prediction scores for classification, or the prediction of a continuous value for regression The proposed framework is very general as we are free to use any learning algorithm Moreover, our formulation generally leads to a (dis-)similarity which, depending on the learning algorithm, can be efficient and simple to learn Experiments performed on a number of classification problems demonstrate the effectiveness of the proposed approach.

#index 1710592
#* Semantic-Distance based clustering for XML keyword search
#@ Weidong Yang;Hao Zhu
#t 2010
#c 3
#% 654442
#% 659990
#% 810052
#% 863389
#% 960259
#% 960261
#% 1015258
#% 1016135
#% 1181282
#% 1206957
#! XML Keyword Search is a user-friendly information discovery technique, which is well-suited to schema-free XML documents We propose a novel scheme for XML keyword search called XKLUSTER, in which a novel semantic-distance model is proposed to specify the set of nodes contained in a result Based on this model, we use clustering approaches to generate all meaningful results in XML keyword search A ranking mechanism is also presented to sort the results.

#index 1710593
#* OddBall: spotting anomalies in weighted graphs
#@ Leman Akoglu;Mary McGlohon;Christos Faloutsos
#t 2010
#c 3
#% 51647
#% 300136
#% 333929
#% 479791
#% 481281
#% 577251
#% 629708
#% 644182
#% 729983
#% 732882
#% 785389
#% 799747
#% 823391
#% 844334
#% 915233
#% 1030876
#% 1051998
#% 1083682
#% 1176868
#% 1663625
#! Given a large, weighted graph, how can we find anomalies? Which rules should be violated, before we label a node as an anomaly? We propose the oddball algorithm, to find such nodes The contributions are the following: (a) we discover several new rules (power laws) in density, weights, ranks and eigenvalues that seem to govern the so-called “neighborhood sub-graphs” and we show how to use these rules for anomaly detection; (b) we carefully choose features, and design oddball, so that it is scalable and it can work un-supervised (no user-defined constants) and (c) we report experiments on many real graphs with up to 1.6 million nodes, where oddball indeed spots unusual nodes that agree with intuition.

#index 1710594
#* Robust outlier detection using commute time and eigenspace embedding
#@ Nguyen Lu Dang Khoa;Sanjay Chawla
#t 2010
#c 3
#% 300136
#% 479791
#% 729912
#% 975021
#% 995140
#! We present a method to find outliers using ‘commute distance' computed from a random walk on graph Unlike Euclidean distance, commute distance between two nodes captures both the distance between them and their local neighborhood densities Indeed commute distance is the Euclidean distance in the space spanned by eigenvectors of the graph Laplacian matrix We show by analysis and experiments that using this measure, we can capture both global and local outliers effectively with just a distance based method Moreover, the method can detect outlying clusters which other traditional methods often fail to capture and also shows a high resistance to noise than local outlier detection method Moreover, to avoid the O(n3) direct computation of commute distance, a graph component sampling and an eigenspace approximation combined with pruning technique reduce the time to O(nlogn) while preserving the outlier ranking.

#index 1710595
#* EigenSpokes: surprising patterns and scalable community chipping in large graphs
#@ B. Aditya Prakash;Ashwin Sridharan;Mukund Seshadri;Sridhar Machiraju;Christos Faloutsos
#t 2010
#c 3
#% 266065
#% 274612
#% 282881
#% 310514
#% 457710
#% 549441
#% 729918
#% 769883
#% 823347
#% 907530
#% 995140
#% 1013696
#% 1055741
#% 1073989
#% 1083690
#% 1214695
#! We report a surprising, persistent pattern in large sparse social graphs, which we term EigenSpokes We focus on large Mobile Call graphs, spanning about 186K nodes and millions of calls, and find that the singular vectors of these graphs exhibit a striking EigenSpokes pattern wherein, when plotted against each other, they have clear, separate lines that often neatly align along specific axes (hence the term “spokes”) Furthermore, analysis of several other real-world datasets e.g. Patent Citations, Internet, etc. reveals similar phenomena indicating this to be a more fundamental attribute of large sparse graphs that is related to their community structure. This is the first contribution of this paper Additional ones include (a) study of the conditions that lead to such EigenSpokes, and (b) a fast algorithm for spotting and extracting tightly-knit communities, called SpokEn, that exploits our findings about the EigenSpokes pattern.

#index 1710596
#* BASSET: scalable gateway finder in large graphs
#@ Hanghang Tong;Spiros Papadimitriou;Christos Faloutsos;Philip S. Yu;Tina Eliassi-Rad
#t 2010
#c 3
#% 80854
#% 730089
#% 769887
#% 769952
#% 780688
#% 881480
#% 881496
#% 989645
#% 994033
#% 1016175
#% 1016176
#% 1047785
#! Given a social network, who is the best person to introduce you to, say, Chris Ferguson, the poker champion? Or, given a network of people and skills, who is the best person to help you learn about, say, wavelets? The goal is to find a small group of ‘gateways': persons who is close enough to us, as well as close enough to the target (person, or skill) or, in other words, are crucial in connecting us to the target. The main contributions are the following: (a) we show how to formulate this problem precisely; (b) we show that it is sub-modular and thus it can be solved near-optimally; (c) we give fast, scalable algorithms to find such gateways Experiments on real data sets validate the effectiveness and efficiency of the proposed methods, achieving up to 6,000,000x speedup.

#index 1710597
#* Ensemble learning based on multi-task class labels
#@ Qing Wang;Liang Zhang
#t 2010
#c 3
#% 209021
#% 236497
#% 246832
#% 256615
#% 290482
#% 400847
#% 400985
#% 458697
#% 551723
#% 565548
#% 722933
#% 742990
#% 799040
#% 961134
#% 1223457
#% 1260394
#% 1271814
#% 1272365
#% 1318647
#! It is well known that diversity among component classifiers is crucial for constructing a strong ensemble Most existing ensemble methods achieve this goal through resampling the training instances or input features Inspired by MTForest and AODE that enumerate each input attribute together with the class attribute to create different component classifiers in the ensemble In this paper, we propose a novel general ensemble method based on manipulating the class labels It generates different biased new class labels through the Cartesian product of the class attribute and each input attribute, and then builds a component classifier for each of them Extensive experiments, using decision tree and naive Bayes as base classifier respectively, show that the accuracy of our method is comparable to state-of-the-art ensemble methods Finally, the bias-variance decomposition results reveal that the success of our method mainly lies in that it can significantly reduce the bias of the base learner.

#index 1710598
#* Supervised learning with minimal effort
#@ Eileen A. Ni;Charles X. Ling
#t 2010
#c 3
#% 90210
#% 432398
#% 763705
#% 770817
#% 801121
#% 843873
#% 936991
#% 983914
#% 1013605
#% 1211695
#% 1232007
#% 1299125
#! Traditional supervised learning learns from whatever training examples given to it This is dramatically different from human learning; human learns simple examples before conquering hard ones to minimize his effort Effort can equate to energy consumption, and it would be important for machine learning modules to use minimal energy in real-world deployments In this paper, we propose a novel, simple and effective machine learning paradigm that explicitly exploits this important simple-to-complex (S2C) human learning strategy, and implement it based on C4.5 efficiently Experiment results show that S2C has several distinctive advantages over the original C4.5 First of all, S2C does indeed take much less effort in learning the training examples than C4.5 which selects examples randomly Second, with minimal effort, the learning process is much more stable Finally, even though S2C only locally updates the model with minimal effort, we show that it is as accurate as the global learner C4.5 The applications of this simple-to-complex learning strategy in real-world learning tasks, especially cognitive learning tasks, will be fruitful.

#index 1710599
#* Generating diverse ensembles to counter the problem of class imbalance
#@ T. Ryan Hoens;Nitesh V. Chawla
#t 2010
#c 3
#% 209021
#% 256615
#% 312727
#% 400847
#% 443616
#% 451221
#% 551723
#% 765521
#% 765522
#% 915253
#% 961134
#% 1085130
#% 1108850
#% 1271973
#% 1272000
#% 1314745
#% 1390402
#% 1558464
#! One of the more challenging problems faced by the data mining community is that of imbalanced datasets In imbalanced datasets one class (sometimes severely) outnumbers the other class, causing correct, and useful predictions to be difficult to achieve In order to combat this, many techniques have been proposed, especially centered around sampling methods In this paper we propose an ensemble framework that combines random subspaces with sampling to overcome the class imbalance problem We then experimentally verify this technique on a wide variety of datasets We conclude by analyzing the performance of the ensembles, and showing that, overall, our technique provides a significant improvement.

#index 1710600
#* Relationship between diversity and correlation in multi-classifier systems
#@ Kuo-Wei Hsu;Jaideep Srivastava
#t 2010
#c 3
#% 400847
#% 451221
#% 552056
#% 742990
#% 823398
#% 916782
#% 1079565
#% 1196041
#% 1491568
#! Diversity plays an important role in the design of Multi-Classifier Systems, but its relationship to classification accuracy is still unclear from a theoretical perspective As a step towards the solution of this probelm, we take a different route and explore the relationship between diversity and correlation In this paper we provide a theoretical analysis and present a nonlinear function that relates diversity to correlation, which hence can be further related to accuracy This paper contributes to connecting existing research in diversity and correlation, and also providing a proxy to the relationship between diversity and accuracy Our experimental results reveal deeper insights into the role of diversity in Multi-Classifier Systems.

#index 1710601
#* Compact margin machine
#@ Bo Dai;Gang Niu
#t 2010
#c 3
#% 304876
#% 466263
#% 876071
#% 961195
#% 1074345
#% 1176910
#% 1396666
#% 1455666
#! How to utilize data more sufficiently is a crucial consideration in machine learning Semi-supervised learning uses both unlabeled data and labeled data for this reason However, Semi-Supervised Support Vector Machine (S3VM) focuses on maximizing margin only, and it abandons the instances which are not support vectors This fact motivates us to modify maximum margin criterion to incorporate the global information contained in both support vectors and common instances In this paper, we propose a new method, whose special variant is a semi-supervised extension of Relative Margin Machine, to utilize data more sufficiently based on S3VM and LDA We employ Concave-Convex Procedure to solve the optimization that makes it practical for large-scale datasets, and then give an error bound to guarantee the classifier's performance theoretically The experimental results on several real-world datasets demonstrate the effectiveness of our method.

#index 1737754
#* Proceedings of the 14th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining - Volume Part I
#@ Mohammed J. Zaki;Jeffrey Xu Yu;B. Ravindran;Vikram Pudi
#t 2010
#c 3

#index 1737755
#* Empower people with knowledge: the next frontier for web search
#@ Wei-Ying Ma
#t 2010
#c 3
#! The Web has continued to evolve quickly. With the emergence of cloud computing, we see a new opportunity of creating a cloud platform to leverage developer ecosystem and enabling the development of millions of micro-vertical services and applications to serve users' various information need. In this new world, there is an opportunity to build a more powerful and intelligent search engine that understands what users are trying to accomplish and helps them learn, decide and take actions. In this talk, I will first discuss a few new trends from cloud computing that will impact web search, and then I will share my thoughts on possible directions to tap into this new wave and develop not only innovative but also potentially disruptive technologies for Web search.

#index 1737756
#* Discovery of patterns in global earth science data using data mining
#@ Vipin Kumar
#t 2010
#c 3
#! The climate and earth sciences have recently undergone a rapid transformation from a data-poor to a data-rich environment. In particular, climate and ecosystem related observations from remote sensors on satellites, as well as outputs of climate or earth system models from large-scale computational platforms, provide terabytes of temporal, spatial and spatio-temporal data. These massive and information-rich datasets offer huge potential for understanding and predicting the behavior of the Earth's ecosystem and for advancing the science of climate change.

#index 1737757
#* Game theoretic approaches to knowledge discovery and data mining
#@ Y. Narahari
#t 2010
#c 3
#! Game theory is replete with brilliant solution concepts such as the Nash equilibrium, the core, the Shapley value, etc. These solution concepts and their extensions are finding widespread use in solving several fundamental problems in knowledge discovery and data mining. The problems include clustering, classification, discovering influential nodes, social network analysis, etc. The first part of the talk will present the conceptual underpinnings underlying the use of game theoretic techniques in such problem solving. The second part of the talk will delve into two problems where we have recently obtained some interesting results: (a) Discovering influential nodes in social networks using the Shapley value, and (b) Identifying topologies of strategically formed social networks using a game theoretic approach.

#index 1737758
#* Proceedings of the 14th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining - Volume Part I
#@ Mohammed J. Zaki;Jeffrey Xu Yu;B. Ravindran;Vikram Pudi
#t 2010
#c 3

#index 1737759
#* A set correlation model for partitional clustering
#@ Nguyen Xuan Vinh;Michael E. Houle
#t 2010
#c 3
#% 314054
#% 410276
#% 714581
#% 763708
#% 778279
#% 800570
#% 1013086
#% 1137068
#% 1211824
#% 1650433
#! This paper introduces GlobalRSC, a novel formulation for partitional data clustering based on the Relevant Set Correlation (RSC) clustering model. Our formulation resembles that of the K-means clustering model, but with a shared-neighbor similarity measure instead of the Euclidean distance. Unlike K-means and most other clustering heuristics that can only work with real-valued data and distance measures taken from specific families, GlobalRSC has the advantage that it can work with any distance measure, and any data representation. We also discuss various techniques for boosting the scalability of GlobalRSC.

#index 1737760
#* iVAT and aVAT: enhanced visual analysis for cluster tendency assessment
#@ Liang Wang;Uyen T. V. Nguyen;James C. Bezdek;Christopher A. Leckie;Kotagiri Ramamohanarao
#t 2010
#c 3
#% 32926
#% 322527
#% 444041
#% 506328
#% 704071
#% 836705
#% 840844
#% 940141
#% 1030809
#% 1141600
#% 1176973
#% 1177869
#% 1189405
#% 1272500
#% 1378459
#% 1562517
#% 1780757
#% 1788654
#% 1861495
#! Given a pairwise dissimilarity matrix D of a set of n objects, visual methods (such as VAT) for cluster tendency assessment generally represent D as an n×n image $\mathrm{I}(\tilde{\bf D})$ where the objects are reordered to reveal hidden cluster structure as dark blocks along the diagonal of the image. A major limitation of such methods is the inability to highlight cluster structure in $\mathrm{I}(\tilde{\bf D})$ when D contains highly complex clusters. To address this problem, this paper proposes an improved VAT (iVAT) method by combining a path-based distance transform with VAT. In addition, an automated VAT (aVAT) method is also proposed to automatically determine the number of clusters from $\mathrm{I}(\tilde{\bf D})$. Experimental results on several synthetic and real-world data sets have demonstrated the effectiveness of our methods.

#index 1737761
#* A robust seedless algorithm for correlation clustering
#@ Mohammad S. Aziz;Chandan K. Reddy
#t 2010
#c 3
#% 36672
#% 248792
#% 273891
#% 280417
#% 300131
#% 629648
#% 765439
#% 778729
#% 800529
#% 1165480
#! Finding correlation clusters in the arbitrary subspaces of high- dimensional data is an important and a challenging research problem. The current state-of-the-art correlation clustering approaches are sensitive to the initial set of seeds chosen and do not yield the optimal result in the presence of noise. To avoid these problems, we propose RObust SEedless Correlation Clustering (ROSECC) algorithm that does not require the selection of the initial set of seeds. Our approach incrementally partitions the data in each iteration and applies PCA to each partition independently. ROSECC does not assume the dimensionality of the cluster beforehand and automatically determines the appropriate dimensionality (and the corresponding subspaces) of the correlation cluster. Experimental results on both synthetic and real-world datasets demonstrate the effectiveness of the proposed method. We also show the robustness of our method in the presence of a significant noise levels in the data.

#index 1737762
#* Integrative parameter-free clustering of data with mixed type attributes
#@ Christian Böhm;Sebastian Goebl;Annahita Oswald;Claudia Plant;Michael Plavinski;Bianca Wackersreuther
#t 2010
#c 3
#% 210173
#% 420081
#% 466425
#% 881462
#% 982763
#% 986227
#% 1063483
#% 1141611
#% 1650362
#% 1664076
#% 1671475
#! Integrative mining of heterogeneous data is one of the major challenges for data mining in the next decade. We address the problem of integrative clustering of data with mixed type attributes. Most existing solutions suffer from one or both of the following drawbacks: Either they require input parameters which are difficult to estimate, or/and they do not adequately support mixed type attributes. Our technique INTEGRATE is a novel clustering approach that truly integrates the information provided by heterogeneous numerical and categorical attributes. Originating from information theory, the Minimum Description Length (MDL) principle allows a unified view on numerical and categorical information and thus naturally balances the influence of both sources of information in clustering. Moreover, supported by the MDL principle, parameter-free clustering can be performed which enhances the usability of INTEGRATE on real world data. Extensive experiments demonstrate the effectiveness of INTEGRATE in exploiting numerical and categorical information for clustering. As an efficient iterative algorithm INTEGRATE is scalable to large data sets.

#index 1737763
#* Data transformation for sum squared residue
#@ Hyuk Cho
#t 2010
#c 3
#% 469422
#% 778215
#% 905728
#% 1014670
#% 1111931
#! The sum squared residue has been popularly used as a clustering and co-clustering quality measure, however little research on its detail properties has been performed. Recent research articulates that the residue is useful to discover shifting patterns but inappropriate to find scaling patterns. To remedy this weakness, we propose to take specific data transformations that can adjust latent scaling factors and eventually lead to lower the residue. First, we consider data matrix models with varied shifting and scaling factors. Then, we formally analyze the effect of several data transformations on the residue. Finally, we empirically validate the analysis with publicly-available human cancer gene expression datasets. Both the analytical and experimental results reveal column standard deviation normalization and column Z-score transformation are effective for the residue to handle scaling factors, through which we are able to achieve better tissue sample clustering accuracy.

#index 1737764
#* A better strategy of discovering link-pattern based communities by classical clustering methods
#@ Chen-Yi Lin;Jia-Ling Koh;Arbee L. P. Chen
#t 2010
#c 3
#% 148149
#% 281214
#% 310514
#% 313959
#% 375388
#% 466675
#% 665658
#% 805906
#% 1117017
#! The definition of a community in social networks varies with applications. To generalize different types of communities, the concept of link-pattern based community was proposed in a previous study to group nodes into communities, where the nodes in a community have similar intra-community and inter-community interaction behaviors. In this paper, by defining centroid of a community, a distance function is provided to measure the similarity between the link pattern of a node and the centroid of a community. The problem of discovering link-pattern based communities is transformed into a data clustering problem on nodes for minimizing a given objective function. By extending the partitioning methods of cluster analysis, two algorithms named G-LPC and KM-LPC are proposed to solve the problem. The experiment results show that KM-LPC outperforms the previous work on the efficiency, the memory utilization, and the clustering result. Besides, G-LPC achieves the best result approaching the optimal solution.

#index 1737765
#* Mining antagonistic communities from social networks
#@ Kuan Zhang;David Lo;Ee-Peng Lim
#t 2010
#c 3
#% 249110
#% 438553
#% 481290
#% 745515
#% 754098
#% 1071523
#% 1190129
#% 1206864
#% 1247796
#% 1673591
#! During social interactions in a community, there are often sub-communities that behave in opposite manner. These antagonistic sub-communities could represent groups of people with opposite tastes, factions within a community distrusting one another, etc. Taking as input a set of interactions within a community, we develop a novel pattern mining approach that extracts for a set of antagonistic sub-communities. In particular, based on a set of user specified thresholds, we extract a set of pairs of sub-communities that behave in opposite ways with one another. To prevent a blow up in these set of pairs, we focus on extracting a compact lossless representation based on the concept of closed patterns. To test the scalability of our approach, we built a synthetic data generator and experimented on the scalability of the algorithm when the size of the dataset and mining parameters are varied. Case studies on an Amazon book rating dataset show the efficiency of our approach and the utility of our technique in extracting interesting information on antagonistic sub-communities.

#index 1737766
#* As time goes by: discovering eras in evolving social networks
#@ Michele Berlingerio;Michele Coscia;Fosca Giannotti;Anna Monreale;Dino Pedreschi
#t 2010
#c 3
#% 300115
#% 438251
#% 448725
#% 640706
#% 823342
#% 867050
#% 877579
#% 1083672
#% 1083675
#% 1083682
#% 1159226
#% 1214722
#% 1267739
#% 1268040
#! Within the large body of research in complex network analysis, an important topic is the temporal evolution of networks. Existing approaches aim at analyzing the evolution on the global and the local scale, extracting properties of either the entire network or local patterns. In this paper, we focus instead on detecting clusters of temporal snapshots of a network, to be interpreted as eras of evolution. To this aim, we introduce a novel hierarchical clustering methodology, based on a dissimilarity measure (derived from the Jaccard coefficient) between two temporal snapshots of the network. We devise a framework to discover and browse the eras, either in top-down or a bottom-up fashion, supporting the exploration of the evolution at any level of temporal resolution. We show how our approach applies to real networks, by detecting eras in an evolving co-authorship graph extracted from a bibliographic dataset; we illustrate how the discovered temporal clustering highlights the crucial moments when the network had profound changes in its structure. Our approach is finally boosted by introducing a meaningful labeling of the obtained clusters, such as the characterizing topics of each discovered era, thus adding a semantic dimension to our analysis.

#index 1737767
#* Online sampling of high centrality individuals in social networks
#@ Arun S. Maiya;Tanya Y. Berger-Wolf
#t 2010
#c 3
#% 268087
#% 330609
#% 577330
#% 823342
#% 937549
#% 992265
#% 1055741
#% 1176911
#! In this work, we investigate the use of online or “crawling” algorithms to sample large social networks in order to determine the most influential or important individuals within the network (by varying definitions of network centrality). We describe a novel sampling technique based on concepts from expander graphs. We empirically evaluate this method in addition to other online sampling strategies on several real-world social networks. We find that, by sampling nodes to maximize the expansion of the sample, we are able to approximate the set of most influential individuals across multiple measures of centrality.

#index 1737768
#* Estimate on expectation for influence maximization in social networks
#@ Yao Zhang;Qing Gu;Jun Zheng;Daoxu Chen
#t 2010
#c 3
#% 342596
#% 577217
#% 729923
#% 949164
#% 989613
#% 1214641
#% 1269888
#% 1663638
#! Finding the most influential nodes is an important issue in social network analysis. To tackle this issue, Kempe et al. proposed the natural greedy strategy, which, although provides a good approximation, suffers from high computation cost on estimating the influence function even if adopting an efficient optimization. In this paper, we propose a simple yet effective evaluation, the expectation, to estimate the influence function. We formulate the expectation of the influence function and its marginal gain first, then give bounds to the expectation of marginal gains. Based on the approximation to the expectation, we put forward a new greedy algorithm called Greedy Estimate-Expectation (GEE), whose advantage over the previous algorithm is to estimate marginal gains via expectation rather than running Monte-Carlo simulation. Experimental results demonstrate that our algorithm can effectively reduce the running time while maintaining the influence spread.

#index 1737769
#* A novel scalable multi-class ROC for effective visualization and computation
#@ Md. Rafiul Hassan;Kotagiri Ramamohanarao;Chandan Karmakar;M. Maruf Hossain;James Bailey
#t 2010
#c 3
#% 349550
#! This paper introduces a new cost function for evaluating the multi-class classifier. The new cost function facilitates both a way to visualize the performance (expected cost) of the multi-class classifier and a summary of the misclassification costs. This function overcomes the limitations of ROC in not being able to represent the classifier performance graphically when there are more than two classes. Here we present a new scalable method for producing a scalar measurement that is used to compare the performance of the multi-class classifier. We mathematically demonstrate that our technique can capture small variations in classifier performance.

#index 1737770
#* Efficiently finding the best parameter for the emerging pattern-based classifier PCL
#@ Thanh-Son Ngo;Mengling Feng;Guimei Liu;Limsoon Wong
#t 2010
#c 3
#% 466426
#% 466483
#% 496966
#% 546047
#% 629678
#% 785359
#% 809268
#% 948224
#% 953982
#% 1105780
#% 1206650
#% 1250571
#% 1393180
#! Emerging patterns are itemsets whose frequencies change sharply from one class to the other. PCL is an example of efficient classification algorithms that leverage the prediction power of emerging patterns. It first selects the top-K emerging patterns of each class that match a testing instance, and then uses these selected patterns to decide the class label of the testing instance. We study the impact of the parameter K on the accuracy of PCL. We have observed that in many cases, the value of K is critical to the performance of PCL. This motivates us to develop an algorithm to find the best value of K for PCL. Our results show that finding the best K can improve the accuracy of PCL greatly, and employing incremental frequent itemset maintenance techniques reduces the running time of our algorithm significantly.

#index 1737771
#* Rough margin based core vector machine
#@ Gang Niu;Bo Dai;Lin Shang;Yangsheng Ji
#t 2010
#c 3
#% 197394
#% 269218
#% 466597
#% 803575
#% 840949
#% 855583
#% 872759
#% 876071
#% 983809
#% 983918
#% 1042029
#% 1558464
#% 1861757
#! The recently proposed rough margin based support vector machine (RMSVM) could tackle the overfitting problem due to outliers effectively with the help of rough margins. However, the standard solvers for them are time consuming and not feasible for large datasets. On the other hand, the core vector machine (CVM) is an optimization technique based on the minimum enclosing ball that can scale up an SVM to handle very large datasets. While the 2-norm error used in the CVM might make it theoretically less robust against outliers, the rough margin could make up this deficiency. Therefore we propose our rough margin based core vector machine algorithms. Experimental results show that our algorithms hold the generalization performance almost as good as the RMSVM on large scale datasets and improve the accuracy of the CVM significantly on extremely noisy datasets, whilst cost much less computational resources and are often faster than the CVM.

#index 1737772
#* BoostML: an adaptive metric learning for nearest neighbor classification
#@ Nayyar Abbas Zaidi;David McG. Squire;David Suter
#t 2010
#c 3
#% 209623
#% 252009
#% 915338
#% 1083645
#! A Nearest Neighbor (NN) classifier assumes class conditional probabilities to be locally smooth. This assumption is often invalid in high dimensions and significant bias can be introduced when using the nearest neighbor rule. This effect can be mitigated to some extent by using a locally adaptive metric. In this work we propose an adaptive metric learning algorithm that learns an optimal metric at the query point. We learn a distance metric using a feature relevance measure inspired by boosting. The modified metric results in a smooth neighborhood that leads to better classification results. We tested our technique on major UCI machine learning databases and compared the results to state of the art techniques. Our method resulted in significant improvements in the performance of the K-NN classifier and also performed better than other techniques on major databases.

#index 1737773
#* A new emerging pattern mining algorithm and its application in supervised classification
#@ Milton García-Borroto;José Francisco Martínez-Trinidad;Jesús Ariel Carrasco-Ochoa
#t 2010
#c 3
#% 136350
#% 197394
#% 256615
#% 272995
#% 280409
#% 356892
#% 564401
#% 732388
#% 742990
#% 865731
#% 916408
#! Obtaining an accurate class prediction of a query object is an important component of supervised classification. However, it could be important to understand the classification in terms of the application domain, mostly if the prediction disagrees with the expected results. Many accurate classifiers are unable to explain their classification results in terms understandable by an application expert. Emerging Pattern classifiers, on the other hand, are accurate and easy to understand. However, they have two characteristics that could degrade their accuracy: global discretization of numerical attributes and high sensitivity to the support threshold value. In this paper, we introduce a novel algorithm to find emerging patterns without global discretization, which uses an accurate estimation of the support threshold. Experimental results show that our classifier attains higher accuracy than other understandable classifiers, while being competitive with Nearest Neighbors and Support Vector Machines classifiers.

#index 1737774
#* Hiding emerging patterns with local recoding generalization
#@ Michael W. K. Cheng;Byron Koon Kau Choi;William Kwok Wai Cheung
#t 2010
#c 3
#% 67453
#% 248791
#% 280409
#% 310550
#% 333876
#% 546047
#% 564401
#% 576761
#% 576762
#% 577233
#% 607791
#% 635220
#% 800514
#% 800515
#% 805092
#% 810011
#% 864406
#% 881551
#% 937550
#% 948224
#% 975045
#% 1040082
#% 1083709
#% 1117733
#% 1117770
#% 1127361
#% 1189780
#% 1214673
#% 1467722
#% 1712962
#! Establishing strategic partnership often requires organizations to publish and share meaningful data to support collaborative business activities. An equally important concern for them is to protect sensitive patterns like unique emerging sales opportunities embedded in their data. In this paper, we contribute to the area of data sanitization by introducing an optimization-based local recoding methodology to hide emerging patterns from a dataset but with the underlying frequent itemsets preserved as far as possible. We propose a novel heuristic solution that captures the unique properties of hiding EPs to carry out iterative local recoding generalization. Also, we propose a metric which measures (i) frequentitemset distortion that quantifies the quality of published data and (ii) the degree of reduction in emerging patterns, to guide a bottom-up recoding process. We have implemented our proposed solution and experimentally verified its effectiveness with a benchmark dataset.

#index 1737775
#* Anonymizing transaction data by integrating suppression and generalization
#@ Junqiang Liu;Ke Wang
#t 2010
#c 3
#% 152934
#% 248030
#% 342643
#% 577239
#% 864406
#% 864412
#% 878624
#% 1083709
#% 1127361
#% 1206581
#% 1328187
#! Privacy protection in publishing transaction data is an important problem. A key feature of transaction data is the extreme sparsity, which renders any single technique ineffective in anonymizing such data. Among recent works, some incur high information loss, some result in data hard to interpret, and some suffer from performance drawbacks. This paper proposes to integrate generalization and suppression to reduce information loss. However, the integration is non-trivial. We propose novel techniques to address the efficiency and scalability challenges. Extensive experiments on real world databases show that this approach outperforms the state-of-the-art methods, including global generalization, local generalization, and total suppression. In addition, transaction data anonymized by this approach can be analyzed by standard data mining tools, a property that local generalization fails to provide.

#index 1737776
#* Satisfying privacy requirements: one step before anonymization
#@ Xiaoxun Sun;Hua Wang;Jiuyong Li
#t 2010
#c 3
#% 443463
#% 576761
#% 800514
#% 810011
#% 864406
#% 864412
#% 956511
#% 1063505
#% 1080356
#% 1083709
#% 1176943
#% 1206581
#% 1292642
#! In this paper, we study a problem of privacy protection in large survey rating data. The rating data usually contains both ratings of sensitive and non-sensitive issues, and the ratings of sensitive issues include personal information. Even when survey participants do not reveal any of their ratings, their survey records are potentially identifiable by using information from other public sources. We propose a new (k,ε,l)-anonymity model, in which each record is required to be similar with at least k−1 others based on the non-sensitive ratings, where the similarity is controlled by ε, and the standard deviation of sensitive ratings is at least l. We study an interesting yet nontrivial satisfaction problem of the (k,ε,l)-anonymity, which is to decide whether a survey rating data set satisfies the privacy requirements given by users. We develop a slice technique for the satisfaction problem and the experimental results show that the slicing technique is fast, scalable and much more efficient in terms of execution time than the heuristic pairwise method.

#index 1737777
#* Computation of ratios of secure summations in multi-party privacy-preserving latent dirichlet allocation
#@ Bin Yang;Hiroshi Nakagawa
#t 2010
#c 3
#% 31041
#% 341437
#% 354287
#% 554524
#% 722904
#% 743280
#% 891559
#% 1066745
#% 1074831
#% 1386180
#% 1721181
#! In this paper, we focus our attention on the problem of Gibbs sampling for privacy-preserving Latent Dirichlet Allocation, which is equals to a problem of computing the ratio of two numbers, both of which are the summations of the private numbers distributed in different parties. Such a problem has been studied in the case that each party is semi-honest. Here we propose a new solution based on a weaken assumption that some of the parties may collaborate together to extract information of other parties.

#index 1737778
#* Privacy-Preserving network aggregation
#@ Troy Raeder;Marina Blanton;Nitesh V. Chawla;Keith Frikken
#t 2010
#c 3
#% 381870
#% 523804
#% 536484
#% 554524
#% 577289
#% 772829
#% 1098511
#% 1254826
#% 1272062
#% 1386180
#% 1718378
#! Consider the scenario where information about a large network is distributed across several different parties or commercial entities. Intuitively, we would expect that the aggregate network formed by combining the individual private networks would be a more faithful representation of the network phenomenon as a whole. However, privacy preservation of the individual networks becomes a mandate. Thus, it would be useful, given several portions of an underlying network p1 ...pn, to securely compute the aggregate of all the networks pi in a manner such that no party learns information about any other party's network. In this work, we propose a novel privacy preservation protocol for the non-trivial case of weighted networks. The protocol is secure against malicious adversaries.

#index 1737779
#* Multivariate equi-width data swapping for private data publication
#@ Yidong Li;Hong Shen
#t 2010
#c 3
#% 416031
#% 883232
#% 959212
#% 1365442
#! In many privacy preserving applications, specific variables are required to be disturbed simultaneously in order to guarantee correlations among them. Multivariate Equi-Depth Swapping (MEDS) is a natural solution in such cases, since it provides uniform privacy protection for each data tuple. However, this approach performs ineffectively not only in computational complexity (basically O(n3) for n data tuples), but in data utility for distance-based data analysis. This paper discusses the utilisation of Multivariate Equi-Width Swapping (MEWS) to enhance the utility preservation for such cases. With extensive theoretical analysis and experimental results, we show that, MEWS can achieve a similar performance in privacy preservation to that of MEDS and has only O(n) computational complexity.

#index 1737780
#* Correspondence clustering: an approach to cluster multiple related spatial datasets
#@ Vadeerat Rinsurongkawong;Christoph F. Eick
#t 2010
#c 3
#% 342621
#% 469422
#% 722917
#% 881514
#% 1135162
#% 1196039
#% 1411038
#! Domain experts are frequently interested to analyze multiple related spatial datasets. This capability is important for change analysis and contrast mining. In this paper, a novel clustering approach called correspondence clustering is introduced that clusters two or more spatial datasets by maximizing cluster interestingness and correspondence between clusters derived from different datasets. A representative-based correspondence clustering framework and clustering algorithms are introduced. In addition, the paper proposes a novel cluster similarity assessment measure that relies on re-clustering techniques and co-occurrence matrices. We conducted experiments in which two earthquake datasets had to be clustered by maximizing cluster interestingness and agreement between the spatial clusters obtained. The results show that correspondence clustering can reduce the variance inherent to representative-based clustering algorithms, which is important for reducing the likelihood of false positives in change analysis. Moreover, high agreements could be obtained by only slightly lowering cluster quality.

#index 1737781
#* Mining trajectory corridors using fréchet distance and meshing grids
#@ Haohan Zhu;Jun Luo;Hang Yin;Xiaotao Zhou;Joshua Zhexue Huang;F. Benjamin Zhan
#t 2010
#c 3
#% 273890
#% 280416
#% 659971
#% 761237
#% 810049
#% 864582
#% 907184
#% 960283
#% 993965
#% 1171472
#! With technology advancement and increasing popularity of location-aware devices, trajectory data are ubiquitous in the real world. Trajectory corridor, as one of the moving patterns, is composed of concatenated sub-trajectory clusters which help analyze the behaviors of moving objects. In this paper we adopt a three-phase approach to discover trajectory corridors using Fréchet distance as a dissimilarity measurement. First, trajectories are segmented into sub-trajectories using meshing-grids. In the second phase, a hierarchical method is utilized to cluster intra-grid sub-trajectories for each grid cell. Finally, local clusters in each single grid cell are concatenated to construct trajectory corridors. By utilizing a grid structure, the segmentation and concatenation need only single traversing of trajectories or grid cells. Experiments demonstrate that the unsupervised algorithm correctly discovers trajectory corridors from the real trajectory data. The trajectory corridors using Fréchet distance with temporal information are different from those having only spatial information. By choosing an appropriate grid size, the computing time could be reduced significantly because the number of sub-trajectories in a single grid cell is a dominant factor influencing the speed of the algorithms.

#index 1737782
#* Subseries join: a similarity-based time series match approach
#@ Yi Lin;Michael D. McCool
#t 2010
#c 3
#% 8153
#% 68722
#% 172949
#% 397381
#% 464994
#% 1405336
#% 1815525
#! Time series data appears in numerous applications including medical data processing, financial analytics, network traffic monitoring, and Web click-stream analysis. An essential task in time series mining is efficiently finding matches between similar time series or parts of time series in a large dataset. In this work, we introduce a new definition of subseries join as a generalization of subseries matching. We then propose an efficient and robust solution to subseries join (and match) based on a non-uniform segmentation and a hierarchical feature representation. Experiments demonstrate the effectiveness of our approach and also show that this approach can better tolerate noise and phase-scaling than previous work.

#index 1737783
#* TWave: high-order analysis of spatiotemporal data
#@ Michael Barnathan;Vasileios Megalooikonomou;Christos Faloutsos;Feroze B. Mohamed;Scott Faro
#t 2010
#c 3
#% 570889
#% 1862054
#! Recent advances in data acquisition and sharing have made available large quantities of complex data in which features may have complex interrelationships or may not be scalar. For such datasets, the traditional matrix model is no longer appropriate and may fail to capture relationships between features or fail to discover the underlying concepts that features represent. These datasets are better modeled using tensors, which are high-order generalizations of matrices. However, naive tensor algorithms suffer from poor efficiency and may fail to consider spatiotemporal neighborhood relationships in analysis. To surmount these difficulties, we propose TWave, a wavelet and tensor-based methodology for automatic summarization, classification, concept discovery, clustering, and compression of complex datasets. We also derive TWaveCluster, a novel high-order clustering approach based on WaveCluster, and compare our approach against WaveCluster and k-means. The efficiency of our method is competitive with WaveCluster and significantly outperforms k-means. TWave consistently outperformed competitors in both speed and accuracy on a 9.3 GB medical imaging dataset. Our results suggest that a combined wavelet and tensor approach such as TWave may be successfully employed in the analysis of complex high-order datasets.

#index 1737784
#* Spatial clustering with obstacles constraints by dynamic piecewise-mapped and nonlinear inertia weights PSO
#@ Xueping Zhang;Haohua Du;Jiayao Wang
#t 2010
#c 3
#% 464890
#% 465004
#% 481413
#% 629693
#% 900934
#% 1359282
#% 1393255
#! Spatial clustering with constraints has been a new topic in spatial data mining. A novel Spatial Clustering with Obstacles Constraints (SCOC) by dynamic piecewise-mapped and nonlinear inertia weights particle swarm optimization is proposed in this paper. The experiments show that the algorithm can not only give attention to higher local constringency speed and stronger global optimum search, but also get down to the obstacles constraints and practicalities of spatial clustering; and it performs better than PSO K-Medoids SCOC in terms of quantization error and has higher constringency speed than Genetic K-Medoids SCOC.

#index 1737785
#* An efficient GA-Based algorithm for mining negative sequential patterns
#@ Zhigang Zheng;Yanchang Zhao;Ziye Zuo;Longbing Cao
#t 2010
#c 3
#% 207535
#% 287054
#% 329537
#% 459006
#% 463903
#% 577256
#% 778732
#% 1040761
#% 1155719
#% 1156596
#% 1960014
#! Negative sequential pattern mining has attracted increasing concerns in recent data mining research because it considers negative relationships between itemsets, which are ignored by positive sequential pattern mining. However, the search space for mining negative patterns is much bigger than that for positive ones. When the support threshold is low, in particular, there will be huge amounts of negative candidates. This paper proposes a Genetic Algorithm (GA) based algorithm to find negative sequential patterns with novel crossover and mutation operations, which are efficient at passing good genes on to next generations without generating candidates. An effective dynamic fitness function and a pruning method are also provided to improve performance. The results of extensive experiments show that the proposed method can find negative patterns efficiently and has remarkable performance compared with some other algorithms of negative pattern mining.

#index 1737786
#* Valency based weighted association rule mining
#@ Yun Sing Koh;Russel Pears;Wai Yeap
#t 2010
#c 3
#% 152934
#% 243790
#% 280487
#% 310541
#% 443393
#% 481290
#% 606569
#% 641014
#% 729988
#% 835018
#% 1038715
#% 1707792
#% 1734441
#! Association rule mining is an important data mining task that discovers relationships among items in a transaction database. Most approaches to association rule mining assume that all items within a dataset have a uniform distribution with respect to support. Therefore, weighted association rule mining (WARM) was introduced to provide a notion of importance to individual items. Previous approaches to the weighted association rule mining problem require users to assign weights to items. This is infeasible when millions of items are present in a dataset. In this paper we propose a method that is based on a novel Valency model that automatically infers item weights based on interactions between items. Our experimentation shows that the weighting scheme results in rules that better capture the natural variation that occurs in a dataset when compared to a miner that does not employ such a weighting scheme.

#index 1737787
#* Ranking sequential patterns with respect to significance
#@ Robert Gwadera;Fabio Crestani
#t 2010
#c 3
#% 227919
#% 350859
#% 463903
#% 727902
#% 778732
#% 985041
#% 1127267
#% 1292684
#! We present a reliable universal method for ranking sequential patterns (itemset-sequences) with respect to significance in the problem of frequent sequential pattern mining. We approach the problem by first building a probabilistic reference model for the collection of itemset-sequences and then deriving an analytical formula for the frequency for sequential patterns in the reference model. We rank sequential patterns by computing the divergence between their actual frequencies and their frequencies in the reference model. We demonstrate the applicability of the presented method for discovering dependencies between streams of news stories in terms of significant sequential patterns, which is an important problem in multi-stream text mining and the topic detection and tracking research.

#index 1737788
#* Mining association rules in long sequences
#@ Boris Cule;Bart Goethals
#t 2010
#c 3
#% 152934
#% 420063
#% 466496
#% 799764
#! Discovering interesting patterns in long sequences, and finding confident association rules within them, is a popular area in data mining. Most existing methods define patterns as interesting if they occur frequently enough in a sufficiently cohesive form. Based on these frequent patterns, association rules are mined in the traditional manner. Recently, a new interestingness measure, combining cohesion and frequency of a pattern, has been proposed, and patterns are deemed interesting if encountering one event from the pattern implies with a high probability that the rest of the pattern can be found nearby. It is quite clear that this probability is not necessarily equally high for all the events making up such a pattern, which is why we propose to introduce the concept of association rules into this problem setting. The confidence of such an association rule tells us how far on average from a particular event, or a set of events, one has to look, in order to find the rest of the pattern. In this paper, we present an efficient algorithm to mine such association rules. After applying our method to both synthetic and real-life data, we conclude that it indeed gives intuitive results in a number of applications.

#index 1737789
#* Mining closed episodes from event sequences efficiently
#@ Wenzhi Zhou;Hongyan Liu;Hong Cheng
#t 2010
#c 3
#% 420063
#% 727902
#% 729933
#% 799764
#% 832572
#% 989612
#% 1390145
#! Recent studies have proposed different methods for mining frequent episodes. In this work, we study the problem of mining closed episodes based on minimal occurrences. We study the properties of minimal occurrences and design effective pruning techniques to prune non-closed episodes. An efficient mining algorithm Clo_episode is proposed to mine all closed episodes following a breadth-first search order and integrating the pruning techniques. Experimental results demonstrate the efficiency of our mining algorithm and the compactness of the mining result set.

#index 1737790
#* Most significant substring mining based on chi-square measure
#@ Sourav Dutta;Arnab Bhattacharya
#t 2010
#c 3
#% 481562
#% 577275
#! Given the vast reservoirs of sequence data stored worldwide, efficient mining of string databases such as intrusion detection systems, player statistics, texts, proteins, etc. has emerged as a great challenge. Searching for an unusual pattern within long strings of data has emerged as a requirement for diverse applications. Given a string, the problem then is to identify the substrings that differs the most from the expected or normal behavior, i.e., the substrings that are statistically significant (i.e., less likely to occur due to chance alone). To this end, we use the chi-square measure and propose two heuristics for retrieving the top-k substrings with the largest chi-square measure. We show that the algorithms outperform other competing algorithms in the runtime, while maintaining a high approximation ratio of more than 0.96.

#index 1737791
#* Probabilistic user modeling in the presence of drifting concepts
#@ Vikas Bhardwaj;Ramaswamy Devarajan
#t 2010
#c 3
#% 170405
#% 204531
#% 280852
#% 342600
#% 543581
#% 659754
#% 894298
#% 915313
#% 1074042
#% 1083671
#% 1083714
#% 1238540
#! We investigate supervised prediction tasks which involve multiple agents over time, in the presence of drifting concepts. The motivation behind choosing the topic is that such tasks arise in many domains which require predicting human actions. An example of such a task is recommender systems, where it is required to predict the future ratings, given features describing items and context along with the previous ratings assigned by the users. In such a system, the relationships among the features and the class values can vary over time. A common challenge to learners in such a setting is that this variation can occur both across time for a given agent, and also across different agents, (i.e. each agent behaves differently). Furthermore, the factors causing this variation are often hidden. We explore probabilistic models suitable for this setting, along with efficient algorithms to learn the model structure. Our experiments use the Netflix Prize dataset, a real world dataset which shows the presence of time variant concepts. The results show that the approaches we describe are more accurate than alternative approaches, especially when there is a large variation among agents. All the data and source code would be made open-source under the GNU GPL.

#index 1737792
#* Using association rules to solve the cold-start problem in recommender systems
#@ Gavin Shaw;Yue Xu;Shlomo Geva
#t 2010
#c 3
#% 397155
#% 414514
#% 734590
#% 783531
#% 794935
#% 813966
#% 1019140
#% 1034287
#% 1145214
#% 1145243
#! Recommender systems are widely used online to help users find other products, items etc that they may be interested in based on what is known about that user in their profile. Often however user profiles may be short on information and thus it is difficult for a recommender system to make quality recommendations. This problem is known as the cold-start problem. Here we investigate using association rules as a source of information to expand a user profile and thus avoid this problem. Our experiments show that it is possible to use association rules to noticeably improve the performance of a recommender system under the cold-start situation. Furthermore, we also show that the improvement in performance obtained can be achieved while using non-redundant rule sets. This shows that non-redundant rules do not cause a loss of information and are just as informative as a set of association rules that contain redundancy.

#index 1737793
#* Semi-supervised tag recommendation - using untagged resources to mitigate cold-start problems
#@ Christine Preisach;Leandro Balby Marinho;Lars Schmidt-Thieme
#t 2010
#c 3
#% 248810
#% 769942
#% 915320
#% 1127452
#% 1156304
#% 1214694
#% 1355024
#% 1667787
#! Tag recommender systems are often used in social tagging systems, a popular family of Web 2.0 applications, to assist users in the tagging process. But in cold-start situations i.e., when new users or resources enter the system, state-of-the-art tag recommender systems perform poorly and are not always able to generate recommendations. Many user profiles contain untagged resources, which could provide valuable information especially for cold-start scenarios where tagged data is scarce. The existing methods do not explore this additional information source. In this paper we propose to use a purely graph-based semi-supervised relational approach that uses untagged posts for addressing the cold-start problem. We conduct experiments on two real-life datasets and show that our approach outperforms the state-of-the-art in many cases.

#index 1737794
#* Cost-Sensitive listwise ranking approach
#@ Min Lu;MaoQiang Xie;Yang Wang;Jie Liu;YaLou Huang
#t 2010
#c 3
#% 411762
#% 577224
#% 983820
#% 987241
#% 1039843
#% 1074021
#% 1211762
#% 1665205
#! This paper addresses listwise approaches in learning to rank for Information Retrieval(IR). The listwise losses are built on the probability of ranking a document highest among the documents set. The probability treats all the documents equally. However, the documents with higher ranks should be emphasized in IR where the ranking order on the top of the ranked list is crucial. In this paper, we establish a framework for cost-sensitive listwise approaches. The framework redefines the probability by imposing weights for the documents. The framework reduces the task of weighting the documents to the task of weighting the document pairs. The weights of the document pairs are computed based on Normalized Discounted Cumulative Gain(NDCG). It is proven that the losses of cost-sensitive listwise approaches are the upper bound of the NDCG loss. As an example, we propose a cost-sensitive ListMLE method. Empirical results shows the advantage of the proposed method.

#index 1737795
#* Mining wikipedia and yahoo! answers for question expansion in opinion QA
#@ Yajie Miao;Chunping Li
#t 2010
#c 3
#% 939969
#% 987328
#% 1214660
#% 1227599
#% 1227600
#% 1250362
#% 1328325
#% 1330520
#! Opinion Question Answering (Opinion QA) is still a relatively new area in QA research. The achieved methods focus on combining sentiment analysis with the traditional Question Answering methods. Few attempts have been made to expand opinion questions with external background information. In this paper, we introduce the broad-mining and deep-mining strategies. Based on these two strategies, we propose four methods to exploit Wikipedia and Yahoo! Answers for enriching representation of questions in Opinion QA. The experimental results show that the proposed expansion methods perform effectively for improving existing Opinion QA models.

#index 1737796
#* Answer diversification for complex question answering on the web
#@ Palakorn Achananuparp;Xiaohua Hu;Tingting He;Christopher C. Yang;Yuan An;Lifan Guo
#t 2010
#c 3
#% 262112
#% 268079
#% 643014
#% 939968
#% 939970
#% 983662
#% 1019165
#% 1074111
#% 1074133
#% 1166473
#% 1166519
#% 1190062
#% 1190129
#% 1280774
#% 1292677
#% 1415746
#! We present a novel graph ranking model to extract a diverse set of answers for complex questions via random walks over a negative-edge graph. We assign a negative sign to edge weights in an answer graph to model the redundancy relation among the answer nodes. Negative edges can be thought of as the propagation of negative endorsements or disapprovals which is used to penalize factual redundancy. As the ranking proceeds, the initial score of the answer node, given by its relevancy to the specific question, will be adjusted according to a long-term negative endorsement from other answer nodes. We empirically evaluate the effectiveness of our method by conducting a comprehensive experiment on two distinct complex question answering data sets.

#index 1737797
#* Vocabulary filtering for term weighting in archived question search
#@ Zhao-Yan Ming;Kai Wang;Tat-Seng Chua
#t 2010
#c 3
#% 169781
#% 411760
#% 570316
#% 838398
#% 987234
#% 1074105
#% 1074110
#% 1227600
#% 1273825
#% 1415727
#! This paper proposes the notion of vocabulary filtering in a term weighting framework that consists of three filters at the document level, collection level, and vocabulary level. While term frequency and document frequency along with their variations are respectively the dominant term weighting factors at the document level and collection level, vocabulary level factors are seldom considered in current models. In a way, stopword removal can be seen as a vocabulary level filter, but it is not well integrated into the current term-weighting models. In this paper, we propose a vocabulary filtering and multi-level term weighting model by integrating point-wise divergence based measure into the commonly used TF-IDF model. With our proposed model, the specificity of the vocabulary is captured as a new factor in term weighting, and stopwords are naturally handled within the model rather than being removed according to a separately constructed list. Experiments conducted on searching for similar questions in a large community-based question answering archive show that: (a)our proposed term weighting model with multiple levels is consistently better than those with single level for retrieval task; (b)the proposed vocabulary filter well distinguishes salient and trivial terms, and can be utilized to construct stopword lists.

#index 1737798
#* On finding the natural number of topics with latent dirichlet allocation: some observations
#@ R. Arun;V. Suresh;C. E. Veni Madhavan;M. N. Narasimha Murthy
#t 2010
#c 3
#% 280819
#% 465031
#% 722904
#% 818291
#% 876017
#% 1182629
#% 1223609
#! It is important to identify the “correct” number of topics in mechanisms like Latent Dirichlet Allocation(LDA) as they determine the quality of features that are presented as features for classifiers like SVM. In this work we propose a measure to identify the correct number of topics and offer empirical evidence in its favor in terms of classification accuracy and the number of topics that are naturally present in the corpus. We show the merit of the measure by applying it on real-world as well as synthetic data sets(both text and images). In proposing this measure, we view LDA as a matrix factorization mechanism, wherein a given corpus C is split into two matrix factors M1 and M2 as given by Cd*w = M1d*t x Qt*w. Where d is the number of documents present in the corpus and w is the size of the vocabulary. The quality of the split depends on “t”, the right number of topics chosen. The measure is computed in terms of symmetric KL-Divergence of salient distributions that are derived from these matrix factors. We observe that the divergence values are higher for non-optimal number of topics – this is shown by a 'dip' at the right value for 't'.

#index 1737799
#* Supervising latent topic model for maximum-margin text classification and regression
#@ Wanhong Xu
#t 2010
#c 3
#% 280819
#% 420077
#% 420507
#% 722904
#% 768632
#% 939346
#% 1211848
#% 1667700
#! In this paper, we investigate the text classification and regression problems: given a corpus of text documents as training, each of which has a response label, the task is to train a predictor for predicting its response of any given document. In previous work, many researchers decompose this task into two separate steps: they first use a generative latent topic model to learn low-dimensional semantic representations of documents; and then train a max-margin predictor using them as features. In this work we demonstrate that it is beneficial to combine both steps of learning low-dimensional representations and training a predictor into one step of minimizing a singe learning objective. We present a novel step-wise convex optimization algorithm which solves this objective properly via a tight variational upper bound. We conduct an extensive experimental study on public available movie review and 20 Newsgroups datasets. Experimental results show that compared with state of art results in the literature, our one step approach can train noticeably better predictors and discover much lower-dimensional representations: a 2% relative accuracy improvement and a 95% relative number of dimensions reduction in the classification task on the Newsgroups dataset; and a 5.7% relative predictive R2 improvement and a 55% relative number of dimensions reduction in the regression task on the movie review dataset.

#index 1737800
#* Resource-Bounded information extraction: acquiring missing feature values on demand
#@ Pallika Kanani;Andrew McCallum;Shaohan Hu
#t 2010
#c 3
#% 754068
#% 757350
#% 844399
#% 876046
#% 989672
#% 1083692
#% 1083705
#% 1269865
#% 1274820
#% 1396699
#% 1673023
#! We present a general framework for the task of extracting specific information “on demand” from a large corpus such as the Web under resource-constraints. Given a database with missing or uncertain information, the proposed system automatically formulates queries, issues them to a search interface, selects a subset of the documents, extracts the required information from them, and fills the missing values in the original database. We also exploit inherent dependency within the data to obtain useful information with fewer computational resources. We build such a system in the citation database domain that extracts the missing publication years using limited resources from the Web. We discuss a probabilistic approach for this task and present first results. The main contribution of this paper is to propose a general, comprehensive architecture for designing a system adaptable to different domains.

#index 1737801
#* Efficient deep web crawling using reinforcement learning
#@ Lu Jiang;Zhaohui Wu;Qian Feng;Jun Liu;Qinghua Zheng
#t 2010
#c 3
#% 124691
#% 256622
#% 384911
#% 480479
#% 741122
#% 809418
#% 864434
#% 993964
#% 1127557
#% 1155648
#% 1272286
#% 1280720
#! Deep web refers to the hidden part of the Web that remains unavailable for standard Web crawlers. To obtain content of Deep Web is challenging and has been acknowledged as a significant gap in the coverage of search engines. To this end, the paper proposes a novel deep web crawling framework based on reinforcement learning, in which the crawler is regarded as an agent and deep web database as the environment. The agent perceives its current state and selects an action (query) to submit to the environment according to Q-value. The framework not only enables crawlers to learn a promising crawling strategy from its own experience, but also allows for utilizing diverse features of query keywords. Experimental results show that the method outperforms the state of art methods in terms of crawling capability and breaks through the assumption of full-text search implied by existing methods.

#index 1737802
#* Topic decomposition and summarization
#@ Wei Chen;Can Wang;Chun Chen;Lijun Zhang;Jiajun Bu
#t 2010
#c 3
#% 340884
#% 397137
#% 643008
#% 765412
#% 1074123
#% 1133170
#% 1275220
#! In this paper, we study topic decomposition and summarization for a temporal-sequenced text corpus of a specific topic. The task is to discover different topic aspects (i.e., sub-topics) and incidents related to each sub-topic of the text corpus, and generate summaries for them. We present a solution with the following steps: (1) deriving sub-topics by applying Non-negative Matrix Factorization (NMF) to terms-by-sentences matrix of the text corpus; (2) detecting incidents of each sub-topic and generating summaries for both sub-topic and its incidents by examining the constitution of its encoding vector generated by NMF; (3) ranking each sentences based on the encoding matrix and selecting top ranked sentences of each sub-topic as the text corpus' summary. Experimental results show that the proposed topic decomposition method can effectively detect various aspects of original documents. Besides, the topic summarization method achieves better results than some well-studied methods.

#index 1737803
#* UNN: a neural network for uncertain data classification
#@ Jiaqi Ge;Yuni Xia;Chandima Nadungodage
#t 2010
#c 3
#% 296679
#% 452821
#% 823402
#% 844385
#% 1063728
#% 1179162
#% 1189215
#% 1195948
#% 1206640
#% 1302133
#% 1669893
#! This paper proposes a new neural network method for classifying uncertain data (UNN). Uncertainty is widely spread in real-world data. Numerous factors lead to data uncertainty including data acquisition device error, approximate measurement, sampling fault, transmission latency, data integration error and so on. The performance and quality of data mining results are largely dependent on whether data uncertainty are properly modeled and processed. In this paper, we focus on one commonly encountered type of data uncertainty - the exact data value is unavailable and we only know the probability distribution of the data. An intuitive method of handling this type of uncertainty is to represent the uncertain range by its expectation value, and then process it as certain data. This method, although simple and straightforward, may cause valuable information loss. In this paper, we extend the conventional neural networks classifier so that it can take not only certain data but also uncertain probability distribution as the input. We start with designing uncertain perceptron in linear classification, and analyze how neurons use the new activation function to process data distribution as inputs. We then illustrate how perceptron generates classification principles upon the knowledge learned from uncertain training data. We also construct a multilayer neural network as a general classifier, and propose an optimization technique to accelerate the training process. Experiment shows that UNN performs well even for highly uncertain data and it significantly outperformed the naïve neural network algorithm. Furthermore, the optimization approach we proposed can greatly improve the training efficiency.

#index 1737804
#* SkyDist: data mining on skyline objects
#@ Christian Böhm;Annahita Oswald;Claudia Plant;Michael Plavinski;Bianca Wackersreuther
#t 2010
#c 3
#% 36672
#% 465167
#% 480671
#% 481281
#% 654480
#% 800555
#% 993954
#! The skyline operator is a well established database primitive which is traditionally applied in a way that only a single skyline is computed. In this paper we use multiple skylines themselves as objects for data exploration and data mining. We define a novel similarity measure for comparing different skylines, called SkyDist. SkyDist can be used for complex analysis tasks such as clustering, classification, outlier detection, etc. We propose two different algorithms for computing SkyDist, based on Monte-Carlo sampling and on the plane sweep paradigm. In an extensive experimental evaluation, we demonstrate the efficiency and usefulness of SkyDist for a number of applications and data mining methods.

#index 1737805
#* Multi-Source skyline queries processing in multi-dimensional space
#@ Cuiping Li;Wenlin He;Hong Chen
#t 2010
#c 3
#% 465167
#% 480671
#% 654480
#% 745464
#% 800555
#% 813973
#% 824670
#% 824671
#% 824672
#% 866981
#% 893150
#% 993954
#% 1022203
#% 1022224
#% 1022270
#! This paper studies the problem of optimizing skyline queries with respect to multiple sources in the multidimensional space (MDMS skyline). It is challenging to process such kinds of queries efficiently due to the difficulties arising from both multi-source preferences and multi-dimensional analysis. We propose a new query evaluation model, called BitStructure, to answer MDMS skyline queries efficiently. Based on the BitStructure, we develop efficient query algorithms. The main intuition and novelty behind our approaches is that we exploit the unified BitStructure structure to seamlessly integrate multi-dimensional selection and multi-source skyline analysis. Our experimental evaluation using various synthetic datasets demonstrates that the proposed algorithms are efficient and scalable.

#index 1737806
#* Efficient pattern mining of uncertain data with sampling
#@ Toon Calders;Calin Garboni;Bart Goethals
#t 2010
#c 3
#% 466490
#% 481290
#% 729418
#% 729942
#% 1214624
#% 1393138
#% 1411036
#% 1411089
#! Mining frequent itemsets from transactional datasets is a well known problem with good algorithmic solutions. In the case of uncertain data, however, several new techniques have been proposed. Unfortunately, these proposals often suffer when a lot of items occur with many different probabilities. Here we propose an approach based on sampling by instantiating “possible worlds” of the uncertain data, on which we subsequently run optimized frequent itemset mining algorithms. As such we gain efficiency at a surprisingly low loss in accuracy. These is confirmed by a statistical and an empirical evaluation on real and synthetic data.

#index 1737807
#* Classifier ensemble for uncertain data stream classification
#@ Shirui Pan;Kuan Wu;Yang Zhang;Xue Li
#t 2010
#c 3
#% 136350
#% 466408
#% 727880
#% 729932
#% 763708
#% 785371
#% 896023
#% 1001525
#% 1069667
#% 1195948
#% 1206939
#! Currently available algorithms for data stream classification are all designed to handle precise data, while data with uncertainty or imperfection is quite natural and widely seen in real-life applications. Uncertainty can arise in attribute values as well as in class values. In this paper, we focus on the classification of streaming data that has different degrees of uncertainty within class values. We propose two types of ensemble based algorithms, Static Classifier Ensemble (SCE) and Dynamic Classifier Ensemble (DCE) for mining uncertain data streams. Experiments on both synthetic and real-life data set are made to compare and contrast our proposed algorithms. The experimental results reveal that DCE algorithm outperforms SCE algorithm.

#index 1745887
#* Proceedings of the 15th international conference on New Frontiers in Applied Data Mining
#@ Longbing Cao;Joshua Zhexue Huang;James Bailey;Yun Sing Koh;Jun Luo
#t 2011
#c 3

#index 1745888
#* Evaluating the regularity of human behavior from mobile phone usage logs
#@ Hyoungnyoun Kim;Ji-Hyung Park
#t 2011
#c 3
#% 272995
#% 739899
#% 858102
#% 1162395
#% 1442149
#% 1489657
#% 1541731
#! This paper investigated the relationship between incrementally logged phone logs and self-reported survey data to derive regularity and predictability from mobile phone usage logs. First, we extracted information not from a single value such as location or call logs, but from multivariate contextual logs. Then we considered the changing pattern of the incrementally logged information over time. To evaluate the patterns of human behavior, we applied entropy changes and the duplicated instances ratios from the stream of mobile phone usage logs. By applying the Hidden Markov Models to the patterns, the accumulated log patterns were classified according to the self-reported survey data. This research confirmed that regularity and predictability of human behavior can be evaluated by mobile phone usages.

#index 1745889
#* Explicit and implicit user preferences in online dating
#@ Joshua Akehurst;Irena Koprinska;Kalina Yacef;Luiz Pizzato;Judy Kay;Tomasz Rej
#t 2011
#c 3
#% 1442149
#% 1450837
#% 1489892
#% 1826412
#! In this paper we study user behavior in online dating, in particular the differences between the implicit and explicit user preferences. The explicit preferences are stated by the user while the implicit preferences are inferred based on the user behavior on the website. We first show that the explicit preferences are not a good predictor of the success of user interactions. We then propose to learn the implicit preferences from both successful and unsuccessful interactions using a probabilistic machine learning method and show that the learned implicit preferences are a very good predictor of the success of user interactions. We also propose an approach that uses the explicit and implicit preferences to rank the candidates in our recommender system. The results show that the implicit ranking method is significantly more accurate than the explicit and that for a small number of recommendations it is comparable to the performance of the best method that is not based on user preferences.

#index 1745890
#* Blogger-Link-Topic model for blog mining
#@ Flora S. Tsai
#t 2011
#c 3
#% 722904
#% 769906
#% 788094
#% 1069354
#% 1202691
#% 1211773
#% 1227702
#% 1392388
#% 1406363
#% 1436411
#% 1442149
#% 1488002
#% 1882500
#! Blog mining is an important area of behavior informatics because produces effective techniques for analyzing and understanding human behaviors from social media. In this paper, we propose the blogger-link-topic model for blog mining based on the multiple attributes of blog content, bloggers, and links. In addition, we present a unique blog classification framework that computes the normalized document-topic matrix, which is applied our model to retrieve the classification results. After comparing the results for blog classification on real-world blog data, we find that our blogger-link-topic model outperforms the other techniques in terms of overall precision and recall. This demonstrates that additional information contained in blog-specific attributes can help improve blog classification and retrieval results.

#index 1745891
#* A random indexing approach for web user clustering and web prefetching
#@ Miao Wan;Arne Jönsson;Cong Wang;Lixiang Li;Yixian Yang
#t 2011
#c 3
#% 216509
#% 341664
#% 369953
#% 413389
#% 420133
#% 424330
#% 466676
#% 478277
#% 641968
#% 642534
#% 800163
#% 828571
#% 1261578
#% 1442149
#% 1788198
#! In this paper we present a novel technique to capture Web users' behaviour based on their interest-oriented actions. In our approach we utilise the vector space model Random Indexing to identify the latent factors or hidden relationships among Web users' navigational behaviour. Random Indexing is an incremental vector space technique that allows for continuous Web usage mining. User requests are modelled by Random Indexing for individual users' navigational pattern clustering and common user profile creation. Clustering Web users' access patterns may capture common user interests and, in turn, build user profiles for advanced Web applications, such as Web caching and prefetching. We present results from the Web user clustering approach through experiments on a real Web log file with promising results. We also apply our data to a prefetching task and compare that with previous approaches. The results show that Random Indexing provides more accurate prefetchings.

#index 1745892
#* Emotional reactions to real-world events in social networks
#@ Thin Nguyen;Dinh Phung;Brett Adams;Svetha Venkatesh
#t 2011
#c 3
#% 643520
#% 722904
#% 939376
#% 1127964
#% 1442149
#! A convergence of emotions among people in social networks is potentially resulted by the occurrence of an unprecedented event in real world. E.g., a majority of bloggers would react angrily at the September 11 terrorist attacks. Based on this observation, we introduce a sentiment index, computed from the current mood tags in a collection of blog posts utilizing an affective lexicon, potentially revealing subtle events discussed in the blogosphere. We then develop a method for extracting events based on this index and its distribution. Our second contribution is establishment of a new bursty structure in text streams termed a sentiment burst. We employ a stochastic model to detect bursty periods of moods and the events associated. Our results on a dataset of more than 12 million mood-tagged blog posts over a 4-year period have shown that our sentiment-based bursty events are indeed meaningful, in several ways.

#index 1745893
#* Constructing personal knowledge base: automatic key-phrase extraction from multiple-domain web pages
#@ Yin-Fu Huang;Cin-Siang Ciou
#t 2011
#c 3
#% 281480
#% 420487
#% 836151
#% 1090218
#% 1131310
#% 1279276
#% 1442149
#% 1700573
#! In the paper, we proposed a general framework that could automatically extract key-phrases from a collection of web pages concerning a specific topic with the help of The Free Dictionary and then construct a personal knowledge base. Both the base and visual feature in a web page are used to calculate the weight of each candidate phrase. The system extracts top p% key-phrases for each web page based on these two features and then generates a term set using union operators. Next, the system builds the relationships between terms in the term set by referencing The Free Dictionary, and then generates a list of terms sorted by weights. With the top q terms specified by users, a semantic graph can be constructed to present the part of a personal knowledge base, which shows the relationships between terms from the same domain. Finally, the experimental results show that the key-phrases generated by the proposed extractor are with good quality and acceptable for humans.

#index 1745894
#* Discovering valuable user behavior patterns in mobile commerce environments
#@ Bai-En Shie;Hui-Fang Hsiao;Philip S. Yu;Vincent S. Tseng
#t 2011
#c 3
#% 443194
#% 463903
#% 481290
#% 483192
#% 804157
#% 829993
#% 945869
#% 1019450
#% 1079273
#% 1245081
#% 1327654
#% 1442149
#% 1451164
#% 1776723
#! Mining user behavior patterns in mobile environments is an emerging topic in data mining fields with wide applications. By integrating moving paths with purchasing transactions, one can find the sequential purchasing patterns with the moving paths, which are called mobile sequential patterns of the mobile users. Mobile sequential patterns can be applied not only for planning mobile commerce environments but also analyzing and managing online shopping websites. However, unit profits and purchased numbers of the items are not considered in traditional framework of mobile sequential pattern mining. Thus, the patterns with high utility (i.e., profit here) cannot be found. In view of this, we aim at integrating mobile data mining with utility mining for finding high utility mobile sequential patterns in this study. A novel algorithm called UMSPL (high Utility Mobile Sequential Pattern mining by a Level-wised method) is proposed to efficiently find high utility mobile sequential patterns. The experimental results show that the proposed algorithm has excellent performance under various system conditions.

#index 1745895
#* A novel method for community detection in complex network using new representation for communities
#@ Wang Yiwen;Yao Min
#t 2011
#c 3
#% 1107312
#% 1308039
#% 1442149
#! During the recent years, community detection in complex network has become a hot research topic in various research fields including mathematics, physics and biology. Identifying communities in complex networks can help us to understand and exploit the networks more clearly and efficiently. In this paper, we investigate the topological structure of complex networks and propose a novel method for community detection in complex network, which owns several outstanding properties, such as efficiency, robustness, broad applicability and semantic. The method is based on partitioning vertex and degree entropy, which are both proposed in this paper. Partitioning vertex is a novel efficient representation for communities and degree entropy is a new measure for the results of community detection. We apply our method to several large-scale data-sets which are up to millions of edges, and the experimental results show that our method has good performance and can find the community structure hidden in complex networks.

#index 1745896
#* Link prediction on evolving data using tensor factorization
#@ Stephan Spiegel;Jan Clausen;Sahin Albayrak;Jérôme Kunegis
#t 2011
#c 3
#% 49501
#% 730089
#% 823342
#% 881493
#% 1055741
#% 1127455
#% 1147645
#% 1235699
#% 1296926
#% 1296933
#% 1296937
#% 1300087
#% 1318728
#% 1384246
#% 1399997
#% 1442149
#% 1482252
#% 1678454
#! Within the last few years a lot of research has been done on large social and information networks. One of the principal challenges concerning complex networks is link prediction. Most link prediction algorithms are based on the underlying network structure in terms of traditional graph theory. In order to design efficient algorithms for large scale networks, researchers increasingly adapt methods from advanced matrix and tensor computations. This paper proposes a novel approach of link prediction for complex networks by means of multi-way tensors. In addition to structural data we furthermore consider temporal evolution of a network. Our approach applies the canonical Parafac decomposition to reduce tensor dimensionality and to retrieve latent trends. For the development and evaluation of our proposed link prediction algorithm we employed various popular datasets of online social networks like Facebook and Wikipedia. Our results show significant improvements for evolutionary networks in terms of prediction accuracy measured through mean average precision.

#index 1745897
#* Permutation anonymization: improving anatomy for privacy preservation in data publication
#@ Xianmang He;Yanghua Xiao;Yujia Li;Qing Wang;Wei Wang;Baile Shi
#t 2011
#c 3
#% 300184
#% 443463
#% 576761
#% 864412
#% 874892
#% 881551
#% 893100
#% 893151
#% 1013611
#% 1026961
#% 1246152
#! Anatomy is a popular technique for privacy preserving in data publication. However, anatomy is fragile under background knowledge attack and can only be applied into limited applications. To overcome these drawbacks, we develop an improved version of anatomy: permutation anonymization, a new anonymization technique that is more effective than anatomy in privacy protection, and meanwhile is able to retain significantly more information in the microdata. We present the detail of the technique and build the underlying theory of the technique. Extensive experiments on real data are conducted, showing that our technique allows highly effective data analysis, while offering strong privacy guarantees.

#index 1745898
#* Efficient mining top-k regular-frequent itemset using compressed tidsets
#@ Komate Amphawan;Philippe Lenca;Athasit Surarerks
#t 2011
#c 3
#% 300124
#% 481290
#% 629644
#% 729942
#% 844211
#% 870871
#% 1195968
#% 1345699
#% 1442149
#% 1443454
#% 1494943
#% 1697245
#! Association rule discovery based on support-confidence framework is an important task in data mining. However, the occurrence frequency (support) of a pattern (itemset) may not be a sufficient criterion for discovering interesting patterns. Temporal regularity, which can be a trace of behavior, with frequency behavior can be revealed as an important key in several applications. A pattern can be regarded as a regular pattern if it occurs regularly in a user-given period. In this paper, we consider the problem of mining top-k regular-frequent itemsets from transactional databases without support threshold. A new concise representation, called compressed transaction-ids set (compressed tidset), and a single pass algorithm, called TR-CT (Top-k Regular frequent itemset mining based on Compressed Tidsets), are proposed to maintain occurrence information of patterns and discover k regular itemsets with highest supports, respectively. Experimental results show that the use of the compressed tidset representation achieves highly efficiency in terms of execution time and memory consumption, especially on dense datasets.

#index 1745899
#* A method of similarity measure and visualization for long time series using binary patterns
#@ Hailin Li;Chonghui Guo;Libin Yang
#t 2011
#c 3
#% 137711
#% 172949
#% 232122
#% 481609
#% 659936
#% 662750
#% 769922
#% 844310
#% 992857
#% 993965
#% 1016248
#% 1082528
#% 1128190
#% 1130291
#% 1218745
#% 1442149
#! Similarity measure and visualization are two of the most interesting tasks in time series data mining and attract much attention in the last decade. Some representations have been proposed to reduce high dimensionality of time series and the corresponding distance functions have been used to measure their similarity. Moreover, visualization techniques are often based on such representations. One of the most popular time series visualization is time series bitmaps using chaos-game algorithm. In this paper, we propose an alternative version of the long time series bitmaps of which the number of the alphabets is not restricted to four. Simultaneously, the corresponding distance function is also proposed to measure the similarity between long time series. Our approach transforms long time series into SAX symbolic strings and constructs a non-sparse matrix which stores the frequency of binary patterns. The matrix can be used to calculate the similarity and visualize the long time series. The experiments demonstrate that our approach not only can measure the long time series as well as the "bag of pattern" (BOP), but also can obtain better visual effects of the long time series visualization than the chaos-game based time series bitmaps (CGB). Especially, the computation cost of pattern matrix construction in our approach is lower than that in CGB.

#index 1745900
#* A BIRCH-Based clustering method for large time series databases
#@ Vo Le Quy Nhon;Duong Tuan Anh
#t 2011
#c 3
#% 310580
#% 420057
#% 430746
#% 466507
#% 631923
#% 722902
#% 818916
#% 948249
#% 1442149
#% 1703507
#! This paper presents a novel approach for time series clustering which is based on BIRCH algorithm. Our BIRCH-based approach performs clustering of time series data with a multi-resolution transform used as feature extraction technique. Our approach hinges on the use of cluster feature (CF) tree that helps to resolve the dilemma associated with the choices of initial centers and significantly improves the execution time and clustering quality. Our BIRCH-based approach not only takes full advantages of BIRCH algorithm in the capacity of handling large databases but also can be viewed as a flexible clustering framework in which we can apply any selected clustering algorithm in Phase 3 of the framework. Experimental results show that our proposed approach performs better than k-Means in terms of clustering quality and running time, and better than I-k-Means in terms of clustering quality with nearly the same running time.

#index 1745901
#* Visualizing cluster structures and their changes over time by two-step application of self-organizing maps
#@ Masahiro Ishikawa
#t 2011
#c 3
#% 248027
#% 329562
#% 333881
#% 342617
#% 387427
#% 391311
#% 1442149
#% 1650433
#% 1707827
#! In this paper, a novel method for visualizing cluster structures and their changes over time is proposed. Clustering is achieved by two-step application of self-organizing maps (SOMs). By two-step application of SOMs, each cluster is assigned an angle and a color. Similar clusters are assigned similar ones. By using colors and angles, cluster structures are visualized in several fashions. In those visualizations, it is easy to identify similar clusters and to see degrees of cluster separations. Thus, we can visually decide whether some clusters should be grouped or separated. Colors and angles are also used to make clusters in multiple datasets from different time periods comparable. Even if they belong to different periods, similar clusters are assigned similar colors and angles, thus it is easy to recognize that which cluster has grown or which one has diminished in time. As an example, the proposed method is applied to a collection of Japanese news articles. Experimental results show that the proposed method can clearly visualize cluster structures and their changes over time, even when multiple datasets from different time periods are concerned.

#index 1745902
#* Analysis of cluster migrations using self-organizing maps
#@  Denny;Peter Christen;Graham J. Williams
#t 2011
#c 3
#% 355154
#% 391311
#% 443515
#% 779906
#% 1411076
#% 1483016
#% 1633202
#% 1707827
#% 1860652
#! Discovering cluster changes in real-life data is important in many contexts, such as fraud detection and customer attrition analysis. Organizations can use such knowledge of change to adapt business strategies in response to changing circumstances. This paper is aimed at the visual exploration of migrations of cluster entities over time using Self-Organizing Maps. The contribution is a method for analyzing and visualizing entity migration between clusters in two or more snapshot datasets. Existing research on temporal clustering primarily focuses on either time-series clustering, clustering of sequences, or data stream clustering. There is a lack of work on clustering snapshot datasets collected at different points in time. This paper explores cluster changes between such snapshot data. Besides analyzing structural cluster changes, analysts often desire deeper insight into changes at the entity level, such as identifying which attributes changed most significantly in the members of a disappearing cluster. This paper presents a method to visualize migration paths and a framework to rank attributes based on the extent of change among selected entities. The method is evaluated using synthetic and real-life datasets, including data from the World Bank.

#index 1745903
#* ClasSi: measuring ranking quality in the presence of object classes with similarity information
#@ Anca Maria Ivanescu;Marc Wichterich;Thomas Seidl
#t 2011
#c 3
#% 349550
#% 375017
#% 1077150
#% 1737769
#! The quality of rankings can be evaluated by computing their correlation to an optimal ranking. State of the art ranking correlation coefficients like Kendall's τ and Spearman's ρ do not allow for the user to specify similarities between differing object classes and thus treat the transposition of objects from similar classes the same way as that of objects from dissimilar classes. We propose ClasSi, a new ranking correlation coefficient which deals with class label rankings and employs a class distance function to model the similarities between the classes. We also introduce a graphical representation of ClasSi akin to the ROCcurve which describes how the correlation evolves throughout the ranking.

#index 1745904
#* The instance easiness of supervised learning for cluster validity
#@ Vladimir Estivill-Castro
#t 2011
#c 3
#% 290482
#% 579655
#% 722902
#% 729437
#% 915231
#% 1023380
#% 1041370
#% 1301004
#! "The statistical problem of testing cluster validity is essentially unsolved" [5]. We translate the issue of gaining credibility on the output of un-supervised learning algorithms to the supervised learning case. We introduce a notion of instance easiness to supervised learning and link the validity of a clustering to how its output constitutes an easy instance for supervised learning. Our notion of instance easiness for supervised learning extends the notion of stability to perturbations (used earlier for measuring clusterability in the un-supervised setting). We follow the axiomatic and generic formulations for cluster-quality measures. As a result, we inform the trust we can place in a clustering result using standard validity methods for supervised learning, like cross validation.

#index 1745905
#* A new efficient and unbiased approach for clustering quality evaluation
#@ Jean-Charles Lamirel;Pascal Cuxac;Raghvendra Mall;Ghada Safi
#t 2011
#c 3
#% 32926
#% 375017
#% 430746
#% 840583
#% 895181
#% 1251667
#% 1349941
#% 1349952
#% 1633202
#! Traditional quality indexes (Inertia, DB, …) are known to be method-dependent indexes that do not allow to properly estimate the quality of the clustering in several cases, as in that one of complex data, like textual data. We thus propose an alternative approach for clustering quality evaluation based on unsupervised measures of Recall, Precision and F-measure exploiting the descriptors of the data associated with the obtained clusters. Two categories of index are proposed, that are Macro and Micro indexes. This paper also focuses on the construction of a new cumulative Micro precision index that makes it possible to evaluate the overall quality of a clustering result while clearly distinguishing between homogeneous and heterogeneous, or degenerated results. The experimental comparison of the behavior of the classical indexes with our new approach is performed on a polythematic dataset of bibliographical references issued from the PASCAL database.

#index 1745906
#* A structure preserving flat data format representation for tree-structured data
#@ Fedja Hadzic
#t 2011
#c 3
#% 136350
#% 478622
#% 728293
#% 729941
#% 813989
#% 841959
#% 907532
#% 944956
#% 1063631
#% 1438597
#% 1495585
#% 1578194
#% 1669921
#! Mining of semi-structured data such as XML is a popular research topic due to many useful applications. The initial work focused mainly on values associated with tags, while most of recent developments focus on discovering association rules among tree structured data objects to preserve the structural information. Other data mining techniques have had limited use in tree-structured data analysis as they were mainly designed to process flat data format with no need to capture the structural properties of data objects. This paper proposes a novel structure-preserving way for representing tree-structured document instances as records in a standard flat data structure to enable applicability of a wider range of data analysis techniques. The experiments using synthetic and real world data demonstrate the effectiveness of the proposed approach.

#index 1745907
#* A fusion of algorithms in near duplicate document detection
#@ Jun Fan;Tiejun Huang
#t 2011
#c 3
#% 201935
#% 204673
#% 255137
#% 311808
#% 345087
#% 347225
#% 728115
#% 730067
#% 769944
#% 818223
#% 879600
#% 956507
#% 1074121
#! With the rapid development of the World Wide Web, there are a huge number of fully or fragmentally duplicated pages in the Internet. Return of these near duplicated results to the users greatly affects user experiences. In the process of deploying digital libraries, the protection of intellectual property and removal of duplicate contents needs to be considered. This paper fuses some "state of the art" algorithms to reach a better performance. We first introduce the three major algorithms (shingling, I-match, simhash) in duplicate document detection and their developments in the following days. We take sequences of words (shingles) as the feature of simhash algorithm. We then import the random lexicons based multi fingerprints generation method into shingling base simhash algorithm and named it shingling based multi fingerprints simhash algorithm. We did some preliminary experiments on the synthetic dataset based on the "China-US Million Book Digital Library Project". The experiment result proves the efficiency of these algorithms.

#index 1745908
#* Searching interesting association rules based on evolutionary computation
#@ Guangfei Yang;Yanzhong Dang;Shingo Mabu;Kaoru Shimada;Kotaro Hirasawa
#t 2011
#c 3
#% 280433
#% 443092
#% 443313
#% 577214
#% 629644
#% 881485
#% 881489
#% 881500
#% 995159
#% 1275285
#! In this paper, we propose an evolutionary method to search interesting association rules. Most of the association rule mining methods give a large number of rules, and it is difficult for human beings to deal with them. We study this problem by borrowing the style of a search engine, that is, searching association rules by keywords. Whether a rule is interesting or not is decided by its relation to the keywords, and we introduce both semantic and statistical methods to measure such relation. The mining process is built on an evolutionary approach, Genetic Network Programming (GNP). Different from the conventional GNP based association rule mining method, the proposed method pays more attention to generate the GNP individuals carefully, which will mine interesting association rules efficiently.

#index 1745909
#* An efficient approach to mine periodic-frequent patterns in transactional databases
#@ Akshat Surana;R. Uday Kiran;P. Krishna Reddy
#t 2011
#c 3
#% 280456
#% 481290
#% 729418
#% 765520
#% 1195968
#% 1494943
#! Recently, temporal occurrences of the frequent patterns in a transactional database has been exploited as an interestingness criterion to discover a class of user-interest-based frequent patterns, called periodic-frequent patterns. Informally, a frequent pattern is said to be periodic-frequent if it occurs at regular intervals specified by the user throughout the database. The basic model of periodic-frequent patterns is based on the notion of "single constraints." The use of this model to mine periodic-frequent patterns containing both frequent and rare items leads to a dilemma called the "rare item problem." To confront the problem, an alternative model based on the notion of "multiple constraints" has been proposed in the literature. The periodic-frequent patterns discovered with this model do not satisfy downward closure property. As a result, it is computationally expensive to mine periodic-frequent patterns with the model. Furthermore, it has been observed that this model still generates some uninteresting patterns as periodic-frequent patterns. With this motivation, we propose an efficient model based on the notion of "multiple constraints." The periodic-frequent patterns discovered with this model satisfy downward closure property. Hence, periodic-frequent patterns can be efficiently discovered. A pattern-growth algorithm has also been discussed for the proposed model. Experimental results show that the proposed model is effective.

#index 1745910
#* Algorithms to discover complete frequent episodes in sequences
#@ Jianjun Wu;Li Wan;Zeren Xu
#t 2011
#c 3
#% 152934
#% 300120
#% 338580
#% 420063
#% 459006
#% 463903
#% 799764
#% 989612
#% 1390145
#! Serial episode is a type of temporal frequent pattern in sequence data. In this paper we compare the performance of serial episode discovering algorithms. Many different algorithms have been proposed to discover different types of episodes for different applications. However, it is unclear which algorithm is more efficient for discovering different types of episodes. We compare Minepi and WinMiner which discover serial episodes defined by minimal occurrence of subsequence. We find Minepi cannot discover all minimal occurrences of serial episodes as the literature, which proposed it, claimed. We also propose an algorithm Ap-epi to discover minimal occurrences of serial episode, which is a complement of Minepi. We propose an algorithm NOE-WinMiner which discovers non-overlapping episodes and compare it with an existing algorithm. Extensive experiments demonstrate that Ap-epi outperforms Minepi(fixed) when the minimum support is large and NOE-WinMiner beats the existing algorithm which discovers non-overlapping episodes with constraints between the two adjacent events.

#index 1745911
#* Certainty upon empirical distributions
#@ Joan Garriga
#t 2011
#c 3
#% 136350
#% 449588
#% 1301004
#! We address the problem of assessing the information conveyed by a finite discrete probability distribution, within the context of knowledge discovery. Our approach is based on two main axiomatic intuitions: (i) the minimum information is given in the case of a uniform distribution, and (ii) knowledge is akin to a notion of richness, related to the dimension of the distribution. From this perspective, we define a statistic that has a clear interpretation in terms of a measure of certainty, and we build up a plausible hypothesis, which offers a comprehensible insight of knowledge, with a consistent algebraic structure. This includes a native value for the uncertainty related to unseen events. Our approach is then faced up with entropy based measures. Finally, by implementing our measure in a decision tree induction algorithm, we show an empirical validation of the behavior of our measure with respect to entropy. Our conclusion is that the contributions of our measure are significant, and should definitely lead to more robust models.

#index 1745912
#* A measure oriented training scheme for imbalanced classification problems
#@ Bo Yuan;Wenhuang Liu
#t 2011
#c 3
#% 369236
#% 466268
#% 471428
#% 915253
#% 1271973
#% 1277382
#% 1324364
#% 1334669
#% 1366878
#% 1493917
#% 1710599
#% 1776849
#! Since the overall prediction error of a classifier on imbalanced problems can be potentially misleading and biased, it is commonly evaluated by measures such as G-mean and ROC (Receiver Operating Characteristic) curves. However, for many classifiers, the learning process is still largely driven by error based objective functions. As a result, there is clearly a gap between the measure according to which the classifier is to be evaluated and how the classifier is trained. This paper investigates the possibility of directly using the measure itself to search the hypothesis space to improve the performance of classifiers. Experimental results on three standard benchmark problems and a real-world problem show that the proposed method is effective in comparison with commonly used sampling techniques.

#index 1745913
#* An SVM-Based approach to discover MicroRNA precursors in plant genomes
#@ Yi Wang;Cheqing Jin;Minqi Zhou;Aoying Zhou
#t 2011
#c 3
#% 669214
#% 832837
#% 833964
#% 906282
#% 1038867
#% 1190817
#! MicroRNAs (miRNAs) are noncoding RNAs of ~22 nucleotides that play versatile regulatory roles in multicelluler organisms. Since the cloning methods for miRNAs identification are biased towards abundant miRNAs, the computational approaches provide useful complements to identify miRNAs which are highly constrained by tissue- and time-specifically expression manners. In this paper, we propose a novel Support Vector Machine (SVM) based detector, named MiR-PD, to identify pre-miRNAs in plants. The classifier is constructed based on twelve features of pre-miRNAs, inclusive of five global features and seven sub-structure features. Trained on 790 plant pre-miRNAs and 7,900 pseudo pre-miRNAs, MiR-PD achieves 96.43% five-fold cross-validation accuracy. Tested on the newly identified 441 plant pre-miRNAs and 62,883 pseudo pre-miRNAs, MiR-PD reports an accuracy of 99.71% with 77.55% sensitivity and 99.87% specificity, suggesting a feasible genome-wide application of this miRNAs detector so as to identify novel miRNAs (especially for those species-specific miRNAs) in plants without relying on phylogenetical conservation.

#index 1745914
#* Towards recommender system using particle swarm optimization based web usage clustering
#@ Shafiq Alam;Gillian Dobbie;Patricia Riddle
#t 2011
#c 3
#% 552180
#% 614610
#% 920673
#% 1155872
#% 1442149
#% 1563332
#! Efficiency and quality of the product of data mining process is a challenging question for the researchers. Different methods have been proposed in the literature to tackle these problems. Optimization based methods are a way to address this issue. We addressed the problem of data clustering by implementing swarm intelligence based optimization technique called Particle Swarm Optimization (PSO). We scaled the approach to implement it in a hierarchical way using Hierarchical Particle Swarm (HPSO) clustering. The paper also aims to outline our novel outlier detection technique. The research will lead us to provide a benchmark for web usage mining and propose a collective intelligence based recommender system for the usage of Java API documentation.

#index 1745915
#* Weighted association rule mining using particle swarm optimization
#@ Russel Pears;Yun Sing Koh
#t 2011
#c 3
#% 152934
#% 280487
#% 310541
#% 443393
#% 481290
#% 606569
#% 641014
#% 729988
#% 915485
#% 1038715
#% 1085188
#% 1734441
#% 1777201
#! Association rule mining is an important data mining task that discovers relationships among items in a transaction database. Most approaches to association rule mining assume that the items within the dataset have a uniform distribution. Therefore, weighted association rule mining (WARM) was introduced to provide a notion of importance to individual items. In previous work most of these approaches require users to assign weights for each item. This is infeasible when we have millions of items in a dataset. In this paper we propose a novel method, Weighted Association Rule Mining using Particle Swarm Optimization (WARM SWARM), which uses particle swarm optimization to assign meaningful item weights for association rule mining.

#index 1745916
#* An unsupervised feature selection framework based on clustering
#@ Sheng-yi Jiang;Lian-xi Wang
#t 2011
#c 3
#% 335012
#% 345824
#% 361100
#% 385564
#% 449568
#% 580509
#% 661048
#% 722929
#% 771842
#% 772208
#% 793239
#% 796212
#% 800188
#% 813902
#% 874856
#% 926881
#% 1035242
#% 1055379
#% 1126942
#% 1230070
#% 1257081
#% 1369563
#% 1378511
#% 1478478
#! Feature selection plays an important part in improving the quality of learning algorithms in machine learning and data mining. It has been widely studied in supervised learning, whereas it is still relatively rare researched in unsupervised learning. In this work, a clustering-based framework formed by an unsupervised feature selection algorithm is proposed. The proposed framework is mainly concerned with the problem of determining and choosing important features, which are selected by ranking the features according to the importance measure scores, from the original feature set without class information. Theory analyzed indicates that the time complexity of each algorithm is nearly linear with the size and the number of features of dataset. Experimental results on UCI datasets show that algorithm with different scores in the framework are able to identify the important features with clustering, and the proposed algorithm have obtained competitive results in terms of classification error rate and the degree of dimensionality reduction when compared with the state-of-the-art supervised and unsupervised feature selection approaches.

#index 1745917
#* Discovery of regularities in the use of herbs in traditional chinese medicine prescriptions
#@ Nevin L. Zhang;Runsun Zhang;Tao Chen
#t 2011
#c 3
#% 770799
#% 771837
#% 940814
#% 1039290
#% 1378546
#! Traditional Chinese medicine (TCM) is a discipline with its own distinct methodologies and philosophical principles. The main method of treatment in TCM is to use herb prescriptions. Typically, a number of herbs are combined to form a formula and different formulae are prescribed for different patients. Regularities on the mixture of herbs in the prescriptions are important for both clinical treatment and novel patent medicine development. In this study, we analyze TCM formula data using latent tree (LT) models. Interesting regularities are discovered. Those regularities are of interest to students of TCM as well as pharmaceutical companies that manufacture medicine using Chinese herbs.

#index 1745918
#* COW: a co-evolving memetic wrapper for herb-herb interaction analysis in TCM informatics
#@ Dion Detterer;Paul Kwan
#t 2011
#c 3
#% 418022
#% 465692
#% 722929
#% 1378546
#% 1720080
#% 1781801
#% 1781805
#! Traditional Chinese Medicine (TCM) relies heavily on interactions between herbs within prescribed formulae. However, given the combinatorial explosion due to the vast number of herbs available for treatment, the study of herb-herb interactions by pure human analysis is impractical, with computeraided analysis computationally expensive. Thus feature selection is crucial as a pre-processing step prior to herb-herb interaction analysis. In accord with this goal, a new feature selection algorithm known as a Co-evolving Memetic Wrapper (COW) is proposed: COW takes advantage of recent developments in genetic algorithms (GAs) and memetic algorithms (MAs), evolving appropriate feature subsets for a given domain. As part of preliminary research, COW is demonstrated to be effective in selecting herbs in the TCM insomnia datatset. Finally, possible future applications of COW are examined, both within TCM research and in broader data mining contexts.

#index 1745919
#* Selecting an appropriate interestingness measure to evaluate the correlation between syndrome elements and symptoms
#@ Lei Zhang;Qi-ming Zhang;Yi-guo Wang;Dong-lin Yu
#t 2011
#c 3
#% 152934
#% 227919
#% 751575
#% 818916
#% 842021
#% 867057
#% 1000578
#! In order to select the best interestingness measure appropriate for evaluating the correlation between syndrome elements and symptoms, 60 objective interestingness measures were selected from different subjects. Firstly, a hypothesis for a good measure was proposed. Based on the hypothesis, an experiment was designed to evaluate the measures. The experiment was based on the clinical record database of past dynasties including 51,186 clinical cases. The selected dataset in this study had 44,600 records. Han and Re were selected as the experimental syndrome elements. Three indicators calculated according to the distances between two syndrome elements were obtained in the experiment and were combined into one indicator. The Z score, φ-coefficient and Kappa were selected from 60 measures after the experiment. The Z score and φ- coefficient were selected according to subjective interestingness. Finally, the φ- coefficient was selected as the best measure for its low computational complexity. The method introduced in this paper may be used in other similar territories. Further research of traditional Chinese medicine can be made based on the conclusion made in this paper.

#index 1745920
#* The impact of feature representation to the biclustering of symptoms-herbs in TCM
#@ Simon Poon;Zhe Luo;Runshun Zhang
#t 2011
#c 3
#% 296738
#% 469422
#% 832775
#% 906512
#% 940814
#% 1378546
#% 1720080
#! Traditional Chinese Medicine (TCM) is a holistic approach to medical treatment. Analysis and decision cannot be made in isolation, hence, the extraction of symptoms-herbs relationship is a crucial step to the research of the underlying TCM principle. Since this kind of relationship bears a lot of similarity with the gene-expression study in the microarray analysis, where the use of biclustering algorithms is common, it is logical to apply biclustering algorithms to the study of symptom-herb relationship. However, the choice of feature representation is a dominant factor in the success of any machine learning problem. This paper aims to understand the impact of different representation schemes in the biclustering of symptoms-herbs relationship. A bicluster is not helpful if the number of features is too large or too small. In order to get a desirable size for the biclusters, modified relative success ratio is considered to be the most appropriate one among the other four schemes. Some of the biclusters (using modified relative success ratio) do follow the therapeutic principle of TCM, while some biclusters with interesting feature combination that are worthwhile for clinical evaluation.

#index 1745921
#* Usage of mobile phones for personalized healthcare solutions
#@ M. Saravanan;S. Shanthi;S. Shalini
#t 2011
#c 3
#% 198016
#% 736273
#% 784270
#% 1392030
#! One of the greatest hurdles in providing the appropriate healthcare is the availability of proper information at the point of individual's care. Mobile phone-based health solutions can bridge this gap and can support with right information at the right time. In order to overcome some of the prevalent issues and hence provide the necessary healthcare, we here introduce one such mobile based system known as the Personalized Mobile Health Service System for Individual's Healthcare which caters to the specific needs of the user without the constraint on mobility. This system helps in guiding the user with regard to the food they consume, the precautionary measures to be taken in case of any ailments, and when they travel to a new location etc. This system also proves to be supportive in situations when the user is in a traumatic condition suffering alone. The main advantage of the system is that it will keep updating the details to the user on a regular basis.

#index 1745922
#* Robust learning of mixture models and its application on trial pruning for EEG signal analysis
#@ Boyu Wang;Feng Wan;Peng Un Mak;Pui In Mak;Mang I Vai
#t 2011
#c 3
#% 254001
#% 261550
#% 345829
#% 443689
#% 789563
#% 1228479
#% 1436441
#% 1699282
#% 1718529
#! This paper presents a novel method based on deterministic annealing to circumvent the problem of the sensitivity to atypical observations associated with the maximum likelihood (ML) estimator via conventional EM algorithm for mixture models. In order to learn the mixture models in a robust way, the parameters of mixture model are estimated by trimmed likelihood estimator (TLE), and the learning process is controlled by temperature based on the principle of maximum entropy. Moreover, we apply the proposed method to the single-trial electroencephalography (EEG) classification task. The motivation of this work is to eliminate the negative effects of artifacts in EEG data, which usually exist in real-life environments, and the experimental results demonstrate that the proposed method can successfully detect the outliers and therefore achieve more reliable result.

#index 1745923
#* An integrated approach to multi-criteria-based health care facility location planning
#@ Wei Gu;Baijie Wang;Xin Wang
#t 2011
#c 3
#% 1034537
#! Optimal location of health care facilities is critical to the success of health care services. Given its importance, this is an active research topic in health informatics, operational research and GIS. This paper presents an integrated approach to health care facility planning whereby the methods from three research topics are combined. The integrated approach is applied in order to solve preventive health care facility location planning problems. In this approach, a new health accessibility estimation method is developed in order to capture the current characteristics of preventive health care services. Based on this, the preventive health care facility location planning problem is formalized as a multi-criteria facility location model. A new algorithm is proposed in order to solve the model. Experiments on synthetic datasets and on the Alberta breast cancer screening program data are conducted and the results support our analysis.

#index 1745924
#* Medicinal property knowledge extraction from herbal documents for supporting question answering system
#@ Chaveevan Pechsiri;Sumran Painuall;Uraiwan Janviriyasopak
#t 2011
#c 3
#% 376266
#% 748339
#% 1270282
#! The aim of this paper is to automatically extract the medicinal properties of an object, especially an herb, from technical documents as knowledge sources for health-care problem solving through the question-answering system, especially What-Question, for disease treatment. The extracted medicinal property knowledge is based on multiple simple sentence or EDUs (Elementary Discourse Units). There are three problems of extracting the medicinal property knowledge: the herbal object identification problem, the medicinal property identification problem for each object and the medicinal property boundary determination problem. We propose using NLP (Natural Language Processing) with statistical based approach to identify the medicinal property and also with machine learning technique as Naïve Bayes with verb features for solving the boundary problem. The result shows successfully the medicinal property extraction of the precision and recall of 86% and 77%, respectively, along with 87% correctness of the boundary determination.

#index 1745925
#* Age estimation using bayesian process
#@ Yu Zhang
#t 2011
#c 3
#% 132676
#% 280100
#% 443971
#% 883908
#% 884100
#% 891549
#% 891559
#% 905156
#% 1013687
#% 1131919
#% 1775747
#% 1781344
#% 1856227
#% 1856665
#! Age problems have attracted many researchers' attentions in recent years since they have many potential applications in human-computer interaction and other areas. Among all the age problems, automatic age estimation is one interesting problem and many methods have been proposed to solve this problem. In this paper, we use two Bayesian process regression algorithms, Gaussian process and t process, for age estimation. Different from previous regression methods on age estimation, which need to specify the form of regression functions or determine many parameters in regression functions in inefficient ways such as cross validation, in our methods, the form of regression function is implicitly defined by kernel function and almost all the parameters of our methods can be learnt from data automatically using efficient gradient methods. Moreover, our methods are very simple and easy to implement. Since Gaussian process is easy to be affected by outlier data points, t process can be viewed as a robust version of Gaussian process to solve this problem. Experiments on one public aging database FG-NET show our method is effective and comparable with the state-of-the-art methods on age estimation.

#index 1745926
#* Significant node identification in social networks
#@ Chi-Yao Tseng;Ming-Syan Chen
#t 2011
#c 3
#% 662755
#% 723439
#% 879570
#% 956516
#% 1116996
#% 1192927
#% 1227654
#% 1348087
#! Given a social network, identifying significant nodes from the network is highly desirable in many applications. In different networks formed by diverse kinds of social connections, the definitions of what are significant nodes differ with circumstances. In the literature, most previous works generally focus on expertise finding in specific social networks. In this paper, we aim to propose a general node ranking model that can be adopted to satisfy a variety of service demands. We devise an unsupervised learning method that produces the ranking list of top-k significant nodes. The characteristic of this method is that it can generate different ranking lists when diverse sets of features are considered. To demonstrate the real application of the proposed method, we design the system DblpNET that is an author ranking system based on the co-author network of DBLP computer science bibliography. We discuss further extensions and evaluate DblpNET empirically on the public DBLP dataset. The evaluation results show that the proposed method can effectively apply to real-world applications.

#index 1745927
#* Improving bagging performance through multi-algorithm ensembles
#@ Kuo-Wei Hsu;Jaideep Srivastava
#t 2011
#c 3
#% 73372
#% 132938
#% 136350
#% 209021
#% 256615
#% 269218
#% 400847
#% 451221
#% 464782
#% 465764
#% 552056
#% 742990
#% 878938
#% 889165
#% 940120
#% 989670
#% 1019061
#% 1023380
#% 1101328
#% 1196041
#% 1270153
#% 1279286
#% 1332074
#% 1336614
#% 1390408
#% 1491568
#% 1674401
#% 1695040
#% 1710600
#% 1712794
#% 1778915
#% 1786904
#! Bagging establishes a committee of classifiers first and then aggregates their outcomes through majority voting. Bagging has attracted considerable research interest and been applied in various application domains. Its advantages include an increased capability of handling small data sets, less sensitivity to noise or outliers, and a parallel structure for efficient implementations. However, it has been found to be less accurate than some other ensemble methods. In this paper, we propose an approach that improves bagging through the employment of multiple classification algorithms in ensembles. Our approach preserves the parallel structure of bagging and improves the accuracy of bagging. As a result, it unlocks the power and expands the user base of bagging.

#index 1745928
#* Mining tourist preferences with twice-learning
#@ Chen Zhang;Jie Zhang
#t 2011
#c 3
#% 136350
#% 290482
#% 443616
#% 1113093
#% 1442149
#% 1669866
#% 1778633
#! Data mining techniques have been recognized as powerful tools for predictive modeling tourist decision-making process. However, two practical yet important problems have not been resolved by the data miners in empirical tourism research. Firstly, comprehensibility-the role of the data mining should not only generate accurate predictions, but also provide insights why certain prediction is made. But most widely used data mining methods that can generalize well are black-box in nature and can provide little information on the tourist decision-making facts. Secondly, the lack of training samples-it is usually rather difficult to collect enough training samples through surveying the tourist on site, especially for surveying the tourist's decision-making facts. Many data mining methods may not achieve satisfactory performance if learned on small data set. In this paper, we show that these two problems can be addressed simultaneously using a twice-learning framework on the travel preference data. The results indicate that by addressing these two problems properly, we can predict tourist preferences accurately as well as extracting meaningful insights which would be useful for tourism marketing.

#index 1745929
#* Towards cost-sensitive learning for real-world applications
#@ Xu-Ying Liu;Zhi-Hua Zhou
#t 2011
#c 3
#% 235377
#% 280437
#% 342611
#% 443509
#% 466268
#% 466561
#% 466760
#% 565245
#% 580510
#% 727925
#% 823337
#% 829981
#% 843876
#% 893461
#% 922066
#% 983880
#% 1073961
#% 1083680
#% 1085131
#% 1100112
#% 1182785
#% 1250597
#% 1272369
#% 1289281
#% 1451180
#% 1464116
#% 1673605
#% 1705261
#! Many research work in cost-sensitive learning focused on binary class problems and assumed that the costs are precise. But real-world applications often have multiple classes and the costs cannot be obtained precisely. It is important to address these issues for cost-sensitive learning to be more useful for real-world applications. This paper gives a short introduction to cost-sensitive learning and then summaries some of our previous work related to the above two issues: (1) The analysis of why traditional Rescaling method fails to solve multi-class problems and our method Rescalenew . (2) The problem of learning with cost intervals and our CISVM method. (3) The problem of learning with cost distributions and our CODIS method.

#index 1864917
#* New Frontiers in Applied Data Mining: PAKDD 2011 International Workshops
#@ Longbing Cao;Joshua Zhexue Huang;James Bailey;Yun Sing Koh;Jun Luo
#t 2012
#c 3
#! This book constitutes the thoroughly refereed post-conference proceedings of five international workshops held in conjunction with PAKDD 2011 in Shenzhen, China, in May 2011: the International Workshop on Behavior Informatics (BI 2011), the Workshop on Quality Issues, Measures of Interestingness and Evaluation of Data Mining Models (QIMIE 2011), the Workshop on Biologically Inspired Techniques for Data Mining (BDM 2011), the Workshop on Advances and Issues in Traditional Chinese Medicine Clinical Data Mining (AI-TCM 2011), and the Second Workshop on Data Mining for Healthcare Management (DMGHM 2011). The book also includes papers from the First PAKDD Doctoral Symposium on Data Mining (DSDM 2011). The42 papers were carefully reviewed and selected from numerous submissions. The papers cover a wide range of topics discussing emerging techniques in the field of knowledge discovery in databases and their application domains extending to previously unexplored areas such as data mining based on optimization techniques from biological behavior of animals and applications in Traditional Chinese Medicine clinical research and health care management.

#index 1874806
#* Proceedings of the 16th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining - Volume Part I
#@ Pang-Ning Tan;Sanjay Chawla;Chin Kuan Ho;James Bailey
#t 2012
#c 3

#index 1874807
#* Time-Evolving relational classification and ensemble methods
#@ Ryan Rossi;Jennifer Neville
#t 2012
#c 3
#% 246831
#% 248810
#% 342596
#% 549441
#% 551723
#% 727834
#% 729982
#% 915320
#% 1047784
#% 1176895
#% 1214635
#% 1524266
#% 1561560
#% 1617091
#! Relational networks often evolve over time by the addition, deletion, and changing of links, nodes, and attributes. However, accurately incorporating the full range of temporal dependencies into relational learning algorithms remains a challenge. We propose a novel framework for discovering temporal-relational representations for classification. The framework considers transformations over all the evolving relational components (attributes, edges, and nodes) in order to accurately incorporate temporal dependencies into relational models. Additionally, we propose temporal ensemble methods and demonstrate their effectiveness against traditional and relational ensembles on two real-world datasets. In all cases, the proposed temporal-relational models outperform competing models that ignore temporal information.

#index 1874808
#* Active learning for hierarchical text classification
#@ Xiao Li;Da Kuang;Charles X. Ling
#t 2012
#c 3
#% 262050
#% 280866
#% 464268
#% 466501
#% 722797
#% 763708
#% 945300
#% 1074128
#% 1117691
#% 1130870
#% 1195838
#% 1214713
#% 1375847
#% 1387560
#% 1480216
#% 1538188
#! Hierarchical text classification plays an important role in many real-world applications, such as webpage topic classification, product categorization and user feedback classification. Usually a large number of training examples are needed to build an accurate hierarchical classification system. Active learning has been shown to reduce the training examples significantly, but it has not been applied to hierarchical text classification due to several technical challenges. In this paper, we study active learning for hierarchical text classification. We propose a realistic multi-oracle setting as well as a novel active learning framework, and devise several novel leveraging strategies under this new framework. Hierarchical relation between different categories has been explored and leveraged to improve active learning further. Experiments show that our methods are quite effective in reducing the number of oracle queries (by 74% to 90%) in building accurate hierarchical classification systems. As far as we know, this is the first work that studies active learning in hierarchical text classification with promising results.

#index 1874809
#* TeamSkill evolved: mixed classification schemes for team-based multi-player games
#@ Colin DeLong;Jaideep Srivastava
#t 2012
#c 3
#% 961152
#% 1100158
#% 1105563
#% 1607977
#! In this paper, we introduce several approaches for maintaining weights over the aggregate skill ratings of subgroups of teams during the skill assessment process and extend our earlier work in this area to include game-specific performance measures as features alongside aggregate skill ratings as part of the online prediction task. We find that the inclusion of these game-specific measures do not improve prediction accuracy in the general case, but do when competing teams are considered evenly matched. As such, we develop a "mixed" classification method called TeamSkill-EVMixed which selects a classifier based on a threshold determined by the prior probability of one team defeating another. This mixed classification method outperforms all previous approaches in most evaluation settings and particularly so in tournament environments. We also find that TeamSkill-EVMixed's ability to perform well in close games is especially useful early on in the rating process where little game history is available.

#index 1874810
#* A novel weighted ensemble technique for time series forecasting
#@ Ratnadip Adhikari;R. K. Agrawal
#t 2012
#c 3
#% 1421751
#! Improvement of time series forecasting accuracy is an active research area having significant importance in many practical domains. Extensive works in literature suggest that substantial enhancement in accuracies can be achieved by combining forecasts from different models. However, forecasts combination is a difficult as well as a challenging task due to various reasons and often simple linear methods are used for this purpose. In this paper, we propose a nonlinear weighted ensemble mechanism for combining forecasts from multiple time series models. The proposed method considers the individual forecasts as well as the correlations in pairs of forecasts for creating the ensemble. A successive validation approach is formulated to determine the appropriate combination weights. Three popular models are used to build up the ensemble which is then empirically tested on three real-world time series. Obtained forecasting results, measured through three well-known error statistics demonstrate that the proposed ensemble method provides significantly better accuracies than each individual model.

#index 1874811
#* Techniques for efficient learning without search
#@ Houssam Salem;Pramuditha Suraweera;Geoffrey I. Webb;Janice R. Boughton
#t 2012
#c 3
#% 312728
#% 321059
#% 478772
#% 799040
#% 926881
#% 1264132
#% 1694443
#! Averaged n -Dependence Estimators (An DE) is a family of learning algorithms that range from low variance coupled with high bias through to high variance coupled with low bias. The asymptotic error of the lowest bias variant is the Bayes optimal. The An DE family of algorithms have a training time that is linear with respect to the training examples, learn in a single pass through the data, support incremental learning, handle missing values directly and are robust in the face of noise. These characteristics make the algorithms particularly well suited to learning from large data. However, for higher orders of n they are very computationally demanding. This paper presents data structures and algorithms developed to reduce both memory and time for training and classification. These enhancements have enabled the evaluation and comparison of A3DE's effectiveness. The results provide further support for the hypothesis that as the number of training examples increases, decreasing error will be attained by members of the An DE family with increasing levels of n .

#index 1874812
#* An aggressive margin-based algorithm for incremental learning
#@ JuiHsi Fu;SingLing Lee
#t 2012
#c 3
#% 232653
#% 302390
#% 449529
#% 466482
#% 661302
#% 801566
#% 961152
#% 987244
#% 1073905
#% 1117000
#% 1139611
#% 1284729
#% 1359251
#! In incremental learning, the classification model is incrementally updated using the small datasets. Different with existing methods, our approach updates the current classifier according to each sample in the dataset, respectively. The classifier is updated by adjusting more than the margin of each sample. Then the new classifier is generated by carefully analyzing classifier adjustments caused for labeled samples. Additionally the new classifier shall correct prediction mistakes of the previous classifier as many as possible. In details, we formulate simple constrained optimization problems and then the updated classifier is the solution derived using Lagrange multipliers. In our experiments, 13 real-world dataset are used to present the effectiveness of the proposed approach. The experimental results are shown that our update strategy is able to adjust the classifier properly. And it is also shown that the proposed incremental learning approach is suitable to be applied for the requirement of frequently adjusting the existing classifiers.

#index 1874813
#* Two-View online learning
#@ Tam T. Nguyen;Kuiyu Chang;Siu Cheung Hui
#t 2012
#c 3
#% 197394
#% 271060
#% 801566
#% 840938
#% 961152
#% 1073905
#% 1338580
#% 1826291
#! We propose a two-view online learning algorithm that utilizes two different views of the same data to achieve something that is greater than the sum of its parts. Our algorithm is an extension of the single-view Passive Aggressive (PA) algorithm, where we minimize the changes in the two view weights and disagreements between the two classifiers. The final classifier is an equally weighted sum of the individual classifiers. As a result, disagreements between the two views are tolerated as long as the final combined classifier output is not compromised. Our approach thus allows the stronger voice (view) to dominate whenever the two views disagree. This additional allowance of diversity between the two views is what gives our approach the edge, as espoused by classical ensemble learning theory. Our algorithm is evaluated and compared to the original PA algorithm on three datasets. The experimental results show that it consistently outperforms the PA algorithm on individual views and concatenated view by up to 3%.

#index 1874814
#* A generic classifier-ensemble approach for biomedical named entity recognition
#@ Zhihua Liao;Zili Zhang
#t 2012
#c 3
#% 219051
#% 551723
#% 551886
#% 854173
#% 1096766
#% 1117003
#% 1196053
#% 1223727
#% 1223730
#% 1223731
#% 1223733
#% 1223734
#% 1223735
#% 1309413
#% 1585698
#% 1607962
#% 1669600
#% 1777136
#! In named entity recognition (NER) for biomedical literature, approaches based on combined classifiers have demonstrated great performance improvement compared to a single (best) classifier. This is mainly owed to sufficient level of diversity exhibited among classifiers, which is a selective property of classifier set. Given a large number of classifiers, how to select different classifiers to put into a classifier-ensemble is a crucial issue of multiple classifier-ensemble design. With this observation in mind, we proposed a generic genetic classifier-ensemble method for the classifier selection in biomedical NER. Various diversity measures and majority voting are considered, and disjoint feature subsets are selected to construct individual classifiers. A basic type of individual classifier --- Support Vector Machine (SVM) classifier is adopted as SVM-classifier committee. A multi-objective Genetic algorithm (GA) is employed as the classifier selector to facilitate the ensemble classifier to improve the overall sample classification accuracy. The proposed approach is tested on the benchmark dataset --- GENIA version 3.02 corpus, and compared with both individual best SVM classifier and SVM-classifier ensemble algorithm as well as other machine learning methods such as CRF, HMM and MEMM. The results show that the proposed approach outperforms other classification algorithms and can be a useful method for the biomedical NER problem.

#index 1874815
#* Neighborhood random classification
#@ Djamel Abdelkader Zighed;Diala Ezzeddine;Fabien Rico
#t 2012
#c 3
#% 2115
#% 400847
#% 400985
#% 466401
#% 937340
#% 1295740
#% 1502432
#% 1539253
#! Ensemble methods (EMs) have become increasingly popular in data mining because of their efficiency. These methods(EMs) generate a set of classifiers using one or several machine learning algorithms (MLAs) and aggregate them into a single classifier (Meta-Classifier, MC). Of the MLAs, k-Nearest Neighbors (kNN) is one of the most well-known used in the context of EMs. However, handling the parameter k can be difficult. This drawback is the same for all MLA that are instance based. Here, we propose an approach based on neighborhood graphs as an alternative. Thanks to these related graphs, like relative neighborhood graphs (RNGs) or Gabriel graphs (GGs), we provide a generalized approach with less arbitrary parameters. Neighborhood graphs have never been introduced into EM approaches before. The results of our algorithm : Neighborhood Random Classification are very promising as they are equal to the best EM approaches such as Random Forest or those based on SVMs. In this exploratory and experimental work, we provide the methodological approach and many comparative results.

#index 1874816
#* SRF: a framework for the study of classifier behavior under training set mislabeling noise
#@ Katsiaryna Mirylenka;George Giannakopoulos;Themis Palpanas
#t 2012
#c 3
#% 105562
#% 444020
#% 629686
#% 738969
#% 818916
#% 856251
#% 874175
#% 922066
#% 1023380
#% 1051405
#% 1051406
#% 1290216
#% 1301004
#% 1378224
#% 1535385
#! Machine learning algorithms perform differently in settings with varying levels of training set mislabeling noise. Therefore, the choice of a good algorithm for a particular learning problem is crucial. In this paper, we introduce the "Sigmoid Rule" Framework focusing on the description of classifier behavior in noisy settings. The framework uses an existing model of the expected performance of learning algorithms as a sigmoid function of the signal-to-noise ratio in the training instances. We study the parameters of the above sigmoid function using five different classifiers, namely, Naive Bayes, kNN, SVM, a decision tree classifier, and a rule-based classifier. Our study leads to the definition of intuitive criteria based on the sigmoid parameters that can be used to compare the behavior of learning algorithms in the presence of varying levels of noise. Furthermore, we show that there exists a connection between these parameters and the characteristics of the underlying dataset, hinting at how the inherent properties of a dataset affect learning. The framework is applicable to concept drift scenaria, including modeling user behavior over time, and mining of noisy data series, as in sensor networks.

#index 1874817
#* Building decision trees for the multi-class imbalance problem
#@ T. Ryan Hoens;Qi Qian;Nitesh V. Chawla;Zhi-Hua Zhou
#t 2012
#c 3
#% 209021
#% 280437
#% 443509
#% 449588
#% 520224
#% 580510
#% 763699
#% 843876
#% 961134
#% 1108850
#% 1176879
#% 1250597
#% 1271973
#% 1301004
#% 1535453
#! Learning in imbalanced datasets is a pervasive problem prevalent in a wide variety of real-world applications. In imbalanced datasets, the class of interest is generally a small fraction of the total instances, but misclassification of such instances is often expensive. While there is a significant body of research on the class imbalance problem for binary class datasets, multi-class datasets have received considerably less attention. This is partially due to the fact that the multi-class imbalance problem is often much harder than its related binary class problem, as the relative frequency and cost of each of the classes can vary widely from dataset to dataset. In this paper we study the multi-class imbalance problem as it relates to decision trees (specifically C4.4 and HDDT), and develop a new multi-class splitting criterion. From our experiments we show that multi-class Hellinger distance decision trees, when combined with decomposition techniques, outperform C4.4.

#index 1874818
#* Scalable random forests for massive data
#@ Bingguo Li;Xiaojun Chen;Mark Junjie Li;Joshua Zhexue Huang;Shengzhong Feng
#t 2012
#c 3
#% 136350
#% 256615
#% 273900
#% 400847
#% 459008
#% 481945
#% 627414
#% 629583
#% 660537
#% 913833
#% 1224594
#% 1328061
#% 1386126
#% 1542029
#% 1562263
#! This paper proposes a scalable random forest algorithm SRF with MapReduce implementation. A breadth-first approach is used to grow decision trees for a random forest model. At each level of the trees, a pair of map and reduce functions split the nodes. A mapper is dispatched to a local machine to compute the local histograms of subspace features of the nodes from a data block. The local histograms are submitted to reducers to compute the global histograms from which the best split conditions of the nodes are calculated and sent to the controller on the master machine to update the random forest model. A random forest model is built with a sequence of map and reduce functions. Experiments on large synthetic data have shown that SRF is scalable to the number of trees and the number of examples. The SRF algorithm is able to build a random forest of 100 trees in a little more than 1 hour from 110 Gigabyte data with 1000 features and 10 million records.

#index 1874819
#* Hybrid random forests: advantages of mixed trees in classifying text data
#@ Baoxun Xu;Joshua Zhexue Huang;Graham Williams;Mark Junjie Li;Yunming Ye
#t 2012
#c 3
#% 136350
#% 169777
#% 209021
#% 256615
#% 280817
#% 400847
#% 478128
#% 1166236
#% 1345660
#% 1345708
#% 1567948
#! Random forests are a popular classification method based on an ensemble of a single type of decision tree. In the literature, there are many different types of decision tree algorithms, including C4.5, CART and CHAID. Each type of decision tree algorithms may capture different information and structures. In this paper, we propose a novel random forest algorithm, called a hybrid random forest. We ensemble multiple types of decision trees into a random forest, and exploit diversity of the trees to enhance the resulting model. We conducted a series of experiments on six text classification datasets to compare our method with traditional random forest methods and some other text categorization methods. The results show that our method consistently outperforms these compared methods.

#index 1874820
#* Learning tree structure of label dependency for multi-label learning
#@ Bin Fu;Zhihai Wang;Rong Pan;Guandong Xu;Peter Dolog
#t 2012
#c 3
#% 290482
#% 311034
#% 478470
#% 785359
#% 838412
#% 950571
#% 1093383
#% 1095861
#% 1176915
#% 1264044
#% 1267771
#% 1451240
#% 1454143
#% 1570399
#% 1583287
#% 1606401
#% 1631661
#% 1811540
#% 1826270
#! There always exists some kind of label dependency in multi-label data. Learning and utilizing those dependencies could improve the learning performance further. Therefore, an approach for multi-label learning is proposed in this paper, which quantifies the dependencies of pairwise labels firstly, and then builds a tree structure of the labels to describe them. Thus the approach could find out potential strong label dependencies and produce more generalized dependent relationships. The experimental results have validated that compared with other state-of-the-art algorithms, the method is not only a competitive alternative, but also has shown better performance after ensemble learning especially.

#index 1874821
#* Multiple instance learning for group record linkage
#@ Zhichun Fu;Jun Zhou;Peter Christen;Mac Boot
#t 2012
#c 3
#% 190581
#% 224755
#% 729913
#% 771844
#% 835018
#% 902511
#% 913783
#% 915273
#% 1117691
#% 1301008
#% 1411073
#% 1535326
#% 1560058
#% 1689578
#% 1890006
#! Record linkage is the process of identifying records that refer to the same entities from different data sources. While most research efforts are concerned with linking individual records, new approaches have recently been proposed to link groups of records across databases. Group record linkage aims to determine if two groups of records in two databases refer to the same entity or not. One application where group record linkage is of high importance is the linking of census data that contain household information across time. In this paper we propose a novel method to group record linkage based on multiple instance learning. Our method treats group links as bags and individual record links as instances. We extend multiple instance learning from bag to instance classification to reconstruct bags from candidate instances. The classified bag and instance samples lead to a significant reduction in multiple group links, thereby improving the overall quality of linked data. We evaluate our method with both synthetic data and real historical census data.

#index 1874822
#* Incremental set recommendation based on class differences
#@ Yasuyuki Shirai;Koji Tsuruma;Yuko Sakurai;Satoshi Oyama;Shin-ichi Minato
#t 2012
#c 3
#% 3873
#% 147928
#% 333679
#% 546047
#% 586253
#% 813966
#% 1246750
#% 1358747
#% 1476463
#% 1620192
#% 1685008
#! In this paper, we present a set recommendation framework that proposes sets of items, whereas conventional recommendation methods recommend each item independently. Our new approach to the set recommendation framework can propose sets of items on the basis on the user's initially chosen set. In this approach, items are added to or deleted from the initial set so that the modified set matches the target classification. Since the data sets created by the latest applications can be quite large, we use ZDD (Zero-suppressed Binary Decision Diagram) to make the searching more efficient. This framework is applicable to a wide range of applications such as advertising on the Internet and healthy life advice based on personal lifelog data.

#index 1874823
#* Active learning for cross language text categorization
#@ Yue Liu;Lin Dai;Weitao Zhou;Heyan Huang
#t 2012
#c 3
#% 252011
#% 344447
#% 722797
#% 771846
#% 832331
#% 992948
#% 1190212
#% 1299481
#% 1328329
#% 1481638
#% 1558464
#% 1688431
#% 1694627
#! Cross Language Text Categorization (CLTC) is the task of assigning class labels to documents written in a target language (e.g. Chinese) while the system is trained using labeled examples in a source language (e.g. English). With the technique of CLTC, we can build classifiers for multiple languages employing the existing training data in only one language, therefore avoid the cost of preparing training data for each individual language. One challenge for CLTC is the culture differences between languages, which causes the classifier trained on the source language doesn't perform well on the target language. In this paper, we propose an active learning algorithm for CLTC, which takes full advantage of both labeled data in the source language and unlabeled data in the target language. The classifier first learns the classification knowledge from the source language, and then learns the cultural dependent knowledge from the target language. In addition, we extend our algorithm to double viewed form by considering the source and target language as two views of the classification problem. Experiments show that our algorithm can effectively improve the cross language classification performance.

#index 1874824
#* Evasion attack of multi-class linear classifiers
#@ Han Xiao;Thomas Stibor;Claudia Eckert
#t 2012
#c 3
#% 402489
#% 425052
#% 769885
#% 823397
#% 829230
#% 961230
#% 961231
#% 1083669
#% 1117691
#! Machine learning has yield significant advances in decision-making for complex systems, but are they robust against adversarial attacks? We generalize the evasion attack problem to the multi-class linear classifiers, and present an efficient algorithm for approximating the optimal disguised instance. Experiments on real-world data demonstrate the effectiveness of our method.

#index 1874825
#* Foundation of mining class-imbalanced data
#@ Da Kuang;Charles X. Ling;Jun Du
#t 2012
#c 3
#% 697
#% 376266
#% 765520
#% 769687
#% 1271973
#% 1604040
#! Mining class-imbalanced data is a common yet challenging problem in data mining and machine learning. When the class is imbalanced, the error rate of the rare class is usually much higher than that of the majority class. How many samples do we need in order to bound the error of the rare class (and the majority class)? If the misclassification cost of the class is known, can the cost-weighted error be bounded as well? In this paper, we attempt to answer those questions with PAC-learning. We derive several upper bounds on the sample size that guarantee the error on a particular class (the rare and majority class) and the cost-weighted error, with the consistent and agnostic learners. Similar to the upper bounds in traditional PAC learning, our upper bounds are quite loose. In order to make them more practical, we empirically study the pattern observed in our upper bounds. From the empirical results we obtain some interesting implications for data mining in real-world applications. As far as we know, this is the first work providing theoretical bounds and the corresponding practical implications for mining class-imbalanced data with unequal cost.

#index 1874826
#* Active learning with c-certainty
#@ Eileen A. Ni;Charles X. Ling
#t 2012
#c 3
#% 169717
#% 464268
#% 875953
#% 1083692
#% 1211801
#% 1214647
#% 1264744
#% 1535336
#% 1535378
#! It is well known that the noise in labels deteriorates the performance of active learning. To reduce the noise, works on multiple oracles have been proposed. However, there is still no way to guarantee the label quality. In addition, most previous works assume that the noise level of oracles is evenly distributed or example-independent which may not be realistic. In this paper, we propose a novel active learning paradigm in which oracles can return both labels and confidences. Under this paradigm, we then propose a new and effective active learning strategy that can guarantee the quality of labels by querying multiple oracles. Furthermore, we remove the assumptions of the previous works mentioned above, and design a novel algorithm that is able to select the best oracles to query. Our empirical study shows that the new algorithm is robust, and it performs well with given different types of oracles. As far as we know, this is the first work that proposes this new active learning paradigm and an active learning algorithm in which label quality is guaranteed.

#index 1874827
#* A term association translation model for naive bayes text classification
#@ Meng-Sung Wu;Hsin-Min Wang
#t 2012
#c 3
#% 78171
#% 262096
#% 280819
#% 311027
#% 311034
#% 318412
#% 340948
#% 458379
#% 629642
#% 722904
#% 804807
#% 818240
#% 1269755
#% 1387556
#% 1392435
#% 1450869
#% 1673574
#! Text classification (TC) has long been an important research topic in information retrieval (IR) related areas. In the literature, the bag-of-words (BoW) model has been widely used to represent a document in text classification and many other applications. However, BoW, which ignores the relationships between terms, offers a rather poor document representation. Some previous research has shown that incorporating language models into the naive Bayes classifier (NBC) can improve the performance of text classification. Although the widely used N -gram language models (LM) can exploit the relationships between words to some extent, they cannot model the long-distance dependencies of words. In this paper, we study the term association modeling approach within the translation LM framework for TC. The new model is called the term association translation model (TATM). The innovation is to incorporate term associations into the document model. We employ the term translation model to model such associative terms in the documents. The term association translation model can be learned based on either the joint probability (JP) of the associative terms through the Bayes rule or the mutual information (MI) of the associative terms. The results of TC experiments evaluated on the Reuters-21578 and 20newsgroups corpora demonstrate that the new model implemented in both ways outperforms the standard NBC method and the NBC with a unigram LM.

#index 1874828
#* A double-ensemble approach for classifying skewed data streams
#@ Chongsheng Zhang;Paolo Soda
#t 2012
#c 3
#% 251145
#% 310500
#% 338606
#% 342639
#% 445344
#% 497414
#% 729932
#% 729965
#% 765519
#% 1271973
#% 1560695
#! Nowadays, many applications need to handle large amounts of streaming data, which often presents a skewed distribution, i.e. one or more classes are largely under-represented in comparison to the others. Unfortunately, little effort has been directed towards the classification of skewed data streams, although class-imbalance learning has already been studied in the area of pattern recognition on static data. Furthermore, while existing class-imbalance learning methods increase the recognition accuracy on minority class, they often harm the global classification accuracy. Motivated by these observations, we develop an approach suited for classifying skewed data streams, which integrates two ensembles of classifiers, each one suited for non-skewed and skewed data. This approach substantially increases the global accuracy compared to existing classification methods for skewed data. Experimental tests have been carried out on three public datasets showing interesting results. As a further contribution, we will study metrics to evaluate the performance of skewed data streams classification. We will also review the literature on class-imbalance learning, and skewed data streams classification.

#index 1874829
#* Generating balanced classifier-independent training samples from unlabeled data
#@ Youngja Park;Zijie Qi;Suresh N. Chari;Ian M. Molloy
#t 2012
#c 3
#% 115608
#% 116165
#% 169717
#% 236729
#% 464291
#% 466419
#% 466576
#% 466887
#% 466890
#% 763699
#% 765523
#% 770847
#% 829025
#% 875997
#% 881575
#% 1019070
#% 1073898
#% 1250678
#% 1271973
#% 1301405
#% 1318738
#! We consider the problem of generating balanced training samples from an unlabeled data set with an unknown class distribution. While random sampling works well when the data is balanced, it is very ineffective for unbalanced data. Other approaches, such as active learning and cost-sensitive learning, are also suboptimal as they are classifier-dependent, and require misclassification costs and labeled samples. We propose a new strategy for generating training samples which is independent of the underlying class distribution of the data and the classifier that will be trained using the labeled data. Our methods are iterative and can be seen as variants of active learning, where we use semi-supervised clustering at each iteration to perform biased sampling from the clusters. Several strategies are provided to estimate the underlying class distributions in the clusters and increase the balancedness in the training samples. Experiments with both highly skewed and balanced data from the UCI repository and a private data show that our algorithm produces much more balanced samples than random sampling or uncertainty sampling. Further, our sampling strategy is substantially more efficient than active learning methods. The experiments also validate that, with more balanced training data, classifiers trained with our samples outperform classifiers trained with random sampling or active learning.

#index 1874830
#* Nyström approximate model selection for LSSVM
#@ Lizhong Ding;Shizhong Liao
#t 2012
#c 3
#% 190581
#% 292664
#% 331916
#% 409380
#% 425040
#% 799827
#% 916799
#% 959434
#% 961134
#% 961275
#% 1386101
#% 1472300
#! Model selection is critical to least squares support vector machine (LSSVM). A major problem of existing model selection approaches is that a standard LSSVM needs to be solved with O (n 3) complexity for each iteration, where n is the number of training examples. In this paper, we propose an approximate approach to model selection of LSSVM. We use Nyström method to approximate a given kernel matrix by a low rank representation of it. With such approximation, we first design an efficient LSSVM algorithm and theoretically analyze the effect of kernel matrix approximation on the decision function of LSSVM. Based on the matrix approximation error bound of Nyström method, we derive a model approximation error bound, which is a theoretical guarantee of approximate model selection. We finally present an approximate model selection scheme, whose complexity is lower than the previous approaches. Experimental results on benchmark datasets demonstrate the effectiveness of approximate model selection.

#index 1874831
#* Exploiting label dependency for hierarchical multi-label classification
#@ Noor Alaydie;Chandan K. Reddy;Farshad Fotouhi
#t 2012
#c 3
#% 451123
#% 906025
#% 961192
#% 989655
#% 1062403
#% 1095862
#% 1229233
#% 1264044
#% 1267771
#% 1417100
#% 1451240
#% 1538188
#% 1590138
#% 1702201
#% 1713756
#! Hierarchical multi-label classification is a variant of traditional classification in which the instances can belong to several labels, that are in turn organized in a hierarchy. Existing hierarchical multi-label classification algorithms ignore possible correlations between the labels. Moreover, most of the current methods predict instance labels in a "flat" fashion without employing the ontological structures among the classes. In this paper, we propose HiBLADE (Hierarchical multi-label Boosting with LAbel DEpendency), a novel algorithm that takes advantage of not only the pre-established hierarchical taxonomy of the classes, but also effectively exploits the hidden correlation among the classes that is not shown through the class hierarchy, thereby improving the quality of the predictions. According to our approach, first, the pre-defined hierarchical taxonomy of the labels is used to decide upon the training set for each classifier. Second, the dependencies of the children for each label in the hierarchy are captured and analyzed using Bayes method and instance-based similarity. Our experimental results on several real-world biomolecular datasets show that the proposed method can improve the performance of hierarchical multi-label classification.

#index 1874832
#* Diversity analysis on boosting nominal concepts
#@ Nida Meddouri;Héla Khoufi;Mondher Sadok Maddouri
#t 2012
#c 3
#% 198701
#% 235377
#% 940120
#% 1228608
#% 1290045
#% 1500303
#% 1736157
#! In this paper, we investigate how the diversity of nominal classifier ensembles affects the AdaBoost performance [13]. Using 5 real data sets from the UCI Machine Learning Repository and 3 different diversity measures, we show that $\mathcal{Q}$ Statistic measure is mostly correlated with AdaBoost performance for 2-class problems. The experimental results suggest that the performance of AdaBoost depend on the nominal classifier diversity that can be used as a stopping criteria in ensemble learning.

#index 1874833
#* Extreme value prediction for zero-inflated data
#@ Fan Xin;Zubin Abraham
#t 2012
#c 3
#! Depending on the domain, there may be significant ramifications associated with the occurrence of an extreme event (for e.g., the occurrence of a flood from a climatological perspective). However, due to the relative low occurrence rate of extreme events, the accurate prediction of extreme values is a challenging endeavor. When it comes to zero-inflated time series, standard regression methods such as multiple linear regression and generalized linear models, which emphasize estimating the conditional expected value, are not best suited for inferring extreme values. And so is the case when the the conditional distribution of the data does not conform to the parametric distribution assumed by the regression model. This paper presents a coupled classification and regression framework that focuses on reliable prediction of extreme value events in a zero-inflated time series. The framework was evaluated by applying it on a real-world problem of statistical downscaling of precipitation for the purpose of climate impact assessment studies. The results suggest that the proposed framework is capable of detecting the timing and magnitude of extreme precipitation events effectively compared with several baseline methods.

#index 1874834
#* Learning to diversify expert finding with subtopics
#@ Hang Su;Jie Tang;Wanling Hong
#t 2012
#c 3
#% 124073
#% 174161
#% 262112
#% 280819
#% 387427
#% 642975
#% 722904
#% 879570
#% 879587
#% 1074025
#% 1083734
#% 1166473
#% 1176930
#% 1268491
#% 1312812
#% 1451162
#% 1481049
#% 1606004
#% 1606043
#! Expert finding is concerned about finding persons who are knowledgeable on a given topic. It has many applications in enterprise search, social networks, and collaborative management. In this paper, we study the problem of diversification for expert finding. Specifically, employing an academic social network as the basis for our experiments, we aim to answer the following question: Given a query and an academic social network, how to diversify the ranking list, so that it captures the whole spectrum of relevant authors' expertise? We precisely define the problem and propose a new objective function by incorporating topic-based diversity into the relevance ranking measurement. A learning-based model is presented to solve the objective function. Our empirical study in a real system validates the effectiveness of the proposed method, which can achieve significant improvements (+15.3%-+94.6% by MAP) over alternative methods.

#index 1874835
#* An associative classifier for uncertain datasets
#@ Metanat Hooshsadat;Osmar R. Zaïane
#t 2012
#c 3
#% 136350
#% 396747
#% 466483
#% 915229
#% 961134
#% 1063531
#% 1195948
#% 1206933
#% 1214624
#% 1214633
#% 1380967
#% 1401258
#% 1451226
#% 1491885
#% 1594654
#% 1606342
#% 1737803
#! The classification of uncertain datasets is an emerging research problem that has recently attracted significant attention. Some attempts to devise a classification model with uncertain training data have been proposed using decision trees, neural networks, or other approaches. Among those, the associative classifiers have inspired some of the uncertain classification algorithms given their promising results on standard datasets. We propose a novel associative classifier for uncertain data. Our method, Uncertain Associative Classifier (UAC) is efficient and has an effective rule pruning strategy. Our experimental results on real datasets show that in most cases, UAC reaches better accuracies than the state of the art algorithms.

#index 1874836
#* Neighborhood-Based smoothing of external cluster validity measures
#@ Ken-ichi Fukui;Masayuki Numao
#t 2012
#c 3
#% 361966
#% 1053052
#% 1213625
#% 1232015
#% 1305502
#% 1535416
#% 1606025
#% 1633202
#! This paper proposes a methodology for introducing a neighborhood relation of clusters to the conventional cluster validity measures using external criteria, that is, class information. The extended measure evaluates the cluster validity together with connectivity of class distribution based on a neighborhood relation of clusters. A weighting function is introduced for smoothing the basic statistics to set-based measures and to pairwise-based measures. Our method can extend any cluster validity measure based on a set or pairwise of data points. In the experiment, we examined the neighbor component of the extended measure and revealed an appropriate neighborhood radius and some properties using synthetic and real-world data.

#index 1874837
#* Sequential entity group topic model for getting topic flows of entity groups within one document
#@ Young-Seob Jeong;Ho-Jin Choi
#t 2012
#c 3
#% 280819
#% 722904
#% 788094
#% 869516
#% 875959
#% 881534
#% 1214638
#% 1457042
#% 1535392
#! Topic mining is regarded as a powerful method to analyze documents, and topic models are used to annotate relationships or to get a topic flow. The research aim in this paper is to get topic flows of entities and entity groups within one document. We propose two topic models: Entity Group Topic Model (EGTM) and Sequential Entity Group Topic Model (S-EGTM). These models provide two contributions. First, topic distributions of entities and entity groups can be analyzed. Second, the topic flow of each entity or each entity group can be captured, through segments in one document. We develop collapsed gibbs sampling methods for performing approximate inference of the models. By experiments, we demonstrate the models by showing the analysis of topics, prediction performance, and the topic flows over segments in one document.

#index 1874838
#* Topological comparisons of proximity measures
#@ Djamel Abdelkader Zighed;Rafik Abdesselam;Asmelash Hadgu
#t 2012
#c 3
#% 2115
#% 222206
#% 306895
#% 448726
#% 453464
#% 465914
#% 823403
#% 992410
#% 992411
#% 1149111
#% 1156228
#% 1295740
#% 1410878
#! In many fields of application, the choice of proximity measure directly affects the results of data mining methods, whatever the task might be: clustering, comparing or structuring of a set of objects. Generally, in such fields of application, the user is obliged to choose one proximity measure from many possible alternatives. According to the notion of equivalence, such as the one based on pre-ordering, certain proximity measures are more or less equivalent, which means that they should produce almost the same results. This information on equivalence might be helpful for choosing one such measure. However, the complexity O (n 4 ) of this approach makes it intractable when the size n of the sample exceeds a few hundred. To cope with this limitation, we propose a new approach with less complexity O (n 2 ). This is based on topological equivalence and it exploits the concept of local neighbors. It defines equivalence between two proximity measures as having the same neighborhood structure on the objects. We illustrate our approach by considering 13 proximity measures used on datasets with continuous attributes.

#index 1874839
#* Quad-tuple PLSA: incorporating entity and its rating in aspect identification
#@ Wenjuan Luo;Fuzhen Zhuang;Qing He;Zhongzhi Shi
#t 2012
#c 3
#% 280819
#% 577246
#% 769892
#% 815915
#% 854646
#% 907489
#% 939848
#% 939896
#% 956510
#% 1127964
#% 1190068
#% 1451218
#! With the opinion explosion on Web, there are growing research interests in opinion mining. In this study we focus on an important problem in opinion mining -- Aspect Identification (AI), which aims to extract aspect terms in entity reviews. Previous PLSA based AI methods exploit the 2-tuples (e.g. the co-occurrence of head and modifier), where each latent topic corresponds to an aspect. Here, we notice that each review is also accompanied by an entity and its overall rating, resulting in quad-tuples joined with the previously mentioned 2-tuples. Believing that the quad-tuples contain more co-occurrence information and thus provide more ability in differentiating topics, we propose a model of Quad-tuple PLSA, which incorporates two more items -- entity and its rating, into topic modeling for more accurate aspect identification. The experiments on different numbers of hotel and restaurant reviews show the consistent and significant improvements of the proposed model compared to the 2-tuple PLSA based methods.

#index 1874840
#* Clustering-Based k-anonymity
#@ Xianmang He;HuaHui Chen;Yefang Chen;Yihong Dong;Peng Wang;Zhenhua Huang
#t 2012
#c 3
#% 248030
#% 443463
#% 576761
#% 800514
#% 800515
#% 810011
#% 864406
#% 864412
#% 881483
#% 881551
#% 893151
#% 1013611
#% 1022264
#% 1022265
#% 1206584
#% 1426564
#! Privacy is one of major concerns when data containing sensitive information needs to be released for ad hoc analysis, which has attracted wide research interest on privacy-preserving data publishing in the past few years. One approach of strategy to anonymize data is generalization. In a typical generalization approach, tuples in a table was first divided into many QI (quasi-identifier)-groups such that the size of each QI-group is no less than k . Clustering is to partition the tuples into many clusters such that the points within a cluster are more similar to each other than points in different clusters. The two methods share a common feature: distribute the tuples into many small groups. Motivated by this observation, we propose a clustering-based k -anonymity algorithm, which achieves k -anonymity through clustering. Extensive experiments on real data sets are also conducted, showing that the utility has been improved by our approach.

#index 1874841
#* Unsupervised ensemble learning for mining top-n outliers
#@ Jun Gao;Weiming Hu;Zhongfei(Mark) Zhang;Ou Wu
#t 2012
#c 3
#% 296738
#% 300136
#% 400847
#% 464451
#% 570886
#% 823340
#% 881506
#% 915267
#% 1073931
#% 1083710
#% 1607957
#! Outlier detection is an important and attractive problem in knowledge discovery in large datasets. Instead of detecting an object as an outlier, we study detecting the n most outstanding outliers, i.e. the top-n outlier detection. Further, we consider the problem of combining the top-n outlier lists from various individual detection methods. A general framework of ensemble learning in the top-n outlier detection is proposed based on the rank aggregation techniques. A score-based aggregation approach with the normalization method of outlier scores and an order-based aggregation approach based on the distance-based Mallows model are proposed to accommodate various scales and characteristics of outlier scores from different detection methods. Extensive experiments on several real datasets demonstrate that the proposed approaches always deliver a stable and effective performance independent of different datasets in a good scalability in comparison with the state-of-the-art literature.

#index 1874842
#* Towards personalized context-aware recommendation by mining context logs through topic models
#@ Kuifei Yu;Baoxian Zhang;Hengshu Zhu;Huanhuan Cao;Jilei Tian
#t 2012
#c 3
#% 280819
#% 311027
#% 643024
#% 722904
#% 753435
#% 1207050
#% 1476453
#% 1535370
#% 1558821
#% 1721319
#% 1913977
#! The increasing popularity of smart mobile devices and their more and more powerful sensing ability make it possible to capture rich contextual information and personal context-aware preferences of mobile users by user context logs in devices. By leveraging such information, many context-aware services can be provided for mobile users such as personalized context-aware recommendation. However, to the best knowledge of ours, how to mine user context logs for personalized context-aware recommendation is still under-explored. A critical challenge of this problem is that individual user's historical context logs may be too few to mine their context-aware preferences. To this end, in this paper we propose to mine common context-aware preferences from many users' context logs through topic models and represent each user's personal context-aware preferences as a distribution of the mined common context-aware preferences. The experiments on a real-world data set contains 443 mobile users' historical context data and activity records clearly show the approach is effective and outperform baselines in terms of personalized context-aware recommendation.

#index 1874843
#* Mining of temporal coherent subspace clusters in multivariate time series databases
#@ Hardy Kremer;Stephan Günnemann;Arne Held;Thomas Seidl
#t 2012
#c 3
#% 273891
#% 280482
#% 397384
#% 659971
#% 727868
#% 769919
#% 810066
#% 1117029
#% 1127609
#% 1165480
#% 1328215
#% 1378458
#% 1503356
#% 1535411
#% 1535464
#% 1606025
#% 1642075
#% 1669860
#% 1705459
#! Mining temporal multivariate data by clustering techniques is recently gaining importance. However, the temporal data obtained in many of today's applications is often complex in the sense that interesting patterns are neither bound to the whole dimensional nor temporal extent of the data domain. Under these conditions, patterns mined by existing multivariate time series clustering and temporal subspace clustering techniques cannot correctly reflect the true patterns in the data. In this paper, we propose a novel clustering method that mines temporal coherent subspace clusters. In our model, these clusters are reflected by sets of objects and relevant intervals. Relevant intervals indicate those points in time in which the clustered time series show a high similarity. In our model, each dimension has an individual set of relevant intervals, which together ensure temporal coherence. In the experimental evaluation we demonstrate the effectiveness of our method in comparison to related approaches.

#index 1874844
#* A vertex similarity probability model for finding network community structure
#@ Kan Li;Yin Pang
#t 2012
#c 3
#% 67565
#% 406493
#% 438553
#% 813966
#% 906588
#% 955712
#% 956540
#! Most methods for finding community structure are based on the prior knowledge of network structure type. These methods grouped the communities only when known network is unipartite or bipartite. This paper presents a vertex similarity probability (VSP) model which can find community structure without priori knowledge of network structure type. Vertex similarity, which assumes that, for any type of network structures, vertices in the same community have similar properties. In the VSP model, "Common neighbor index" is used to measure the vertex similarity probability, as it has been proved to be an effective index for vertex similarity. We apply the algorithm to real-world network data. The results show that the VSP model is uniform for both unipartite networks and bipartite networks, and it is able to find the community structure successfully without the use of the network structure type.

#index 1874845
#* Hybrid-ε-greedy for mobile context-aware recommender system
#@ Djallel Bouneffouf;Amel Bouzeghoub;Alda Lopes Gançarski
#t 2012
#c 3
#% 401199
#% 722799
#% 748600
#% 873110
#% 1209185
#% 1245091
#% 1252990
#% 1332975
#% 1399999
#% 1451141
#% 1482460
#! The wide development of mobile applications provides a considerable amount of data of all types. In this sense, Mobile Context-aware Recommender Systems (MCRS) suggest the user suitable information depending on her/his situation and interests. Our work consists in applying machine learning techniques and reasoning process in order to adapt dynamically the MCRS to the evolution of the user's interest. To achieve this goal, we propose to combine bandit algorithm and case-based reasoning in order to define a contextual recommendation process based on different context dimensions (social, temporal and location). This paper describes our ongoing work on the implementation of a MCRS based on a hybrid-ε -greedy algorithm. It also presents preliminary results by comparing the hybrid-ε -greedy and the standard ε -greedy algorithm.

#index 1874846
#* Unsupervised multi-label text classification using a world knowledge ontology
#@ Xiaohui Tao;Yuefeng Li;Raymond Y. K. Lau;Hua Wang
#t 2012
#c 3
#% 1019160
#% 1083703
#% 1130831
#% 1176893
#% 1214660
#% 1214713
#% 1289518
#% 1330552
#% 1391387
#% 1451172
#% 1451215
#% 1451256
#% 1555377
#% 1605938
#! The development of text classification techniques has been largely promoted in the past decade due to the increasing availability and widespread use of digital documents. Usually, the performance of text classification relies on the quality of categories and the accuracy of classifiers learned from samples. When training samples are unavailable or categories are unqualified, text classification performance would be degraded. In this paper, we propose an unsupervised multi-label text classification method to classify documents using a large set of categories stored in a world ontology. The approach has been promisingly evaluated by compared with typical text classification methods, using a real-world document collection and based on the ground truth encoded by human experts.

#index 1874847
#* Semantic social network analysis with text corpora
#@ Dong-mei Yang;Hui Zheng;Ji-kun Yan;Ye Jin
#t 2012
#c 3
#% 722904
#% 788094
#% 881534
#% 891559
#% 1268037
#% 1302868
#% 1701756
#! We present the Document-Entity-Topic (DET) model for semantic social network analysis which tries to find out the interested entities through the topics we aim at, detect groups according to the entities which concern the similar topics, and rank the plentiful entities in a document to figure out the most valuable ones. DET model learns the topic distributions by the literal descriptions of entities. The model is similar to Author-Topic (AT) model, adding the key attribute that the distribution of entities in a document is not uniform but Dirichlet allocation. We experiment on the "Libya Event" data set which is collected from the Internet. DET model increases the precision on tasks of social network analysis and gives much lower perplexity than AT model.

#index 1874848
#* Visualizing clusters in parallel coordinates for visual knowledge discovery
#@ Yang Xiang;David Fuhry;Ruoming Jin;Ye Zhao;Kun Huang
#t 2012
#c 3
#% 286639
#% 296738
#% 316709
#% 341704
#% 348963
#% 529288
#% 533699
#% 727807
#% 789227
#% 789228
#% 844525
#% 871014
#% 910875
#% 933329
#% 940982
#% 1512954
#% 1546431
#% 1670185
#% 1708682
#% 1788326
#! Parallel coordinates is frequently used to visualize multi-dimensional data. In this paper, we are interested in how to effectively visualize clusters of multi-dimensional data in parallel coordinates for the purpose of facilitating knowledge discovery. In particular, we would like to efficiently find a good order of coordinates for different emphases on visual knowledge discovery. To solve this problem, we link it to the metric-space Hamiltonian path problem by defining the cost between every pair of coordinates as the number of inter-cluster or intra-cluster crossings. This definition connects to various efficient solutions and leads to very fast algorithms. In addition, to better observe cluster interactions, we also propose to shape clusters smoothly by an energy reduction model which provides both macro and micro view of clusters.

#index 1874849
#* Feature enriched nonparametric bayesian co-clustering
#@ Pu Wang;Carlotta Domeniconi;Huzefa Rangwala;Kathryn B. Laskey
#t 2012
#c 3
#% 220709
#% 301590
#% 722904
#% 729918
#% 734592
#% 844369
#% 871574
#% 915330
#% 1073982
#% 1176960
#% 1214623
#% 1267788
#% 1409610
#% 1476500
#% 1535449
#! Co-clustering has emerged as an important technique for mining relational data, especially when data are sparse and high-dimensional. Co-clustering simultaneously groups the different kinds of objects involved in a relation. Most co-clustering techniques typically only leverage the entries of the given contingency matrix to perform the two-way clustering. As a consequence, they cannot predict the interaction values for new objects. In many applications, though, additional features associated to the objects of interest are available. The Infinite Hidden Relational Model (IHRM) has been proposed to make use of these features. As such, IHRM has the capability to forecast relationships among previously unseen data. The work on IHRM lacks an evaluation of the improvement that can be achieved when leveraging features to make predictions for unseen objects. In this work, we fill this gap and re-interpret IHRM from a co-clustering point of view. We focus on the empirical evaluation of forecasting relationships between previously unseen objects by leveraging object features. The empirical evaluation demonstrates the effectiveness of the feature-enriched approach and identifies the conditions under which the use of features is most useful, i.e., with sparse data.

#index 1874850
#* Shape-Based clustering for time series data
#@ Warissara Meesrikamolkul;Vit Niennattrakul;Chotirat Ann Ratanamahatana
#t 2012
#c 3
#% 424088
#% 466083
#% 974699
#% 1096890
#% 1378458
#% 1465170
#% 1679142
#! One of the most famous algorithms for time series data clustering is k -means clustering with Euclidean distance as a similarity measure. However, many recent works have shown that Dynamic Time Warping (DTW) distance measure is more suitable for most time series data mining tasks due to its much improved alignment based on shape. Unfortunately, k -means clustering with DTW distance is still not practical since the current averaging functions fail to preserve characteristics of time series data within the cluster. Recently, Shape-based Template Matching Framework (STMF) has been proposed to discover a cluster representative of time series data. However, STMF is very computationally expensive. In this paper, we propose a Shape-based Clustering for Time Series (SCTS) using a novel averaging method called Ranking Shape-based Template Matching Framework (RSTMF), which can average a group of time series effectively but take as much as 400 times less computational time than that of STMF. In addition, our method outperforms other well-known clustering techniques in terms of accuracy and criterion based on known ground truth.

#index 1874851
#* Privacy-Preserving EM algorithm for clustering on social network
#@ Bin Yang;Issei Sato;Hiroshi Nakagawa
#t 2012
#c 3
#% 266230
#% 729930
#% 743280
#% 809530
#% 823389
#% 1002377
#% 1015132
#% 1227606
#% 1318624
#% 1318653
#% 1386180
#% 1721181
#! We consider the clustering problem in a private social network, in which all vertices are independent and private, and each of them knows nothing about vertices other than itself and its neighbors. Many clustering methods for networks have recently been proposed. Some of these works have dealt with a mixed network of assortative and disassortative models. These methods have been based on the fact that the entire structure of the network is observable. However, entities in real social network may be private and thus cannot be observed. We propose a privacy-preserving EM algorithm for clustering on distributed networks that not only deals with the mixture of assortative and disassortative models but also protects the privacy of each vertex in the network. In our solution, each vertex is treated as an independent private party, and the problem becomes an n -party privacy-preserving clustering, where n is the number of vertices in the network. Our algorithm does not reveal any intermediate information through its execution. The total running time is only related to the number of clusters and the maximum degree of the network but this is nearly independent of the total vertex number.

#index 1874852
#* Named entity recognition and identification for finding the owner of a home page
#@ Vassilis Plachouras;Matthieu Rivière;Michalis Vazirgiannis
#t 2012
#c 3
#% 464434
#% 742424
#% 815876
#% 840966
#% 854824
#% 855112
#% 939376
#% 939909
#% 1030805
#% 1117023
#% 1131172
#% 1275029
#% 1332992
#% 1558464
#% 1588364
#! Entity-based applications, such as expert search or online social networks where users search for persons, require high-quality datasets of named entity references. Obtaining such high-quality datasets can be achieved by automatically extracting metadata from Web pages. In this work, we focus on the identification of the named entity that corresponds to the owner of a particular Web page, for example, a home page or an organizational staff Web page. More specifically, from a set of named entities that have already been extracted from a Web page, we identify the one which corresponds to the owner of the home page. First, we develop a set of features which are combined in a scoring function to select the named entity of the Web page owner. Second, we formulate the problem as a classification problem in which a pair of a Web page and named entity is classified as being associated or not. We evaluate the proposed approaches on a set of Web pages in which we have previously identified named entities. Our experimental results show that we can identify the named entity corresponding to the owner of a home page with accuracy over 90%.

#index 1874853
#* Clustering and understanding documents via discrimination information maximization
#@ Malik Tahir Hassan;Asim Karim
#t 2012
#c 3
#% 643008
#% 747890
#% 766432
#% 809268
#% 835018
#% 842709
#% 961134
#% 983869
#% 989614
#% 1136450
#% 1176922
#% 1213625
#% 1214660
#% 1249577
#% 1408776
#% 1573152
#% 1713158
#! Text document clustering is a popular task for understanding and summarizing large document collections. Besides the need for efficiency, document clustering methods should produce clusters that are readily understandable as collections of documents relating to particular contexts or topics. Existing clustering methods often ignore term-document semantics while relying upon geometric similarity measures. In this paper, we present an efficient iterative partitional clustering method, CDIM, that maximizes the sum of discrimination information provided by documents. The discrimination information of a document is computed from the discrimination information provided by the terms in it, and term discrimination information is estimated from the currently labeled document collection. A key advantage of CDIM is that its clusters are describable by their highly discriminating terms --- terms with high semantic relatedness to their clusters' contexts. We evaluate CDIM both qualitatively and quantitatively on ten text data sets. In clustering quality evaluation, we find that CDIM produces high-quality clusters superior to those generated by the best methods. We also demonstrate the understandability provided by CDIM, suggesting its suitability for practical document clustering.

#index 1874854
#* A semi-supervised incremental clustering algorithm for streaming data
#@ Maria Halkidi;Myra Spiliopoulou;Aikaterini Pavlou
#t 2012
#c 3
#% 464291
#% 464631
#% 769881
#% 770782
#% 844372
#% 1015261
#% 1016200
#% 1108920
#% 1332141
#% 1663626
#% 1673558
#! Nowadays many applications need to deal with evolving data streams . In this work, we propose an incremental clustering approach for the exploitation of user constraints on data streams. Conventional constraints do not make sense on streaming data, so we extend the classic notion of constraint set into a constraint stream . We propose methods for using the constraint stream as data items are forgotten or new items arrive. Also we present an on-line clustering approach for the cost-based enforcement of the constraints during cluster adaptation on evolving data streams. Our method introduces the concept of multi-clusters (m-clusters) to capture arbitrarily shaped clusters. An m-cluster consists of multiple dense overlapping regions, named s-clusters, each of which can be efficiently represented by a single point. Also it proposes the definition of outliers clusters in order to handle outliers while it provides methods to observe changes in structure of clusters as data evolves.

#index 1874855
#* Unsupervised sparse matrix co-clustering for marketing and sales intelligence
#@ Anastasios Zouzias;Michail Vlachos;Nikolaos M. Freris
#t 2012
#c 3
#% 217817
#% 281668
#% 296756
#% 313959
#% 342621
#% 390741
#% 729918
#% 769883
#% 778215
#% 989640
#% 995140
#% 1063729
#% 1169663
#% 1176961
#% 1840160
#! Business intelligence focuses on the discovery of useful retail patterns by combining both historical and prognostic data. Ultimate goal is the orchestration of more targeted sales and marketing efforts. A frequent analytic task includes the discovery of associations between customers and products. Matrix co-clustering techniques represent a common abstraction for solving this problem. We identify shortcomings of previous approaches, such as the explicit input for the number of co-clusters and the common assumption for existence of a block-diagonal matrix form. We address both of these issues and present techniques for automated matrix co-clustering. We formulate the problem as a recursive bisection on Fiedler vectors in conjunction with an eigengap-driven termination criterion. Our technique does not assume perfect block-diagonal matrix structure after reordering. We explore and identify off-diagonal cluster structures by devising a Gaussian-based density estimator. Finally, we show how to explicitly couple co-clustering with product recommendations, using real-world business intelligence data. The final outcome is a robust co-clustering algorithm that can discover in an automatic manner both disjoint and overlapping cluster structures, even in the preserve of noisy observations.

#index 1874856
#* Expectation-Maximization collaborative filtering with explicit and implicit feedback
#@ Bin Wang;Mohammadreza Rahimi;Dequan Zhou;Xin Wang
#t 2012
#c 3
#% 734592
#% 1083539
#% 1102242
#% 1116993
#% 1176909
#% 1214688
#% 1260273
#% 1358747
#% 1396094
#% 1482349
#! Collaborative Filtering (CF) is a popular strategy for recommender systems, which infers users' preferences typically using either explicit feedback (e.g., ratings) or implicit feedback (e.g., clicks). Explicit feedback is more accurate, but the quantity is not sufficient; whereas implicit feedback has an abundant quantity, but can be fairly inaccurate. In this paper, we propose a novel method, Expectation-Maximization Collaborative Filtering (EMCF), based on matrix factorization. The contributions of this paper include: first, we combine explicit and implicit feedback together in EMCF to infer users' preferences by learning latent factor vectors from matrix factorization; second, we observe four different cases of implicit feedback in terms of the distribution of latent factor vectors, and then propose different methods to estimate implicit feedback for different cases in EMCF; third, we develop an algorithm for EMCF to iteratively propagate the estimations of implicit feedback and update the latent factor vectors in order to fully utilize implicit feedback. We designed experiments to compare EMCF with other CF methods. The experimental results show that EMCF outperforms other methods by combining explicit and implicit feedback.

#index 1874857
#* Proceedings of the 16th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining - Volume Part II
#@ Pang-Ning Tan;Sanjay Chawla;Chin Kuan Ho;James Bailey
#t 2012
#c 3

#index 1874858
#* Heterogeneous ensemble for feature drifts in data streams
#@ Hai-Long Nguyen;Yew-Kwong Woon;Wee-Keong Ng;Li Wan
#t 2012
#c 3
#% 209021
#% 226499
#% 246831
#% 256615
#% 310500
#% 342600
#% 342639
#% 400847
#% 448194
#% 729932
#% 796212
#% 803770
#% 829005
#% 1189216
#% 1196041
#% 1214635
#% 1318657
#% 1472282
#% 1513024
#! The nature of data streams requires classification algorithms to be real-time, efficient, and able to cope with high-dimensional data that are continuously arriving. It is a known fact that in high-dimensional datasets, not all features are critical for training a classifier. To improve the performance of data stream classification, we propose an algorithm called HEFT-Stream (H eterogeneous E nsemble with F eature drifT for Data Streams ) that incorporates feature selection into a heterogeneous ensemble to adapt to different types of concept drifts. As an example of the proposed framework, we first modify the FCBF [13] algorithm so that it dynamically update the relevant feature subsets for data streams. Next, a heterogeneous ensemble is constructed based on different online classifiers, including Online Naive Bayes and CVFDT [5]. Empirical results show that our ensemble classifier outperforms state-of-the-art ensemble classifiers (AWE [15] and OnlineBagging [21]) in terms of accuracy, speed, and scalability. The success of HEFT-Stream opens new research directions in understanding the relationship between feature selection techniques and ensemble learning to achieve better classification performance.

#index 1874859
#* OMC-IDS: at the cross-roads of OLAP mining and intrusion detection
#@ Hanen Brahmi;Imen Brahmi;Sadok Ben Yahia
#t 2012
#c 3
#% 152934
#% 223781
#% 279120
#% 709657
#% 818759
#% 1050852
#! Due to the growing threat of network attacks, the efficient detection as well as the network abuse assessment are of paramount importance. In this respect, the Intrusion Detection Systems (IDS) are intended to protect information systems against intrusions. However, IDS are plugged with several problems that slow down their development, such as low detection accuracy and high false alarm rate. In this paper, we introduce a new IDS, called OMC-IDS, which integrates data mining techniques and On Line Analytical Processing (OLAP) tools. The association of the two fields can be a powerful solution to deal with the defects of IDS. Our experiment results show the effectiveness of our approach in comparison with those fitting in the same trend.

#index 1874860
#* Towards linear time overlapping community detection in social networks
#@ Jierui Xie;Boleslaw K. Szymanski
#t 2012
#c 3
#% 1719412
#% 1754217
#! Membership diversity is a characteristic aspect of social networks in which a person may belong to more than one social group. For this reason, discovering overlapping structures is necessary for realistic social analysis. In this paper, we present a fast algorithm, called SLPA, for overlapping community detection in large-scale networks. SLPA spreads labels according to dynamic interaction rules. It can be applied to both unipartite and bipartite networks. It is also able to uncover overlapping nested hierarchy . The time complexity of SLPA scales linearly with the number of edges in the network. Experiments in both synthetic and real-world networks show that SLPA has an excellent performance in identifying both node and community level overlapping structures.

#index 1874861
#* WeightTransmitter: weighted association rule mining using landmark weights
#@ Yun Sing Koh;Russel Pears;Gillian Dobbie
#t 2012
#c 3
#% 280456
#% 310541
#% 641014
#% 729988
#% 741335
#% 1038715
#% 1546617
#% 1734441
#% 1737786
#! Weighted Association Rule Mining (WARM) is a technique that is commonly used to overcome the well-known limitations of the classical Association Rule Mining approach. The assignment of high weights to important items enables rules that express relationships between high weight items to be ranked ahead of rules that only feature less important items. Most previous research to weight assignment has used subjective measures to assign weights and are reliant on domain specific information. Whilst there have been a few approaches that automatically deduce weights from patterns of interaction between items, none of them take advantage of the situation where weights of only a subset of items are known in advance. We propose a model, WeightTransmitter, that interpolates the unknown weights from a known subset of weights.

#index 1874862
#* Co-occurring cluster mining for damage patterns analysis of a fuel cell
#@ Daiki Inaba;Ken-ichi Fukui;Kazuhisa Sato;Junichirou Mizusaki;Masayuki Numao
#t 2012
#c 3
#% 248792
#% 361966
#% 478456
#% 481290
#% 577220
#% 844411
#% 1044131
#% 1165515
#! In this study, we research the mechanical correlations among components of solid oxide fuel cell (SOFC) by analyzing the co-occurrence of acoustic emission (AE) events which are caused by damage. Then we propose a novel method for mining patterns from the numerical data such as AE. The proposed method extracts patterns of two clusters considering co-occurrence between clusters and similarity within each cluster at the same time. In addition, we utilize the dendrogram obtained from hierarchical clustering for reduction of the search space. We applied the proposed method to AE data, and the damage patterns which represent the main mechanical correlations were extracted. We can acquire novel knowledge about damage mechanism of SOFC from the results.

#index 1874863
#* New exact concise representation of rare correlated patterns: application to intrusion detection
#@ Souad Bouasker;Tarek Hamrouni;Sadok Ben Yahia
#t 2012
#c 3
#% 399793
#% 420062
#% 452846
#% 481290
#% 483808
#% 737307
#% 893372
#% 1083506
#% 1332128
#% 1417352
#% 1607975
#% 1617309
#! During the last years, many works focused on the exploitation of rare patterns. In fact, these patterns allow conveying knowledge on unexpected events. Nevertheless, a main problem is related to their very high number and to the low quality of several mined rare patterns. In order to overcome these limits, we propose to integrate the correlation measure bond aiming at only mining the set of rare correlated patterns. A characterization of the resulting set is then detailed, based on the study of constraints of different natures induced by the rarity and the correlation. In addition, based on the equivalence classes associated to a closure operator dedicated to the bond measure, we propose a new exact concise representation of rare correlated patterns. We then design the new RcprMiner algorithm allowing an efficient extraction of the proposed representation. The carried out experimental studies prove the compactness rate offered by our approach. We also design an association rules based classifier and we prove its effectiveness in the context of intrusion detection.

#index 1874864
#* Life activity modeling of news event on twitter using energy function
#@ Rong Lu;Zhiheng Xu;Yang Zhang;Qing Yang
#t 2012
#c 3
#% 67565
#% 262042
#% 262043
#% 268079
#% 375017
#% 1040837
#% 1158333
#% 1194140
#% 1355042
#% 1399992
#% 1400018
#% 1432574
#% 1517726
#% 1676017
#! This research is the first exploration on modeling life activity of news event on Twitter. We consider a news event as a natural life form, and use an energy function to evaluate its activity. A news event on Twitter becomes more active with a burst of tweets discussing it, and it fades away with time. These changes of the activity are well captured by the energy function. Then, we incorporate this energy function into the traditional single-pass clustering algorithm, and propose a more adaptive on-line news event detection method. A corpus of tweets which discuss news events was analyzed using our method. Experimental results show that our method not only compares favorably to those of other methods in official TDT measures like precision, recall etc., but also has better time and memory performance, which makes it more suitable for a real system.

#index 1874865
#* Quantifying reciprocity in large weighted communication networks
#@ Leman Akoglu;Pedro O. S. Vaz de Melo;Christos Faloutsos
#t 2012
#c 3
#% 283833
#% 309749
#% 342592
#% 907530
#% 989643
#% 1083690
#% 1083737
#% 1214695
#% 1300556
#% 1400031
#% 1496793
#% 1506252
#! If a friend called you 50 times last month, how many times did you call him back? Does the answer change if we ask about SMS, or e-mails? We want to quantify reciprocity between individuals in weighted networks, and we want to discover whether it depends on their topological features (like degree, or number of common neighbors). Here we answer these questions, by studying the call- and SMS records of millions of mobile phone users from a large city, with more than 0.5 billion phone calls and 60 million SMSs, exchanged over a period of six months. Our main contributions are: (1) We propose a novel distribution, the Triple Power Law (3PL), that fits the reciprocity behavior of all 3 datasets we study, with a better fit than older competitors, (2) 3PL is parsimonious; it has only three parameters and thus avoids over-fitting, (3) 3PL can spot anomalies, and we report the most surprising ones, in our real networks, (4) We observe that the degree of reciprocity between users is correlated with their local topological features; reciprocity is higher among mutual users with larger local network overlap and greater degree similarity.

#index 1874866
#* Hierarchical graph summarization: leveraging hybrid information through visible and invisible linkage
#@ Rui Yan;Zi Yuan;Xiaojun Wan;Yan Zhang;Xiaoming Li
#t 2012
#c 3
#% 340883
#% 340948
#% 766444
#% 815920
#% 816173
#% 1190062
#% 1223707
#% 1264796
#% 1270224
#% 1305544
#% 1310459
#% 1482206
#% 1482374
#% 1598408
#% 1711847
#! Graph-based ranking algorithm has been recently exploited for summarization by using sentence-to-sentence relationships. Given a document set with linkage information to summarize, different sentences belong to different documents or clusters (either visible cluster via anchor texts or invisible cluster by semantics), which enables a hierarchical structure. It is challenging and interesting to investigate the impacts and weights of source documents/clusters: sentence from important ones are deemed more salient than the others. This paper aims to integrate three types of hierarchical linkage into traditional graph-based methods by proposing Hierarchical Graph Summarization (HGS). We utilize a hierarchical language model to measure the sentence relationships in HGS. We develop experimental systems to compare 5 rival algorithms on 4 instinctively different datasets which amount to 5197 documents. Performance comparisons between different system-generated summaries and manually created ones by human editors demonstrate the effectiveness of our approach in ROUGE metrics.

#index 1874867
#* Mining mobile users' activities based on search query text and context
#@ Bingyue Peng;Yujing Wang;Jian-Tao Sun
#t 2012
#c 3
#% 245087
#% 818259
#% 975699
#% 1019113
#% 1065183
#% 1115196
#% 1409929
#% 1535370
#! Mobile search market is growing very fast. Mining mobile search activities is helpful for understanding user preference, interest and even regular patterns. In previous works, text information contained by either search queries or web pages visited by users is well studied to mine search activities. Since rich context information (e.g., time, location and other sensor inputs) is contained in the mobile search data, it has also been leveraged by researchers for mining user activities. However, the two types of information were used separately. In this paper, we propose a graphical model approach, namely the Text and Context-based User Activity Model (TCUAM), which mines user activity patterns by utilizing query text and context simultaneously. The model is developed based on Latent Dirichlet Allocation (LDA) by regarding users' activities as latent topics. In order to guide the activity mining process, we borrow some external knowledge of topic-word relationship to build a constrained TCUAM model. The experimental results indicate that the TCUAM model yields better results compared with text-only and context-only approaches. We also find that the constrained TCUAM model is more effective than the unconstrained TCUAM model.

#index 1874868
#* Spread of information in a social network using influential nodes
#@ Arpan Chaudhury;Partha Basuchowdhuri;Subhashis Majumder
#t 2012
#c 3
#% 342596
#% 577217
#% 729923
#% 919688
#% 949164
#% 1136040
#% 1350272
#% 1407355
#% 1560183
#% 1663638
#% 1676017
#% 1825319
#! Viral marketing works with a social network as its backbone, where social interactions help spreading a message from one person to another. In social networks, a node with a higher degree can reach larger number of nodes in a single hop, and hence can be considered to be more influential than a node with lesser degree. For viral marketing with limited resources, initially the seller can focus on marketing the product to a certain influential group of individuals, here mentioned as core . If k persons are targeted for initial marketing, then the objective is to find the initial set of k active nodes, which will facilitate the spread most efficiently. We did a degree based scaling in graphs for making the edge weights suitable for degree based spreading. Then we detect the core from the maximum spanning tree (MST) of the graph by finding the top k influential nodes and the paths in MST that joins them. The paths within the core depict the key interaction sequences that will trigger the spread within the network. Experimental results show that the set of k influential nodes found by our core finding method spreads information faster than the greedy k -center method for the same k value.

#index 1874869
#* Discovering coverage patterns for banner advertisement placement
#@ P. Gowtham Srinivas;P. Krishna Reddy;S. Bhargav;R. Uday Kiran;D. Satheesh Kumar
#t 2012
#c 3
#% 152934
#% 280487
#% 481290
#% 600034
#% 723556
#% 818916
#% 1055713
#% 1055862
#% 1083629
#% 1190080
#% 1246502
#% 1536516
#% 1560211
#! We propose a model of coverage patterns and a methodology to extract coverage patterns from transactional databases. We have discussed how the coverage patterns are useful by considering the problem of banner advertisements placement in e-commerce web sites. Normally, advertiser expects that the banner advertisement should be displayed to a certain percentage of web site visitors. On the other hand, to generate more revenue for a given web site, the publisher has to meet the coverage demands of several advertisers by providing appropriate sets of web pages. Given web pages of a web site, a coverage pattern is a set of pages visited by a certain percentage of visitors. The coverage patterns discovered from click-stream data could help the publisher in meeting the demands of several advertisers. The efficiency and advantages of the proposed approach is shown by conducting experiments on real world click-stream data sets.

#index 1874870
#* Discovering unknown but interesting items on personal social network
#@ Juang-Lin Duan;Shashi Prasad;Jen-Wei Huang
#t 2012
#c 3
#% 330687
#% 577356
#% 871468
#% 989580
#% 1002007
#% 1016092
#% 1127457
#% 1214687
#% 1396093
#% 1396094
#! Social networking service has become very popular recently. Many recommendation systems have been proposed to integrate with social networking websites. Traditional recommendation systems focus on providing popular items or items posted by close friends. This strategy causes some problems. Popular items always occupy the recommendation list and they are usually already known by the user. In addition, items recommended by familiar users, who frequently communicate with the target user, may not be interesting. Moreover, interesting items from similar users with lower popularity are ignored. In this paper, we propose an algorithm, UBI, to discover unknown but interesting items. We propose three scores, i.e., Quartile-aided Popularity Score, Social Behavior Score, and User Similarity Score, to model the popularity of items, the familiarity of friends, and the similarity of users respectively in the target user's personal social network. Combining these three scores, the recommendation list containing unknown but interesting items can be generated. Experimental results show that UBI outperforms traditional methods in terms of the percentages of unknown and interesting items in the recommendation list.

#index 1874871
#* The pattern next door: towards spatio-sequential pattern discovery
#@ Hugo Alatrista Salas;Sandra Bringay;Frédéric Flouvat;Nazha Selmaoui-Folcher;Maguelonne Teisseire
#t 2012
#c 3
#% 227996
#% 310559
#% 464996
#% 527188
#% 527319
#% 778732
#% 784509
#% 844292
#% 989604
#% 1038716
#% 1117699
#% 1716981
#! Health risks management such as epidemics study produces large quantity of spatio-temporal data. The development of new methods able to manage such specific characteristics becomes crucial. To tackle this problem, we define a theoretical framework for extracting spatio-temporal patterns (sequences representing evolution of locations and their neighborhoods over time). Classical frequency support doesn't consider the pattern neighbor neither its evolution over time. We thus propose a new interestingness measure taking into account both spatial and temporal aspects. An algorithm based on pattern-growth approach with efficient successive projections over the database is proposed. Experiments conducted on real datasets highlight the relevance of our method.

#index 1874872
#* Accelerating outlier detection with uncertain data using graphics processors
#@ Takazumi Matsumoto;Edward Hung
#t 2012
#c 3
#% 430430
#% 1179162
#% 1370114
#! Outlier detection (also known as anomaly detection) is a common data mining task in which data points that lie outside expected patterns in a given dataset are identified. This is useful in areas such as fault detection, intrusion detection and in pre-processing before further analysis. There are many approaches already in use for outlier detection, typically adapting other existing data mining techniques such as cluster analysis, neural networks and classification methods such as Support Vector Machines. However, in many cases data from sources such as sensor networks can be better represented with an uncertain model. Detecting outliers with uncertain data involves far more computation as each data object is usually represented by a number of probability density functions (pdf s). In this paper, we demonstrate an implementation of outlier detection with uncertain objects based on an existing density sampling method that we have parallelized using the cross-platform OpenCL framework. While the density sampling method is a well understood and relatively straightforward outlier detection technique, its application to uncertain data results in a much higher computational workload. Our optimized implementation uses an inexpensive GPU (Graphics Processing Unit) to greatly reduce the running time. This improvement in performance may be leveraged when attempting to detect outliers with uncertain data in time sensitive situations such as when responding to sensor failure or network intrusion.

#index 1874873
#* Finding collections of k-clique percolated components in attributed graphs
#@ Pierre-Nicolas Mougel;Christophe Rigotti;Olivier Gandrillon
#t 2012
#c 3
#% 937814
#% 989622
#% 989645
#% 1063629
#% 1328169
#% 1332034
#% 1446960
#% 1535346
#% 1656705
#% 1710568
#! In this paper, we consider graphs where a set of Boolean attributes is associated to each vertex, and we are interested in k -clique percolated components (components made of overlapping cliques) in such graphs. We propose the task of finding the collections of homogeneous k -clique percolated components, where homogeneity means sharing a common set of attributes having value true. A sound and complete algorithm based on subgraph enumeration is proposed. We report experiments on two real databases (a social network of scientific collaborations and a network of gene interactions), showing that the extracted patterns capture meaningful structures.

#index 1874874
#* Reciprocal and heterogeneous link prediction in social networks
#@ Xiongcai Cai;Michael Bain;Alfred Krzywicki;Wayne Wobcke;Yang Sok Kim;Paul Compton;Ashesh Mahidadia
#t 2012
#c 3
#% 730089
#% 955043
#% 1030874
#% 1047390
#% 1117026
#% 1190129
#% 1318728
#% 1399997
#% 1535366
#% 1535418
#% 1583603
#! Link prediction is a key technique in many applications in social networks, where potential links between entities need to be predicted. Conventional link prediction techniques deal with either homogeneous entities, e.g., people to people, item to item links, or non-reciprocal relationships, e.g., people to item links. However, a challenging problem in link prediction is that of heterogeneous and reciprocal link prediction, such as accurate prediction of matches on an online dating site, jobs or workers on employment websites, where the links are reciprocally determined by both entities that heterogeneously belong to disjoint groups. The nature and causes of interactions in these domains makes heterogeneous and reciprocal link prediction significantly different from the conventional version of the problem. In this work, we address these issues by proposing a novel learnable framework called ReHeLP , which learns heterogeneous and reciprocal knowledge from collaborative information and demonstrate its impact on link prediction. Evaluation on a large commercial online dating dataset shows the success of the proposed method and its promise for link prediction.

#index 1874875
#* Detecting multiple stochastic network motifs in network data
#@ Kai Liu;William K. Cheung;Jiming Liu
#t 2012
#c 3
#% 345829
#% 408396
#% 727845
#% 832742
#% 949164
#% 1107295
#% 1232785
#% 1236646
#% 1384246
#% 1689537
#! Network motif detection methods are known to be important for studying the structural properties embedded in network data. Extending them to stochastic ones help capture the interaction uncertainties in stochastic networks. In this paper, we propose a finite mixture model to detect multiple stochastic motifs in network data with the conjecture that interactions to be modeled in the motifs are of stochastic nature. Component-wise Expectation Maximization algorithm is employed so that both the optimal number of motifs and the parameters of their corresponding probabilistic models can be estimated. For evaluating the effectiveness of the algorithm, we applied the stochastic motif detection algorithm to both synthetic and benchmark datasets. Also, we discuss how the obtained stochastic motifs could help the domain experts to gain better insights on the over-represented patterns in the network data.

#index 1874876
#* Scalable similarity matching in streaming time series
#@ Alice Marascu;Suleiman A. Khan;Themis Palpanas
#t 2012
#c 3
#% 379444
#% 460862
#% 576113
#% 659971
#% 757716
#% 769878
#% 844343
#% 907185
#% 958197
#% 990806
#% 993961
#% 1056068
#% 1127609
#% 1535372
#% 1643113
#! Nowadays online monitoring of data streams is essential in many real life applications, like sensor network monitoring, manufacturing process control, and video surveillance. One major problem in this area is the online identification of streaming sequences similar to a predefined set of pattern-sequences. In this paper, we present a novel solution that extends the state of the art both in terms of effectiveness and efficiency. We propose the first online similarity matching algorithm based on Longest Common SubSequence that is specifically designed to operate in a streaming context, and that can effectively handle time scaling, as well as noisy data. In order to deal with high stream rates and multiple streams, we extend the algorithm to operate on multilevel approximations of the streaming data, therefore quickly pruning the search space. Finally, we incorporate in our approach error estimation mechanisms in order to reduce the number of false negatives. We perform an extensive experimental evaluation using forty real datasets, diverse in nature and characteristics, and we also compare our approach to previous techniques. The experiments demonstrate the validity of our approach.

#index 1874877
#* Scalable mining of frequent tri-concepts from folksonomies
#@ Chiraz Trabelsi;Nader Jelassi;Sadok Ben Yahia
#t 2012
#c 3
#% 465484
#% 893155
#% 946524
#% 953950
#% 1039362
#% 1105478
#% 1165482
#% 1250929
#! Mining frequent tri-concepts from folksonomies is an interesting problem with broad applications. Most of the previous tri-concepts mining based algorithms avoided a straightforward handling of the triadic contexts and paid attention to an unfruitful projection of the induced search space into dyadic contexts. As a such projection is very computationally expensive since several tri-concepts are computed redundantly, scalable mining of folksonomies remains a challenging problem. In this paper, we introduce a new algorithm, called Tricons, that directly tackles the triadic form of folksonomies towards a scalable extraction of tri-concepts. The main thrust of the introduced algorithm stands in the application of an appropriate closure operator that splits the search space into equivalence classes for the the localization of tri-minimal generators. These tri-minimal generators make the computation of the tri-concepts less arduous than do the pioneering approches of the literature.The experimental results show that the Tricons enables the scalable frequent tri-concepts mining over two real-life folksonomies .

#index 1874878
#* SHARD: a framework for sequential, hierarchical anomaly ranking and detection
#@ Jason Robinson;Margaret Lonergan;Lisa Singh;Allison Candido;Mehmet Sayal
#t 2012
#c 3
#% 300136
#% 577275
#% 641202
#% 781774
#% 981000
#% 1022239
#% 1202160
#% 1382627
#% 1708162
#% 1715376
#! This work explores unsupervised anomaly detection within sequential, hierarchical data. We present a flexible framework for detecting, ranking and analyzing anomalies. The framework 1) allows users to incorporate complex, multidimensional, hierarchical data into the anomaly detection process; 2) uses an ensemble method that can incorporate multiple unsupervised anomaly detection algorithms and configurations; 3) identifies anomalies from combinations of categorical, numeric and temporal data at different conceptual resolutions of hierarchical data; 4) supports a set of anomaly ranking schemes; and 5) uses an interactive tree hierarchy visualization to highlight anomalous regions and relationships. Using both synthetic and real world data, we show that standard anomaly detection algorithms, when plugged into our framework, maintain a high anomaly detection accuracy and identify both micro-level, detailed anomalies and macro-level global anomalies in the data.

#index 1874879
#* Instant social graph search
#@ Sen Wu;Jie Tang;Bo Gao
#t 2012
#c 3
#% 220708
#% 328257
#% 729923
#% 769887
#% 805841
#% 853538
#% 869503
#% 1001363
#% 1083734
#% 1166473
#% 1190093
#% 1214641
#% 1214702
#% 1451159
#% 1451234
#% 1606004
#% 1606043
#% 1617365
#% 1693935
#! In this paper, we study a new problem of instant social graph search, which aims to find a sub graph that closely connects two and more persons in a social network. This is a natural requirement in our real daily life, such as "Who can be my referrals for applying for a job position?". In this paper, we formally define the problem and present a series of approximate algorithms to solve this problem: Path, Influence, and Diversity. To evaluate the social graph search results, we have developed two prototype systems, which are online available and have attracted thousands of users. In terms of both user's viewing time and the number of user clicks, we demonstrate that the three algorithms can significantly outperform (+34.56%-+131.37%) the baseline algorithm.

#index 1874880
#* Peer matrix alignment: a new algorithm
#@ Mohammed Kayed
#t 2012
#c 3
#% 330784
#% 577319
#% 654469
#% 769437
#% 788941
#% 805846
#% 838491
#% 889107
#% 1327636
#! Web data extraction has been one of the keys for web content mining that tries to understand Web pages and discover valuable information from them. Most of the developed Web data extraction systems have used data (string/tree) alignment techniques. In this paper, we suggest a new algorithm for multiple string (peer matrix) alignment. Each row in the matrix represents one string of characters, where every character (symbol) corresponds to a subtree in the DOM tree of a web page. Two subtrees take the same symbol in the peer matrix if they are similar, where similarity can be measured using either structural, content, or visual information. Our algorithm is not a generalization of 2-strings alignment; it looks at multiple strings at the same time. Also, our algorithm considers the common problems in the field of Web data extraction: missing, multi-valued, multi-ordering, and disjunctive attributes. The experiments show a perfect alignment result with the matrices constructed from the nodes closed to the top (root) and an encourage result for the nodes closed to the leaves of the DOM trees of the test web pages.

#index 1874881
#* Domain transfer dimensionality reduction via discriminant kernel learning
#@ Ming Zeng;Jiangtao Ren
#t 2012
#c 3
#% 80995
#% 743284
#% 763697
#% 766438
#% 791402
#% 857439
#% 876003
#% 906248
#% 983828
#% 1074363
#% 1108915
#% 1214724
#% 1270196
#% 1438392
#! Kernel discriminant analysis (KDA) is a popular technique for discriminative dimensionality reduction in data analysis. But, when a limited number of labeled data is available, it is often hard to extract the required low dimensional representation from a high dimensional feature space. Thus, one expects to improve the performance with the labeled data in other domains. In this paper, we propose a method, referred to as the domain transfer discriminant kernel learning (DTDKL), to find the optimal kernel by using the other labeled data from out-of-domain distribution to carry out discriminant dimensionality reduction. Our method learns a kernel function and discriminative projection by maximizing the Fisher discriminant distance and minimizing the mismatch between the in-domain and out-of-domain distributions simultaneously, by which we may get a better feature space for discriminative dimensionality reduction with cross-domain.

#index 1874882
#* Prioritizing disease genes by bi-random walk
#@ Maoqiang Xie;Taehyun Hwang;Rui Kuang
#t 2012
#c 3
#% 906419
#% 906613
#% 1038995
#% 1214474
#% 1214480
#% 1387891
#% 1446886
#! Random walk methods have been successfully applied to prioritizing disease causal genes. In this paper, we propose a bi-random walk algorithm (BiRW) based on a regularization framework for graph matching to globally prioritize disease genes for all phenotypes simultaneously. While previous methods perform random walk either on the protein-protein interaction network or the complete phenome-genome heterogenous network, BiRW performs random walk on the Kronecker product graph between the protein-protein interaction network and the phenotype similarity network. Three variations of BiRW that perform balanced or unbalanced bi-directional random walks are analyzed and compared with other random walk methods. Experiments on analyzing the disease phenotype-gene associations in Online Mendelian Inheritance in Man (OMIM) demonstrate that BiRW effectively improved disease gene prioritization over existing methods by ranking more known associations in the top 100 out of nearly 10,000 candidate genes.

#index 1874883
#* Selecting feature subset via constraint association rules
#@ Guangtao Wang;Qinbao Song
#t 2012
#c 3
#% 136350
#% 169659
#% 172386
#% 243728
#% 465922
#% 466410
#% 466483
#% 722929
#% 729418
#% 736899
#% 770799
#% 793239
#% 793250
#% 835018
#% 926881
#% 943937
#% 1038415
#% 1210532
#% 1249131
#% 1257889
#% 1650665
#! In this paper, a novel feature selection algorithm FEAST is proposed based on association rule mining. The proposed algorithm first mines association rules from a data set; then, it identifies the relevant and interactive feature values with the constraint association rules whose consequent is the target concept, and detects the redundant feature values with constraint association rules whose consequent and antecedent are both single feature value. After that, it eliminates the redundant feature values, and obtains the feature subset by mapping the relevant feature values to corresponding features. The efficiency and effectiveness of FEAST are tested upon both synthetic and real world data sets, and the classification results of the three different types of classifiers (including Naive Bayes, C4.5 and PART) with the other four representative feature subset selection algorithms (including CFS, FCBF, INTERACT and associative-based FSBAR) were compared. The results on synthetic data sets show that FEAST can effectively identify irrelevant and redundant features while reserving interactive ones. The results on the real world data sets show that FEAST outperformed other feature subset selection algorithms in terms of average classification accuracy and Win/Draw/Loss record.

#index 1874884
#* RadialViz: an orientation-free frequent pattern visualizer
#@ Carson Kai-Sang Leung;Fan Jiang
#t 2012
#c 3
#% 232136
#% 280511
#% 300120
#% 310525
#% 443086
#% 577222
#% 641140
#% 641150
#% 729976
#% 789001
#% 996871
#% 1176875
#% 1286760
#% 1386681
#% 1411088
#% 1428407
#% 1537191
#% 1689635
#% 1689744
#% 1710566
#% 1737769
#! Frequent pattern mining algorithms aim to find sets of frequently co-occurring items. Visual representation of the mining results is more comprehensible to users than the traditional long textual list of frequent patterns. Existing visualizers mostly show frequent patterns as graphs in a two-dimensional space with (x ,y )-coordinates. Nowadays, in a collaborative environment, it is not uncommon for users to have face-to-face meetings when they show the graphs visualizing frequent patterns. In these situations, the viewing orientation of the graphs plays an important role as different orientations positively or negatively impact the graph legibility. A legible right-side-up graph to one user may become an illegible upside-down graph towards another user. In this paper, we propose a visualizer that uses a radial layout--which is orientation free--to show frequent patterns. Having such a visualizer is beneficial in the collaborative environment.

#index 1874885
#* Feature weighting by RELIEF based on local hyperplane approximation
#@ Hongmin Cai;Michael Ng
#t 2012
#c 3
#% 169659
#% 209623
#% 229931
#% 420507
#% 425048
#% 443148
#% 444007
#% 444044
#% 722929
#% 729437
#% 770774
#% 906040
#% 919460
#% 975162
#% 1036164
#% 1083123
#% 1229199
#% 1314713
#% 1464096
#% 1736176
#% 1828389
#! In this paper, we propose a new feature weighting algorithm through the classical RELIEF framework. The key idea is to estimate the feature weights through local approximation rather than global measurement, as used in previous methods. The weights obtained by our method are more robust to degradation of noisy features, even when the number of dimensions is huge. To demonstrate the performance of our method, we conduct experiments on classification by combining hyperplane KNN model (HKNN) and the proposed feature weight scheme. Empirical study on both synthetic and real-world data sets demonstrate the superior performance of the feature selection for supervised learning, and the effectiveness of our algorithm.

#index 1874886
#* Towards identity disclosure control in private hypergraph publishing
#@ Yidong Li;Hong Shen
#t 2012
#c 3
#% 312212
#% 883235
#% 956511
#% 1063476
#% 1206763
#% 1415851
#! Identity disclosure control (IDC) on complex data has attracted increasing interest in security and database communities. Most existing work focuses on preventing identity disclosure in graphs that describes pairwise relations between data entities. Many data analysis applications need information about multi-relations among entities, which can be well represented with hypergraphs. However, the IDC problem has been little studied in publishing hypergraphs due to the diversity of hypergraph information which may expose to many types of background knowledge attacks. In this paper, we introduce a novel attack model with the properties of hyperedge rank as background knowledge, and formalize the rank-based hypergraph anonymization (RHA) problem. We propose an algorithm running in near-quadratic time on hypergraph size for rank anonymization which we show to be NP-hard, and in the meanwhile, maintaining data utility for community detection. We also show how to construct the hypergraph under the anonymized properties to protect a hypergraph from rank-based attacks. The performances of the methods have been validated by extensive experiments on real-world datasets. Our rank-based attack model and algorithms for rank anonymization and hypergraph construction are, to our best knowledge, the first systematic study for private hypergraph publishing.

#index 1874887
#* EWNI: efficient anonymization of vulnerable individuals in social networks
#@ Frank Nagle;Lisa Singh;Aris Gkoulalas-Divanis
#t 2012
#c 3
#% 956511
#% 1029292
#% 1063476
#% 1127360
#% 1206763
#% 1259854
#% 1328173
#% 1328188
#% 1372691
#% 1384246
#% 1415851
#% 1426540
#% 1594593
#% 1606069
#% 1984487
#! Social networks, patient networks, and email networks are all examples of graphs that can be studied to learn about information diffusion, community structure and different system processes; however, they are also all examples of graphs containing potentially sensitive information. While several anonymization techniques have been proposed for social network data publishing, they all apply the anonymization procedure on the entire graph. Instead, we propose a local anonymization algorithm that focuses on obscuring structurally important nodes that are not well anonymized, thereby reducing the cost of the overall anonymization procedure. Based on our experiments, we observe that we reduce the cost of anonymization by an order of magnitude while maintaining, and even improving, the accuracy of different graph centrality measures, e.g. degree and betweenness, when compared to another well known data publishing approach.

#index 1874888
#* A pruning-based approach for searching precise and generalized region for synthetic minority over-sampling
#@ Kamthorn Puntumapon;Kitsana Waiyamai
#t 2012
#c 3
#% 136350
#% 375017
#% 765520
#% 1195987
#% 1246173
#% 1271973
#% 1301004
#% 1378224
#% 1607960
#% 1708211
#! One solution to deal with class imbalance is to modify its class distribution. Synthetic over-sampling is a well-known method to modify class distribution by generating new synthetic minority data. Synthetic Minority Over-sampling TEchnique (SMOTE) is a state-of-the-art synthetic over-sampling algorithm that generates new synthetic data along the line between the minority data and their selected nearest neighbors. Advantages of SMOTE is to have decision regions larger and less specific to original data. However, its drawback is the over-generalization problem where synthetic data is generated into majority class region. Over-generalization leads to misclassify non-minority class region into minority class. To overcome the over-generalization problem, we propose an algorithm, called TRIM, to search for precise minority region while maintaining its generalization. TRIM iteratively filters out irrelevant majority data from the precise minority region. Output of the algorithm is the multiple set of seed minority data, and each individual set will be used for generating new synthetic data. Compared with state-of-the-art over-sampling algorithms, experimental results show significant performance improvement in terms of F-measure and AUC. This suggests over-generalization has a significant impact on the performance of the synthetic over-sampling method.

#index 1874889
#* Towards more efficient multi-label classification using dependent and independent dual space reduction
#@ Eakasit Pacharawongsakda;Thanaruk Theeramunkong
#t 2012
#c 3
#% 311034
#% 818234
#% 1231935
#% 1454143
#% 1495503
#% 1583287
#% 1647889
#! While multi-label classification can be widely applied for problems where multiple classes can be assigned to an object, its effectiveness may be sacrificed due to curse of dimensionality in the feature space and sparseness of dimensionality in the label space. Moreover, it suffers with high computational cost when there exist a high number of dimensions, as well as with lower accuracy when there are a number of noisy examples. As a solution, this paper presents two alternative methods, namely Dependent Dual Space Reduction and Independent Dual Space Reduction, to reduce dimensions in the dual spaces, i.e., the feature and label spaces, using Singular Value Decomposition (SVD). The first approach constructs the covariance matrix to represent dependency between the features and labels, project both of them into a single reduced space, and then perform prediction on the reduced space. On the other hand, the second approach handles the feature space and the label space separately by constructing a covariance matrix for each space to represent feature dependency and label dependency before performing SVD on dependency profile of each space to reduce dimension and for noise elimination and then predicting using their reduced dimensions. A number of experiments evidence that prediction on the reduced spaces for both dependent and independent reduction approaches can obtain better classification performance as well as faster computation, compared to the prediction using the original spaces. The dependent approach helps saving computational time while the independent approach tends to obtain better classification performance.

#index 1874890
#* Automatic identification of protagonist in fairy tales using verb
#@ Hui-Ngo Goh;Lay-Ki Soon;Su-Cheng Haw
#t 2012
#c 3
#% 815283
#% 817472
#% 855117
#% 855119
#% 939909
#% 1338584
#% 1399979
#% 1465843
#% 1471193
#% 1481633
#! Named entity recognition (NER) has been a well-studied problem in the area of text mining for locating atomic element into predefined categories, where "name of people" is one of the most commonly studied categories. Numerous new NER techniques have been unfolded to accommodate the needs of the application developed. However, most research works carried out focused on non-fiction domain. Fiction domain exhibits complexity and uncertainty in locating protagonist as it represents name of person in a diverse spectrums, ranging from living things (animals, plants, person) to non-living things (vehicle, furniture). This paper proposes automated protagonist identification in fiction domain, particularly in fairy tales. Verb has been used as a determinant in substantiating the existence of protagonist with the assistance of WordNet. The experimental results show that it is viable to use verb in identifying named entity, particularly "people" category and it can be applied in a small text size environment.

#index 1874891
#* CD: a coupled discretization algorithm
#@ Can Wang;Mingchun Wang;Zhong She;Longbing Cao
#t 2012
#c 3
#% 46479
#% 420146
#% 501359
#% 944159
#% 945006
#% 1104431
#% 1156097
#% 1195948
#% 1607963
#% 1642025
#! Discretization technique plays an important role in data mining and machine learning. While numeric data is predominant in the real world, many algorithms in supervised learning are restricted to discrete variables. Thus, a variety of research has been conducted on discretization, which is a process of converting the continuous attribute values into limited intervals. Recent work derived from entropy-based discretization methods, which has produced impressive results, introduces information attribute dependency to reduce the uncertainty level of a decision table; but no attention is given to the increment of certainty degree from the aspect of positive domain ratio. This paper proposes a discretization algorithm based on both positive domain and its coupling with information entropy, which not only considers information attribute dependency but also concerns deterministic feature relationship. Substantial experiments on extensive UCI data sets provide evidence that our proposed coupled discretization algorithm generally outperforms other seven existing methods and the positive domain based algorithm proposed in this paper, in terms of simplicity, stability, consistency, and accuracy.

#index 1874892
#* Co-embedding of structurally missing data by locally linear alignment
#@ Takehisa Yairi
#t 2012
#c 3
#% 272536
#% 443903
#% 931230
#% 1275102
#% 1535460
#! This paper proposes a "co-embedding" method to embed the row and column vectors of an observation matrix data whose large portion is structurally missing into low-dimensional latent spaces simultaneously. A remarkable characteristic of this method is that the co-embedding is efficiently obtained via eigendecomposition of a matrix, unlike the conventional methods which require iterative estimation of missing values and suffer from local optima. Besides, we extend the unsupervised co-embedding method to a semi-supervised version, which is reduced to a system of linear equations.In an experimental study, we apply the proposed method to two kinds of tasks --- (1) Structure from Motion (SFM) and (2) Simultaneous Localization and Mapping (SLAM).

#index 1874893
#* Relevant feature selection from EEG signal for mental task classification
#@ Akshansh Gupta;R. K. Agrawal
#t 2012
#c 3
#% 243728
#% 425048
#% 722929
#% 729437
#% 940380
#% 984336
#% 1076295
#% 1348885
#% 1349055
#% 1788631
#% 1812869
#! In last few years, the research community has shown interest in the development of Brain Computer Interface which may assists physically challenged people to communicate with the help of brain signal. The two important components of such BCI system are to determine appropriate features and classification method to achieve better performance. In literature, Empirical Mode Decomposition is suggested for feature extraction from EEG which is suitable for the analysis of non-linear and non-stationary time series. However, the features obtained from EEG may contain irrelevant and redundant features which make them inefficient for machine learning. Relevant features not only decrease the processing time to train a classifier but also provide better generalization. Hence, relevant features which provide maximum classification accuracy are selected using ratio of scatter matrices, Chernoff distance measure and linear regression. The performance of different mental task using different measures used for feature selection is compared and evaluated in terms of classification accuracy. Experimental results show that there is significant improvement in classification accuracy with features selected using all feature selection methods and in particular with ratio of scatter matrices.

#index 1904463
#* Advances in Knowledge Discovery and Data Mining, Part I: 16th Pacific-Asia Conference, PAKDD 2012, Kuala Lumpur, Malaysia, May 29-June1, 2012
#@ Pang-Ning Tan;Sanjay Chawla;Chin Kuan Ho;James Bailey
#t 2012
#c 3
#! The two-volume set LNAI 7301 and 7302 constitutes the refereed proceedings of the 16th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2012, held in Kuala Lumpur, Malaysia, in May 2012. The total of 20 revised full papers and 66 revised short papers were carefully reviewed and selected from 241 submissions. The papers present new ideas, original research results, and practical development experiences from all KDD-related areas. The papers are organized in topical sections on supervised learning: active, ensemble, rare-class and online; unsupervised learning: clustering, probabilistic modeling in the first volume and on pattern mining: networks, graphs, time-series and outlier detection, and data manipulation: pre-processing and dimension reduction in the second volume.

#index 1960578
#* Proceedings of the 2012 Pacific-Asia conference on Emerging Trends in Knowledge Discovery and Data Mining
#@ Takashi Washio;Jun Luo
#t 2012
#c 3

#index 1960579
#* Modality classification for medical images using sparse coded affine-invariant descriptors
#@ Viktor Gál;Illés Solt;Etienne Kerre;Mike Nachtegael
#t 2012
#c 3
#% 213673
#% 321652
#% 635689
#% 722904
#% 724320
#% 883971
#% 1301004
#% 1302875
#% 1388958
#% 1857579
#! Modality is a key facet in medical image retrieval, as a user is likely interested in only one of e.g. radiology images, flowcharts, and pathology photos. While assessing image modality is trivial for humans, reliable automatic methods are required to deal with large un-annotated image bases, such as figures taken from the millions of scientific publications. We present a multi-disciplinary approach to tackle the classification problem by combining image features, meta-data, textual and referential information. We test our system's accuracy on the Image- CLEF 2011 medical modality classification data set. We show that using a fully affine-invariant feature descriptor and sparse coding on these descriptors in the Bag-of-Words image representation significantly increases the classification accuracy. Our best method achieves 87.89 and outperforms the state of the art.

#index 1960580
#* Mining web data for epidemiological surveillance
#@ Didier Breton;Sandra Bringay;François Marques;Pascal Poncelet;Mathieu Roche
#t 2012
#c 3
#% 1184851
#% 1277378
#% 1905624
#! Epidemiological surveillance is an important issue of public health policy. In this paper, we describe a method based on knowledge extraction from news and news classification to understand the epidemic evolution. Descriptive studies are useful for gathering information on the incidence and characteristics of an epidemic. New approaches, based on new modes of mass publication through the web, are developed: based on the analysis of user queries or on the echo that an epidemic may have in the media. In this study, we focus on a particular media: web news. We propose the Epimining approach, which allows the extraction of information from web news (based on pattern research) and a fine classification of these news into various classes (new cases, deaths...). The experiments conducted on a real corpora (AFP news) showed a precision greater than 94% and an F-measure above 85%. We also investigate the interest of tacking into account the data collected through social networks such as Twitter to trigger alarms.

#index 1960581
#* Getting a grasp on clinical pathway data: an approach based on process mining
#@ Jochen De Weerdt;Filip Caron;Jan Vanthienen;Bart Baesens
#t 2012
#c 3
#% 772836
#% 798290
#% 945706
#% 948211
#% 1015843
#% 1021671
#% 1136045
#% 1232050
#% 1576946
#% 1631730
#! Since healthcare processes are pre-eminently heterogeneous and multi-disciplinary, information systems supporting these processes face important challenges in terms of design, implementation and diagnosis. Nonetheless, streamlining clinical pathways with the purpose of delivering high quality care while at the same time reducing costs is a promising goal. In this paper, we propose a methodology founded on process mining for intelligent analysis of clinical pathway data. Process mining can be considered a valuable approach to obtain a better understanding about the actual way of working in human-centric processes such as clinical pathways by investigating the event data as recorded in healthcare information systems. However, capturing tangible knowledge from clinical processes with their ad hoc and complex nature proves difficult. Accordingly, this paper proposes a data analysis methodology focussing on the extraction of tangible insights from clinical pathway data by adopting both a drill up and a drill down perspective.

#index 1960582
#* ALIVE: a multi-relational link prediction environment for the healthcare domain
#@ Reid A. Johnson;Yang Yang;Everaldo Aguiar;Andrew Rider;Nitesh V. Chawla
#t 2012
#c 3
#% 955712
#% 1117026
#% 1332120
#% 1451163
#% 1451178
#% 1635130
#! An underlying assumption of biomedical informatics is that decisions can be more informed when professionals are assisted by analytical systems. For this purpose, we propose ALIVE, a multi-relational link prediction and visualization environment for the healthcare domain. ALIVE combines novel link prediction methods with a simple user interface and intuitive visualization of data to enhance the decision-making process for healthcare professionals. It also includes a novel link prediction algorithm, MRPF, which outperforms many comparable algorithms on multiple networks in the biomedical domain. ALIVE is one of the first attempts to provide an analytical and visual framework for healthcare analytics, promoting collaboration and sharing of data through ease of use and potential extensibility. We encourage the development of similar tools, which can assist in facilitating successful sharing, collaboration, and a vibrant online community.

#index 1960583
#* The relevance of spatial relation terms and geographical feature types
#@ Chunju Zhang;Xueying Zhang;Chaoli Du
#t 2012
#c 3
#% 262215
#% 370876
#% 1062238
#% 1075367
#% 1256554
#% 1291426
#% 1407878
#! Spatial relation terms can generally indicate spatial relations described in natural language context. Their semantic representation is closely related to geographical entities and their characteristics e.g. geometry, scale and geographical feature types. This paper proposes a quantitative approach to explore the semantic relevance of spatial relation terms and geographical feature types in text. Firstly, a classification of spatial relation terms is performed. Secondly, the "Overlap" similarity measure is introduced to define the relevance of spatial relation terms and geographical feature types based on a large scale annotation corpus. Thirdly, the relevance is expanded with the semantic distance and hierarchical relationship of the classification system of geographical feature types. Finally, a knowledge base based on protégé is developed to formally represent and visualize geographical feature types, spatial relation classifications, and the relevance of spatial relation terms and geographical feature types. This study indicates that spatial relation terms are strongly relevant to geographical feature types. The semantic representation of topological relation terms is diverse and their relevance with geographical feature types is much stronger than directional relation and distance relation terms, but the annotation quality and the classification granularity of geographical entities in the corpus have a great effect on the performance.

#index 1960584
#* Applying NLP techniques for query reformulation to information retrieval with geographical references
#@ José M. Perea-Ortega;Miguel A. García-Cumbreras;L. Alfonso Ureña-López
#t 2012
#c 3
#% 387427
#% 642985
#% 730051
#% 1016368
#% 1055914
#% 1102258
#% 1125716
#% 1125717
#% 1125718
#% 1224723
#% 1432320
#% 1432326
#% 1674995
#% 1674999
#% 1726012
#! Geographic Information Retrieval (GIR) is an active and growing research area that focuses on the retrieval of textual documents according to a geographical criteria of relevance. However, since a GIR system can be treated as a traditional Information Retrieval (IR) system, it is important to pay attention to finding effective methods for query reformulation. In this way, the search results will improve their quality and recall. In this paper, we propose different Natural Language Processing (NLP) techniques of query reformulation related to the modification and/or expansion of both parts thematic and geospatial that are usually recognized in a geographical query. We have evaluated each of the reformulations proposed using GeoCLEF as an evaluation framework for GIR systems. The results obtained show that all proposed query reformulations retrieved relevant documents that were not retrieved using the original query.

#index 1960585
#* Adaptive evidence accumulation clustering using the confidence of the objects' assignments
#@ João M. M. Duarte;Ana L. N. Fred;F. Jorge F. Duarte
#t 2012
#c 3
#% 479863
#% 494396
#% 520224
#% 551737
#% 722902
#% 727903
#% 745793
#% 770836
#% 774878
#% 803762
#% 940282
#% 1005441
#% 1103986
#% 1133031
#! Ensemble methods are known to increase the performance of learning algorithms, both on supervised and unsupervised learning. Boosting algorithms are quite successful in supervised ensemble methods. These algorithms build incrementally an ensemble of classifiers by focusing on objects previously misclassified while training the current classifier. In this paper we propose an extension to the Evidence Accumulation Clustering method inspired by the Boosting algorithms. While on supervised learning the identification of misclassified objects is a trivial task because the labels for each object are known, on unsupervised learning these are unknown, making it difficult to identify the objects on which the clustering algorithm should focus. The proposed approach uses the information contained in the co-association matrix to identify degrees of confidence of the assignments of each object to its cluster. The degree of confidence is then used to select which objects should be emphasized in the learning process of the clustering algorithm. New consensus partition validity measures, based on the notion of degree of confidence, are also proposed. In order to evaluate the performance of our approaches, experiments on several artificial and real data sets were performed and shown the adaptive clustering ensemble method and the consensus partition validity measure help to improve the quality of data clustering.

#index 1960586
#* An explicit description of the extended gaussian kernel
#@ Yong Liu;Shizhong Liao
#t 2012
#c 3
#% 190581
#% 266426
#% 393059
#% 493731
#% 803203
#% 1488365
#% 1674772
#% 1816307
#! Kernel methods play an important role in machine learning, pattern recognition and data mining. Although the kernel functions are the central part of the kernel methods, little is known about the structure of its reproducing kernel Hilbert spaces (RKHS) and the eigenvalues of the integral operator. In this paper, we first give the definition of the extended Gaussian kernel which includes the Gaussian kernel as its special case. Then, through a generalization form of the Weyl inner product, we present an explicit description of the RKHS of the extended Gaussian kernel. Furthermore, using the Funk-Hecke formula, we get the eigenvalues and eigenfunctions of the integral operator on the unit sphere.

#index 1960587
#* An improved genetic clustering algorithm for categorical data
#@ Hongwu Qin;Xiuqin Ma;Tutut Herawan;Jasni Mohamad Zain
#t 2012
#c 3
#% 114994
#% 314054
#% 413618
#% 420081
#% 1042044
#% 1376133
#% 1382052
#% 1580877
#! Deng et al. [Deng, S., He, Z., Xu, X.: G-ANMI: A mutual information based genetic clustering algorithm for categorical data, Knowledge-Based Systems 23, 144---149(2010)] proposed a mutual information based genetic clustering algorithm named G-ANMI for categorical data. While G-ANMI is superior or comparable to existing algorithms for clustering categorical data in terms of clustering accuracy, it is very time-consuming due to the low efficiency of genetic algorithm (GA). In this paper, we propose a new initialization method for G-ANMI to improve its efficiency. Experimental results show that the new method greatly improves the efficiency of G-ANMI as well as produces higher clustering accuracy.

#index 1960588
#* Instance-Ranking: a new perspective to consider the instance dependency for classification
#@ Xin Xia;Xiaohu Yang;Shanping Li;Chao Wu
#t 2012
#c 3
#% 311034
#% 478470
#% 878224
#% 889101
#% 950571
#% 1100077
#% 1212553
#% 1267771
#% 1451240
#% 1482213
#% 1551186
#% 1643150
#! Single-label classification refers to the task to predict an instance to be one unique label in a set of labels. Different from single-label classification, for multi-label classification, one instance is associated with one or more labels in a set of labels simultaneously. Various works have focused on the algorithms for those two types of classification. Since the ranking problem is always coexisting with the classification problem, and traditional researches mainly assume the uniform distribution for the instances, in this paper, we propose a new perspective for the ranking problem. With the assumption that the distribution for the instance is not uniform, different instances have different influences for the distribution, the Instance-Ranking algorithm is presented. With the Instance- Ranking algorithm, the famous K-nearest-neighbors (KNN) algorithm is modified to confirm the validity of our algorithm. Lastly, the Instance-Ranking algorithm is combined with the ML.KNN algorithm for multi-label classification. Experiment with different datasets show that our Instance-Ranking algorithm achieves better performance than the original state-of-art algorithm such as KNN and ML.KNN.

#index 1960589
#* Triangular kernel nearest-neighbor-based clustering algorithm for discovering true clusters
#@ Aina Musdholifah;Siti Zaiton Mohd Hashim
#t 2012
#c 3
#% 375017
#% 444006
#% 729954
#% 735042
#% 835018
#% 925099
#% 937551
#% 938985
#% 992321
#% 1010466
#% 1111126
#% 1294264
#% 1671982
#% 1693320
#! Clustering is a powerful exploratory technique for extracting the knowledge of given data. Several clustering techniques that have been proposed require predetermined number of clusters. However, the triangular kernel-nearest neighbor-based clustering (TKNN) has been proven able to determine the number and member of clusters automatically. TKNN provides good solutions for clustering non-spherical and high-dimensional data without prior knowledge of data labels. On the other hand, there is no definite measure to evaluate the accuracy of the clustering result. In order to evaluate the performance of the proposed TKNN clustering algorithm, we utilized various benchmark classification datasets. Thus, TKNN is proposed for discovering true clusters with arbitrary shape, size and density contained in the datasets. The experimental results on benched-mark datasets showed the effectiveness of our technique. Our proposed TKNN achieved more accurate clustering results and required less time processing compared with k-means, ILGC, DBSCAN and KFCM.

#index 1960590
#* DisClose: discovering colossal closed itemsets via a memory efficient compact row-tree
#@ Nurul F. Zulkurnain;David J. Haglin;John A. Keane
#t 2012
#c 3
#% 248791
#% 300120
#% 662759
#% 729984
#% 785383
#% 953950
#% 985041
#% 1165881
#! A recent focus in itemset mining has been the discovery of frequent itemsets from high-dimensional datasets. With exponentially increasing running time as average row length increases, mining such datasets renders most conventional algorithms impractical. Unfortunately, large cardinality itemsets are likely to be more informative than small cardinality itemsets in this type of dataset. This paper proposes an approach, termed DisClose, to extract large cardinality (colossal) closed itemsets from high-dimensional datasets. The approach relies on a Compact Row-Tree data structure to represent itemsets during the search process. Large cardinality itemsets are enumerated first followed by smaller ones. In addition, we utilize a minimum cardinality threshold to further reduce the search space. Experimental results show that DisClose can achieve extraction of colossal closed itemsets in the discovered datasets, even for low support thresholds. The algorithm immediately discovers closed itemsets without needing to check if each new closed itemset has previously been found.

#index 2009378
#* Emerging Trends in Knowledge Discovery and Data Mining: PAKDD 2012 International Workshops DMHM, GeoDoc, 3Clust, and DSDM, Kuala Lumpur, Malaysia
#@ Takashi Washio;Jun Luo
#t 2013
#c 3
#! This book constitutes the thoroughly refereed proceedings of the PAKDD 2012 International Workshops: Third Workshop on Data Mining for Healthcare Management (DMHM 2012), First Workshop on Geospatial Information and Documents (GeoDoc 2012), First Workshop on Multi-view data, High-dimensionality, External Knowledge: Striving for a Unified Approach to Clustering (3Clust 2012), and the Second Doctoral Symposium on Data Mining (DSDM 2012); held in conjunction with the 16th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD 2012), in Kuala Lumpur, Malaysia, May/June 2012. The 12 revised papers presented were carefully reviewed and selected from numerous submissions. DMHM 2012 aimed at providing a common platform for the discussion of challenging issues and potential techniques in this emerging field of data mining for health care management; 3Clust 2012 focused on solving emerging problems such as clustering ensembles, semi-supervised clustering, subspace/projective clustering, co-clustering, and multi-view clustering; GeoDoc 2012 highlighted the formalization of geospatial concepts and relationships with a focus on the extraction of geospatial relations in free text datasets to offer to the database community a unified framework for geodata discovery; and DSDM 2012 provided the opportunity for Ph.D. students and junior researchers to discuss their work on data mining foundations, techniques and applications.

#index 2020427
#* Advances in Knowledge Discovery and Data Mining: 17th Pacific-Asia Conference, PAKDD 2013, Gold Coast, Australia, April 14-17, 2013, Proceedings, Part ... / Lecture Notes in Artificial Intelligence)
#@ Jian Pei;Vincent S. Tseng;Longbing Cao;Hiroshi Motoda;Guandong Xu
#t 2013
#c 3
#! The two-volume set LNAI 7818 + LNAI 7819 constitutes the refereed proceedings of the 17th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2013, held in Gold Coast, Australia, in April 2013. The total of 98 papers presented in these proceedings was carefully reviewed and selected from 363 submissions. They cover the general fields of data mining and KDD extensively, including pattern mining, classification, graph mining, applications, machine learning, feature selection and dimensionality reduction, multiple information sources mining, social networks, clustering, text mining, text classification, imbalanced data, privacy-preserving data mining, recommendation, multimedia data mining, stream data mining, data preprocessing and representation.

#index 2054499
#* Trends and Applications in Knowledge Discovery and Data Mining: PAKDD 2013 Workshops DMApps, DANTH, QIMIE, BDM, CDA, CloudSD, Golden Coast, QLD
#@ Jiuyong Li;Longbing Cao;Can Wang;Kay Chen Tan;Bo Liu;Jian Pei;Vincent S. Tseng
#t 2013
#c 3
#! This book constitutes the refereed proceedings at PAKDD Workshops 2013, affiliated with the 17th Pacific-Asia Conference on Knowledge Discovery and Data Mining (PAKDD) held in Gold Coast, Australia in April 2013. The 47 revised full papers presented were carefully reviewed and selected from 92 submissions. The workshops affiliated with PAKDD 2013 include: Data Mining Applications in Industry and Government (DMApps), Data Analytics for Targeted Healthcare (DANTH), Quality Issues, Measures of Interestingness and Evaluation of Data Mining Models (QIMIE), Biologically Inspired Techniques for Data Mining (BDM), Constraint Discovery and Application (CDA), Cloud Service Discovery (CloudSD).

