#index 280433
#* Pruning and summarizing the discovered associations
#@ 2438 2439 2440
#t 1999
#c KDD '99 Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 136350
#% 152934
#% 172386
#% 210160
#% 227919
#% 248785
#% 280433
#% 420112
#% 443092
#% 459008
#% 461909
#% 462238
#% 479484
#% 481290
#% 481588
#% 1499588

#index 280487
#* Mining association rules with multiple minimum supports
#@ 2438 2439 2440
#t 1999
#c KDD '99 Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 152934
#% 201894
#% 227917
#% 248785
#% 280433
#% 280487
#% 462234
#% 462238
#% 481290
#% 481588
#% 481758

#index 280522
#* Mining interesting knowledge using DM-II
#@ 2438 2439 2440 2529
#t 1999
#c KDD '99 Proceedings of the fifth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 136350
#% 172386
#% 280433
#% 280487
#% 443092
#% 481290
#% 637522
#% 1271849
#% 1499588

#index 310520
#* Multi-level organization and summarization of the discovered rules
#@ 2438 3558 2439
#t 2000
#c Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 78791
#% 136350
#% 172386
#% 248785
#% 280433
#% 280500
#% 443092
#% 481290
#% 481588
#% 501204
#% 529648
#% 1499588

#index 310571
#* Exploration mining in diabetic patients databases: findings and conclusions
#@ 2439 3239 2438 3577
#t 2000
#c Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 152934
#% 172386
#% 201889
#% 280433
#% 310520
#% 412479
#% 443092
#% 1499588

#index 310575
#* Targeting the right students using data mining
#@ 2440 2438 3634 850 3635
#t 2000
#c Proceedings of the sixth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 136350
#% 152934
#% 210162
#% 227917
#% 248785
#% 273900
#% 280436
#% 280439
#% 280442
#% 280473
#% 280487
#% 280494
#% 462234
#% 481290
#% 481588
#% 481779
#% 481945
#% 1272365

#index 320932
#* Web for data mining: organizing and interpreting the discovered rules using the Web
#@ 2440 2438 3634
#t 2000
#c ACM SIGKDD Explorations Newsletter
#% 136350
#% 152934
#% 172386
#% 201894
#% 280433
#% 310520
#% 481290
#% 481758
#% 631970
#% 1499588

#index 342605
#* Discovering unexpected information from your competitors' web sites
#@ 2438 2440 850
#t 2001
#c Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining
#% 46803
#% 244103
#% 248791
#% 248801
#% 249110
#% 261741
#% 268068
#% 268079
#% 281209
#% 281218
#% 281251
#% 282905
#% 303113
#% 310496
#% 310518
#% 312861
#% 387427
#% 406493
#% 443092
#% 481290
#% 1499588
#! Ever since the beginning of the Web, finding useful information from the Web has been an important problem. Existing approaches include keyword-based search, wrapper-based information extraction, Web query and user preferences. These approaches essentially find information that matches the user's explicit specifications. This paper argues that this is insufficient. There is another type of information that is also of great interest, i.e., unexpected information, which is unanticipated by the user. Finding unexpected information is useful in many applications. For example, it is useful for a company to find unexpected information bout its competitors, e.g., unexpected services and products that its competitors offer. With this information, the company can learn from its competitors and/or design counter measures to improve its competitiveness. Since the number of pages of a typical commercial site is very large and there are also many relevant sites (competitors), it is very difficult for a human user to view each page to discover the unexpected information. Automated assistance is needed. In this paper, we propose a number of methods to help the user find various types of unexpected information from his/her competitors' Web sites. Experiment results show that these techniques are very useful in practice and also efficient.

#index 342631
#* Identifying non-actionable association rules
#@ 2438 2439 2440
#t 2001
#c Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining
#% 136350
#% 172386
#% 280433
#% 280436
#% 280485
#% 280500
#% 310494
#% 310496
#% 443092
#% 462238
#% 481290
#% 481588
#% 1499588
#! Building predictive models and finding useful rules are two important tasks of data mining. While building predictive models has been well studied, finding useful rules for action still presents a major problem. A main obstacle is that many data mining algorithms often produce too many rules. Existing research has shown that most of the discovered rules are actually redundant or insignificant. Pruning techniques have been developed to remove those spurious and/or insignificant rules. In this paper, we argue that being a significant rule (or a non-redundant rule), however, does not mean that it is a potentially useful rule for action. Many significant rules (unpruned rules) are in fact not actionable. This paper studies this issue and presents an efficient algorithm to identify these non-actionable rules. Experiment results on many real-life datasets show that the number of non-actionable rules is typically quite large. The proposed technique thus enables the user to focus on fewer rules and to be assured that the remaining rules are non-redundant and potentially useful for action.

#index 342632
#* Discovering the set of fundamental rule changes
#@ 2438 2439 2440
#t 2001
#c Proceedings of the seventh ACM SIGKDD international conference on Knowledge discovery and data mining
#% 204531
#% 273693
#% 280409
#% 280433
#% 310496
#% 443092
#% 464204
#% 481290
#% 481588
#! The world around us changes constantly. Knowing what has changed is an important part of our lives. For businesses, recognizing changes is also crucial. It allows businesses to adapt themselves to the changing market needs. In this paper, we study changes of association rules from one time period to another. One approach is to compare the supports and/or confidences of each rule in the two time periods and report the differences. This technique, however, is too simplistic as it tends to report a huge number of rule changes, and many of them are, in fact, simply the snowball effect of a small subset of fundamental changes. Here, we present a technique to highlight the small subset of fundamental changes. A change is fundamental if it cannot be explained by some other changes. The proposed technique has been applied to a number of real-life datasets. Experiments results show that the number of rules whose changes are unexplainable is quite small (about 20% of the total number of changes discovered), and many of these unexplainable changes reflect some fundamental shifts in the application domain.

#index 427033
#* Research activities in database management and information retrieval at University of Illinois at Chicago
#@ 4685 4686 2438 276 2243 278
#t 2002
#c ACM SIGMOD Record
#% 116048
#% 249933
#% 309103
#% 316253
#% 348190
#% 443450
#% 461923
#% 464641
#% 481600
#% 500896
#% 538889
#% 577232
#% 620060
#% 637796

#index 455102
#* Proceedings of the 6th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining
#@ 4845 850 2438
#t 2002
#c PAKDD '02 Proceedings of the 6th Pacific-Asia Conference on Advances in Knowledge Discovery and Data Mining
#! From the Publisher:This book constitutes the refereed proceedings of the 6th Pacific-Asia Conference on Knowledge Discovery and Data Mining, PAKDD 2002, held in Taipei, Taiwan, in May 2002. The 32 revised full papers and 20 short papers presented together with 4 invited contributions were carefully reviewed and selected from a total of 128 submissions. The papers are organized in topical sections on association rules; classification; interestingness; sequence mining; clustering; Web mining; semi-structure and concept mining; data warehouse and data cube; bio-data mining; temporal mining; and outliers, missing data, and causation.

#index 464641
#* Partially Supervised Classification of Text Documents
#@ 2438 5658 850 5659
#t 2002
#c ICML '02 Proceedings of the Nineteenth International Conference on Machine Learning

#index 466658
#* Analyzing the Interestingness of Association Rules from the Temporal Dimension
#@ 2438 2440 6020
#t 2001
#c ICDM '01 Proceedings of the 2001 IEEE International Conference on Data Mining
#! Rule discovery is one of the central tasks of data mining. Existing research has produced many algorithms for the purpose. These algorithms, however, often generate too manyrules. In the past few years, rule interestingness techniques were proposed to help the user find interesting rules. These techniques typically employ the dataset as a whole to mine rules, and then filter and/or rank the discovered rules in various ways. In this paper, we argue that this is insufficient. These techniques are unable to answer a question that is of criticalimportance to the application of rules, i.e., can the rules be trusted? In practice, the users are always concerned with the question. They want to know whether the rules indeed represent some true and stable (or reliable)underlying relationships in the domain. If a rule is not stable, does it show any systematic pattern such as a trend? Before any rule can be used, these questions must be answered. This paper proposes a technique to use statistical methods to analyze rules from the temporal dimension to answer these questions. Experimental results show that the proposed technique is very effective.

#index 478294
#* Improving an Association Rule Based Classifier
#@ 2438 2440 3634
#t 2000
#c PKDD '00 Proceedings of the 4th European Conference on Principles of Data Mining and Knowledge Discovery
#% 136350
#% 153021
#% 280439
#% 481290
#! Existing classification algorithms in machine learning mainly use heuristic search to find a subset of regularities in data for classification. In the past few years, extensive research was done in the database community on learning rules using exhaustive search under the name of association rule mining. Although the whole set of rules may not be used directly for accurate classification, effective classifiers have been built using the rules. This paper aims to improve such an exhaustive search based classification system CBA (Classification Based on Associations). The main strength of this system is that it is able to use the most accurate rules for classification. However, it also has weaknesses. This paper proposes two new techniques to deal with these weaknesses. This results in remarkably accurate classifiers. Experiments on a set of 34 benchmark datasets show that on average the new techniques reduce the error of CBA by 17% and is superior to CBA on 26 of the 34 datasets. They reduce the error of C4.5 by 19%, and improve performance on 29 datasets. Similar good results are also achieved against RIPPER, LB and a Naïve-Bayes classifier.

#index 501519
#* Visually Aided Exploration of Interesting Association Rules
#@ 2438 2439 1282 2529
#t 1999
#c PAKDD '99 Proceedings of the Third Pacific-Asia Conference on Methodologies for Knowledge Discovery and Data Mining
#% 136350
#% 152934
#% 172386
#% 232106
#% 443092
#% 481758
#! Association rules are a class of important regularities in databases. They are found to be very useful in practical applications. However, the number of association rules discovered in a database can be huge, thus making manual inspection and analysis of the rules difficult. In this paper, we propose a new framework to allow the user to explore the discovered rules to identify those interesting ones. This framework has two components, an interestingness analysis component, and a visualization component. The interestingness analysis component analyzes and organizes the discovered rules according to various interestingness criteria with respect to the user's existing knowledge. The visualization component enables the user to visually explore those potentially interesting rules. The key strength of the visualization component is that from a single screen, the user is able to obtain a global and yet detailed picture of various interesting aspects of the discovered rules. Enhanced with color effects, the user can easily and quickly focus his/her attention on the more interesting/useful rules.

#index 577216
#* Querying multiple sets of discovered rules
#@ 2494 2438
#t 2002
#c Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining
#! Rule mining is an important data mining task that has been applied to numerous real-world applications. Often a rule mining system generates a large number of rules and only a small subset of them is really useful in applications. Although there exist some systems allowing the user to query the discovered rules, they are less suitable for complex ad hoc querying of multiple data mining rulebases to retrieve interesting rules. In this paper, we propose a new powerful rule query language Rule-QL for querying multiple rulebases that is modeled after SQL and has rigorous theoretical foundations of a rule-based calculus. In particular, we first propose a rule-based calculus RC based on the first-order logic, and then present the language Rule-QL that is at least as expressive as the safe fragment of RC. We also propose a number of efficient query evaluation techniques for Rule-QL and test them experimentally on some representative queries to demonstrate the feasibility of Rule-QL.

#index 577232
#* A refinement approach to handling model misfit in text categorization
#@ 8191 8192 2438 5659
#t 2002
#c Proceedings of the eighth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 132938
#% 169717
#% 169806
#% 190581
#% 197394
#% 209021
#% 218961
#% 219050
#% 219051
#% 262085
#% 266215
#% 280817
#% 302391
#% 309122
#% 310503
#% 311034
#% 318412
#% 340940
#% 458379
#% 465746
#% 465895
#% 465919
#% 466572
#% 682681
#% 1271840
#% 1499573
#! Text categorization or classification is the automated assigning of text documents to pre-defined classes based on their contents. This problem has been studied in information retrieval, machine learning and data mining. So far, many effective techniques have been proposed. However, most techniques are based on some underlying models and/or assumptions. When the data fits the model well, the classification accuracy will be high. However, when the data does not fit the model well, the classification accuracy can be very low. In this paper, we propose a refinement approach to dealing with this problem of model misfit. We show that we do not need to change the classification technique itself (or its underlying model) to make it more flexible. Instead, we propose to use successive refinements of classification on the training data to correct the model misfit. We apply the proposed technique to improve the classification performance of two simple and efficient text classifiers, the Rocchio classifier and the naïve Bayesian classifier. These techniques are suitable for very large text collections because they allow the data to reside on disk and need only one scan of the data to build a text classifier. Extensive experiments on two benchmark document corpora show that the proposed technique is able to improve text categorization accuracy of the two techniques dramatically. In particular, our refined model is able to improve the naïve Bayesian or Rocchio classifier's prediction performance by 45% on average.

#index 577326
#* Mining topic-specific concepts and definitions on the web
#@ 2438 8338 715
#t 2003
#c WWW '03 Proceedings of the 12th international conference on World Wide Web
#% 209690
#% 244103
#% 248791
#% 255177
#% 268068
#% 268073
#% 268079
#% 281209
#% 281218
#% 281252
#% 282905
#% 303113
#% 310518
#% 330616
#% 340295
#% 348191
#% 406493
#% 479969
#% 481290
#% 495937
#! Traditionally, when one wants to learn about a particular topic, one reads a book or a survey paper. With the rapid expansion of the Web, learning in-depth knowledge about a topic from the Web is becoming increasingly important and popular. This is also due to the Web's convenience and its richness of information. In many cases, learning from the Web may even be essential because in our fast changing world, emerging topics appear constantly and rapidly. There is often not enough time for someone to write a book on such topics. To learn such emerging topics, one can resort to research papers. However, research papers are often hard to understand by non-researchers, and few research papers cover every aspect of the topic. In contrast, many Web pages often contain intuitive descriptions of the topic. To find such Web pages, one typically uses a search engine. However, current search techniques are not designed for in-depth learning. Top ranking pages from a search engine may not contain any description of the topic. Even if they do, the description is usually incomplete since it is unlikely that the owner of the page has good knowledge of every aspect of the topic. In this paper, we attempt a novel and challenging task, mining topic-specific knowledge on the Web. Our goal is to help people learn in-depth knowledge of a topic systematically on the Web. The proposed techniques first identify those sub-topics or salient concepts of the topic, and then find and organize those informative pages, containing definitions and descriptions of the topic and sub-topics, just like those in a book. Experimental results using 28 topics show that the proposed techniques are highly effective.

#index 629655
#* Speed-up Iterative Frequent Itemset Mining with Constraint Changes
#@ 9362 2438
#t 2002
#c ICDM '02 Proceedings of the 2002 IEEE International Conference on Data Mining
#! Mining of frequent itemsets is a fundamental datamining task. Past research has proposed many efficientalgorithms for the purpose. Recent work also highlightedthe importance of using constraints to focus the miningprocess to mine only those relevant itemsets. In practice,data mining is often an interactive and iterative process.The user typically changes constraints and runs the miningalgorithm many times before satisfied with the finalresults. This interactive process is very time consuming.Existing mining algorithms are unable to take advantageof this iterative process to use previous mining results tospeed up the current mining process. This results inenormous waste in time and in computation. In this paper,we propose an efficient technique to utilize previousmining results to improve the efficiency of current miningwhen constraints are changed. We first introduce theconcept of tree boundary to summarize the usefulinformation available from previous mining. We then showthat the tree boundary provides an effective and efficientframework for the new mining. The proposed techniquehas been implemented in the contexts of two existingfrequent itemset mining algorithms, FP-tree and TreeProjection. Experiment results on both synthetic and real-lifedatasets show that the proposed approach achievesdramatic saving in computation.

#index 727807
#* Detecting Patterns of Change Using Enhanced Parallel Coordinates Visualization
#@ 9919 2438 9920 9921
#t 2003
#c ICDM '03 Proceedings of the Third IEEE International Conference on Data Mining
#% 25351
#% 65341
#% 136350
#% 286721
#% 436116
#% 481290
#% 481611
#% 727807
#! Analyzing data to find trends, correlations, and stablepatterns is an important problem for many industrialapplications. In this paper, we propose a new techniquebased on parallel coordinates visualization. Previous workon parallel coordinates methods has shown that they areeffective only when variables that are correlated and/orshow similar patterns are displayed adjacently. Althoughcurrent parallel coordinates tools allow the user tomanually rearrange the order of variables, this process isvery time-consuming when the number of variables islarge. Automated assistance is needed. This paperproposes an edit-distance based technique to rearrangevariables so that interesting patterns can be easilydetected. Our system, V-Miner, includes both automatedmethods for visualizing common patterns and a query toolthat enables the user to describe specific target patterns tobe mined/displayed by the system. Following an overviewof the system, a case study is presented to explain howMotorola engineers have used V-Miner to identifysignificant patterns in their product test and design data.

#index 727883
#* Building Text Classifiers Using Positive and Unlabeled Examples
#@ 2438 6051 5659 5658 850
#t 2003
#c ICDM '03 Proceedings of the Third IEEE International Conference on Data Mining
#% 169717
#% 169806
#% 190581
#% 252011
#% 269217
#% 280817
#% 304876
#% 311027
#% 406493
#% 458379
#% 458758
#% 464466
#% 464604
#% 464631
#% 464641
#% 464777
#% 464780
#% 466229
#% 466888
#% 476553
#% 564957
#% 577235
#% 669214
#% 722811
#% 891711
#% 1279298
#! This paper studies the problem of building text classifiersusing positive and unlabeled examples. The key feature ofthis problem is that there is no negative example forlearning. Recently, a few techniques for solving thisproblem were proposed in the literature. These techniquesare based on the same idea, which builds a classifier intwo steps. Each existing technique uses a different methodfor each step. In this paper, we first introduce some newmethods for the two steps, and perform a comprehensiveevaluation of all possible combinations of methods of thetwo steps. We then propose a more principled approachto solving the problem based on a biased formulation ofSVM, and show experimentally that it is more accuratethan the existing techniques.

#index 729939
#* Eliminating noisy information in Web pages for data mining
#@ 10139 2438 5659
#t 2003
#c Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 169717
#% 255137
#% 271060
#% 278106
#% 282905
#% 310546
#% 348180
#% 413617
#% 438676
#% 451536
#% 465754
#% 577281
#% 746910
#! A commercial Web page typically contains many information blocks. Apart from the main content blocks, it usually has such blocks as navigation panels, copyright and privacy notices, and advertisements (for business purposes and for easy user access). We call these blocks that are not the main content blocks of the page the noisy blocks. We show that the information contained in these noisy blocks can seriously harm Web data mining. Eliminating these noises is thus of great importance. In this paper, we propose a noise elimination technique based on the following observation: In a given Web site, noisy blocks usually share some common contents and presentation styles, while the main content blocks of the pages are often diverse in their actual contents and/or presentation styles. Based on this observation, we propose a tree structure, called Style Tree, to capture the common presentation styles and the actual contents of the pages in a given Web site. By sampling the pages of the site, a Style Tree can be built for the site, which we call the Site Style Tree (SST). We then introduce an information based measure to determine which parts of the SST represent noises and which parts represent the main contents of the site. The SST is employed to detect and eliminate noises in any Web page of the site by mapping this page to the SST. The proposed technique is evaluated with two data mining tasks, Web page clustering and classification. Experimental results show that our noise elimination technique is able to improve the mining results significantly.

#index 729978
#* Mining data records in Web pages
#@ 2438 3675 10204
#t 2003
#c Proceedings of the ninth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 65341
#% 235941
#% 240955
#% 271065
#% 273925
#% 275915
#% 312860
#% 330784
#% 348146
#! A large amount of information on the Web is contained in regularly structured objects, which we call data records. Such data records are important because they often present the essential information of their host pages, e.g., lists of products or services. It is useful to mine such data records in order to extract information from them to provide value-added services. Existing automatic techniques are not satisfactory because of their poor accuracies. In this paper, we propose a more effective technique to perform the task. The technique is based on two observations about data records on the Web and a string matching algorithm. The proposed technique is able to mine both contiguous and non-contiguous data records. Our experimental results show that the proposed technique outperforms existing techniques substantially.

#index 766197
#* Proceedings of the 9th ACM SIGMOD workshop on Research issues in data mining and knowledge discovery
#@ 3660 2438 850
#t 2004
#c 9th ACM SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery 2004 (co-located with SIGMOD/PODS 2004 Conference)
#! This volume contains all the papers presented in the SIGMOD Workshop on Research Issues in Data Mining and Knowledge Discovery (DMKD), June 13, 2004, Maison de la Chimie, Paris, France. This was the 9th workshop on DMKD held annually in conjunction with ACM SIGMOD conference. The workshop was sponsored by ACM SIGMOD with corporate support from Microsoft Research. With the help of program committee, we selected 7 full papers and 4 short papers out of 34 submissions. The theme of this year's workshop was on data mining and information integration.

#index 769892
#* Mining and summarizing customer reviews
#@ 3558 2438
#t 2004
#c Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 71752
#% 78171
#% 118040
#% 180254
#% 194251
#% 211514
#% 279755
#% 280835
#% 457935
#% 481290
#% 529193
#% 577246
#% 577355
#% 741940
#% 746867
#% 746885
#% 755835
#% 756232
#% 786506
#% 786539
#% 815915
#% 854646
#% 1250237
#% 1478826
#! Merchants selling products on the Web often ask their customers to review the products that they have purchased and the associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds or even thousands. This makes it difficult for a potential customer to read them to make an informed decision on whether to purchase the product. It also makes it difficult for the manufacturer of the product to keep track and to manage customer opinions. For the manufacturer, there are additional difficulties because many merchant sites may sell the same product and the manufacturer normally produces many kinds of products. In this research, we aim to mine and to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we only mine the features of the product on which the customers have expressed their opinions and whether the opinions are positive or negative. We do not summarize the reviews by selecting a subset or rewrite some of the original sentences from the reviews to capture the main points as in the classic text summarization. Our task is performed in three steps: (1) mining product features that have been commented on by customers; (2) identifying opinion sentences in each review and deciding whether each opinion sentence is positive or negative; (3) summarizing the results. This paper proposes several novel techniques to perform these tasks. Our experimental results using reviews of a number of products sold online demonstrate the effectiveness of the techniques.

#index 769926
#* V-Miner: using enhanced parallel coordinates to mine product design and test data
#@ 9919 2438 9920 9921
#t 2004
#c Proceedings of the tenth ACM SIGKDD international conference on Knowledge discovery and data mining
#% 25351
#% 65341
#% 136350
#% 286721
#% 436116
#% 481290
#% 481611
#% 529288
#! Analyzing data to find trends, correlations, and stable patterns is an important task in many industrial applications. This paper proposes a new technique based on parallel coordinate visualization. Previous work on parallel coordinate methods has shown that they are effective only when variables that are correlated and/or show similar patterns are displayed adjacently. Although current parallel coordinate tools allow the user to manually rearrange the order of variables, this process is very time-consuming when the number of variables is large. Automated assistance is required. This paper introduces an edit-distance based technique to rearrange variables so that interesting change patterns can be easily detected visually. The Visual Miner (V-Miner) software includes both automated methods for visualizing common patterns and a query tool that enables the user to describe specific target patterns to be mined or displayed by the system. In addition, the system can filter data according to rules sets imported from other data mining tools. This feature was found very helpful in practice, because it enables decision makers to visually identify interesting rules and data segments for further analysis or data mining. This paper begins with an introduction to the proposed techniques and the V-Miner system. Next, a case study illustrates how V-Miner has been used at Motorola to guide product design and test decisions.

#index 794508
#* Editorial: special issue on web content mining
#@ 2438 11916
#t 2004
#c ACM SIGKDD Explorations Newsletter
#% 271065
#% 273925
#% 281186
#% 312860
#% 330767
#% 330784
#% 342605
#% 348146
#% 348163
#% 348180
#% 348187
#% 348190
#% 413617
#% 451536
#% 464434
#% 480824
#% 531459
#% 577246
#% 577301
#% 577326
#% 577355
#% 577356
#% 643004
#% 654459
#% 654469
#% 723243
#% 729939
#% 729978
#% 754068
#% 754078
#% 754091
#% 754102
#% 754104
#% 754108
#% 754124
#% 765409
#% 765410
#% 765411
#% 766433
#% 769884
#% 769890
#% 769892
#% 783483
#% 783791
#% 815915
#% 854646
#% 855119
#% 1015284
#% 1250238
#% 1279218
#! With the phenomenal growth of the Web, there is an everincreasing volume of data and information published in numerous Web pages. The research in Web mining aims to develop new techniques to effectively extract and mine useful knowledge or information from these Web pages [8]. Due to the heterogeneity and lack of structure of Web data, automated discovery of targeted or unexpected knowledge/information is a challenging task. It calls for novel methods that draw from a wide range of fields spanning data mining, machine learning, natural language processing, statistics, databases, and information retrieval. In the past few years, there was a rapid expansion of activities in the Web mining field, which consists of Web usage mining, Web structure mining, and Web content mining. Web usage mining refers to the discovery of user access patterns from Web usage logs. Web structure mining tries to discover useful knowledge from the structure of hyperlinks. Web content mining aims to extract/mine useful information or knowledge from Web page contents. For this special issue, we focus on Web content mining.

#index 794533
#* WebKDD 2004: web mining and web usage analysis post-workshop report
#@ 10102 9400 2449 2438
#t 2004
#c ACM SIGKDD Explorations Newsletter
#% 575990
#% 631002
#% 1674708
#% 1674709
#% 1674712
#% 1674713
#% 1674714
#! In this report, we summarize the contents and outcomes of the recent WebKDD 2004 workshop that was held in conjunction with the 10th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD 2004), August 22-25, 2004, in Seattle, Washington. We also reflect on the trend in participation levels in the WebKDD series of workshops over the last six years, and indicate new directions in Web mining research as reflected in the latest workshop.

#index 805846
#* Web data extraction based on partial tree alignment
#@ 10204 2438
#t 2005
#c WWW '05 Proceedings of the 14th international conference on World Wide Web
#% 46465
#% 65341
#% 103525
#% 121462
#% 235941
#% 240955
#% 256623
#% 271065
#% 273925
#% 275915
#% 289193
#% 312860
#% 330784
#% 348146
#% 348147
#% 348180
#% 349489
#% 413572
#% 451536
#% 480824
#% 577319
#% 643004
#% 654469
#% 729978
#% 754078
#% 754102
#% 754108
#% 755816
#% 765411
#! This paper studies the problem of extracting data from a Web page that contains several structured data records. The objective is to segment these data records, extract data items/fields from them and put the data in a database table. This problem has been studied by several researchers. However, existing methods still have some serious limitations. The first class of methods is based on machine learning, which requires human labeling of many examples from each Web site that one is interested in extracting data from. The process is time consuming due to the large number of sites and pages on the Web. The second class of algorithms is based on automatic pattern discovery. These methods are either inaccurate or make many assumptions. This paper proposes a new method to perform the task automatically. It consists of two steps, (1) identifying individual data records in a page, and (2) aligning and extracting data items from the identified data records. For step 1, we propose a method based on visual information to segment data records, which is more accurate than existing methods. For step 2, we propose a novel partial alignment technique based on tree matching. Partial alignment means that we align only those data fields in a pair of data records that can be aligned (or matched) with certainty, and make no commitment on the rest of the data fields. This approach enables very accurate alignment of multiple data records. Experimental results using a large number of Web pages from diverse domains show that the proposed two-step technique is able to segment data records, align and extract data from them very accurately.

#index 805873
#* Opinion observer: analyzing and comparing opinions on the Web
#@ 2438 3558 12407
#t 2005
#c WWW '05 Proceedings of the 14th international conference on World Wide Web
#% 118040
#% 271065
#% 330764
#% 464434
#% 481290
#% 531459
#% 577246
#% 577355
#% 577356
#% 723399
#% 729978
#% 752092
#% 754068
#% 755835
#% 769892
#% 786539
#% 805846
#% 815915
#% 854646
#% 855279
#% 855282
#% 938707
#% 938708
#% 1250238
#! The Web has become an excellent source for gathering consumer opinions. There are now numerous Web sites containing such opinions, e.g., customer reviews of products, forums, discussion groups, and blogs. This paper focuses on online customer reviews of products. It makes two contributions. First, it proposes a novel framework for analyzing and comparing consumer opinions of competing products. A prototype system called Opinion Observer is also implemented. The system is such that with a single glance of its visualization, the user is able to clearly see the strengths and weaknesses of each product in the minds of consumers in terms of various product features. This comparison is useful to both potential customers and product manufacturers. For a potential customer, he/she can see a visual side-by-side and feature-by-feature comparison of consumer opinions on these products, which helps him/her to decide which product to buy. For a product manufacturer, the comparison enables it to easily gather marketing intelligence and product benchmarking information. Second, a new technique based on language pattern mining is proposed to extract product features from Pros and Cons in a particular type of reviews. Such features form the basis for the above comparison. Experimental results show that the technique is highly effective and outperform existing methods significantly.

#index 844348
#* A Visual Data Mining Framework for Convenient Identification of Useful Knowledge
#@ 9919 2438 9920 14796
#t 2005
#c ICDM '05 Proceedings of the Fifth IEEE International Conference on Data Mining
#% 136350
#% 280487
#% 310525
#% 310531
#% 342631
#% 434613
#% 443092
#% 481290
#% 577216
#% 641130
#% 769926
#% 838395
#! Data mining algorithms usually generate a large number of rules, which may not always be useful to human users. In this project, we propose a novel visual data-mining framework, called Opportunity Map, to identify useful and actionable knowledge quickly and easily from the discovered rules. The framework is inspired by the House of Quality from Quality Function Deployment (QFD) in Quality Engineering. It associates discovered rules, related summarized data and data distributions with the application objective using an interactive matrix. Combined with drill down visualization, integrated visualization of data distribution bars and rules, visualization of trend behaviors, and comparative analysis, the Opportunity Map allows users to analyze rules and data at different levels of detail and quickly identify the actionable knowledge and opportunities. The proposed framework represents a systematic and flexible approach to rule analysis. Applications of the system to large-scale data sets from our industrial partner have yielded promising results.

#index 879595
#* Identifying comparative sentences in text documents
#@ 15955 2438
#t 2006
#c SIGIR '06 Proceedings of the 29th annual international ACM SIGIR conference on Research and development in information retrieval
#% 118040
#% 190581
#% 269217
#% 280487
#% 376266
#% 577256
#% 577355
#% 723399
#% 742368
#% 755835
#% 756207
#% 769892
#% 769967
#% 778732
#% 786539
#% 805873
#% 815915
#% 828958
#% 854646
#% 855279
#% 855282
#% 936239
#% 1250238
#% 1250367
#! This paper studies the problem of identifying comparative sentences in text documents. The problem is related to but quite different from sentiment/opinion sentence identification or classification. Sentiment classification studies the problem of classifying a document or a sentence based on the subjective opinion of the author. An important application area of sentiment/opinion identification is business intelligence as a product manufacturer always wants to know consumers' opinions on its products. Comparisons on the other hand can be subjective or objective. Furthermore, a comparison is not concerned with an object in isolation. Instead, it compares the object with others. An example opinion sentence is "the sound quality of CD player X is poor". An example comparative sentence is "the sound quality of CD player X is not as good as that of CD player Y". Clearly, these two sentences give different information. Their language constructs are quite different too. Identifying comparative sentences is also useful in practice because direct comparisons are perhaps one of the most convincing ways of evaluation, which may even be more important than opinions on each individual object. This paper proposes to study the comparative sentence identification problem. It first categorizes comparative sentences into different types, and then presents a novel integrated pattern discovery and supervised learning approach to identifying comparative sentences from text documents. Experiment results using three types of documents, news articles, consumer reviews of products, and Internet forum postings, show a precision of 79% and recall of 81%. More detailed results are given in the paper.

#index 881485
#* Rule interestingness analysis using OLAP operations
#@ 2438 9919 16091 14796
#t 2006
#c Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining
#% 136350
#% 172386
#% 190581
#% 280436
#% 280487
#% 310525
#% 310531
#% 316709
#% 389169
#% 417589
#% 420101
#% 434613
#% 443092
#% 443313
#% 481290
#% 481954
#% 501204
#% 577216
#% 577252
#% 729934
#% 769893
#% 769926
#% 844348
#! The problem of interestingness of discovered rules has been investigated by many researchers. The issue is that data mining algorithms often generate too many rules, which make it very hard for the user to find the interesting ones. Over the years many techniques have been proposed. However, few have made it to real-life applications. Since August 2004, we have been working on a major application for Motorola. The objective is to find causes of cellular phone call failures from a large amount of usage log data. Class association rules have been shown to be suitable for this type of diagnostic data mining application. We were also able to put several existing interestingness methods to the test, which revealed some major shortcomings. One of the main problems is that most existing methods treat rules individually. However, we discovered that users seldom regard a single rule to be interesting by itself. A rule is only interesting in the context of some other rules. Furthermore, in many cases, each individual rule may not be interesting, but a group of them together can represent an important piece of knowledge. This led us to discover a deficiency of the current rule mining paradigm. Using non-zero minimum support and non-zero minimum confidence eliminates a large amount of context information, which makes rule analysis difficult. This paper proposes a novel approach to deal with all of these issues, which casts rule analysis as OLAP operations and general impression mining. This approach enables the user to explore the knowledge space to find useful knowledge easily and systematically. It also provides a natural framework for visualization. As an evidence of its effectiveness, our system, called Opportunity Map, based on these ideas has been deployed, and it is in daily use in Motorola for finding actionable knowledge from its engineering and other types of data sets.

#index 881569
#* Opportunity map: identifying causes of failure - a deployed data mining system
#@ 9919 2438 16091 14796
#t 2006
#c Proceedings of the 12th ACM SIGKDD international conference on Knowledge discovery and data mining
#% 136350
#% 172386
#% 190581
#% 252367
#% 280436
#% 280487
#% 389169
#% 417589
#% 420101
#% 443313
#% 481290
#% 481954
#% 501204
#% 577214
#% 577216
#% 577252
#% 729934
#% 769893
#% 769926
#% 844348
#! In this paper, we report a deployed data mining application system for Motorola. Originally, its intended use was for identifying causes of cellular phone failures, but it has been found to be useful for many other engineering data sets as well. For this report, the case study is a dataset containing cellular phone call records. This data set is like any dataset used in classification applications, i.e., with a set of attributes which can be continuous or discrete, and a discrete class attribute. In our application, the classes are normally ended calls, calls which failed to setup, and calls which failed while in progress. However, the task is not to predict any failure, but to identify possible causes that resulted in failures. Then, engineering efforts may focus on improvements that can be made to the phones. In the course of the project, various classification techniques, e.g., decision trees, naïve Bayesian classification and SVM were tried. However, the results were unsatisfactory. After several demonstrations and interaction with domain experts, we finally designed and implemented an effective approach to perform the task. The final system is based on class association rules, general impressions and visualization. The system has been deployed and is in regular use at Motorola. In this paper, we first describe our experiences with some existing classification systems and discuss why they are not suitable for the task. We then present our techniques. As an illustration, we show several visualization screens in the case study, which reveal some important knowledge. Due to confidentiality, we will not give specifics but only present a general discussion about the results.

#index 907596
#* Measuring the meaning in time series clustering of text search queries
#@ 2438 2922 17504
#t 2006
#c CIKM '06 Proceedings of the 15th ACM international conference on Information and knowledge management
#% 805839
#% 869501
#! We use a combination of proven methods from time series analysis and machine learning to explore the relationship between temporal and semantic similarity in web query logs; we discover that the combination of correlation and cycles is a good, but not perfect, sign of semantic relationship.

#index 915363
#* Mining Latent Associations of Objects Using a Typed Mixture Model--A Case Study on Expert/Expertise Mining
#@ 17579 12517 2438 7717 4267
#t 2006
#c ICDM '06 Proceedings of the Sixth International Conference on Data Mining
#! This paper studies the problem of discovering latent associations among objects in text documents. Specifically, given two sets of objects and various types of co-occurrence data concerning the objects existing in texts, we aim to discover the hidden or latent associative relationships between the two sets of objects. Existing methods are not directly applicable as they are unable to consider all this information. For example, the probabilistic mixture model called Separable Mixture Model (SMM) proposed by Hofmann can use only one type of co-occurrences to mine latent associations. This paper proposes a more general probabilistic mixture model called the Typed Separable Mixture Model (TSMM), which is able to use all types of co-occurrences within a single framework. Experimental results based on the expert/expertise mining task show that TSMM outperforms SMM significantly.

#index 924883
#* Advances in Web Mining and Web Usage Analysis: 6th International Workshop on Knowledge Discovery on the Web, WEBKDD 2004Seattle, WA, USA, August 22-25, ... Papers (Lecture Notes in Computer Science)
#@ 9400 10102 2438 2449
#t 2006
#c Advances in Web Mining and Web Usage Analysis: 6th International Workshop on Knowledge Discovery on the Web, WEBKDD 2004Seattle, WA, USA, August 22-25, ... Papers (Lecture Notes in Computer Science)

#index 987308
#* Semantic text classification of disease reporting
#@ 2429 2438
#t 2007
#c SIGIR '07 Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval
#% 269217
#% 280817
#% 741891
#% 854933
#! Traditional text classification studied in the IR literature is mainly based on topics. That is, each class or category represents a particular topic, e.g., sports, politics or sciences. However, many real-world text classification problems require more refined classification based on some semantic aspects. For example, in a set of documents about a particular disease, some documents may report the outbreak of the disease, some may describe how to cure the disease, some may discuss how to prevent the disease, and yet some others may include all the above information. To classify text at this semantic level, the traditional "bag of words" model is no longer sufficient. In this paper, we report a text classification study at the semantic level and show that sentence semantic and structure features are very useful for such kind of classification. Our experimental results based on a disease outbreak dataset demonstrated the effectiveness of the proposed approach.

#index 987340
#* The utility of linguistic rules in opinion mining
#@ 18515 2438
#t 2007
#c SIGIR '07 Proceedings of the 30th annual international ACM SIGIR conference on Research and development in information retrieval
#% 746885
#% 769892
#% 936239
#% 939896
#% 1261566
#! Online product reviews are one of the important opinion sources on the Web. This paper studies the problem of determining the semantic orientations (positive or negative) of opinions expressed on product features in reviews. Most existing approaches use a set of opinion words for the purpose. However, the semantic orientations of many words are context dependent. In this paper, we propose to use some linguistic rules to deal with the problem together with a new opinion aggregation function. Extensive experiments show that these rules and the function are highly effective. A system, called Opinion Observer, has also been built.

#index 1023794
#* KDD Cup and Workshop 2007
#@ 2438 19271 3731 2426 14937
#t 2007
#c Proceedings of the 13th ACM SIGKDD international conference on Knowledge discovery and data mining

#index 1035590
#* Opinion spam and analysis
#@ 15955 2438
#t 2008
#c WSDM '08 Proceedings of the 2008 International Conference on Web Search and Data Mining
#% 451536
#% 577355
#% 616528
#% 679843
#% 769892
#% 807297
#% 815915
#% 818223
#% 854646
#% 869469
#% 869471
#% 879600
#% 907490
#% 912202
#% 936239
#% 939896
#% 956518
#% 956523
#% 956559
#% 963698
#% 1117058
#% 1250376
#% 1663483
#! Evaluative texts on the Web have become a valuable source of opinions on products, services, events, individuals, etc. Recently, many researchers have studied such opinion sources as product reviews, forum posts, and blogs. However, existing research has been focused on classification and summarization of opinions using natural language processing and data mining techniques. An important issue that has been neglected so far is opinion spam or trustworthiness of online opinions. In this paper, we study this issue in the context of product reviews, which are opinion rich and are widely used by consumers and product manufacturers. In the past two years, several startup companies also appeared which aggregate opinions from product reviews. It is thus high time to study spam in reviews. To the best of our knowledge, there is still no published study on this topic, although Web spam and email spam have been investigated extensively. We will see that opinion spam is quite different from Web spam and email spam, and thus requires different detection techniques. Based on the analysis of 5.8 million reviews and 2.14 million reviewers from amazon.com, we show that opinion spam in reviews is widespread. This paper analyzes such spam activities and presents some novel techniques to detect them

#index 1035591
#* A holistic lexicon-based approach to opinion mining
#@ 18515 2438 850
#t 2008
#c WSDM '08 Proceedings of the 2008 International Conference on Web Search and Data Mining
#% 118040
#% 577246
#% 577355
#% 723399
#% 746885
#% 755835
#% 769892
#% 805873
#% 815915
#% 848644
#% 854646
#% 855279
#% 855282
#% 907489
#% 939346
#% 939634
#% 939848
#% 939896
#% 983579
#% 983583
#% 983599
#% 987340
#% 1250238
#% 1250367
#% 1261566
#% 1299640
#% 1700552
#% 1708349
#! One of the important types of information on the Web is the opinions expressed in the user generated content, e.g., customer reviews of products, forum posts, and blogs. In this paper, we focus on customer reviews of products. In particular, we study the problem of determining the semantic orientations (positive, negative or neutral) of opinions expressed on product features in reviews. This problem has many applications, e.g., opinion mining, summarization and search. Most existing techniques utilize a list of opinion (bearing) words (also called opinion lexicon) for the purpose. Opinion words are words that express desirable (e.g., great, amazing, etc.) or undesirable (e.g., bad, poor, etc) states. These approaches, however, all have some major shortcomings. In this paper, we propose a holistic lexicon-based approach to solving the problem by exploiting external evidences and linguistic conventions of natural language expressions. This approach allows the system to handle opinion words that are context dependent, which cause major difficulties for existing algorithms. It also deals with many special words, phrases and language constructs which have impacts on opinions based on their linguistic patterns. It also has an effective function for aggregating multiple conflicting opinion words in a sentence. A system, called Opinion Observer, based on the proposed technique has been implemented. Experimental results using a benchmark product review data set and some additional reviews show that the proposed technique is highly effective. It outperforms existing methods significantly

#index 1038328
#* KDD Cup and workshop 2007
#@ 19271 3731 2438 2426 14937
#t 2007
#c ACM SIGKDD Explorations Newsletter - Special issue on visual analytics
#% 983865
#% 983903
#! The KDD Cup is the oldest of the many data mining competitions that are now popular [1]. It is an integral part of the annual ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD). In 2007, the traditional KDD Cup competition was augmented with a workshop with a focus on the concurrently active Netflix Prize competition [2]. The KDD Cup itself in 2007 consisted of a prediction competition using Netflix movie rating data, with tasks that were different and separate from those being used in the Netflix Prize itself. At the workshop, participants in both the KDD Cup and the Netflix Prize competition presented their results and analyses, and exchanged ideas.

#index 1083618
#* Proceedings of the 14th ACM SIGKDD international conference on Knowledge discovery and data mining
#@ 4269 2438 1049
#t 2008
#c The 14th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining
#! We welcome you to the Fourteenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining (KDD'08) being held in Las Vegas, Nevada, USA, on August 24 - 27, 2008. We are pleased to present the proceedings of the conference as its published record. As the flagship conference in the field, KDD provides a highly competitive forum for reporting the latest and the best developments in the research and application of data mining and knowledge discovery worldwide. KDD'08 received a record number of 693 total submissions. The Research Track received 510 submissions from 30 different countries and the Industrial Track received 83 submissions from 10 different countries. For the Research Track, the program committee accepted 95 papers, of which, 50 (9.8% of the total) were chosen for a 25 minute oral presentation and 45 (8.8% of the total) were chosen for a 15 minute oral presentation. The corresponding numbers for the Industrial Track were 13 (15.7% of the total) and 10 (12.0% of the total) respectively. All accepted papers are given a presentation length of up to 9 pages in the proceedings, and all accepted papers are also given poster presentation opportunities in one of the two evening poster sessions during the conference. Apart from the paper presentations, the conference also features seven tutorials, thirteen workshops, one panel, the KDD-Cup competition, a demo session, and three invited talks by Trevor Hastie (Stanford University), Jitendra Malik (UC Berkeley) and Michael Schwarz (Yahoo! Research). The Industrial Track includes two additional invited presentations by Thore Graepel (Microsoft Research Cambridge, U.K.) and Udo Miletzki (Siemens, Germany).

#index 1100060
#* Learning to Classify Documents with Only a Small Positive Training Set
#@ 20883 2438 16082
#t 2007
#c ECML '07 Proceedings of the 18th European conference on Machine Learning
#% 197922
#% 311027
#% 406493
#% 464641
#% 550254
#% 564957
#% 577235
#% 727829
#% 729939
#% 843873
#% 855602
#% 1279298
#! Many real-world classification applications fall into the class of positive and unlabeled (PU) learning problems. In many such applications, not only could the negative training examples be missing, the number of positive examples available for learning may also be fairly limited due to the impracticality of hand-labeling a large number of training examples. Current PU learning techniques have focused mostly on identifying reliable negative instances from the unlabeled set U. In this paper, we address the oft-overlooked PU learning problem when the number of training examples in the positive set Pis small. We propose a novel technique LPLP (Learning from Probabilistically Labeled Positive examples) and apply the approach to classify product pages from commercial websites. The experimental results demonstrate that our approach outperforms existing methods significantly, even in the challenging cases where the positive examples in Pand the hidden positive examples in Uwere not drawn from the same distribution.

#index 1100189
#* Semantic Text Classification of Emergent Disease Reports
#@ 2429 2438
#t 2007
#c PKDD 2007 Proceedings of the 11th European conference on Principles and Practice of Knowledge Discovery in Databases
#% 280817
#% 344447
#% 741891
#% 743629
#% 939568
#% 939718
#! Traditional text classification studied in the information retrieval and machine learning literature is mainly based on topics. That is, each class represents a particular topic, e.g., sports and politics. However, many real-world problems require more refined classification based on some semantic perspectives. For example, in a set of sentences about a disease, some may report outbreaks of the disease, some may describe how to cure the disease, and yet some may discuss how to prevent the disease. To classify sentences at this semantic level, the traditional bag-of-words model is no longer sufficient. In this paper, we study semantic sentence classification of disease reporting. We show that both keywords and sentence semantic features are useful. Our results demonstrated that this integrated approach is highly effective.

#index 1117058
#* Analyzing and Detecting Review Spam
#@ 15955 2438
#t 2007
#c ICDM '07 Proceedings of the 2007 Seventh IEEE International Conference on Data Mining
#! Mining of opinions from product reviews, forum posts and blogs is an important research topic with many applications. However, existing research has been focused on extraction, classification and summarization of opinions from these sources. An important issue that has not been studied so far is the opinion spam or the trustworthiness of online opinions. In this paper, we study this issue in the context of product reviews. To our knowledge, there is still no published study on this topic, although Web page spam and email spam have been investigated extensively. We will see that review spam is quite different from Web page spam and email spam, and thus requires different detection techniques. Based on the analysis of 5.8 million reviews and 2.14 million reviewers from amazon.com, we show that review spam is widespread. In this paper, we first present a categorization of spam reviews and then propose several techniques to detect them.

#index 1176882
#* Time Sensitive Ranking with Application to Publication Search
#@ 12098 2438 15637
#t 2008
#c ICDM '08 Proceedings of the 2008 Eighth IEEE International Conference on Data Mining
#! Link-based ranking has contributed significantly to the success of Web search. PageRank and HITS are the best known link-based ranking algorithms. These algorithms do not consider an important dimension, the temporal dimension. They favor older pages because these pages have many in-links accumulated over time. Bringing new and quality pages to the users is important because most users want the latest information. Existing remedies to PageRank are mostly heuristic approaches. This paper investigates the temporal aspect of ranking with application to publication search, and proposes a principled method based on the stationary probability distribution of the Markov Chain. The proposed techniques are evaluated empirically using a large collection of high energy particle physics publication. The results show that the proposed methods are highly effective.

#index 1206822
#* Finding Actionable Knowledge via Automated Comparison
#@ 11538 2438 16091 17738
#t 2009
#c ICDE '09 Proceedings of the 2009 IEEE International Conference on Data Engineering
#! The problem of finding interesting and actionable patterns is a major challenge in data mining. It has been studied by many data mining researchers. The issue is that data mining algorithms often generate too many patterns, which make it very hard for the user to find those truly useful ones. Over the years many techniques have been proposed. However, few have made it to real-life applications. At the end of 2005, we built a data mining system for Motorola (called Opportunity Map) to enable the user to explore the space of a large number of rules in order to find actionable knowledge. The approach is based on the concept of rule cubes and operations on rule cubes. A rule cube is similar to a data cube, but stores rules. Since its deployment, some issues have also been identified during the regular use of the system in Motorola. One of the key issues is that although the operations on rule cubes are flexible, each operation is primitive and has to be initiated by the user. Finding a piece of actionable knowledge typically involves many operations and intense visual inspections, which are labor-intensive and time-consuming. From interactions with our users, we identified a generic problem that is crucial for finding actionable knowledge. The problem involves extensive comparison of sub-populations and identification of the cause of their differences. This paper first defines the problem and then proposes an effective method to solve the problem automatically. To the best of our knowledge, there is no reported study of this problem. The new method has been added to the Opportunity Map system and is now in daily use in Motorola.

#index 1214734
#* Entity discovery and assignment for opinion mining applications
#@ 18515 2438 11538
#t 2009
#c Proceedings of the 15th ACM SIGKDD international conference on Knowledge discovery and data mining
#% 464434
#% 577355
#% 746885
#% 769892
#% 815915
#% 818916
#% 854646
#% 855279
#% 939352
#% 939848
#% 939896
#% 940000
#% 956510
#% 1035591
#% 1117045
#% 1250367
#% 1251616
#% 1261526
#% 1261566
#! Opinion mining became an important topic of study in recent years due to its wide range of applications. There are also many companies offering opinion mining services. One problem that has not been studied so far is the assignment of entities that have been talked about in each sentence. Let us use forum discussions about products as an example to make the problem concrete. In a typical discussion post, the author may give opinions on multiple products and also compare them. The issue is how to detect what products have been talked about in each sentence. If the sentence contains the product names, they need to be identified. We call this problem entity discovery. If the product names are not explicitly mentioned in the sentence but are implied due to the use of pronouns and language conventions, we need to infer the products. We call this problem entity assignment. These problems are important because without knowing what products each sentence talks about the opinion mined from the sentence is of little use. In this paper, we study these problems and propose two effective methods to solve the problems. Entity discovery is based on pattern discovery and entity assignment is based on mining of comparative sentences. Experimental results using a large number of forum posts demonstrate the effectiveness of the technique. Our system has also been successfully tested in a commercial setting.

#index 1250186
#* Text classification by labeling words
#@ 2438 5659 5658 850
#t 2004
#c AAAI'04 Proceedings of the 19th national conference on Artifical intelligence
#% 36672
#% 169717
#% 190581
#% 252011
#% 311027
#% 406493
#% 458379
#% 464291
#% 464604
#% 464631
#% 464641
#% 464777
#% 465754
#% 466888
#% 565531
#% 577235
#! Traditionally, text classifiers are built from labeled training examples. Labeling is usually done manually by human experts (or the users), which is a labor intensive and time consuming process. In the past few years, researchers investigated various forms of semi-supervised learning to reduce the burden of manual labeling. In this paper, we propose a different approach. Instead of labeling a set of documents, the proposed method labels a set of representative words for each class. It then uses these words to extract a set of documents for each class from a set of unlabeled documents to form the initial training set. The EM algorithm is then applied to build the classifier. The key issue of the approach is how to obtain a set of representative words for each class. One way is to ask the user to provide them, which is difficult because the user usually can only give a few words (which are insufficient for accurate learning). We propose a method to solve the problem. It combines clustering and feature selection. The technique can effectively rank the words in the unlabeled set according to their importance. The user then selects/labels some words from the ranked list for each class. This process requires less effort than providing words with no help or manual labelillg of documents. Our results show that the new method is highly effective and promising.

#index 1250237
#* Mining opinion features in customer reviews
#@ 3558 2438
#t 2004
#c AAAI'04 Proceedings of the 19th national conference on Artifical intelligence
#% 71752
#% 78171
#% 194251
#% 279755
#% 481290
#% 577355
#% 741106
#% 855043
#% 1478826
#! It is a common practice that merchants selling products on the Web ask their customers to review the products and associated services. As e-commerce is becoming more and more popular, the number of customer reviews that a product receives grows rapidly. For a popular product, the number of reviews can be in hundreds. This makes it difficult for a potential customer to read them in order to make a decision on whether to buy the product. In this project, we aim to summarize all the customer reviews of a product. This summarization task is different from traditional text summarization because we are only interested in the specific features of the product that customers have opinions on and also whether the opinions are positive or negative. We do not summarize the reviews by selecting or rewriting a subset of the original sentences from the reviews to capture their main points as in the classic text summarization. In this paper, we only focus on mining opinion/product features that the reviewers have commented on. A number of techniques are presented to mine such features. Our experimental results show that these techniques are highly effective.

#index 1250367
#* Mining comparative sentences and relations
#@ 15955 2438
#t 2006
#c AAAI'06 proceedings of the 21st national conference on Artificial intelligence - Volume 2
#% 269217
#% 463903
#% 464434
#% 577246
#% 577355
#% 727877
#% 742368
#% 756207
#% 769892
#% 815915
#% 828958
#% 829971
#% 854646
#% 855279
#% 855282
#% 879595
#% 939848
#% 939896
#% 1250238
#! This paper studies a text mining problem, comparative sentence mining (CSM). A comparative sentence expresses an ordering relation between two sets of entities with respect to some common features. For example, the comparative sentence "Canon's optics are better than those of Sony and Nikon" expresses the comparative relation: (better, {optics}, {Canon}, {Sony, Nikon}). Given a set of evaluative texts on the Web, e.g., reviews, forum postings, and news articles, the task of comparative sentence mining is (1) to identify comparative sentences from the texts and (2) to extract comparative relations from the identified comparative sentences. This problem has many applications. For example, a product manufacturer wants to know customer opinions of its products in comparison with those of its competitors. In this paper, we propose two novel techniques based on two new types of sequential rules to perform the tasks. Experimental evaluation has been conducted using different types of evaluative texts from the Web. Results show that our techniques are very promising.

#index 1250423
#* Opinion extraction and summarization on the web
#@ 3558 2438
#t 2006
#c AAAI'06 proceedings of the 21st national conference on Artificial intelligence - Volume 2
#% 71752
#% 118040
#% 180254
#% 577246
#% 577355
#% 727877
#% 741106
#% 769892
#% 805873
#% 815915
#% 828958
#% 829971
#% 854646
#% 855043
#% 855282
#% 939848
#% 939896
#% 939926
#% 1250238
#% 1269535
#% 1478826
#! We propose two new online methods for estimating the size of a backtracking search tree. The first method is based on a weighted sample of the branches visited by chronological backtracking. The second is a recursive method based on assuming that the ...

#index 1250439
#* Automatic wrapper generation using tree matching and partial tree alignment
#@ 10204 2438
#t 2006
#c AAAI'06 proceedings of the 21st national conference on Artificial intelligence - Volume 2
#% 91245
#% 271065
#% 273925
#% 275915
#% 312860
#% 330784
#% 348146
#% 424931
#% 480648
#% 480824
#% 488367
#% 577319
#% 654469
#% 660272
#% 729978
#% 765411
#% 805845
#% 805846
#% 805847
#! This paper is concerned with the problem of structured data extraction from Web pages. The objective of the research is to automatically segment data records in a page, extract data items/fields from these records and store the extracted data in a database. In this paper, we first introduce the extraction problem, and then discuss the main existing approaches and their limitations. After that, we introduce a novel technique (called DEPTA) to automatically perform Web data extraction. The method consists of three steps: (1) identifying data records with similar patterns in a page, (2) aligning and extracting data items from the identified data records and (3) generating tree-based regular expressions to facilitate later extraction from other similar pages. The key innovation is the proposal of a new multiple tree alignment algorithm called partial tree alignment, which was found to be particularly suitable for Web data extraction. This paper is based on our work published in KDD-03 and WWW-05.

#index 1271849
#* Discovering interesting holes in data
#@ 2438 26751 2439
#t 1997
#c IJCAI'97 Proceedings of the Fifteenth international joint conference on Artifical intelligence - Volume 2
#% 2115
#% 10131
#% 24538
#% 136350
#% 152934
#% 451038
#% 451042
#% 451052
#% 1499588
#! Current machine learning and discovery techniques focus on discovering rules or regularities that exist in data. An important aspect of the research that has been ignored in the past is the learning or discovering of interesting holes in the database. If we view each case in the database as a point in a it-dimensional space, then a hole is simply a region in the space that contains no data point. Clearly, not every hole is interesting. Some holes are obvious because it is known that certain value combinations are not possible. Some holes exist because there are insufficient cases in the database. However, in some situations, empty regions do carry important information. For instance, they could warn us about some missing value combinations that are either not known before or are unexpected. Knowing these missing value combinations may lead to significant discoveries. In this paper, we propose an algorithm to discover holes in databases.

#index 1275203
#* Learning to identify unexpected instances in the test set
#@ 20883 2438 16082
#t 2007
#c IJCAI'07 Proceedings of the 20th international joint conference on Artifical intelligence
#% 169717
#% 464641
#% 577235
#% 722811
#% 770821
#% 800568
#% 1279298
#! Traditional classification involves building a classifier using labeled training examples from a set of predefined classes and then applying the classifier to classify test instances into the same set of classes. In practice, this paradigm can be problematic because the test data may contain instances that do not belong to any of the previously defined classes. Detecting such unexpected instances in the test set is an important issue in practice. The problem can be formulated as learning from positive and unlabeled examples (PU learning). However, current PU learning algorithms require a large proportion of negative instances in the unlabeled set to be effective. This paper proposes a novel technique to solve this problem in the text classification domain. The technique first generates a single artificial negative document AN. The sets P and {AN} are then used to build a naïve Bayesian classifier. Our experiment results show that this method is significantly better than existing techniques.

#index 1279218
#* Web page cleaning for web mining through feature weighting
#@ 10139 2438
#t 2003
#c IJCAI'03 Proceedings of the 18th international joint conference on Artificial intelligence
#% 144012
#% 269217
#% 271060
#% 278106
#% 282905
#% 310546
#% 340919
#% 348180
#% 387427
#% 406493
#% 413617
#% 458379
#% 465754
#% 577281
#% 746910
#% 786504
#% 786553
#! Unlike conventional data or text, Web pages typically contain a large amount of information that is not part of the main contents of the pages, e.g., banner ads, navigation bars, and copyright notices. Such irrelevant information (which we call Web page noise) in Web pages can seriously harm Web mining, e.g., clustering and classification. In this paper, we propose a novel feature weighting technique to deal with Web page noise to enhance Web mining. This method first builds a compressed structure tree to capture the common structure and comparable blocks in a set of Web pages. It then uses an information based measure to evaluate the importance of each node in the compressed structure tree. Based on the tree and its node importance values, our method assigns a weight to each word feature in its content block. The resulting weights are used in Web mining. We evaluated the proposed technique with two Web mining tasks, Web page clustering and Web page classification. Experimental results show that our weighting method is able to dramatically improve the mining results.

#index 1279298
#* Learning to classify texts using positive and unlabeled data
#@ 5659 2438
#t 2003
#c IJCAI'03 Proceedings of the 18th international joint conference on Artificial intelligence
#% 169717
#% 169806
#% 190581
#% 252011
#% 264164
#% 269217
#% 280817
#% 311027
#% 406493
#% 464466
#% 464604
#% 464631
#% 464641
#% 466888
#% 577235
#! In traditional text classification, a classifier is built using labeled training documents of every class. This paper studies a different problem. Given a set P of documents of a particular class (called positive class) and a set U of unlabeled documents that contains documents from class P and also other types of documents (called negative class documents), we want to build a classifier to classify the documents in U into documents from P and documents not from P. The key feature of this problem is that there is no labeled negative document, which makes traditional text classification techniques inapplicable. In this paper, we propose an effective technique to solve the problem. It combines the Rocchio method and the SVM technique for classifier building. Experimental results show that the new method outperforms existing methods significantly.

#index 1305481
#* Expanding domain sentiment lexicon through double propagation
#@ 18432 2438 18434 17347
#t 2009
#c IJCAI'09 Proceedings of the 21st international jont conference on Artifical intelligence
#% 464434
#% 529193
#% 722308
#% 746885
#% 769892
#% 815915
#% 838521
#% 854646
#% 855282
#% 939348
#% 939848
#% 1261566
#% 1275184
#! In most sentiment analysis applications, the sentiment lexicon plays a key role. However, it is hard, if not impossible, to collect and maintain a universal sentiment lexicon for all application domains because different words may be used in different domains. The main existing technique extracts such sentiment words from a large domain corpus based on different conjunctions and the idea of sentiment coherency in a sentence. In this paper, we propose a novel propagation approach that exploits the relations between sentiment words and topics or product features that the sentiment words modify, and also sentiment words and product features themselves to extract new sentiment words. As the method propagates information through both sentiment words and features, we call it double propagation. The extraction rules are designed based on relations described in dependency trees. A new method is also proposed to assign polarities to newly discovered sentiment words in a domain. Experimental results show that our approach is able to extract a large number of new sentiment words. The polarity assignment method is also effective.

#index 1358066
#* Exploring user opinions in recommender systems
#@ 2438
#t 2008
#c Proceedings of the 2nd KDD Workshop on Large-Scale Recommender Systems and the Netflix Prize Competition
#! Traditionally, recommender systems operate based on user-behavior and rating data at the personal and/or aggregate level. In this talk, I will try to go beyond this tradition to discuss some new/future developments of recommender systems, even general advertising systems for that matter, based on opinions on the Web (e.g., in reviews, forum discussions, blogs, etc). Recommendations based on such data can be highly targeted and can also be embedded widely in the most appropriate context. Needless to say, I will introduce some recent developments in the area of opinion mining and sentiment analysis, and discuss whether these developments are ready for prime time.

#index 1476306
#* Using constraints to model disjunctions in rule-based reasoning
#@ 2438 2853
#t 1996
#c AAAI'96 Proceedings of the thirteenth national conference on Artificial intelligence - Volume 2
#% 3463
#% 35562
#% 56471
#% 118278
#% 126385
#% 131561
#% 406437
#% 520420
#% 1275303
#% 1275304
#! Rule-based systems have long been widely used for building expert systems to perform practical knowledge intensive tasks. One important issue that has not been addressed satisfactorily is the disjunction, and this significantly limits their problem solving power. In this paper, we show that some important types of disjunction can be modeled with Constraint Satisfaction Problem (CSP) techniques, employing their simple representation schemes and efficient algorithms. A key idea is that disjunctions are represented as constraint variables, relations among disjunctions are represented as constraints, and rule chaining is integrated with constraint solving. In this integration, a constraint variable or a constraint is regarded as a special fact, and rules can be written with constraints and information about constraints. Chaining of rules may trigger constraint propagation, and constraint propagation may cause firing of rules. A prototype system (called CFR) based on this idea has been implemented.

#index 1482272
#* Detecting product review spammers using rating behaviors
#@ 4337 28621 15955 2438 19711
#t 2010
#c CIKM '10 Proceedings of the 19th ACM international conference on Information and knowledge management
#% 309095
#% 314935
#% 769892
#% 838490
#% 939896
#% 956642
#% 1022742
#% 1035590
#% 1190069
#% 1227655
#% 1261574
#% 1355303
#% 1482375
#! This paper aims to detect users generating spam reviews or review spammers. We identify several characteristic behaviors of review spammers and model these behaviors so as to detect the spammers. In particular, we seek to model the following behaviors. First, spammers may target specific products or product groups in order to maximize their impact. Second, they tend to deviate from the other reviewers in their ratings of products. We propose scoring methods to measure the degree of spam for each reviewer and apply them on an Amazon review dataset. We then select a subset of highly suspicious reviewers for further scrutiny by our user evaluators with the help of a web based spammer evaluation software specially developed for user evaluation experiments. Our results show that our proposed ranking and supervised methods are effective in discovering spammers and outperform other baseline method based on helpfulness votes alone. We finally show that the detected spammers have more significant impact on ratings compared with the unhelpful reviewers.

#index 1482375
#* Finding unusual review patterns using unexpected rules
#@ 15955 2438 4337
#t 2010
#c CIKM '10 Proceedings of the 19th ACM international conference on Information and knowledge management
#% 136350
#% 869469
#% 869471
#% 907490
#% 1035590
#% 1482272
#! In recent years, opinion mining attracted a great deal of research attention. However, limited work has been done on detecting opinion spam (or fake reviews). The problem is analogous to spam in Web search [1, 9 11]. However, review spam is harder to detect because it is very hard, if not impossible, to recognize fake reviews by manually reading them [2]. This paper deals with a restricted problem, i.e., identifying unusual review patterns which can represent suspicious behaviors of reviewers. We formulate the problem as finding unexpected rules. The technique is domain independent. Using the technique, we analyzed an Amazon.com review dataset and found many unexpected rules and rule groups which indicate spam activities.

#index 1499588
#* Post-analysis of learned rules
#@ 2438 2439
#t 1996
#c AAAI'96 Proceedings of the thirteenth national conference on Artificial intelligence - Volume 1
#% 124708
#% 136350
#% 179008
#% 212710
#% 449566
#% 1290033
#! Rule induction research implicitly assumes that after producing the rules from a dataset, these rules will be used directly by an expert system or a human user. In real-life applications, the situation may not be as simple as that, particularly, when the user of the rules is a human being. The human user almost always has some previous concepts or knowledge about the domain represented by the dataset. Naturally, he/she wishes to know how the new rules compare with his/her existing knowledge. In dynamic domains where the rules may change over time, it is important to know what the changes are. These aspects of research have largely been ignored in the past. With the increasing use of machine leaming tcclmiques in practical applications such as data mining, this issue of post analysis of rules warrants greater emphasis and attention. In this paper, we propose a technique to deal with this problem. A system has been implemented to perform the post analysis of classification rules genemted by systems such as C4.5. The proposed technique is general and highly interactive. It will be particularly useful in data mining and data analysis.

#index 1603758
#* Constrained LDA for grouping product features in opinion mining
#@ 36004 2438 36005 36006
#t 2011
#c PAKDD'11 Proceedings of the 15th Pacific-Asia conference on Advances in knowledge discovery and data mining - Volume Part I
#% 464291
#% 722904
#% 769892
#% 805873
#% 828958
#% 1085668
#% 1211693
#% 1271481
#% 1292576
#% 1338553
#% 1484383
#! In opinion mining of product reviews, one often wants to produce a summary of opinions based on product features. However, for the same feature, people can express it with different words and phrases. To produce an effective summary, these words and phrases, which are domain synonyms, need to be grouped under the same feature. Topic modeling is a suitable method for the task. However, instead of simply letting topic modeling find groupings freely, we believe it is possible to do better by giving it some pre-existing knowledge in the form of automatically extracted constraints. In this paper, we first extend a popular topic modeling method, called Latent Dirichlet Allocation (LDA), with the ability to process large scale constraints. Then, two novel methods are proposed to extract two types of constraints automatically. Finally, the resulting constrained-LDA and the extracted constraints are applied to group product features. Experiments show that constrained-LDA outperforms the original LDA and the latest mLSA by a large margin.

#index 1663671
#* Discovering overlapping communities of named entities
#@ 12098 2438 850
#t 2006
#c PKDD'06 Proceedings of the 10th European conference on Principle and Practice of Knowledge Discovery in Databases
#% 268079
#% 282905
#% 343768
#% 438553
#% 504443
#% 578775
#% 756821
#% 811281
#% 938705
#% 1272053
#! Although community discovery based on social network analysis has been studied extensively in the Web hyperlink environment, limited research has been done in the case of named entities in text documents. The co-occurrence of entities in documents usually implies some connections among them. Investigating such connections can reveal important patterns. In this paper, we mine communities among named entities in Web documents and text corpus. Most existing works on community discovery generate a partition of the entity network, assuming each entity belongs to one community. However, in the scenario of named entities, an entity may participate in several communities. For example, a person is in the communities of his/her family, colleagues, and friends. In this paper, we propose a novel technique to mine overlapping communities of named entities. This technique is based on triangle formation, expansion, and clustering with content similarity. Our experimental results show that the proposed technique is highly effective.

#index 1674704
#* Proceedings of the 6th international conference on Knowledge Discovery on the Web: advances in Web Mining and Web Usage Analysis
#@ 9400 10102 2438 2449
#t 2004
#c WebKDD'04 Proceedings of the 6th international conference on Knowledge Discovery on the Web: advances in Web Mining and Web Usage Analysis

#index 1688551
#* Review Graph Based Online Store Review Spammer Detection
#@ 22224 22238 2438 850
#t 2011
#c ICDM '11 Proceedings of the 2011 IEEE 11th International Conference on Data Mining
#! Online reviews provide valuable information about products and services to consumers. However, spammers are joining the community trying to mislead readers by writing fake reviews. Previous attempts for spammer detection used reviewers' behaviors, text similarity, linguistics features and rating patterns. Those studies are able to identify certain types of spammers, e.g., those who post many similar reviews about one target entity. However, in reality, there are other kinds of spammers who can manipulate their behaviors to act just like genuine reviewers, and thus cannot be detected by the available techniques. In this paper, we propose a novel concept of a heterogeneous review graph to capture the relationships among reviewers, reviews and stores that the reviewers have reviewed. We explore how interactions between nodes in this graph can reveal the cause of spam and propose an iterative model to identify suspicious reviewers. This is the first time such intricate relationships have been identified for review spam detection. We also develop an effective computation method to quantify the trustiness of reviewers, the honesty of reviews, and the reliability of stores. Different from existing approaches, we don't use review text information. Our model is thus complementary to existing approaches and able to find more difficult and subtle spamming activities, which are agreed upon by human judges after they evaluate our results.

#index 1699593
#* Learning from positive and unlabeled examples with different data distributions
#@ 20883 2438
#t 2005
#c ECML'05 Proceedings of the 16th European conference on Machine Learning
#% 169717
#% 190581
#% 252011
#% 280817
#% 311027
#% 464604
#% 464631
#% 464641
#% 466888
#% 564957
#% 577235
#% 727829
#% 727883
#% 729927
#% 770821
#% 770858
#% 770870
#% 1279298
#! We study the problem of learning from positive and unlabeled examples. Although several techniques exist for dealing with this problem, they all assume that positive examples in the positive set P and the positive examples in the unlabeled set U are generated from the same distribution. This assumption may be violated in practice. For example, one wants to collect all printer pages from the Web. One can use the printer pages from one site as the set P of positive pages and use product pages from another site as U. One wants to classify the pages in U into printer pages and non-printer pages. Although printer pages from the two sites have many similarities, they can also be quite different because different sites often present similar products in different styles and have different focuses. In such cases, existing methods perform poorly. This paper proposes a novel technique A-EM to deal with the problem. Experiment results with product page classification demonstrate the effectiveness of the proposed technique.

#index 1710575
#* Hierarchical web-page clustering via in-page and cross-page link structures
#@ 22155 24022 961 2438
#t 2010
#c PAKDD'10 Proceedings of the 14th Pacific-Asia conference on Advances in Knowledge Discovery and Data Mining - Volume Part II
#% 262045
#% 279755
#% 282905
#% 413608
#% 481281
#% 607793
#% 827127
#% 907509
#% 989654
#% 1090774
#% 1100188
#% 1275120
#% 1410607
#! Despite of the wide diversity of web-pages, web-pages residing in a particular organization, in most cases, are organized with semantically hierarchic structures For example, the website of a computer science department contains pages about its people, courses and research, among which pages of people are categorized into faculty, staff and students, and pages of research diversify into different areas Uncovering such hierarchic structures could supply users a convenient way of comprehensive navigation and accelerate other web mining tasks In this study, we extract a similarity matrix among pages via in-page and crosspage link structures, based on which a density-based clustering algorithm is developed, which hierarchically groups densely linked webpages into semantic clusters Our experiments show that this method is efficient and effective, and sheds light on mining and exploring web structures.

#index 1872332
#* Mining contentions from discussions and debates
#@ 41764 2438
#t 2012
#c Proceedings of the 18th ACM SIGKDD international conference on Knowledge discovery and data mining
#% 458379
#% 577356
#% 722904
#% 788094
#% 876067
#% 938737
#% 956510
#% 989621
#% 1055681
#% 1055682
#% 1083684
#% 1117083
#% 1127964
#% 1211693
#% 1211773
#% 1261563
#% 1264719
#% 1264771
#% 1292503
#% 1310458
#% 1328328
#% 1338553
#% 1425621
#% 1450945
#% 1481541
#% 1535392
#% 1536586
#% 1544065
#% 1544104
#% 1591964
#% 1591967
#% 1592079
#% 1650298
#% 1732740
#! Social media has become a major source of information for many applications. Numerous techniques have been proposed to analyze network structures and text contents. In this paper, we focus on fine-grained mining of contentions in discussion/debate forums. Contentions are perhaps the most important feature of forums that discuss social, political and religious issues. Our goal is to discover contention and agreement indicator expressions, and contention points or topics both at the discussion collection level and also at each individual post level. To the best of our knowledge, limited work has been done on such detailed analysis. This paper proposes three models to solve the problem, which not only model both contention/agreement expressions and discussion topics, but also, more importantly, model the intrinsic nature of discussions/debates, i.e., interactions among discussants or debaters and topic sharing among posts through quoting and replying relations. Evaluation results using real-life discussion/debate posts from several domains demonstrate the effectiveness of the proposed models.

